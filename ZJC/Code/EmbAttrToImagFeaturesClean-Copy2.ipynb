{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications import resnet50, vgg16\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from keras.regularizers import l1, l2\n",
    "# from skimage.io import imread\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "path = '../Data/'\n",
    "\n",
    "# class_emb = pd.read_csv(path + '/DatasetA_train_20180813/class_wordembeddings.txt', \n",
    "#                         index_col = 0, sep = ' ', header = None)\n",
    "# class_emb.index.name = 'class_name'\n",
    "# # class_emb_vec = pd.DataFrame(index = class_emb.index)\n",
    "# class_emb = class_emb.apply(lambda s: np.array([float(x) for x in s]), axis = 1)\n",
    "\n",
    "# class_id_to_name = pd.read_csv(path + '/DatasetA_train_20180813/label_list.txt', \n",
    "#                                index_col = 'class_name', sep = '\\t', header = None, names = ['class_id', 'class_name'])\n",
    "\n",
    "# attr_list = pd.read_csv(path + '/DatasetA_train_20180813/attribute_list.txt', index_col = 0, sep = '\\t', header = None)\n",
    "\n",
    "# attributes_per_class = pd.read_csv(path + '/DatasetA_train_20180813/attributes_per_class.txt', \n",
    "#                                    index_col = 0, sep = '\\t', header = None)\n",
    "# attributes_per_class.index.name = 'class_id'\n",
    "# attributes_per_class = attributes_per_class.apply(lambda s: np.array([float(x) for x in s]), axis = 1)\n",
    "\n",
    "# class_id_emb_attr = class_id_to_name.copy()\n",
    "# class_id_emb_attr['emb'] = class_emb\n",
    "# class_id_emb_attr.reset_index(inplace = True)\n",
    "# class_id_emb_attr.set_index('class_id', inplace = True)\n",
    "# class_id_emb_attr['attr'] = attributes_per_class\n",
    "\n",
    "# with open(path + 'class_id_emb_attr.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(class_id_emb_attr, handle)\n",
    "def read_image(imag_path, image_id):\n",
    "    img = image.load_img(imag_path + image_id)\n",
    "    img = image.img_to_array(img)\n",
    "#     img= vgg16.preprocess_input(image.img_to_array(img))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(path + '/DatasetA_train_20180813/train.txt', index_col = 'class_id', \n",
    "#                          sep = '\\t', header = None, names = ['image_id', 'class_id'])\n",
    "# train_data = train_data.merge(class_id_emb_attr, how = 'left', on = 'class_id')\n",
    "\n",
    "# imag_path = path + r'/DatasetA_train_20180813/train/'\n",
    "\n",
    "# train_data['img'] = train_data['image_id'].apply(lambda id: read_image(id))\n",
    "\n",
    "# train_data.reset_index(inplace = True)\n",
    "with open(path + 'class_id_emb_attr.pickle', 'rb') as handle:\n",
    "    class_id_emb_attr = pickle.load(handle)\n",
    "class_id_emb_attr.reset_index(inplace = True)    \n",
    "with open(path + 'train_img.pickle', 'rb') as handle:\n",
    "    train_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>emb</th>\n",
       "      <th>attr</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>7d93ef45972154aae150b4f9980a79c0.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_id                               image_id class_name  \\\n",
       "0     ZJL1  a6394b0f513290f4651cc46792e5ac86.jpeg   goldfish   \n",
       "1     ZJL1  2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg   goldfish   \n",
       "2     ZJL1  eda9f3bef2bd8da038f6acbc8355fc25.jpeg   goldfish   \n",
       "3     ZJL1  7d93ef45972154aae150b4f9980a79c0.jpeg   goldfish   \n",
       "4     ZJL1  fb901b4f9a8e396c1d0155bccc5e5671.jpeg   goldfish   \n",
       "\n",
       "                                                 emb  \\\n",
       "0  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "1  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "2  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "3  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "4  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "\n",
       "                                                attr  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "\n",
       "                                                 img  \n",
       "0  [[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...  \n",
       "1  [[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...  \n",
       "2  [[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....  \n",
       "3  [[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....  \n",
       "4  [[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imread(path + '/DatasetA_train_20180813/train/a6394b0f513290f4651cc46792e5ac86.jpeg').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = train_data['class_id'].unique()\n",
    "category_dict = dict((category[i], i) for i in range(category.shape[0]))\n",
    "\n",
    "# vgg_model = vgg16.VGG16(include_top=True, weights = None, input_shape=(64, 64, 3), classes = train_data['class_id'].unique().shape[0])\n",
    "\n",
    "\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_y = pickle.load(handle)\n",
    "\n",
    "# input = Input(shape = (2048, ))\n",
    "# dense = Dense(2048, activation=\"relu\")(input)\n",
    "# dense = Dropout(0.5)(dense)\n",
    "# dense = Dense(2048, activation=\"relu\")(input)\n",
    "# dense = Dense(1024, activation=\"relu\")(input)\n",
    "# dense = Dense(category.shape[0], activation=\"softmax\")(input)\n",
    "\n",
    "# vgg_model = Model(input, dense)\n",
    "\n",
    "# vgg_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "# print (vgg_model.summary())\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "# train_data['target'] = list(train_image_feature_map)\n",
    "\n",
    "def small_vgg(img_input_shape, classes):\n",
    "    # Block 1\n",
    "    img_input = Input(shape = (img_input_shape))\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "#     # Block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "#     # Block 3\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    \n",
    "#     # Block 4\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    \n",
    "#     # Block 5\n",
    "#     x = layers.Conv2D(256, (3, 3),\n",
    "#                       activation='relu',\n",
    "#                       padding='same',\n",
    "#                       name='block5_conv1')(x)\n",
    "#     x = layers.Conv2D(256, (3, 3),\n",
    "#                       activation='relu',\n",
    "#                       padding='same',\n",
    "#                       name='block5_conv2')(x)\n",
    "#     x = layers.Conv2D(256, (3, 3),\n",
    "#                       activation='relu',\n",
    "#                       padding='same',\n",
    "#                       name='block5_conv3')(x)\n",
    "#     x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    # Classification block\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "#     x = layers.Dense(1024, activation='relu', name='fc1')(x)\n",
    "#     x = layers.Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    model = Model(img_input, x)\n",
    "    print (model.summary())\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def dense_block(x, blocks, name):\n",
    "    \"\"\"A dense block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        blocks: integer, the number of building blocks.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
    "    return x\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    \"\"\"A transition block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        reduction: float, compression rate at transition layers.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                name=name + '_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_relu')(x)\n",
    "    x = layers.Conv2D(int(K.int_shape(x)[bn_axis] * reduction), 1,\n",
    "                    use_bias=False,\n",
    "                    name=name + '_conv')(x)\n",
    "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(x, growth_rate, name, dropout_rate = None):\n",
    "    \"\"\"A building block for a dense block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        growth_rate: float, growth rate at dense layers.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "    x1 = layers.BatchNormalization(axis=bn_axis,\n",
    "                                epsilon=1.001e-5,\n",
    "                                name=name + '_0_bn')(x)\n",
    "    x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n",
    "    x1 = layers.Conv2D(4 * growth_rate, 1,\n",
    "                    use_bias=False,\n",
    "                    name=name + '_1_conv')(x1)\n",
    "    x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                name=name + '_1_bn')(x1)\n",
    "    x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n",
    "    x1 = layers.Conv2D(growth_rate, 3,\n",
    "                    padding='same',\n",
    "                    use_bias=False,\n",
    "                    name=name + '_2_conv')(x1)\n",
    "    if dropout_rate:\n",
    "            x1 = Dropout(dropout_rate)(x1)\n",
    "    x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n",
    "    return x\n",
    "    \n",
    "def small_densenet(img_input_shape, classes, blocks = [6, 12, 24, 16]):\n",
    "    img_input = Input(shape = (img_input_shape))\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=3, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "    \n",
    "    x = dense_block(x, blocks[0], name='conv2')\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "    x = dense_block(x, blocks[1], name='conv3')\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "    x = dense_block(x, blocks[2], name='conv4')\n",
    "    x = transition_block(x, 0.5, name='pool4')\n",
    "    x = dense_block(x, blocks[3], name='conv5')\n",
    "    \n",
    "    x = layers.BatchNormalization(\n",
    "        axis=3, epsilon=1.001e-5, name='bn')(x)\n",
    "    x = layers.Activation('relu', name='relu')(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='fc')(x)\n",
    "    \n",
    "    model = Model(img_input, x)\n",
    "    print (model.summary())\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "train_img = extract_array_from_series(train_data['img'])\n",
    "train_img = vgg16.preprocess_input(train_img)\n",
    "OneHotEncoder = sklearn.preprocessing.OneHotEncoder()\n",
    "train_target = train_data['class_id'].apply(lambda id: category_dict[id]).values\n",
    "train_target = OneHotEncoder.fit_transform(np.reshape(train_target, (-1, 1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c2481948a47c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     train_image_feature_map = pickle.load(handle)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_part_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvalidate_part_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_img' is not defined"
     ]
    }
   ],
   "source": [
    "fold = 5\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "num_fold = 0\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "\n",
    "for train_index, test_index in kf.split(train_img):\n",
    "    train_part_img = train_img[train_index]\n",
    "    validate_part_img = train_img[test_index]\n",
    "    \n",
    "    train_part_target = train_target[train_index]\n",
    "    validate_part_target = train_target[test_index]\n",
    "    \n",
    "    print ('Train target nunique: ', np.unique(np.argwhere(train_part_target == 1)[:, 1]).shape[0], \n",
    "           'Validate target nuique: ', np.unique(np.argwhere(validate_part_target == 1)[:, 1]).shape[0])\n",
    "#     model = vgg16.VGG16(include_top=True, weights = None, input_shape=(64, 64, 3), classes = category.shape[0])\n",
    "#     model = resnet50.ResNet50(include_top=True, weights = None, input_shape=(224, 224, 3), classes = category.shape[0])\n",
    "#     print (model.summary())\n",
    "#     model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "    img_model = small_densenet(blocks = [6, 12, 24, 16], img_input_shape=(64, 64, 3), classes = train_target.shape[1]) \n",
    "#     print (img_model.summary())\n",
    "    # img_model = small_vgg(img_input_shape = (64, 64, 3), classes = train_target.shape[1])\n",
    "    h = img_model.fit(train_part_img, train_part_target, validation_data=(validate_part_img, validate_part_target), \n",
    "                  epochs=100, batch_size = 256, shuffle=True, verbose = 1, \n",
    "                  callbacks=[EarlyStopping(monitor='val_categorical_accuracy', patience=15, verbose=0)])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38221, 64, 64, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(h.history)\n",
    "# df = df.append(df)\n",
    "# df.groupby(df.index).agg({'mean', 'max', 'median'})\n",
    "# h.epoch\n",
    "# x = pd.DataFrame()\n",
    "# x.append(df)\n",
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n03598930', 'jigsaw_puzzle', 0.023861792), ('n02095314', 'wire-haired_fox_terrier', 0.022931756), ('n04589890', 'window_screen', 0.021361042)]\n"
     ]
    }
   ],
   "source": [
    "# np.asarray(list(train_data['img'])).shape\n",
    "# train_data[train_data['class_id'] == 'ZJL1']\n",
    "# train_data['class_id'].value_counts().hist()\n",
    "# train_data.head()\n",
    "# class_id_emb_attr.iloc[0].name\n",
    "# resnet50_model = ResNet50(weights='imagenet', input_shape=(224, 224, 3))\n",
    "img = image.load_img(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg', target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = vgg16.preprocess_input(img)\n",
    "preds = vgg_model.predict(np.expand_dims(img, axis=0))\n",
    "print('Predicted:', vgg16.decode_predictions(preds, top=3)[0])\n",
    "# imread(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg')\n",
    "# image.img_to_array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_array_from_series(s):\n",
    "    return np.asarray(list(s))\n",
    "    \n",
    "def create_dnn_data(df):\n",
    "    return [extract_array_from_series(df['attr']), extract_array_from_series(df['emb'])]\n",
    "            \n",
    "def lgbm_train(train_part, train_part_label, valide_part, valide_part_label, fold_seed,\n",
    "        fold = 5, train_weight = None, valide_weight = None, flags = None):\n",
    "    \"\"\"\n",
    "    LGBM Training\n",
    "    \"\"\"\n",
    "    print(\"-----LGBM training-----\")\n",
    "\n",
    "    d_train = lgb.Dataset(train_part, train_part_label) #, categorical_feature = CATEGORY_FEATURES) #, init_score = train_part[:, -1])\n",
    "    d_valide = lgb.Dataset(valide_part, valide_part_label) #, categorical_feature = CATEGORY_FEATURES) #, init_score = valide_part[:, -1])\n",
    "    params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt', #'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            # 'num_leaves':-1,\n",
    "            'min_sum_hessian_in_leaf':None,\n",
    "            'max_depth':7,\n",
    "            'learning_rate':0.005,\n",
    "            'feature_fraction':0.1,\n",
    "            'verbose':-1,\n",
    "            'num_boost_round':3000,\n",
    "            'drop_rate':None,\n",
    "            'bagging_fraction':0.6,\n",
    "            'bagging_freq':5,\n",
    "            'early_stopping_round':100,\n",
    "            # 'min_data_in_leaf':100,\n",
    "            'max_bin': None,\n",
    "            'scale_pos_weight':None,\n",
    "        }\n",
    "    print (\"lightgbm params: {0}\\n\".format(params))\n",
    "\n",
    "    bst = lgb.train(\n",
    "                    params ,\n",
    "                    d_train,\n",
    "                    verbose_eval = 200,\n",
    "                    valid_sets = [d_train, d_valide],\n",
    "                    # feature_name= keras_train.DENSE_FEATURE_LIST,\n",
    "                    #feval = gini_lgbm\n",
    "                    #num_boost_round = 1\n",
    "                    )\n",
    "    #pred = model_eval(bst, 'l', valide_part)\n",
    "    #print(pred[:10])\n",
    "    #print(valide_part_label[:10])\n",
    "    #print(valide_part[:10, -1])\n",
    "    # exit(0)\n",
    "    feature_imp = bst.feature_importance(importance_type = 'gain')\n",
    "    sort_ind = np.argsort(feature_imp)[::-1]\n",
    "    print (np.c_[np.array(FEATURE_LIST)[sort_ind], feature_imp[sort_ind]][:10])\n",
    "    # print (np.array(keras_train.FEATURE_LIST)[np.argsort(feature_imp)])\n",
    "    # exit(0)\n",
    "    # cv_result = lgb.cv(params, d_train, nfold=fold) #, feval = gini_lgbm)\n",
    "    # pd.DataFrame(cv_result).to_csv('cv_result', index = False)\n",
    "    # exit(0)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_y = pickle.load(handle)\n",
    "# img_model_flat = Model(input = img_model.input, output = img_model.get_layer(name = 'avg_pool').output)\n",
    "# train_data['target'] = list(train_y) #\n",
    "# train_data['target'] = list(img_model_flat.predict(train_img, verbose = 1))\n",
    "img_model_flat = pd.read_csv(path + '/model_sub/6_12_24_16_03274/sub_2018_09_07_20_58_46.csv')\n",
    "\n",
    "img_model_flat.set_index('image_id', inplace = True)\n",
    "train_data['target'] = img_model_flat.apply(lambda s: np.asarray(s.astype(float)), axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a6394b0f513290f4651cc46792e5ac86.jpeg</th>\n",
       "      <td>0.222450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102360</td>\n",
       "      <td>0.410408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619550</td>\n",
       "      <td>0.469335</td>\n",
       "      <td>0.808152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638106</td>\n",
       "      <td>1.262975</td>\n",
       "      <td>0.716701</td>\n",
       "      <td>0.649398</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>2.584138</td>\n",
       "      <td>0.299704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775807</td>\n",
       "      <td>0.657141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513933</td>\n",
       "      <td>0.727034</td>\n",
       "      <td>0.205590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634150</td>\n",
       "      <td>0.386227</td>\n",
       "      <td>1.307551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289387</td>\n",
       "      <td>1.043166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.390443</td>\n",
       "      <td>0.291443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.544563</td>\n",
       "      <td>0.258394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</th>\n",
       "      <td>0.192894</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>0.642721</td>\n",
       "      <td>0.485429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463746</td>\n",
       "      <td>0.188616</td>\n",
       "      <td>0.250049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681179</td>\n",
       "      <td>2.148037</td>\n",
       "      <td>0.335496</td>\n",
       "      <td>0.230386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.919400</td>\n",
       "      <td>0.227866</td>\n",
       "      <td>0.139630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d93ef45972154aae150b4f9980a79c0.jpeg</th>\n",
       "      <td>0.518664</td>\n",
       "      <td>0.570357</td>\n",
       "      <td>0.081985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470126</td>\n",
       "      <td>0.712403</td>\n",
       "      <td>0.132547</td>\n",
       "      <td>0.683170</td>\n",
       "      <td>0.231919</td>\n",
       "      <td>0.490414</td>\n",
       "      <td>...</td>\n",
       "      <td>1.055093</td>\n",
       "      <td>0.289770</td>\n",
       "      <td>1.330755</td>\n",
       "      <td>0.931580</td>\n",
       "      <td>0.007386</td>\n",
       "      <td>2.596373</td>\n",
       "      <td>0.145607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</th>\n",
       "      <td>0.580390</td>\n",
       "      <td>0.293492</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>0.231948</td>\n",
       "      <td>0.214693</td>\n",
       "      <td>0.486738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269853</td>\n",
       "      <td>0.458110</td>\n",
       "      <td>0.080292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059787</td>\n",
       "      <td>1.077016</td>\n",
       "      <td>0.858712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0         1         2         3  \\\n",
       "image_id                                                                        \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  0.222450  0.000000  0.000000  0.000000   \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  0.000000  0.092368  0.000000  0.513933   \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  0.192894  0.106830  0.000000  0.031785   \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  0.518664  0.570357  0.081985  0.000000   \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.580390  0.293492  0.007867  0.231948   \n",
       "\n",
       "                                              4         5         6         7  \\\n",
       "image_id                                                                        \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  0.102360  0.410408  0.000000  0.619550   \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  0.727034  0.205590  0.000000  0.634150   \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  0.642721  0.485429  0.000000  0.463746   \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  0.470126  0.712403  0.132547  0.683170   \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.214693  0.486738  0.000000  0.000000   \n",
       "\n",
       "                                              8         9    ...         1014  \\\n",
       "image_id                                                     ...                \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  0.469335  0.808152    ...     0.638106   \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  0.386227  1.307551    ...     0.289387   \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  0.188616  0.250049    ...     0.681179   \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  0.231919  0.490414    ...     1.055093   \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.000000  0.163543    ...     0.000000   \n",
       "\n",
       "                                           1015      1016      1017      1018  \\\n",
       "image_id                                                                        \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  1.262975  0.716701  0.649398  0.024636   \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  1.043166  0.000000  0.270949  0.000000   \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  2.148037  0.335496  0.230386  0.000000   \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  0.289770  1.330755  0.931580  0.007386   \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.269853  0.458110  0.080292  0.000000   \n",
       "\n",
       "                                           1019      1020      1021      1022  \\\n",
       "image_id                                                                        \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  2.584138  0.299704  0.000000  0.775807   \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  1.390443  0.291443  0.000000  1.544563   \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  1.919400  0.227866  0.139630  0.000000   \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  2.596373  0.145607  0.000000  0.296896   \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.149054  0.000000  0.059787  1.077016   \n",
       "\n",
       "                                           1023  \n",
       "image_id                                         \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  0.657141  \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  0.258394  \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  0.529273  \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  0.000000  \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.858712  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_model_flat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>emb</th>\n",
       "      <th>attr</th>\n",
       "      <th>img</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...</td>\n",
       "      <td>[1.5649712, 0.22537939999999998, 0.0, 0.511434...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...</td>\n",
       "      <td>[0.95975924, 0.31657952, 0.005624798, 0.542549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....</td>\n",
       "      <td>[0.73883903, 0.08649281, 0.12541012, 0.1657913...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>7d93ef45972154aae150b4f9980a79c0.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....</td>\n",
       "      <td>[0.97788334, 0.741634, 0.28850228, 0.12216809,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...</td>\n",
       "      <td>[0.6483536999999999, 0.4635263, 0.4247312, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_id                               image_id class_name  \\\n",
       "0     ZJL1  a6394b0f513290f4651cc46792e5ac86.jpeg   goldfish   \n",
       "1     ZJL1  2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg   goldfish   \n",
       "2     ZJL1  eda9f3bef2bd8da038f6acbc8355fc25.jpeg   goldfish   \n",
       "3     ZJL1  7d93ef45972154aae150b4f9980a79c0.jpeg   goldfish   \n",
       "4     ZJL1  fb901b4f9a8e396c1d0155bccc5e5671.jpeg   goldfish   \n",
       "\n",
       "                                                 emb  \\\n",
       "0  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "1  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "2  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "3  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "4  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "\n",
       "                                                attr  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "\n",
       "                                                 img  \\\n",
       "0  [[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...   \n",
       "1  [[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...   \n",
       "2  [[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....   \n",
       "3  [[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....   \n",
       "4  [[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...   \n",
       "\n",
       "                                              target  \n",
       "0  [1.5649712, 0.22537939999999998, 0.0, 0.511434...  \n",
       "1  [0.95975924, 0.31657952, 0.005624798, 0.542549...  \n",
       "2  [0.73883903, 0.08649281, 0.12541012, 0.1657913...  \n",
       "3  [0.97788334, 0.741634, 0.28850228, 0.12216809,...  \n",
       "4  [0.6483536999999999, 0.4635263, 0.4247312, 0.0...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 th train :-)\n",
      "Train size: 30583 Valide size: 7638\n",
      "Train category: 152 Valide category: 38\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attr (InputLayer)               (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wv (InputLayer)                 (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 256)          7680        attr[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 556)          0           wv[0][0]                         \n",
      "                                                                 dense_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 556)          2224        concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_157 (Dense)               (None, 1536)         855552      batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 1536)         6144        dense_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 1024)         1573888     batch_normalization_124[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 2,445,488\n",
      "Trainable params: 2,441,304\n",
      "Non-trainable params: 4,184\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 30583 samples, validate on 7638 samples\n",
      "Epoch 1/50\n",
      "30583/30583 [==============================] - 11s 374us/step - loss: 0.7970 - val_loss: 0.4416\n",
      "\n",
      " Accuracy epoch: 1 - score: 0.172296 \n",
      " 1316/7638\n",
      "Epoch 2/50\n",
      "30583/30583 [==============================] - 8s 276us/step - loss: 0.3570 - val_loss: 0.4042\n",
      "\n",
      " Accuracy epoch: 2 - score: 0.240639 \n",
      " 1838/7638\n",
      "Epoch 3/50\n",
      "30583/30583 [==============================] - 8s 273us/step - loss: 0.3359 - val_loss: 0.3957\n",
      "\n",
      " Accuracy epoch: 3 - score: 0.234355 \n",
      " 1790/7638\n",
      "Epoch 4/50\n",
      "30583/30583 [==============================] - 8s 277us/step - loss: 0.3259 - val_loss: 0.3875\n",
      "\n",
      " Accuracy epoch: 4 - score: 0.201362 \n",
      " 1538/7638\n",
      "Epoch 5/50\n",
      "30583/30583 [==============================] - 8s 276us/step - loss: 0.3182 - val_loss: 0.3818\n",
      "\n",
      " Accuracy epoch: 5 - score: 0.201362 \n",
      " 1538/7638\n",
      "Epoch 6/50\n",
      "30583/30583 [==============================] - 9s 279us/step - loss: 0.3122 - val_loss: 0.3770\n",
      "\n",
      " Accuracy epoch: 6 - score: 0.239592 \n",
      " 1830/7638\n",
      "Epoch 7/50\n",
      "30583/30583 [==============================] - 8s 278us/step - loss: 0.3073 - val_loss: 0.3748\n",
      "\n",
      " Accuracy epoch: 7 - score: 0.222964 \n",
      " 1703/7638\n",
      "Epoch 8/50\n",
      "30583/30583 [==============================] - 9s 278us/step - loss: 0.3036 - val_loss: 0.3732\n",
      "\n",
      " Accuracy epoch: 8 - score: 0.270621 \n",
      " 2067/7638\n",
      "Epoch 9/50\n",
      "30583/30583 [==============================] - 9s 282us/step - loss: 0.3011 - val_loss: 0.3713\n",
      "\n",
      " Accuracy epoch: 9 - score: 0.254517 \n",
      " 1944/7638\n",
      "Epoch 10/50\n",
      "30583/30583 [==============================] - 9s 279us/step - loss: 0.2989 - val_loss: 0.3699\n",
      "\n",
      " Accuracy epoch: 10 - score: 0.221393 \n",
      " 1691/7638\n",
      "Epoch 11/50\n",
      "30583/30583 [==============================] - 9s 280us/step - loss: 0.2970 - val_loss: 0.3715\n",
      "\n",
      " Accuracy epoch: 11 - score: 0.208432 \n",
      " 1592/7638\n",
      "Epoch 12/50\n",
      "30583/30583 [==============================] - 9s 279us/step - loss: 0.2962 - val_loss: 0.3684\n",
      "\n",
      " Accuracy epoch: 12 - score: 0.220869 \n",
      " 1687/7638\n",
      "Epoch 13/50\n",
      "30583/30583 [==============================] - 9s 281us/step - loss: 0.2952 - val_loss: 0.3698\n",
      "\n",
      " Accuracy epoch: 13 - score: 0.202540 \n",
      " 1547/7638\n",
      "Epoch 14/50\n",
      "30583/30583 [==============================] - 9s 281us/step - loss: 0.2942 - val_loss: 0.3691\n",
      "\n",
      " Accuracy epoch: 14 - score: 0.225844 \n",
      " 1725/7638\n",
      "Epoch 15/50\n",
      "30583/30583 [==============================] - 9s 289us/step - loss: 0.2935 - val_loss: 0.3706\n",
      "\n",
      " Accuracy epoch: 15 - score: 0.206730 \n",
      " 1579/7638\n"
     ]
    }
   ],
   "source": [
    "def find_nearest_class(class_id_emb_attr, model, eval_df, img_feature_map = None):\n",
    "    if img_feature_map is None:\n",
    "        img_feature_map = np.reshape(vgg_model.predict(np.asarray(list(eval_df['img'])), verbose = 1), (eval_img.shape[0], -1))\n",
    "    cand_feature_map = model.predict(create_dnn_data(class_id_emb_attr))\n",
    "    # img_feature_map = np.repeat(img_feature_map, [cand_feature_map.shape[0]] * img_feature_map.shape[0], axis = 0)\n",
    "    nearest_class_id = ['ZJL'] * eval_df.shape[0]\n",
    "    for i in range(img_feature_map.shape[0]):\n",
    "        img = img_feature_map[i]\n",
    "        dis = np.linalg.norm(img - cand_feature_map, axis = 1)\n",
    "        min_ind = np.where(dis == np.amin(dis))[0]\n",
    "        if len(min_ind) > 1:\n",
    "            print ('eval img id: ', eval_df.iloc[i]['class_id'], 'has multiple best candidates: ', len(min_ind), 'min val: ', np.amin(dis))\n",
    "#         print (i, img, class_id_emb_attr.iloc[min_ind[0]].name)\n",
    "        nearest_class_id[i] = class_id_emb_attr.iloc[min_ind[0]]['class_id']\n",
    "#     print (nearest_class_id)\n",
    "    return np.asarray(nearest_class_id)\n",
    "\n",
    "class AccuracyEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_interval = 1000000, verbose = 2, \\\n",
    "            scores = [], class_id_emb_attr = None, eval_df = None):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        # print(\"y_val shape:{0}\".format(self.y_val.shape))\n",
    "        self.batch_interval = batch_interval\n",
    "        self.verbose = verbose\n",
    "        self.scores = scores\n",
    "        self.class_id_emb_attr = class_id_emb_attr\n",
    "        self.eval_df = eval_df\n",
    "#         self.img_feature_map = self.y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "#             zs_model = Model(inputs = self.model.inputs[:2], outputs = self.model.outpus[0])\n",
    "            pred_nearest_class_id = find_nearest_class(self.class_id_emb_attr, self.model, self.eval_df, self.y_val)\n",
    "            true_class_id = self.eval_df['class_id'].values\n",
    "#             print (pred_nearest_class_id, \"\\n\", true_class_id)\n",
    "            right_num = np.sum(pred_nearest_class_id == true_class_id)\n",
    "            score = right_num / true_class_id.shape[0]\n",
    "            self.scores.append(\"epoch:{0} {1}\".format(epoch + 1, score))\n",
    "            print(\"\\n Accuracy epoch: %d - score: %.6f \\n %d/%d\" % (epoch+1, score, right_num, true_class_id.shape[0]))\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "        if(self.verbose >= 2) and (batch % self.batch_interval == 0):\n",
    "            # y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            # loss = metrics.log_loss(self.y_val, y_pred)\n",
    "            print(\"Hi! on_batch_end() , batch=\",batch,\",logs:\",logs)\n",
    "            # print(\"Valide size=\",y_pred.shape[0], \"  Valide loss=\",loss)\n",
    "\n",
    "def full_connect_layer(input, hidden_dim):\n",
    "    full_connect = input\n",
    "    for hn in hidden_dim:\n",
    "        fc_in = full_connect\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#         full_connect = Dropout(0.2)(full_connect)\n",
    "        full_connect = BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "        # full_connect = Dense(hn, kernel_regularizer = l2(0.001), activity_regularizer = l1(0.001))(full_connect)\n",
    "#         full_connect = Concatenate()([Dense(hn, kernel_initializer='lecun_uniform', activation = 'relu')(full_connect), \n",
    "#             Dense(hn, kernel_initializer='lecun_uniform', activation = 'sigmoid')(full_connect)])\n",
    "        full_connect = Dense(hn, kernel_initializer='he_normal', activation = 'relu', kernel_regularizer = l2(0.001))(full_connect)\n",
    "        # full_connect = self.act_blend(full_connect)\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#             full_connect = Dropout(self.full_connect_dropout)(full_connect) #Dropout(self.full_connect_dropout)(full_connect)\n",
    "#         full_connect = Concatenate()([fc_in, full_connect])\n",
    "    return full_connect\n",
    "\n",
    "def create_dnn():\n",
    "    alpha = 0.03\n",
    "    attr_input = Input(shape = (30,), name = 'attr')\n",
    "    word_emb = Input(shape = (300,), name = 'wv')\n",
    "    imag_classifier = Input(shape = (1024,), name = 'img')\n",
    "\n",
    "    attr_dense = Dense(256, use_bias = False, kernel_initializer='he_normal', kernel_regularizer = l2(0.001))(attr_input)\n",
    "#     attr_dense = Dense(512)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(256)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(300, activation=\"relu\")(attr_dense)\n",
    "    # attr_dense = Dense(512, activation=\"relu\")(attr_dense)\n",
    "\n",
    "    attr_word_emb = Concatenate()([word_emb, attr_dense])\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb, hidden_dim = [1024 + 512])\n",
    "    \n",
    "#     attr_word_emb_dense = Concatenate()([attr_word_emb_dense, attr_word_emb])\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb_dense, hidden_dim = [1024])\n",
    "#     attr_word_emb_dense = Dense(1024, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = attr_word_emb\n",
    "#     attr_word_emb_dense = Dense(4096, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(1024)(attr_word_emb)\n",
    "\n",
    "    model = Model([attr_input, word_emb], outputs = attr_word_emb_dense) #, vgg_output])\n",
    "    # model.add_loss(mse_loss)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "def create_siae():\n",
    "    alpha = 0.03\n",
    "    gamma = 0.01\n",
    "    attr_input = Input(shape = (30,))\n",
    "    word_emb = Input(shape = (300,))\n",
    "    imag_classifier = Input(shape = (1024,))\n",
    "\n",
    "    attr_dense = Dense(32, use_bias = False)(attr_input)\n",
    "#     attr_dense = Dense(512)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(256)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(300, activation=\"relu\")(attr_dense)\n",
    "    # attr_dense = Dense(512, activation=\"relu\")(attr_dense)\n",
    "\n",
    "    attr_word_emb = Concatenate()([word_emb, attr_dense])\n",
    "    \n",
    "    img_from_attr_w2v = full_connect_layer(attr_word_emb, hidden_dim = [1024, 1024, 1024, 1024])\n",
    "    attr_w2v_from_img = full_connect_layer(img_from_attr_w2v, hidden_dim = [512, 512, 512, 332])\n",
    "#     attr_word_emb_dense = Dense(1024, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = attr_word_emb\n",
    "#     attr_word_emb_dense = Dense(4096, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(1024)(attr_word_emb)\n",
    "    \n",
    "    mse_loss = keras.losses.mean_squared_error(imag_classifier, img_from_attr_w2v) + \\\n",
    "        gamma * keras.losses.mean_squared_error(attr_word_emb, attr_w2v_from_img)\n",
    "    model = Model([attr_input, word_emb, imag_classifier], outputs = [img_from_attr_w2v, attr_w2v_from_img]) #, vgg_output])\n",
    "    model.add_loss(mse_loss)\n",
    "    model.compile(optimizer='adam', loss=None)\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "#data.loc[class_id] #data_atten.loc[n]\n",
    "fold = 5\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "num_fold = 0\n",
    "class_ids = train_data['class_id'].unique() #[:5]\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "\n",
    "for train_index, test_index in kf.split(class_ids):\n",
    "    train_part_id = class_ids[train_index]\n",
    "    validate_part_id = class_ids[test_index]\n",
    "    \n",
    "    train_part_df = train_data[train_data['class_id'].isin(train_part_id)]\n",
    "    validate_part_df = train_data[train_data['class_id'].isin(validate_part_id)]\n",
    "\n",
    "    train_part_data = create_dnn_data(train_part_df)\n",
    "    train_part_target = extract_array_from_series(train_part_df['target'])\n",
    "    \n",
    "    validate_part_data = create_dnn_data(validate_part_df)\n",
    "    validate_part_target = extract_array_from_series(validate_part_df['target'])\n",
    "    \n",
    "    print('fold: %d th train :-)' % (num_fold))\n",
    "    print('Train size: {} Valide size: {}'.format(train_part_df.shape[0], validate_part_df.shape[0]))\n",
    "    print('Train category: {} Valide category: {}'.format(train_part_id.shape[0], validate_part_id.shape[0]))\n",
    "\n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "            AccuracyEvaluation(validation_data=(validate_part_data,  validate_part_target), interval=1, \\\n",
    "                class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(validate_part_id)], eval_df = validate_part_df)\n",
    "            ]\n",
    "    \n",
    "    zs_model = create_dnn()\n",
    "    if num_fold == 0:\n",
    "        print (zs_model.summary())\n",
    "    zs_model.fit(train_part_data, train_part_target,  validation_data = (validate_part_data, validate_part_target),\n",
    "                  epochs=50, batch_size = 32, shuffle=True, verbose = 1, callbacks=callbacks)\n",
    "    break\n",
    "#     model = lgbm_train(train_part_data[0], train_part_target, validate_part_data[0], validate_part_target, num_fold, fold)\n",
    "    num_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_model.save(path + 'zs_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path + '/DatasetA_test_20180813/DatasetA_test/image.txt', header = None, names = ['img_id'])\n",
    "imag_path = path + '/DatasetA_test_20180813/DatasetA_test/test/'\n",
    "test_data['img'] = test_data['img_id'].apply(lambda id: read_image(imag_path, id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-40babdab7be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# def sub(imgs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmall_densenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_input_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'avg_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/model_sub/6_12_24_16_03274/model_0_2018_09_07_20_58_46.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-edc8ec0f9cea>\u001b[0m in \u001b[0;36msmall_densenet\u001b[0;34m(img_input_shape, classes, blocks)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m   3162\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m     \"\"\"\n\u001b[0;32m-> 3164\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "# def sub(imgs):\n",
    "img_model = small_densenet(blocks = [6, 12, 24, 16], img_input_shape=(64, 64, 3), classes = train_target.shape[1])\n",
    "img_model = Model(inputs = img_model.inputs, outputs = img_model.get_layer(name = 'avg_pool').output)\n",
    "img_model.load_weights(path + '/model_sub/6_12_24_16_03274/model_0_2018_09_07_20_58_46.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = extract_array_from_series(test_data['img'])\n",
    "test_img = vgg16.preprocess_input(test_img)\n",
    "test_img_feature_map = img_model.predict(test_img, verbose = 1)\n",
    "\n",
    "train_id = train_data['class_id'].unique()\n",
    "class_id_emb_attr.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)]\n",
    "pred_nearest_class_id = find_nearest_class(test_class_id_emb_attr, zs_model, test_data, test_img_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_label = time.strftime('_%Y_%m_%d_%H_%M_%S', time.gmtime())\n",
    "sub_name = path + '/model_sub/sub' + time_label + '.csv'\n",
    "sub = pd.DataFrame(pred_nearest_class_id, index = test_data['img_id'])\n",
    "sub.to_csv(sub_name, header = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ZJL219', 'ZJL217', 'ZJL217', ..., 'ZJL221', 'ZJL201', 'ZJL218'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nearest_class_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
