{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications import resnet50, vgg16\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from keras.regularizers import l1, l2\n",
    "# from skimage.io import imread\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "path = '../Data/'\n",
    "\n",
    "# class_emb = pd.read_csv(path + '/DatasetA_train_20180813/class_wordembeddings.txt', \n",
    "#                         index_col = 0, sep = ' ', header = None)\n",
    "# class_emb.index.name = 'class_name'\n",
    "# # class_emb_vec = pd.DataFrame(index = class_emb.index)\n",
    "# class_emb = class_emb.apply(lambda s: np.array([float(x) for x in s]), axis = 1)\n",
    "\n",
    "# class_id_to_name = pd.read_csv(path + '/DatasetA_train_20180813/label_list.txt', \n",
    "#                                index_col = 'class_name', sep = '\\t', header = None, names = ['class_id', 'class_name'])\n",
    "\n",
    "# attr_list = pd.read_csv(path + '/DatasetA_train_20180813/attribute_list.txt', index_col = 0, sep = '\\t', header = None)\n",
    "\n",
    "# attributes_per_class = pd.read_csv(path + '/DatasetA_train_20180813/attributes_per_class.txt', \n",
    "#                                    index_col = 0, sep = '\\t', header = None)\n",
    "# attributes_per_class.index.name = 'class_id'\n",
    "# attributes_per_class = attributes_per_class.apply(lambda s: np.array([float(x) for x in s]), axis = 1)\n",
    "\n",
    "# class_id_emb_attr = class_id_to_name.copy()\n",
    "# class_id_emb_attr['emb'] = class_emb\n",
    "# class_id_emb_attr.reset_index(inplace = True)\n",
    "# class_id_emb_attr.set_index('class_id', inplace = True)\n",
    "# class_id_emb_attr['attr'] = attributes_per_class\n",
    "\n",
    "# with open(path + 'class_id_emb_attr.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(class_id_emb_attr, handle)\n",
    "def read_image(imag_path, image_id):\n",
    "    img = image.load_img(imag_path + image_id)\n",
    "    img = image.img_to_array(img)\n",
    "#     img= vgg16.preprocess_input(image.img_to_array(img))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(path + '/DatasetA_train_20180813/train.txt', index_col = 'class_id', \n",
    "#                          sep = '\\t', header = None, names = ['image_id', 'class_id'])\n",
    "# train_data = train_data.merge(class_id_emb_attr, how = 'left', on = 'class_id')\n",
    "\n",
    "# imag_path = path + r'/DatasetA_train_20180813/train/'\n",
    "\n",
    "# train_data['img'] = train_data['image_id'].apply(lambda id: read_image(id))\n",
    "\n",
    "# train_data.reset_index(inplace = True)\n",
    "with open(path + 'class_id_emb_attr.pickle', 'rb') as handle:\n",
    "    class_id_emb_attr = pickle.load(handle)\n",
    "class_id_emb_attr.reset_index(inplace = True)    \n",
    "with open(path + 'train_img.pickle', 'rb') as handle:\n",
    "    train_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>emb</th>\n",
       "      <th>attr</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>7d93ef45972154aae150b4f9980a79c0.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_id                               image_id class_name  \\\n",
       "0     ZJL1  a6394b0f513290f4651cc46792e5ac86.jpeg   goldfish   \n",
       "1     ZJL1  2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg   goldfish   \n",
       "2     ZJL1  eda9f3bef2bd8da038f6acbc8355fc25.jpeg   goldfish   \n",
       "3     ZJL1  7d93ef45972154aae150b4f9980a79c0.jpeg   goldfish   \n",
       "4     ZJL1  fb901b4f9a8e396c1d0155bccc5e5671.jpeg   goldfish   \n",
       "\n",
       "                                                 emb  \\\n",
       "0  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "1  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "2  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "3  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "4  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "\n",
       "                                                attr  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "\n",
       "                                                 img  \n",
       "0  [[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...  \n",
       "1  [[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...  \n",
       "2  [[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....  \n",
       "3  [[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....  \n",
       "4  [[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imread(path + '/DatasetA_train_20180813/train/a6394b0f513290f4651cc46792e5ac86.jpeg').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = train_data['class_id'].unique()\n",
    "category_dict = dict((category[i], i) for i in range(category.shape[0]))\n",
    "\n",
    "# vgg_model = vgg16.VGG16(include_top=True, weights = None, input_shape=(64, 64, 3), classes = train_data['class_id'].unique().shape[0])\n",
    "\n",
    "\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_y = pickle.load(handle)\n",
    "\n",
    "# input = Input(shape = (2048, ))\n",
    "# dense = Dense(2048, activation=\"relu\")(input)\n",
    "# dense = Dropout(0.5)(dense)\n",
    "# dense = Dense(2048, activation=\"relu\")(input)\n",
    "# dense = Dense(1024, activation=\"relu\")(input)\n",
    "# dense = Dense(category.shape[0], activation=\"softmax\")(input)\n",
    "\n",
    "# vgg_model = Model(input, dense)\n",
    "\n",
    "# vgg_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "# print (vgg_model.summary())\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "# train_data['target'] = list(train_image_feature_map)\n",
    "\n",
    "class DenseNet:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, cat_max, blocks, weight_decay, kernel_initializer, reduction):\n",
    "        self.cat_max = cat_max\n",
    "        self.blocks = blocks\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.model = self.small_densenet(classes = self.cat_max, \n",
    "                                         blocks = self.blocks, \n",
    "                                         weight_decay = self.weight_decay, \n",
    "                                         kernel_initializer = self.kernel_initializer,\n",
    "                                         reduction = reduction)\n",
    "\n",
    "    def dense_block(self, x, blocks, name, weight_decay = 1e-4, kernel_initializer = 'he_normal'):\n",
    "        \"\"\"A dense block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            blocks: integer, the number of building blocks.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            output tensor for the block.\n",
    "        \"\"\"\n",
    "        for i in range(blocks):\n",
    "            x = self.conv_block(x, 32, name=name + '_block' + str(i + 1), \n",
    "                weight_decay = weight_decay,\n",
    "                kernel_initializer = kernel_initializer)\n",
    "        return x\n",
    "\n",
    "    def transition_block(self, x, reduction, name, weight_decay = 1e-4, kernel_initializer = 'he_normal'):\n",
    "        \"\"\"A transition block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            reduction: float, compression rate at transition layers.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            output tensor for the block.\n",
    "        \"\"\"\n",
    "        bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                    name=name + '_bn')(x)\n",
    "        x = layers.Activation('relu', name=name + '_relu')(x)\n",
    "        x = layers.Conv2D(int(K.int_shape(x)[bn_axis] * reduction), 1,\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_conv')(x)\n",
    "        x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "        return x\n",
    "\n",
    "    def conv_block(self, x, growth_rate, name, weight_decay = 1e-4, kernel_initializer = 'he_normal'):\n",
    "        \"\"\"A building block for a dense block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            growth_rate: float, growth rate at dense layers.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            Output tensor for the block.\n",
    "        \"\"\"\n",
    "        bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "        x1 = layers.BatchNormalization(axis=bn_axis,\n",
    "                                    epsilon=1.001e-5,\n",
    "                                    name=name + '_0_bn')(x)\n",
    "        x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n",
    "        x1 = layers.Conv2D(4 * growth_rate, 1,\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_1_conv')(x1)\n",
    "        x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                    name=name + '_1_bn')(x1)\n",
    "        x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n",
    "        x1 = layers.Conv2D(growth_rate, 3,\n",
    "                        padding='same',\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_2_conv')(x1)\n",
    "        x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n",
    "        return x\n",
    "\n",
    "    def small_densenet(self, classes = None, \n",
    "                       img_input_shape = (64, 64, 3), \n",
    "                       blocks = [6, 12, 24, 16], \n",
    "                       weight_decay = 1e-4, \n",
    "                       kernel_initializer = 'he_normal',\n",
    "                       reduction = 0.5):\n",
    "        img_input = Input(shape = (img_input_shape))\n",
    "        x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "        x = layers.Conv2D(64, 7, strides=2, use_bias=False, \n",
    "            kernel_initializer = kernel_initializer, \n",
    "            kernel_regularizer = l2(weight_decay),\n",
    "            name='conv1/conv')(x)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=3, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "        x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "        x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "        x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "        \n",
    "        x = self.dense_block(x, blocks[0], name='conv2', weight_decay = weight_decay, kernel_initializer = kernel_initializer)\n",
    "        x = self.transition_block(x, reduction, name='pool2', weight_decay = weight_decay, kernel_initializer = kernel_initializer)\n",
    "        x = self.dense_block(x, blocks[1], name='conv3', weight_decay = weight_decay, kernel_initializer = kernel_initializer)\n",
    "        x = self.transition_block(x, reduction, name='pool3', weight_decay = weight_decay, kernel_initializer = kernel_initializer)\n",
    "        x = self.dense_block(x, blocks[2], name='conv4', weight_decay = weight_decay, kernel_initializer = kernel_initializer)\n",
    "        x = self.transition_block(x, reduction, name='pool4', weight_decay = weight_decay, kernel_initializer = kernel_initializer)\n",
    "        x = self.dense_block(x, blocks[3], name='conv5', weight_decay = weight_decay, kernel_initializer = kernel_initializer)\n",
    "        \n",
    "        x = layers.BatchNormalization(\n",
    "            axis=3, epsilon=1.001e-5, name='bn')(x)\n",
    "        x = layers.Activation('relu', name='relu')(x)\n",
    "\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        # x = Lambda(lambda x: x, name = 'densenet_features')(x)\n",
    "        x = layers.Dense(classes, activation='softmax',\n",
    "            kernel_initializer = kernel_initializer, \n",
    "            kernel_regularizer = l2(weight_decay), \n",
    "            name='fc')(x)\n",
    "        \n",
    "        model = Model(img_input, x)\n",
    "        print (model.summary())\n",
    "        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "        \n",
    "        return model\n",
    "train_data = train_data[:1000]\n",
    "train_img = extract_array_from_series(train_data['img'])\n",
    "train_img = vgg16.preprocess_input(train_img)\n",
    "OneHotEncoder = sklearn.preprocessing.OneHotEncoder()\n",
    "train_target = train_data['class_id'].apply(lambda id: category_dict[id]).values\n",
    "train_target = OneHotEncoder.fit_transform(np.reshape(train_target, (-1, 1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train target nunique:  6 Validate target nuique:  6\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_113 (InputLayer)          (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 70, 70, 3)    0           input_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 32, 32, 64)   9408        zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 32, 32, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 34, 34, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 16, 16, 64)   0           zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 16, 16, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 16, 16, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 16, 16, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 16, 16, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 16, 16, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 16, 16, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 16, 16, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 16, 16, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 16, 16, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 16, 16, 128)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 16, 16, 64)   8192        pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 8, 8, 64)     0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 8, 8, 64)     256         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 8, 8, 64)     0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    8192        conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 8, 8, 96)     0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 8, 8, 96)     384         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 8, 8, 96)     0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    12288       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 8, 8, 128)    0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 8, 8, 128)    512         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 8, 8, 128)    0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 8, 8, 64)     8192        pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 4, 4, 64)     0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 4, 4, 64)     256         pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 4, 4, 64)     0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 128)    8192        conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 4, 4, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 4, 4, 96)     0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 4, 4, 96)     384         conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 4, 4, 96)     0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 128)    12288       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 4, 4, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 4, 4, 128)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 4, 4, 128)    512         conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 4, 4, 128)    0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 4, 4, 64)     8192        pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 2, 2, 64)     0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 2, 2, 64)     256         pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 2, 2, 64)     0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 128)    8192        conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 2, 2, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 2, 2, 96)     0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 2, 2, 96)     384         conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 2, 2, 96)     0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 128)    12288       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 2, 2, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 2, 2, 128)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 2, 2, 128)    512         conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 2, 2, 128)    0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 128)          0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 6)            774         avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 420,550\n",
      "Trainable params: 416,070\n",
      "Non-trainable params: 4,480\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 42s 52ms/step - loss: 1.7065 - categorical_accuracy: 0.3562 - val_loss: 1.9188 - val_categorical_accuracy: 0.4100\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 30s 37ms/step - loss: 1.3988 - categorical_accuracy: 0.5288 - val_loss: 2.1152 - val_categorical_accuracy: 0.4600\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 1.2312 - categorical_accuracy: 0.5862 - val_loss: 2.2976 - val_categorical_accuracy: 0.4700\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 31s 38ms/step - loss: 1.1362 - categorical_accuracy: 0.6212 - val_loss: 1.8414 - val_categorical_accuracy: 0.4450\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 31s 39ms/step - loss: 1.0393 - categorical_accuracy: 0.6700 - val_loss: 1.8027 - val_categorical_accuracy: 0.4450\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.9712 - categorical_accuracy: 0.6900 - val_loss: 1.6306 - val_categorical_accuracy: 0.4700\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.9159 - categorical_accuracy: 0.7137 - val_loss: 1.5033 - val_categorical_accuracy: 0.4700\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 31s 38ms/step - loss: 0.8567 - categorical_accuracy: 0.7437 - val_loss: 1.3539 - val_categorical_accuracy: 0.5650\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.7891 - categorical_accuracy: 0.7700 - val_loss: 1.5621 - val_categorical_accuracy: 0.4900\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 30s 37ms/step - loss: 0.7262 - categorical_accuracy: 0.7987 - val_loss: 1.5109 - val_categorical_accuracy: 0.4850\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 31s 39ms/step - loss: 0.6953 - categorical_accuracy: 0.8062 - val_loss: 1.5918 - val_categorical_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "256/800 [========>.....................] - ETA: 20s - loss: 0.6290 - categorical_accuracy: 0.8164"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-9c0cc4300105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     h = img_model.model.fit(train_part_img, train_part_target, validation_data=(validate_part_img, validate_part_target), \n\u001b[1;32m     43\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                   callbacks=[EarlyStopping(monitor='val_categorical_accuracy', patience=15, verbose=0)])\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fold = 5\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "num_fold = 0\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "\n",
    "for train_index, test_index in kf.split(train_img):\n",
    "    train_part_img = train_img[train_index]\n",
    "    validate_part_img = train_img[test_index]\n",
    "    \n",
    "    train_part_target = train_target[train_index]\n",
    "    validate_part_target = train_target[test_index]\n",
    "    \n",
    "    print ('Train target nunique: ', np.unique(np.argwhere(train_part_target == 1)[:, 1]).shape[0], \n",
    "           'Validate target nuique: ', np.unique(np.argwhere(validate_part_target == 1)[:, 1]).shape[0])\n",
    "#     model = vgg16.VGG16(include_top=True, weights = None, input_shape=(64, 64, 3), classes = category.shape[0])\n",
    "#     model = resnet50.ResNet50(include_top=True, weights = None, input_shape=(224, 224, 3), classes = category.shape[0])\n",
    "#     print (model.summary())\n",
    "#     model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "    img_model = DenseNet(blocks = [2, 2, 2, 2], \n",
    "                                cat_max = train_target.shape[1],\n",
    "                                weight_decay = 1e-4, \n",
    "                                kernel_initializer = 'glorot_normal',\n",
    "                                reduction = 0.5) \n",
    "#     print (img_model.summary())\n",
    "    # img_model = small_vgg(img_input_shape = (64, 64, 3), classes = train_target.shape[1])\n",
    "#     datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "# #             featurewise_center=True,\n",
    "# #             featurewise_std_normalization=True,\n",
    "#             rotation_range=20,\n",
    "#             width_shift_range=0.2,\n",
    "#             height_shift_range=0.2,\n",
    "#             horizontal_flip=True)\n",
    "#     datagen.fit(train_part_img)\n",
    "#     h = img_model.model.fit_generator(datagen.flow(train_part_img, train_part_target, batch_size=256), validation_data=(validate_part_img, validate_part_target), \n",
    "#                   epochs=100, shuffle=True, verbose = 1, workers=1, use_multiprocessing=False, \n",
    "#                   callbacks=[EarlyStopping(monitor='val_categorical_accuracy', patience=15, verbose=0)])\n",
    "    h = img_model.model.fit(train_part_img, train_part_target, validation_data=(validate_part_img, validate_part_target), \n",
    "                  epochs=100, batch_size = 256, shuffle=True, verbose = 1, \n",
    "                  callbacks=[EarlyStopping(monitor='val_categorical_accuracy', patience=15, verbose=0)])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8e6b6548d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(h.history)[['val_categorical_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model.model.save(path + '/model_sub/densenet_4_6_8_10_03266.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n03598930', 'jigsaw_puzzle', 0.023861792), ('n02095314', 'wire-haired_fox_terrier', 0.022931756), ('n04589890', 'window_screen', 0.021361042)]\n"
     ]
    }
   ],
   "source": [
    "# np.asarray(list(train_data['img'])).shape\n",
    "# train_data[train_data['class_id'] == 'ZJL1']\n",
    "# train_data['class_id'].value_counts().hist()\n",
    "# train_data.head()\n",
    "# class_id_emb_attr.iloc[0].name\n",
    "# resnet50_model = ResNet50(weights='imagenet', input_shape=(224, 224, 3))\n",
    "img = image.load_img(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg', target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = vgg16.preprocess_input(img)\n",
    "preds = vgg_model.predict(np.expand_dims(img, axis=0))\n",
    "print('Predicted:', vgg16.decode_predictions(preds, top=3)[0])\n",
    "# imread(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg')\n",
    "# image.img_to_array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_array_from_series(s):\n",
    "    return np.asarray(list(s))\n",
    "    \n",
    "def create_dnn_data(df):\n",
    "    return [extract_array_from_series(df['attr']), extract_array_from_series(df['emb'])]\n",
    "            \n",
    "def lgbm_train(train_part, train_part_label, valide_part, valide_part_label, fold_seed,\n",
    "        fold = 5, train_weight = None, valide_weight = None, flags = None):\n",
    "    \"\"\"\n",
    "    LGBM Training\n",
    "    \"\"\"\n",
    "    print(\"-----LGBM training-----\")\n",
    "\n",
    "    d_train = lgb.Dataset(train_part, train_part_label) #, categorical_feature = CATEGORY_FEATURES) #, init_score = train_part[:, -1])\n",
    "    d_valide = lgb.Dataset(valide_part, valide_part_label) #, categorical_feature = CATEGORY_FEATURES) #, init_score = valide_part[:, -1])\n",
    "    params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt', #'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            # 'num_leaves':-1,\n",
    "            'min_sum_hessian_in_leaf':None,\n",
    "            'max_depth':7,\n",
    "            'learning_rate':0.005,\n",
    "            'feature_fraction':0.1,\n",
    "            'verbose':-1,\n",
    "            'num_boost_round':3000,\n",
    "            'drop_rate':None,\n",
    "            'bagging_fraction':0.6,\n",
    "            'bagging_freq':5,\n",
    "            'early_stopping_round':100,\n",
    "            # 'min_data_in_leaf':100,\n",
    "            'max_bin': None,\n",
    "            'scale_pos_weight':None,\n",
    "        }\n",
    "    print (\"lightgbm params: {0}\\n\".format(params))\n",
    "\n",
    "    bst = lgb.train(\n",
    "                    params ,\n",
    "                    d_train,\n",
    "                    verbose_eval = 200,\n",
    "                    valid_sets = [d_train, d_valide],\n",
    "                    # feature_name= keras_train.DENSE_FEATURE_LIST,\n",
    "                    #feval = gini_lgbm\n",
    "                    #num_boost_round = 1\n",
    "                    )\n",
    "    #pred = model_eval(bst, 'l', valide_part)\n",
    "    #print(pred[:10])\n",
    "    #print(valide_part_label[:10])\n",
    "    #print(valide_part[:10, -1])\n",
    "    # exit(0)\n",
    "    feature_imp = bst.feature_importance(importance_type = 'gain')\n",
    "    sort_ind = np.argsort(feature_imp)[::-1]\n",
    "    print (np.c_[np.array(FEATURE_LIST)[sort_ind], feature_imp[sort_ind]][:10])\n",
    "    # print (np.array(keras_train.FEATURE_LIST)[np.argsort(feature_imp)])\n",
    "    # exit(0)\n",
    "    # cv_result = lgb.cv(params, d_train, nfold=fold) #, feval = gini_lgbm)\n",
    "    # pd.DataFrame(cv_result).to_csv('cv_result', index = False)\n",
    "    # exit(0)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_y = pickle.load(handle)\n",
    "# img_model_flat = Model(input = img_model.model.input, output = img_model.model.get_layer(name = 'avg_pool').output)\n",
    "# # train_data['target'] = list(train_y) #\n",
    "# train_data['target'] = list(img_model_flat.predict(train_img, verbose = 1))\n",
    "img_model_flat = pd.read_csv(path + '/model_sub/6_12_24_16_03274/sub_2018_09_07_20_58_46.csv')\n",
    "\n",
    "img_model_flat.set_index('image_id', inplace = True)\n",
    "train_data['target'] = img_model_flat.apply(lambda s: np.asarray(s.astype(float)), axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a6394b0f513290f4651cc46792e5ac86.jpeg</th>\n",
       "      <td>0.222450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102360</td>\n",
       "      <td>0.410408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619550</td>\n",
       "      <td>0.469335</td>\n",
       "      <td>0.808152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638106</td>\n",
       "      <td>1.262975</td>\n",
       "      <td>0.716701</td>\n",
       "      <td>0.649398</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>2.584138</td>\n",
       "      <td>0.299704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775807</td>\n",
       "      <td>0.657141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513933</td>\n",
       "      <td>0.727034</td>\n",
       "      <td>0.205590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634150</td>\n",
       "      <td>0.386227</td>\n",
       "      <td>1.307551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289387</td>\n",
       "      <td>1.043166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.390443</td>\n",
       "      <td>0.291443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.544563</td>\n",
       "      <td>0.258394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</th>\n",
       "      <td>0.192894</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>0.642721</td>\n",
       "      <td>0.485429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463746</td>\n",
       "      <td>0.188616</td>\n",
       "      <td>0.250049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681179</td>\n",
       "      <td>2.148037</td>\n",
       "      <td>0.335496</td>\n",
       "      <td>0.230386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.919400</td>\n",
       "      <td>0.227866</td>\n",
       "      <td>0.139630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d93ef45972154aae150b4f9980a79c0.jpeg</th>\n",
       "      <td>0.518664</td>\n",
       "      <td>0.570357</td>\n",
       "      <td>0.081985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470126</td>\n",
       "      <td>0.712403</td>\n",
       "      <td>0.132547</td>\n",
       "      <td>0.683170</td>\n",
       "      <td>0.231919</td>\n",
       "      <td>0.490414</td>\n",
       "      <td>...</td>\n",
       "      <td>1.055093</td>\n",
       "      <td>0.289770</td>\n",
       "      <td>1.330755</td>\n",
       "      <td>0.931580</td>\n",
       "      <td>0.007386</td>\n",
       "      <td>2.596373</td>\n",
       "      <td>0.145607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</th>\n",
       "      <td>0.580390</td>\n",
       "      <td>0.293492</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>0.231948</td>\n",
       "      <td>0.214693</td>\n",
       "      <td>0.486738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269853</td>\n",
       "      <td>0.458110</td>\n",
       "      <td>0.080292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059787</td>\n",
       "      <td>1.077016</td>\n",
       "      <td>0.858712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0         1         2         3  \\\n",
       "image_id                                                                        \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  0.222450  0.000000  0.000000  0.000000   \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  0.000000  0.092368  0.000000  0.513933   \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  0.192894  0.106830  0.000000  0.031785   \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  0.518664  0.570357  0.081985  0.000000   \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.580390  0.293492  0.007867  0.231948   \n",
       "\n",
       "                                              4         5         6         7  \\\n",
       "image_id                                                                        \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  0.102360  0.410408  0.000000  0.619550   \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  0.727034  0.205590  0.000000  0.634150   \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  0.642721  0.485429  0.000000  0.463746   \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  0.470126  0.712403  0.132547  0.683170   \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.214693  0.486738  0.000000  0.000000   \n",
       "\n",
       "                                              8         9    ...         1014  \\\n",
       "image_id                                                     ...                \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  0.469335  0.808152    ...     0.638106   \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  0.386227  1.307551    ...     0.289387   \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  0.188616  0.250049    ...     0.681179   \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  0.231919  0.490414    ...     1.055093   \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.000000  0.163543    ...     0.000000   \n",
       "\n",
       "                                           1015      1016      1017      1018  \\\n",
       "image_id                                                                        \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  1.262975  0.716701  0.649398  0.024636   \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  1.043166  0.000000  0.270949  0.000000   \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  2.148037  0.335496  0.230386  0.000000   \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  0.289770  1.330755  0.931580  0.007386   \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.269853  0.458110  0.080292  0.000000   \n",
       "\n",
       "                                           1019      1020      1021      1022  \\\n",
       "image_id                                                                        \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  2.584138  0.299704  0.000000  0.775807   \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  1.390443  0.291443  0.000000  1.544563   \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  1.919400  0.227866  0.139630  0.000000   \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  2.596373  0.145607  0.000000  0.296896   \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.149054  0.000000  0.059787  1.077016   \n",
       "\n",
       "                                           1023  \n",
       "image_id                                         \n",
       "a6394b0f513290f4651cc46792e5ac86.jpeg  0.657141  \n",
       "2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg  0.258394  \n",
       "eda9f3bef2bd8da038f6acbc8355fc25.jpeg  0.529273  \n",
       "7d93ef45972154aae150b4f9980a79c0.jpeg  0.000000  \n",
       "fb901b4f9a8e396c1d0155bccc5e5671.jpeg  0.858712  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_model_flat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>emb</th>\n",
       "      <th>attr</th>\n",
       "      <th>img</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...</td>\n",
       "      <td>[1.5649712, 0.22537939999999998, 0.0, 0.511434...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...</td>\n",
       "      <td>[0.95975924, 0.31657952, 0.005624798, 0.542549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....</td>\n",
       "      <td>[0.73883903, 0.08649281, 0.12541012, 0.1657913...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>7d93ef45972154aae150b4f9980a79c0.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....</td>\n",
       "      <td>[0.97788334, 0.741634, 0.28850228, 0.12216809,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...</td>\n",
       "      <td>[0.6483536999999999, 0.4635263, 0.4247312, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_id                               image_id class_name  \\\n",
       "0     ZJL1  a6394b0f513290f4651cc46792e5ac86.jpeg   goldfish   \n",
       "1     ZJL1  2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg   goldfish   \n",
       "2     ZJL1  eda9f3bef2bd8da038f6acbc8355fc25.jpeg   goldfish   \n",
       "3     ZJL1  7d93ef45972154aae150b4f9980a79c0.jpeg   goldfish   \n",
       "4     ZJL1  fb901b4f9a8e396c1d0155bccc5e5671.jpeg   goldfish   \n",
       "\n",
       "                                                 emb  \\\n",
       "0  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "1  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "2  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "3  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "4  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "\n",
       "                                                attr  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "\n",
       "                                                 img  \\\n",
       "0  [[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...   \n",
       "1  [[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...   \n",
       "2  [[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....   \n",
       "3  [[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....   \n",
       "4  [[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...   \n",
       "\n",
       "                                              target  \n",
       "0  [1.5649712, 0.22537939999999998, 0.0, 0.511434...  \n",
       "1  [0.95975924, 0.31657952, 0.005624798, 0.542549...  \n",
       "2  [0.73883903, 0.08649281, 0.12541012, 0.1657913...  \n",
       "3  [0.97788334, 0.741634, 0.28850228, 0.12216809,...  \n",
       "4  [0.6483536999999999, 0.4635263, 0.4247312, 0.0...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 th train :-)\n",
      "Train size: 30579 Valide size: 7642\n",
      "Train category: 152 Valide category: 38\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "attr (InputLayer)                (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "wv (InputLayer)                  (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 256)           7680        attr[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 556)           0           wv[0][0]                         \n",
      "                                                                   dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 556)           2224        concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 1536)          855552      batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 1536)          6144        dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 1024)          1573888     batch_normalization_8[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 2,445,488\n",
      "Trainable params: 2,441,304\n",
      "Non-trainable params: 4,184\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 30579 samples, validate on 7642 samples\n",
      "Epoch 1/1\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  1.1753625 batch_size:  512\n",
      "k:  batch v:  1 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  1.0688899 batch_size:  512\n",
      "k:  batch v:  2 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.9942877 batch_size:  512\n",
      "k:  batch v:  3 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.94641083 batch_size:  512\n",
      "k:  batch v:  4 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.92665243 batch_size:  512\n",
      "k:  batch v:  5 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.9056311 batch_size:  512\n",
      "k:  batch v:  6 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.88987976 batch_size:  512\n",
      "k:  batch v:  7 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.8722205 batch_size:  512\n",
      "k:  batch v:  8 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.8619019 batch_size:  512\n",
      "k:  batch v:  9 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.8504615 batch_size:  512\n",
      "k:  batch v:  10 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.8424484 batch_size:  512\n",
      "k:  batch v:  11 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.8361778 batch_size:  512\n",
      "k:  batch v:  12 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.83403516 batch_size:  512\n",
      "k:  batch v:  13 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.8207605 batch_size:  512\n",
      "k:  batch v:  14 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.81447995 batch_size:  512\n",
      "k:  batch v:  15 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.8072218 batch_size:  512\n",
      "k:  batch v:  16 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.80756724 batch_size:  512\n",
      "k:  batch v:  17 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.79739285 batch_size:  512\n",
      "k:  batch v:  18 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.79188997 batch_size:  512\n",
      "k:  batch v:  19 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7899709 batch_size:  512\n",
      "k:  batch v:  20 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.77945834 batch_size:  512\n",
      "k:  batch v:  21 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7745286 batch_size:  512\n",
      "k:  batch v:  22 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7739793 batch_size:  512\n",
      "k:  batch v:  23 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.764909 batch_size:  512\n",
      "k:  batch v:  24 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.766224 batch_size:  512\n",
      "k:  batch v:  25 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.75573236 batch_size:  512\n",
      "k:  batch v:  26 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7539108 batch_size:  512\n",
      "k:  batch v:  27 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7438557 batch_size:  512\n",
      "k:  batch v:  28 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7413049 batch_size:  512\n",
      "k:  batch v:  29 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7379847 batch_size:  512\n",
      "k:  batch v:  30 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7397841 batch_size:  512\n",
      "k:  batch v:  31 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.73428917 batch_size:  512\n",
      "k:  batch v:  32 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7341875 batch_size:  512\n",
      "k:  batch v:  33 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.72443986 batch_size:  512\n",
      "k:  batch v:  34 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7254091 batch_size:  512\n",
      "k:  batch v:  35 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7231448 batch_size:  512\n",
      "k:  batch v:  36 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7183322 batch_size:  512\n",
      "k:  batch v:  37 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.71548885 batch_size:  512\n",
      "k:  batch v:  38 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.71498257 batch_size:  512\n",
      "k:  batch v:  39 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.7082894 batch_size:  512\n",
      "k:  batch v:  40 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.70299953 batch_size:  512\n",
      "k:  batch v:  41 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.70371836 batch_size:  512\n",
      "k:  batch v:  42 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.6987168 batch_size:  512\n",
      "k:  batch v:  43 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.69482464 batch_size:  512\n",
      "k:  batch v:  44 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.6934782 batch_size:  512\n",
      "k:  batch v:  45 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.68661934 batch_size:  512\n",
      "k:  batch v:  46 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.6884166 batch_size:  512\n",
      "k:  batch v:  47 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.68292224 batch_size:  512\n",
      "k:  batch v:  48 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.67838067 batch_size:  512\n",
      "k:  batch v:  49 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.6771537 batch_size:  512\n",
      "k:  batch v:  50 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.6743799 batch_size:  512\n",
      "k:  batch v:  51 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.6699324 batch_size:  512\n",
      "k:  batch v:  52 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.66440856 batch_size:  512\n",
      "k:  batch v:  53 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.668029 batch_size:  512\n",
      "k:  batch v:  54 batch_size:  512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.6637999 batch_size:  512\n",
      "k:  batch v:  55 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.6558645 batch_size:  512\n",
      "k:  batch v:  56 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.6580056 batch_size:  512\n",
      "k:  batch v:  57 batch_size:  512\n",
      "k:  size v:  512 batch_size:  512\n",
      "k:  loss v:  0.65530294 batch_size:  512\n",
      "k:  batch v:  58 batch_size:  512\n",
      "k:  size v:  371 batch_size:  371\n",
      "k:  loss v:  0.6520934 batch_size:  371\n",
      "k:  batch v:  59 batch_size:  371\n",
      "\n",
      " Accuracy epoch: 1 - score: 0.162130 \n",
      " 1239/7642\n",
      "2s - loss: 0.7782 - val_loss: 0.8183\n"
     ]
    }
   ],
   "source": [
    "def find_nearest_class(class_id_emb_attr, model, eval_df, img_feature_map = None):\n",
    "    if img_feature_map is None:\n",
    "        img_feature_map = np.reshape(vgg_model.predict(np.asarray(list(eval_df['img'])), verbose = 1), (eval_img.shape[0], -1))\n",
    "    cand_feature_map = model.predict(create_dnn_data(class_id_emb_attr))\n",
    "    # img_feature_map = np.repeat(img_feature_map, [cand_feature_map.shape[0]] * img_feature_map.shape[0], axis = 0)\n",
    "    nearest_class_id = ['ZJL'] * eval_df.shape[0]\n",
    "    for i in range(img_feature_map.shape[0]):\n",
    "        img = img_feature_map[i]\n",
    "        dis = np.linalg.norm(img - cand_feature_map, axis = 1)\n",
    "        min_ind = np.where(dis == np.amin(dis))[0]\n",
    "        if len(min_ind) > 1:\n",
    "            print ('eval img id: ', eval_df.iloc[i]['class_id'], 'has multiple best candidates: ', len(min_ind), 'min val: ', np.amin(dis))\n",
    "#         print (i, img, class_id_emb_attr.iloc[min_ind[0]].name)\n",
    "        nearest_class_id[i] = class_id_emb_attr.iloc[min_ind[0]]['class_id']\n",
    "#     print (nearest_class_id)\n",
    "    return np.asarray(nearest_class_id)\n",
    "\n",
    "class AccuracyEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_interval = 1000000, verbose = 2, \\\n",
    "            scores = [], class_id_emb_attr = None, eval_df = None):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        # print(\"y_val shape:{0}\".format(self.y_val.shape))\n",
    "        self.batch_interval = batch_interval\n",
    "        self.verbose = verbose\n",
    "        self.scores = scores\n",
    "        self.class_id_emb_attr = class_id_emb_attr\n",
    "        self.eval_df = eval_df\n",
    "#         self.img_feature_map = self.y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "#             zs_model = Model(inputs = self.model.inputs[:2], outputs = self.model.outpus[0])\n",
    "            pred_nearest_class_id = find_nearest_class(self.class_id_emb_attr, self.model, self.eval_df, self.y_val)\n",
    "            true_class_id = self.eval_df['class_id'].values\n",
    "#             print (pred_nearest_class_id, \"\\n\", true_class_id)\n",
    "            right_num = np.sum(pred_nearest_class_id == true_class_id)\n",
    "            score = right_num / true_class_id.shape[0]\n",
    "            self.scores.append(\"epoch:{0} {1}\".format(epoch + 1, score))\n",
    "            print(\"\\n Accuracy epoch: %d - score: %.6f \\n %d/%d\" % (epoch+1, score, right_num, true_class_id.shape[0]))\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "        if(self.verbose >= 2) and (batch % self.batch_interval == 0):\n",
    "            # y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            # loss = metrics.log_loss(self.y_val, y_pred)\n",
    "            print(\"Hi! on_batch_end() , batch=\",batch,\",logs:\",logs)\n",
    "            # print(\"Valide size=\",y_pred.shape[0], \"  Valide loss=\",loss)\n",
    "\n",
    "def full_connect_layer(input, hidden_dim):\n",
    "    full_connect = input\n",
    "    for hn in hidden_dim:\n",
    "        fc_in = full_connect\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#         full_connect = Dropout(0.2)(full_connect)\n",
    "        full_connect = BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "        # full_connect = Dense(hn, kernel_regularizer = l2(0.001), activity_regularizer = l1(0.001))(full_connect)\n",
    "#         full_connect = Concatenate()([Dense(hn, kernel_initializer='lecun_uniform', activation = 'relu')(full_connect), \n",
    "#             Dense(hn, kernel_initializer='lecun_uniform', activation = 'sigmoid')(full_connect)])\n",
    "        full_connect = Dense(hn, kernel_initializer='he_normal', activation = 'relu', kernel_regularizer = l2(1e-4))(full_connect)\n",
    "        # full_connect = self.act_blend(full_connect)\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#             full_connect = Dropout(self.full_connect_dropout)(full_connect) #Dropout(self.full_connect_dropout)(full_connect)\n",
    "#         full_connect = Concatenate()([fc_in, full_connect])\n",
    "    return full_connect\n",
    "\n",
    "def create_dnn():\n",
    "    alpha = 0.03\n",
    "    attr_input = Input(shape = (30,), name = 'attr')\n",
    "    word_emb = Input(shape = (300,), name = 'wv')\n",
    "    imag_classifier = Input(shape = (1024,), name = 'img')\n",
    "\n",
    "    attr_dense = Dense(256, use_bias = False, kernel_initializer='he_normal', kernel_regularizer = l2(1e-4))(attr_input)\n",
    "#     attr_dense = Dense(512)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(256)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(300, activation=\"relu\")(attr_dense)\n",
    "    # attr_dense = Dense(512, activation=\"relu\")(attr_dense)\n",
    "\n",
    "    attr_word_emb = Concatenate()([word_emb, attr_dense])\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb, hidden_dim = [int(1024 * 1.5)])\n",
    "    \n",
    "#     attr_word_emb_dense = Concatenate()([attr_word_emb_dense, attr_word_emb])\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb_dense, hidden_dim = [1024])\n",
    "#     attr_word_emb_dense = Dense(1024, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = attr_word_emb\n",
    "#     attr_word_emb_dense = Dense(4096, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(1024)(attr_word_emb)\n",
    "\n",
    "    model = Model([attr_input, word_emb], outputs = attr_word_emb_dense) #, vgg_output])\n",
    "    # model.add_loss(mse_loss)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "def create_siae():\n",
    "    alpha = 0.03\n",
    "    gamma = 0.01\n",
    "    attr_input = Input(shape = (30,))\n",
    "    word_emb = Input(shape = (300,))\n",
    "    imag_classifier = Input(shape = (1024,))\n",
    "\n",
    "    attr_dense = Dense(32, use_bias = False, kernel_initializer='he_normal', kernel_regularizer = l2(1e-4))(attr_input)\n",
    "\n",
    "    attr_word_emb = Concatenate()([word_emb, attr_dense])\n",
    "    \n",
    "#     attr_word_emb_dense = Concatenate()([attr_word_emb_dense, attr_word_emb])\n",
    "#     attr_word_emb_dense = full_connect_layer(attr_word_emb_dense, hidden_dim = [1024])\n",
    "    \n",
    "    img_from_attr_w2v = full_connect_layer(attr_word_emb, hidden_dim = [1024, 1024, 1024, 1024])\n",
    "    attr_w2v_from_img = full_connect_layer(img_from_attr_w2v, hidden_dim = [512, 512, 512, 332])\n",
    "#     attr_word_emb_dense = Dense(1024, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = attr_word_emb\n",
    "#     attr_word_emb_dense = Dense(4096, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(1024)(attr_word_emb)\n",
    "    \n",
    "    mse_loss = keras.losses.mean_squared_error(imag_classifier, img_from_attr_w2v) + \\\n",
    "        gamma * keras.losses.mean_squared_error(attr_word_emb, attr_w2v_from_img)\n",
    "    model = Model([attr_input, word_emb, imag_classifier], outputs = [img_from_attr_w2v, attr_w2v_from_img]) #, vgg_output])\n",
    "    model.add_loss(mse_loss)\n",
    "    model.compile(optimizer='adam', loss=None)\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "#data.loc[class_id] #data_atten.loc[n]\n",
    "fold = 5\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "num_fold = 0\n",
    "class_ids = train_data['class_id'].unique() #[:5]\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "\n",
    "for train_index, test_index in kf.split(class_ids):\n",
    "    train_part_id = class_ids[train_index]\n",
    "    validate_part_id = class_ids[test_index]\n",
    "    \n",
    "    train_part_df = train_data[train_data['class_id'].isin(train_part_id)]\n",
    "    validate_part_df = train_data[train_data['class_id'].isin(validate_part_id)]\n",
    "\n",
    "    train_part_data = create_dnn_data(train_part_df)\n",
    "    train_part_target = extract_array_from_series(train_part_df['target'])\n",
    "    \n",
    "    validate_part_data = create_dnn_data(validate_part_df)\n",
    "    validate_part_target = extract_array_from_series(validate_part_df['target'])\n",
    "    \n",
    "    print('fold: %d th train :-)' % (num_fold))\n",
    "    print('Train size: {} Valide size: {}'.format(train_part_df.shape[0], validate_part_df.shape[0]))\n",
    "    print('Train category: {} Valide category: {}'.format(train_part_id.shape[0], validate_part_id.shape[0]))\n",
    "\n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "            AccuracyEvaluation(validation_data=(validate_part_data,  validate_part_target), interval=1, \\\n",
    "                class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(validate_part_id)], eval_df = validate_part_df)\n",
    "            ]\n",
    "    \n",
    "    zs_model = create_dnn()\n",
    "    if num_fold == 0:\n",
    "        print (zs_model.summary())\n",
    "    zs_model.fit(train_part_data, train_part_target,  validation_data = (validate_part_data, validate_part_target),\n",
    "                  epochs=1, batch_size = 512, shuffle=True, verbose = 2, callbacks=callbacks)\n",
    "    break\n",
    "#     model = lgbm_train(train_part_data[0], train_part_target, validate_part_data[0], validate_part_target, num_fold, fold)\n",
    "    num_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 th train :-)\n",
      "Train size: 30611 Valide size: 7610\n",
      "Train category: 152 Valide category: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:103: UserWarning: Output \"dense_179\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_179\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:103: UserWarning: Output \"dense_182\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_182\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:103: UserWarning: Output \"lambda_49\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"lambda_49\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:103: UserWarning: Output \"lambda_50\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"lambda_50\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_102 (InputLayer)          (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_101 (InputLayer)          (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 330)          0           input_102[0][0]                  \n",
      "                                                                 input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 330)          1320        concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_177 (Dense)               (None, 1536)         508416      batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 1536)         6144        dense_177[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_178 (Dense)               (None, 1280)         1967360     batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 1280)         5120        dense_178[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_179 (Dense)               (None, 1024)         1311744     batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 1024)         4096        dense_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_180 (Dense)               (None, 768)          787200      batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 768)          3072        dense_180[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_181 (Dense)               (None, 512)          393728      batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 512)          2048        dense_181[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_182 (Dense)               (None, 330)          169290      batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "input_103 (InputLayer)          (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None,)              0           input_103[0][0]                  \n",
      "                                                                 dense_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None,)              0           concatenate_34[0][0]             \n",
      "                                                                 dense_182[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,159,538\n",
      "Trainable params: 5,148,638\n",
      "Non-trainable params: 10,900\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 30611 samples, validate on 7610 samples\n",
      "Epoch 1/50\n",
      "30611/30611 [==============================] - 112s 4ms/step - loss: 0.5590 - val_loss: 0.4007\n",
      "\n",
      " Accuracy epoch: 1 - score: 0.236662 \n",
      " 1801/7610\n",
      "Epoch 2/50\n",
      "30611/30611 [==============================] - 107s 3ms/step - loss: 0.3439 - val_loss: 0.4021\n",
      "\n",
      " Accuracy epoch: 2 - score: 0.248883 \n",
      " 1894/7610\n",
      "Epoch 3/50\n",
      "30611/30611 [==============================] - 111s 4ms/step - loss: 0.3305 - val_loss: 0.3893\n",
      "\n",
      " Accuracy epoch: 3 - score: 0.237188 \n",
      " 1805/7610\n",
      "Epoch 4/50\n",
      "30611/30611 [==============================] - 104s 3ms/step - loss: 0.3138 - val_loss: 0.3797\n",
      "\n",
      " Accuracy epoch: 4 - score: 0.216820 \n",
      " 1650/7610\n",
      "Epoch 5/50\n",
      "30611/30611 [==============================] - 104s 3ms/step - loss: 0.3067 - val_loss: 0.3718\n",
      "\n",
      " Accuracy epoch: 5 - score: 0.264520 \n",
      " 2013/7610\n",
      "Epoch 6/50\n",
      "30611/30611 [==============================] - 104s 3ms/step - loss: 0.3009 - val_loss: 0.3695\n",
      "\n",
      " Accuracy epoch: 6 - score: 0.246386 \n",
      " 1875/7610\n",
      "Epoch 7/50\n",
      "30611/30611 [==============================] - 103s 3ms/step - loss: 0.2994 - val_loss: 0.3677\n",
      "\n",
      " Accuracy epoch: 7 - score: 0.255716 \n",
      " 1946/7610\n",
      "Epoch 8/50\n",
      "30611/30611 [==============================] - 105s 3ms/step - loss: 0.2959 - val_loss: 0.3655\n",
      "\n",
      " Accuracy epoch: 8 - score: 0.246912 \n",
      " 1879/7610\n",
      "Epoch 9/50\n",
      "30611/30611 [==============================] - 103s 3ms/step - loss: 0.2943 - val_loss: 0.3661\n",
      "\n",
      " Accuracy epoch: 9 - score: 0.210907 \n",
      " 1605/7610\n",
      "Epoch 10/50\n",
      "30611/30611 [==============================] - 103s 3ms/step - loss: 0.2927 - val_loss: 0.3620\n",
      "\n",
      " Accuracy epoch: 10 - score: 0.232720 \n",
      " 1771/7610\n",
      "Epoch 11/50\n",
      "30611/30611 [==============================] - 104s 3ms/step - loss: 0.2899 - val_loss: 0.3596\n",
      "\n",
      " Accuracy epoch: 11 - score: 0.223390 \n",
      " 1700/7610\n",
      "Epoch 12/50\n",
      "30611/30611 [==============================] - 104s 3ms/step - loss: 0.2875 - val_loss: 0.3601\n",
      "\n",
      " Accuracy epoch: 12 - score: 0.219711 \n",
      " 1672/7610\n",
      "Epoch 13/50\n",
      "30611/30611 [==============================] - 103s 3ms/step - loss: 0.2860 - val_loss: 0.3584\n",
      "\n",
      " Accuracy epoch: 13 - score: 0.208673 \n",
      " 1588/7610\n",
      "Epoch 14/50\n",
      "30611/30611 [==============================] - 103s 3ms/step - loss: 0.2845 - val_loss: 0.3587\n",
      "\n",
      " Accuracy epoch: 14 - score: 0.209067 \n",
      " 1591/7610\n",
      "Epoch 15/50\n",
      "30611/30611 [==============================] - 103s 3ms/step - loss: 0.2829 - val_loss: 0.3552\n",
      "\n",
      " Accuracy epoch: 15 - score: 0.224442 \n",
      " 1708/7610\n",
      "Epoch 16/50\n",
      "30611/30611 [==============================] - 103s 3ms/step - loss: 0.2816 - val_loss: 0.3555\n",
      "\n",
      " Accuracy epoch: 16 - score: 0.223784 \n",
      " 1703/7610\n",
      "Epoch 17/50\n",
      "30611/30611 [==============================] - 103s 3ms/step - loss: 0.2804 - val_loss: 0.3560\n",
      "\n",
      " Accuracy epoch: 17 - score: 0.222602 \n",
      " 1694/7610\n",
      "Epoch 18/50\n",
      "30611/30611 [==============================] - 105s 3ms/step - loss: 0.2798 - val_loss: 0.3582\n",
      "\n",
      " Accuracy epoch: 18 - score: 0.199343 \n",
      " 1517/7610\n"
     ]
    }
   ],
   "source": [
    "def find_nearest_class(class_id_emb_attr, model, eval_df, img_feature_map = None):\n",
    "    if img_feature_map is None:\n",
    "        img_feature_map = np.reshape(vgg_model.predict(np.asarray(list(eval_df['img'])), verbose = 1), (eval_img.shape[0], -1))\n",
    "    cand_feature_map = model.predict(create_dnn_data(class_id_emb_attr))\n",
    "#     attr_w2v_from_img = model.predict(img_feature_map)\n",
    "#     cand_feature_map = np.hstack(create_dnn_data(class_id_emb_attr))\n",
    "#     print (cand_feature_map.shape)\n",
    "    # img_feature_map = np.repeat(img_feature_map, [cand_feature_map.shape[0]] * img_feature_map.shape[0], axis = 0)\n",
    "    nearest_class_id = ['ZJL'] * eval_df.shape[0]\n",
    "    cand_size = class_id_emb_attr.shape[0]\n",
    "    for i in range(img_feature_map.shape[0]):\n",
    "        img = img_feature_map[i]\n",
    "#         img = attr_w2v_from_img[i]\n",
    "        dis = np.linalg.norm(img - cand_feature_map, axis = 1)\n",
    "#         img = np.array([img_feature_map[i]] * cand_size)\n",
    "#         dis = model.predict(create_dnn_data(class_id_emb_attr) + [img])\n",
    "        min_ind = np.where(dis == np.amin(dis))[0]\n",
    "        if len(min_ind) > 1:\n",
    "            print ('eval img id: ', eval_df.iloc[i]['class_id'], 'has multiple best candidates: ', len(min_ind), 'min val: ', np.amin(dis))\n",
    "#         print (i, img, class_id_emb_attr.iloc[min_ind[0]].name)\n",
    "        nearest_class_id[i] = class_id_emb_attr.iloc[min_ind[0]]['class_id']\n",
    "#     print (nearest_class_id)\n",
    "    return np.asarray(nearest_class_id)\n",
    "\n",
    "class AccuracyEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_interval = 1000000, verbose = 2, \\\n",
    "            scores = [], class_id_emb_attr = None, eval_df = None):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        # print(\"y_val shape:{0}\".format(self.y_val.shape))\n",
    "        self.batch_interval = batch_interval\n",
    "        self.verbose = verbose\n",
    "        self.scores = scores\n",
    "        self.class_id_emb_attr = class_id_emb_attr\n",
    "        self.eval_df = eval_df\n",
    "#         self.img_feature_map = self.y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            zs_model = Model(inputs = self.model.inputs[:2], outputs = self.model.outputs[0])\n",
    "            pred_nearest_class_id = find_nearest_class(self.class_id_emb_attr, zs_model, self.eval_df, self.y_val)\n",
    "            true_class_id = self.eval_df['class_id'].values\n",
    "#             print (pred_nearest_class_id, \"\\n\", true_class_id)\n",
    "            right_num = np.sum(pred_nearest_class_id == true_class_id)\n",
    "            score = right_num / true_class_id.shape[0]\n",
    "            self.scores.append(\"epoch:{0} {1}\".format(epoch + 1, score))\n",
    "            print(\"\\n Accuracy epoch: %d - score: %.6f \\n %d/%d\" % (epoch+1, score, right_num, true_class_id.shape[0]))\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "        if(self.verbose >= 2) and (batch % self.batch_interval == 0):\n",
    "            # y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            # loss = metrics.log_loss(self.y_val, y_pred)\n",
    "            print(\"Hi! on_batch_end() , batch=\",batch,\",logs:\",logs)\n",
    "            # print(\"Valide size=\",y_pred.shape[0], \"  Valide loss=\",loss)\n",
    "\n",
    "def full_connect_layer(input, hidden_dim):\n",
    "    full_connect = input\n",
    "    for hn in hidden_dim:\n",
    "        fc_in = full_connect\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#         full_connect = Dropout(0.2)(full_connect)\n",
    "        full_connect = BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "        # full_connect = Dense(hn, kernel_regularizer = l2(0.001), activity_regularizer = l1(0.001))(full_connect)\n",
    "#         full_connect = Concatenate()([Dense(hn, kernel_initializer='lecun_uniform', activation = 'relu')(full_connect), \n",
    "#             Dense(hn, kernel_initializer='lecun_uniform', activation = 'sigmoid')(full_connect)])\n",
    "        full_connect = Dense(hn, kernel_initializer='he_normal', activation = 'relu', kernel_regularizer = l2(1e-4))(full_connect)\n",
    "        # full_connect = self.act_blend(full_connect)\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#             full_connect = Dropout(self.full_connect_dropout)(full_connect) #Dropout(self.full_connect_dropout)(full_connect)\n",
    "#         full_connect = Concatenate()([fc_in, full_connect])\n",
    "    return full_connect\n",
    "\n",
    "def create_siae():\n",
    "    alpha = 0.03\n",
    "    gamma = 0\n",
    "    attr_emb_dim = 256\n",
    "    attr_input = Input(shape = (30,))\n",
    "    word_emb = Input(shape = (300,))\n",
    "    imag_classifier = Input(shape = (1024,))\n",
    "\n",
    "    attr_dense = Dense(attr_emb_dim, use_bias = False, kernel_initializer='he_normal', kernel_regularizer = l2(1e-4))(attr_input)\n",
    "\n",
    "    attr_word_emb = Concatenate()([word_emb, attr_input])\n",
    "    \n",
    "#     attr_word_emb_dense = Concatenate()([attr_word_emb_dense, attr_word_emb])\n",
    "#     attr_word_emb_dense = full_connect_layer(attr_word_emb_dense, hidden_dim = [1024])\n",
    "    \n",
    "    img_from_attr_w2v = full_connect_layer(attr_word_emb, hidden_dim = [1024 + 512, 1024 + 256, 1024])\n",
    "    attr_w2v_from_img = full_connect_layer(img_from_attr_w2v, hidden_dim = [1024 - 256, 1024 - 512, 300 + 30])\n",
    "#     attr_word_emb_dense = Dense(1024, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = attr_word_emb\n",
    "#     attr_word_emb_dense = Dense(4096, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(1024)(attr_word_emb)\n",
    "    \n",
    "    imag_classifier_loss = Lambda(lambda x: keras.losses.mean_squared_error(x[0], x[1]))([imag_classifier, img_from_attr_w2v])\n",
    "    attr_word_emb_loss = Lambda(lambda x: keras.losses.mean_squared_error(x[0], x[1]))([attr_word_emb, attr_w2v_from_img])\n",
    "    mse_loss = K.mean(imag_classifier_loss + gamma * attr_word_emb_loss)\n",
    "    model = Model([attr_input, word_emb, imag_classifier], \n",
    "                  outputs = [img_from_attr_w2v, attr_w2v_from_img, imag_classifier_loss, attr_word_emb_loss]) #, vgg_output])\n",
    "    model.add_loss(mse_loss)\n",
    "    model.compile(optimizer='adam', loss=None)\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "def create_isae():\n",
    "    alpha = 0.03\n",
    "    gamma = 0\n",
    "    attr_emb_dim = 256\n",
    "    attr_input = Input(shape = (30,))\n",
    "    word_emb = Input(shape = (300,))\n",
    "    imag_classifier = Input(shape = (1024,))\n",
    "\n",
    "    attr_dense = Dense(attr_emb_dim, use_bias = False, kernel_initializer='he_normal', kernel_regularizer = l2(1e-4))(attr_input)\n",
    "\n",
    "    attr_word_emb = Concatenate()([word_emb, attr_input])\n",
    "    \n",
    "#     attr_word_emb_dense = Concatenate()([attr_word_emb_dense, attr_word_emb])\n",
    "#     attr_word_emb_dense = full_connect_layer(attr_word_emb_dense, hidden_dim = [1024])\n",
    "    \n",
    "    attr_w2v_from_img = full_connect_layer(imag_classifier, hidden_dim = [1024 - 256, 1024 - 512, 300 + 30])\n",
    "    img_from_attr_w2v = full_connect_layer(attr_w2v_from_img, hidden_dim = [1024 - 512, 1024 - 256, 1024])\n",
    "    \n",
    "#     attr_word_emb_dense = Dense(1024, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = attr_word_emb\n",
    "#     attr_word_emb_dense = Dense(4096, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(1024)(attr_word_emb)\n",
    "    \n",
    "    imag_classifier_loss = Lambda(lambda x: keras.losses.mean_squared_error(x[0], x[1]))([imag_classifier, img_from_attr_w2v])\n",
    "    attr_word_emb_loss = Lambda(lambda x: keras.losses.mean_squared_error(x[0], x[1]))([attr_word_emb, attr_w2v_from_img])\n",
    "    mse_loss = K.mean(attr_word_emb_loss + gamma * imag_classifier_loss)\n",
    "    model = Model([attr_input, word_emb, imag_classifier], \n",
    "                  outputs = [img_from_attr_w2v, attr_w2v_from_img, imag_classifier_loss, attr_word_emb_loss]) #, vgg_output])\n",
    "    model.add_loss(mse_loss)\n",
    "    model.compile(optimizer='adam', loss=None)\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "#data.loc[class_id] #data_atten.loc[n]\n",
    "fold = 5\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "num_fold = 0\n",
    "class_ids = train_data['class_id'].unique() #[:5]\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "\n",
    "for train_index, test_index in kf.split(class_ids):\n",
    "    train_part_id = class_ids[train_index]\n",
    "    validate_part_id = class_ids[test_index]\n",
    "    \n",
    "    train_part_df = train_data[train_data['class_id'].isin(train_part_id)]\n",
    "    validate_part_df = train_data[train_data['class_id'].isin(validate_part_id)]\n",
    "\n",
    "    train_part_data = create_dnn_data(train_part_df)\n",
    "    train_part_target = extract_array_from_series(train_part_df['target'])\n",
    "    \n",
    "    validate_part_data = create_dnn_data(validate_part_df)\n",
    "    validate_part_target = extract_array_from_series(validate_part_df['target'])\n",
    "    \n",
    "    print('fold: %d th train :-)' % (num_fold))\n",
    "    print('Train size: {} Valide size: {}'.format(train_part_df.shape[0], validate_part_df.shape[0]))\n",
    "    print('Train category: {} Valide category: {}'.format(train_part_id.shape[0], validate_part_id.shape[0]))\n",
    "\n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "            AccuracyEvaluation(validation_data=(validate_part_data,  validate_part_target), interval=1, \\\n",
    "                class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(validate_part_id)], eval_df = validate_part_df)\n",
    "            ]\n",
    "    \n",
    "    zs_model = create_siae()\n",
    "    if num_fold == 0:\n",
    "        print (zs_model.summary())\n",
    "    zs_model.fit(train_part_data + [train_part_target],  \n",
    "                 validation_data = (validate_part_data + [validate_part_target], None),\n",
    "                  epochs=50, batch_size = 32, shuffle=True, verbose = 1, callbacks=callbacks)\n",
    "    break\n",
    "#     model = lgbm_train(train_part_data[0], train_part_target, validate_part_data[0], validate_part_target, num_fold, fold)\n",
    "    num_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_model.save(path + 'zs_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path + '/DatasetA_test_20180813/DatasetA_test/image.txt', header = None, names = ['img_id'])\n",
    "imag_path = path + '/DatasetA_test_20180813/DatasetA_test/test/'\n",
    "test_data['img'] = test_data['img_id'].apply(lambda id: read_image(imag_path, id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 70, 70, 3)    0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 32, 32, 64)   9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 32, 32, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 34, 34, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 16, 16, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 16, 16, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 16, 16, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 16, 16, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 16, 16, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 16, 16, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 16, 16, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 16, 16, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 16, 16, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 16, 16, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 16, 16, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 16, 16, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 16, 16, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 16, 16, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 16, 16, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 16, 16, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 16, 16, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 16, 16, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 16, 16, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 16, 16, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 16, 16, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 16, 16, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 16, 16, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 16, 16, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 16, 16, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 16, 16, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 16, 16, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 16, 16, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 16, 16, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 16, 16, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 8, 8, 128)    0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 8, 8, 128)    512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 8, 8, 128)    0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 8, 8, 160)    0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 8, 8, 160)    640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 8, 8, 160)    0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 8, 8, 192)    0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 8, 8, 192)    768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 8, 8, 192)    0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 8, 8, 224)    0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 8, 8, 224)    896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 8, 8, 224)    0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 8, 8, 256)    0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 8, 8, 256)    0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 8, 8, 128)    0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 8, 8, 288)    0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 8, 8, 288)    1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 8, 8, 288)    0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 8, 8, 128)    36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 8, 8, 128)    0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 8, 8, 320)    0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 8, 8, 320)    1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 8, 8, 320)    0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 8, 8, 128)    40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 8, 8, 128)    0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 8, 8, 352)    0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 8, 8, 352)    1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 8, 8, 352)    0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 8, 8, 128)    45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 8, 8, 128)    0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 8, 8, 384)    0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 8, 8, 384)    1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 8, 8, 384)    0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 8, 8, 128)    49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 8, 8, 128)    0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 8, 8, 416)    0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 8, 8, 416)    1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 8, 8, 416)    0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 8, 8, 128)    53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 8, 8, 448)    0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 8, 8, 448)    1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 8, 8, 448)    0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 8, 8, 128)    57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 8, 8, 480)    0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 8, 8, 480)    1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 8, 8, 480)    0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 8, 8, 128)    61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 8, 8, 512)    0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 8, 8, 512)    2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 8, 8, 512)    0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 8, 8, 256)    131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 4, 4, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 4, 4, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 4, 4, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 4, 4, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 4, 4, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 4, 4, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 4, 4, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 4, 4, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 4, 4, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 4, 4, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 4, 4, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 4, 4, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 4, 4, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 4, 4, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 4, 4, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 4, 4, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 4, 4, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 4, 4, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 4, 4, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 4, 4, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 4, 4, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 4, 4, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 4, 4, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 4, 4, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 4, 4, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 4, 4, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 4, 4, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 4, 4, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 4, 4, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 4, 4, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 4, 4, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 4, 4, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 4, 4, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 4, 4, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 4, 4, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 4, 4, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 4, 4, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 4, 4, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 4, 4, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 4, 4, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 4, 4, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 4, 4, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 4, 4, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 4, 4, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 4, 4, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 4, 4, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 4, 4, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 4, 4, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 4, 4, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 4, 4, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 4, 4, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 4, 4, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 4, 4, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 4, 4, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 4, 4, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 4, 4, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 4, 4, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 4, 4, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 4, 4, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 4, 4, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 4, 4, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 4, 4, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 4, 4, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 4, 4, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 4, 4, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 4, 4, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 4, 4, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 4, 4, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 4, 4, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 4, 4, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 4, 4, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 4, 4, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 4, 4, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 4, 4, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 4, 4, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 4, 4, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 4, 4, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 4, 4, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 4, 4, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 4, 4, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 4, 4, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 4, 4, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 4, 4, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 4, 4, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 4, 4, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 4, 4, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 4, 4, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 4, 4, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 4, 4, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 4, 4, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 4, 4, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 4, 4, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 4, 4, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 4, 4, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 4, 4, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 4, 4, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 4, 4, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 4, 4, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 4, 4, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 4, 4, 1024)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 4, 4, 512)    524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 2, 2, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 2, 2, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 2, 2, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 2, 2, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 2, 2, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 2, 2, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 2, 2, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 2, 2, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 2, 2, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 2, 2, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 2, 2, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 2, 2, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 2, 2, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 2, 2, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 2, 2, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 2, 2, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 2, 2, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 2, 2, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 2, 2, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 2, 2, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 2, 2, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 2, 2, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 2, 2, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 2, 2, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 2, 2, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 2, 2, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 2, 2, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 2, 2, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 2, 2, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 2, 2, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 2, 2, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 2, 2, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 2, 2, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 2, 2, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 2, 2, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 2, 2, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 2, 2, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 2, 2, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 2, 2, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 2, 2, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 2, 2, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 2, 2, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 2, 2, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 2, 2, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 2, 2, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 2, 2, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 2, 2, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 2, 2, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 2, 2, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 2, 2, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 2, 2, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 2, 2, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 2, 2, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 2, 2, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 2, 2, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 2, 2, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 2, 2, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 2, 2, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 2, 2, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 2, 2, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 2, 2, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 2, 2, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 2, 2, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 2, 2, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 2, 2, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 2, 2, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 2, 2, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 2, 2, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 2, 2, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 2, 2, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 2, 2, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 2, 2, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 2, 2, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 190)          194750      avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,232,254\n",
      "Trainable params: 7,148,606\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# def sub(imgs):\n",
    "img_model = DenseNet(blocks = [6, 12, 24, 16], \n",
    "                                cat_max = train_target.shape[1],\n",
    "                                weight_decay = 1e-4, \n",
    "                                kernel_initializer = 'glorot_normal',\n",
    "                                reduction = 0.5).model\n",
    "# img_model = small_densenet(blocks = [6, 12, 24, 16], img_input_shape=(64, 64, 3), classes = train_target.shape[1])\n",
    "img_model = Model(inputs = img_model.inputs, outputs = img_model.get_layer(name = 'avg_pool').output)\n",
    "img_model.load_weights(path + '/model_sub/6_12_24_16_03274/model_0_2018_09_07_20_58_46.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14633/14633 [==============================] - 106s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test_img = extract_array_from_series(test_data['img'])\n",
    "test_img = vgg16.preprocess_input(test_img)\n",
    "test_img_feature_map = img_model.predict(test_img, verbose = 1)\n",
    "\n",
    "train_id = train_data['class_id'].unique()\n",
    "class_id_emb_attr.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_partial_model = Model(inputs = zs_model.inputs[:2], outputs = zs_model.outputs[0])\n",
    "test_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)]\n",
    "pred_nearest_class_id = find_nearest_class(test_class_id_emb_attr, zs_partial_model, test_data, test_img_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_label = time.strftime('_%Y_%m_%d_%H_%M_%S', time.gmtime())\n",
    "sub_name = path + '/model_sub/sub' + time_label + '.txt'\n",
    "sub = pd.DataFrame(pred_nearest_class_id, index = test_data['img_id'])\n",
    "sub.to_csv(sub_name, header = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ZJL210', 'ZJL217', 'ZJL218', ..., 'ZJL214', 'ZJL237', 'ZJL215'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nearest_class_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
