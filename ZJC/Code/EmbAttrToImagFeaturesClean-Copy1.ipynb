{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import Model, Sequential\n",
    "# from keras.applications import resnet50, vgg16, densenet\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras import layers\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "# from skimage.io import imread\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "path = '../Data/'\n",
    "\n",
    "# class_emb = pd.read_csv(path + '/DatasetA_train_20180813/class_wordembeddings.txt', \n",
    "#                         index_col = 0, sep = ' ', header = None)\n",
    "# class_emb.index.name = 'class_name'\n",
    "# # class_emb_vec = pd.DataFrame(index = class_emb.index)\n",
    "# class_emb = class_emb.apply(lambda s: np.array([float(x) for x in s]), axis = 1)\n",
    "\n",
    "# class_id_to_name = pd.read_csv(path + '/DatasetA_train_20180813/label_list.txt', \n",
    "#                                index_col = 'class_name', sep = '\\t', header = None, names = ['class_id', 'class_name'])\n",
    "\n",
    "# attr_list = pd.read_csv(path + '/DatasetA_train_20180813/attribute_list.txt', index_col = 0, sep = '\\t', header = None)\n",
    "\n",
    "# attributes_per_class = pd.read_csv(path + '/DatasetA_train_20180813/attributes_per_class.txt', \n",
    "#                                    index_col = 0, sep = '\\t', header = None)\n",
    "# attributes_per_class.index.name = 'class_id'\n",
    "# attributes_per_class = attributes_per_class.apply(lambda s: np.array([float(x) for x in s]), axis = 1)\n",
    "\n",
    "# class_id_emb_attr = class_id_to_name.copy()\n",
    "# class_id_emb_attr['emb'] = class_emb\n",
    "# class_id_emb_attr.reset_index(inplace = True)\n",
    "# class_id_emb_attr.set_index('class_id', inplace = True)\n",
    "# class_id_emb_attr['attr'] = attributes_per_class\n",
    "\n",
    "# with open(path + 'class_id_emb_attr.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(class_id_emb_attr, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(path + '/DatasetA_train_20180813/train.txt', index_col = 'class_id', \n",
    "#                          sep = '\\t', header = None, names = ['image_id', 'class_id'])\n",
    "# train_data = train_data.merge(class_id_emb_attr, how = 'left', on = 'class_id')\n",
    "\n",
    "# imag_path = path + r'/DatasetA_train_20180813/train/'\n",
    "# def read_image(image_id):\n",
    "#     img = image.load_img(imag_path + image_id)\n",
    "#     img = image.img_to_array(img)\n",
    "# #     img= vgg16.preprocess_input(image.img_to_array(img))\n",
    "#     return img\n",
    "# train_data['img'] = train_data['image_id'].apply(lambda id: read_image(id))\n",
    "\n",
    "# train_data.reset_index(inplace = True)\n",
    "with open(path + 'class_id_emb_attr.pickle', 'rb') as handle:\n",
    "    class_id_emb_attr = pickle.load(handle)\n",
    "    \n",
    "with open(path + 'train_img.pickle', 'rb') as handle:\n",
    "    train_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f964e93e518>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage import io\n",
    "from skimage import transform\n",
    "\n",
    "img = train_data.iloc[5000].img / 255\n",
    "\n",
    "afine_tf = transform.AffineTransform(shear=-0.2)\n",
    "\n",
    "# Apply transform to image data\n",
    "modified = transform.warp(img, inverse_map=afine_tf)\n",
    "\n",
    "# Display the result\n",
    "# io.imshow(modified)\n",
    "# io.imshow(img)\n",
    "pyplot.subplot(121)\n",
    "pyplot.imshow(img)\n",
    "pyplot.subplot(122)\n",
    "pyplot.imshow(modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 81.,  69.,  21.],\n",
       "        [ 86.,  74.,  26.],\n",
       "        [ 85.,  75.,  26.],\n",
       "        ...,\n",
       "        [ 78.,  81.,  38.],\n",
       "        [ 97., 100.,  57.],\n",
       "        [130., 133.,  90.]],\n",
       "\n",
       "       [[ 90.,  79.,  51.],\n",
       "        [ 89.,  78.,  50.],\n",
       "        [ 84.,  72.,  46.],\n",
       "        ...,\n",
       "        [ 75.,  75.,  49.],\n",
       "        [104., 104.,  76.],\n",
       "        [121., 120.,  92.]],\n",
       "\n",
       "       [[ 76.,  66.,  57.],\n",
       "        [ 69.,  60.,  51.],\n",
       "        [ 60.,  51.,  44.],\n",
       "        ...,\n",
       "        [ 99.,  96.,  87.],\n",
       "        [ 76.,  73.,  64.],\n",
       "        [ 53.,  49.,  40.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 15.,  21.,  19.],\n",
       "        [ 25.,  34.,  31.],\n",
       "        [ 27.,  39.,  35.],\n",
       "        ...,\n",
       "        [ 26.,  30.,  13.],\n",
       "        [ 11.,   9.,   0.],\n",
       "        [ 11.,   4.,   0.]],\n",
       "\n",
       "       [[ 53.,  55.,  54.],\n",
       "        [ 37.,  41.,  40.],\n",
       "        [ 36.,  42.,  38.],\n",
       "        ...,\n",
       "        [  2.,  10.,   0.],\n",
       "        [ 11.,  10.,   5.],\n",
       "        [ 25.,  21.,  18.]],\n",
       "\n",
       "       [[ 74.,  72.,  73.],\n",
       "        [ 46.,  46.,  44.],\n",
       "        [ 39.,  44.,  40.],\n",
       "        ...,\n",
       "        [ 39.,  49.,  38.],\n",
       "        [ 22.,  23.,  18.],\n",
       "        [  3.,   2.,   0.]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[2].img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = train_data['class_id'].unique()\n",
    "category_dict = dict((category[i], i) for i in range(category.shape[0]))\n",
    "\n",
    "# vgg_model = vgg16.VGG16(include_top=True, weights = None, input_shape=(64, 64, 3), classes = train_data['class_id'].unique().shape[0])\n",
    "\n",
    "\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_y = pickle.load(handle)\n",
    "\n",
    "# input = Input(shape = (2048, ))\n",
    "# dense = Dense(2048, activation=\"relu\")(input)\n",
    "# dense = Dropout(0.5)(dense)\n",
    "# dense = Dense(2048, activation=\"relu\")(input)\n",
    "# dense = Dense(1024, activation=\"relu\")(input)\n",
    "# dense = Dense(category.shape[0], activation=\"softmax\")(input)\n",
    "\n",
    "# vgg_model = Model(input, dense)\n",
    "\n",
    "# vgg_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "# print (vgg_model.summary())\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "# train_data['target'] = list(train_image_feature_map)\n",
    "\n",
    "def small_vgg(img_input_shape, classes):\n",
    "    # Block 1\n",
    "    img_input = Input(shape = (img_input_shape))\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "#     # Block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "#     # Block 3\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    \n",
    "#     # Block 4\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    \n",
    "#     # Block 5\n",
    "#     x = layers.Conv2D(256, (3, 3),\n",
    "#                       activation='relu',\n",
    "#                       padding='same',\n",
    "#                       name='block5_conv1')(x)\n",
    "#     x = layers.Conv2D(256, (3, 3),\n",
    "#                       activation='relu',\n",
    "#                       padding='same',\n",
    "#                       name='block5_conv2')(x)\n",
    "#     x = layers.Conv2D(256, (3, 3),\n",
    "#                       activation='relu',\n",
    "#                       padding='same',\n",
    "#                       name='block5_conv3')(x)\n",
    "#     x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    # Classification block\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "#     x = layers.Dense(1024, activation='relu', name='fc1')(x)\n",
    "#     x = layers.Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    model = Model(img_input, x)\n",
    "    print (model.summary())\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def small_densenet(img_input_shape, classes, blocks = [6, 12, 24, 16]):\n",
    "    img_input = Input(shape = (img_input_shape))\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=3, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "    \n",
    "    x = densenet.dense_block(x, blocks[0], name='conv2')\n",
    "    x = densenet.transition_block(x, 0.5, name='pool2')\n",
    "    x = densenet.dense_block(x, blocks[1], name='conv3')\n",
    "    x = densenet.transition_block(x, 0.5, name='pool3')\n",
    "    x = densenet.dense_block(x, blocks[2], name='conv4')\n",
    "    x = densenet.transition_block(x, 0.5, name='pool4')\n",
    "    x = densenet.dense_block(x, blocks[3], name='conv5')\n",
    "    \n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name='bn')(x)\n",
    "    x = layers.Activation('relu', name='relu')(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='fc')(x)\n",
    "    \n",
    "    model = Model(img_input, x)\n",
    "    print (model.summary())\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "train_img = extract_array_from_series(train_data['img'])\n",
    "train_img = vgg16.preprocess_input(train_img)\n",
    "OneHotEncoder = sklearn.preprocessing.OneHotEncoder()\n",
    "train_target = train_data['class_id'].apply(lambda id: category_dict[id]).values\n",
    "train_target = OneHotEncoder.fit_transform(np.reshape(train_target, (-1, 1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train target nunique:  190 Validate target nuique:  190\n",
      "Train on 30576 samples, validate on 7645 samples\n",
      "Epoch 1/10\n",
      "30576/30576 [==============================] - 646s 21ms/step - loss: 3.7635 - categorical_accuracy: 0.1645 - val_loss: 3.9950 - val_categorical_accuracy: 0.1440\n",
      "Epoch 2/10\n",
      "30576/30576 [==============================] - 656s 21ms/step - loss: 3.5163 - categorical_accuracy: 0.2014 - val_loss: 3.5633 - val_categorical_accuracy: 0.1996\n",
      "Epoch 3/10\n",
      "30576/30576 [==============================] - 658s 22ms/step - loss: 3.3222 - categorical_accuracy: 0.2366 - val_loss: 3.5310 - val_categorical_accuracy: 0.2114\n",
      "Epoch 4/10\n",
      "30576/30576 [==============================] - 652s 21ms/step - loss: 3.1632 - categorical_accuracy: 0.2608 - val_loss: 3.5205 - val_categorical_accuracy: 0.2126\n",
      "Epoch 5/10\n",
      "30576/30576 [==============================] - 653s 21ms/step - loss: 3.0152 - categorical_accuracy: 0.2864 - val_loss: 3.4801 - val_categorical_accuracy: 0.2275\n",
      "Epoch 6/10\n",
      "30576/30576 [==============================] - 653s 21ms/step - loss: 2.8761 - categorical_accuracy: 0.3114 - val_loss: 3.3676 - val_categorical_accuracy: 0.2391\n",
      "Epoch 7/10\n",
      "30576/30576 [==============================] - 643s 21ms/step - loss: 2.7443 - categorical_accuracy: 0.3354 - val_loss: 3.5025 - val_categorical_accuracy: 0.2323\n",
      "Epoch 8/10\n",
      "30576/30576 [==============================] - 657s 21ms/step - loss: 2.6284 - categorical_accuracy: 0.3577 - val_loss: 3.3872 - val_categorical_accuracy: 0.2483\n",
      "Epoch 9/10\n",
      "30576/30576 [==============================] - 653s 21ms/step - loss: 2.4952 - categorical_accuracy: 0.3843 - val_loss: 3.4574 - val_categorical_accuracy: 0.2445\n"
     ]
    }
   ],
   "source": [
    "fold = 5\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "num_fold = 0\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "\n",
    "for train_index, test_index in kf.split(train_img):\n",
    "    train_part_img = train_img[train_index]\n",
    "    validate_part_img = train_img[test_index]\n",
    "    \n",
    "    train_part_target = train_target[train_index]\n",
    "    validate_part_target = train_target[test_index]\n",
    "    \n",
    "    print ('Train target nunique: ', np.unique(np.argwhere(train_part_target == 1)[:, 1]).shape[0], \n",
    "           'Validate target nuique: ', np.unique(np.argwhere(validate_part_target == 1)[:, 1]).shape[0])\n",
    "#     model = vgg16.VGG16(include_top=True, weights = None, input_shape=(64, 64, 3), classes = category.shape[0])\n",
    "#     model = resnet50.ResNet50(include_top=True, weights = None, input_shape=(224, 224, 3), classes = category.shape[0])\n",
    "#     print (model.summary())\n",
    "#     model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "    img_model = small_densenet(blocks = [2, 2, 2, 2], img_input_shape=(64, 64, 3), classes = train_target.shape[1]) \n",
    "#     print (img_model.summary())\n",
    "    # img_model = small_vgg(img_input_shape = (64, 64, 3), classes = train_target.shape[1])\n",
    "    h = img_model.fit(train_part_img, train_part_target, validation_data=(validate_part_img, validate_part_target), \n",
    "                  epochs=10, batch_size = 64, shuffle=True, verbose = 1, \n",
    "                  callbacks=[EarlyStopping(monitor='val_loss', patience=3, verbose=0)])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38221, 64, 64, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(h.history)\n",
    "# df = df.append(df)\n",
    "# df.groupby(df.index).agg({'mean', 'max', 'median'})\n",
    "# h.epoch\n",
    "# x = pd.DataFrame()\n",
    "# x.append(df)\n",
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n03598930', 'jigsaw_puzzle', 0.023861792), ('n02095314', 'wire-haired_fox_terrier', 0.022931756), ('n04589890', 'window_screen', 0.021361042)]\n"
     ]
    }
   ],
   "source": [
    "# np.asarray(list(train_data['img'])).shape\n",
    "# train_data[train_data['class_id'] == 'ZJL1']\n",
    "# train_data['class_id'].value_counts().hist()\n",
    "# train_data.head()\n",
    "# class_id_emb_attr.iloc[0].name\n",
    "# resnet50_model = ResNet50(weights='imagenet', input_shape=(224, 224, 3))\n",
    "img = image.load_img(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg', target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = vgg16.preprocess_input(img)\n",
    "preds = vgg_model.predict(np.expand_dims(img, axis=0))\n",
    "print('Predicted:', vgg16.decode_predictions(preds, top=3)[0])\n",
    "# imread(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg')\n",
    "# image.img_to_array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_connect_layer(input, hidden_dim):\n",
    "    full_connect = input\n",
    "    for hn in hidden_dim:\n",
    "        fc_in = full_connect\n",
    "        # if self.full_connect_dropout > 0:\n",
    "        #     full_connect = Dropout(self.full_connect_dropout)(full_connect)\n",
    "        # full_connect = BatchNormalization()(full_connect)\n",
    "        # full_connect = Dense(hn, kernel_regularizer = l2(0.001), activity_regularizer = l1(0.001))(full_connect)\n",
    "        full_connect = Concatenate()([Dense(hn, kernel_initializer='lecun_uniform', activation = 'relu')(full_connect), \n",
    "            Dense(hn, kernel_initializer='lecun_uniform', activation = 'sigmoid')(full_connect)])\n",
    "        # full_connect = Dense(hn, kernel_initializer='lecun_uniform', activation = 'sigmoid')(full_connect)\n",
    "        # full_connect = self.act_blend(full_connect)\n",
    "        # if self.full_connect_dropout > 0:\n",
    "        #     full_connect = Dropout(self.full_connect_dropout)(full_connect) #Dropout(self.full_connect_dropout)(full_connect)\n",
    "        full_connect = Concatenate()([fc_in, full_connect])\n",
    "    return full_connect\n",
    "\n",
    "def create_dnn():\n",
    "    alpha = 0.03\n",
    "    attr_input = Input(shape = (30,))\n",
    "    word_emb = Input(shape = (300,))\n",
    "    imag_classifier = Input(shape = (1024,))\n",
    "\n",
    "    attr_dense = Dense(64, use_bias = False)(attr_input)\n",
    "#     attr_dense = Dense(512)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(256)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(300, activation=\"relu\")(attr_dense)\n",
    "    # attr_dense = Dense(512, activation=\"relu\")(attr_dense)\n",
    "\n",
    "    attr_word_emb = Concatenate()([word_emb, attr_dense])\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb, hidden_dim = [2048, 2048])\n",
    "    attr_word_emb_dense = Dense(1024, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = attr_word_emb\n",
    "#     attr_word_emb_dense = Dense(4096, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(1024)(attr_word_emb)\n",
    "#     attr_word_emb_dense = LeakyReLU(alpha=alpha)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(512)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = LeakyReLU(alpha=alpha)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(256)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = LeakyReLU(alpha=alpha)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(128)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = LeakyReLU(alpha=alpha)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dropout(0.2)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(2048, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(1024, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dropout(0.2)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(512, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dropout(0.2)(attr_word_emb_dense)\n",
    "    # attr_word_emb_dense = Dense(2048, activation=\"sigmoid\", kernel_regularizer=keras.regularizers.l2(0.01))(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(1024, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(2048, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(4096, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(8192, activation=\"relu\")(attr_word_emb_dense)\n",
    "\n",
    "    # mse = Dense(6, activation=\"softmax\")(dense_output)\n",
    "#     vgg_input = vgg_model.input\n",
    "#     vgg_output = Flatten()(vgg_model.output)\n",
    "#     vgg_output = Dense(1024, activation=\"sigmoid\")(vgg_output)\n",
    "\n",
    "    # mse_loss = keras.losses.mean_squared_error(vgg_output, attr_word_emb_dense)\n",
    "\n",
    "    model = Model([attr_input, word_emb], outputs = attr_word_emb_dense) #, vgg_output])\n",
    "    # model.add_loss(mse_loss)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "def find_nearest_class(class_id_emb_attr, model, eval_df, img_feature_map = None):\n",
    "    if img_feature_map is None:\n",
    "        img_feature_map = np.reshape(vgg_model.predict(np.asarray(list(eval_df['img'])), verbose = 1), (eval_img.shape[0], -1))\n",
    "    cand_feature_map = model.predict(create_dnn_data(class_id_emb_attr))\n",
    "    # img_feature_map = np.repeat(img_feature_map, [cand_feature_map.shape[0]] * img_feature_map.shape[0], axis = 0)\n",
    "    nearest_class_id = ['ZJL'] * eval_df.shape[0]\n",
    "    for i in range(img_feature_map.shape[0]):\n",
    "        img = img_feature_map[i]\n",
    "        dis = np.linalg.norm(img - cand_feature_map, axis = 1)\n",
    "        min_ind = np.where(dis == np.amin(dis))[0]\n",
    "        if len(min_ind) > 1:\n",
    "            print ('eval img id: ', eval_df.iloc[i]['class_id'], 'has multiple best candidates: ', len(min_ind), 'min val: ', np.amin(dis))\n",
    "#         print (i, img, class_id_emb_attr.iloc[min_ind[0]].name)\n",
    "        nearest_class_id[i] = class_id_emb_attr.iloc[min_ind[0]].name\n",
    "#     print (nearest_class_id)\n",
    "    return np.asarray(nearest_class_id)\n",
    "    \n",
    "    \n",
    "def extract_array_from_series(s):\n",
    "    return np.asarray(list(s))\n",
    "    \n",
    "def create_dnn_data(df):\n",
    "    return [extract_array_from_series(df['attr']), extract_array_from_series(df['emb'])]\n",
    "    \n",
    "class AccuracyEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_interval = 1000000, verbose = 2, \\\n",
    "            scores = [], class_id_emb_attr = None, eval_df = None):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        # print(\"y_val shape:{0}\".format(self.y_val.shape))\n",
    "        self.batch_interval = batch_interval\n",
    "        self.verbose = verbose\n",
    "        self.scores = scores\n",
    "        self.class_id_emb_attr = class_id_emb_attr\n",
    "        self.eval_df = eval_df\n",
    "#         self.img_feature_map = self.y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            pred_nearest_class_id = find_nearest_class(self.class_id_emb_attr, self.model, self.eval_df, self.y_val)\n",
    "            true_class_id = self.eval_df['class_id'].values\n",
    "#             print (pred_nearest_class_id, \"\\n\", true_class_id)\n",
    "            right_num = np.sum(pred_nearest_class_id == true_class_id)\n",
    "            score = right_num / true_class_id.shape[0]\n",
    "            self.scores.append(\"epoch:{0} {1}\".format(epoch + 1, score))\n",
    "            print(\"\\n Accuracy epoch: %d - score: %.6f \\n %d/%d\" % (epoch+1, score, right_num, true_class_id.shape[0]))\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "        if(self.verbose >= 2) and (batch % self.batch_interval == 0):\n",
    "            # y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            # loss = metrics.log_loss(self.y_val, y_pred)\n",
    "            print(\"Hi! on_batch_end() , batch=\",batch,\",logs:\",logs)\n",
    "            # print(\"Valide size=\",y_pred.shape[0], \"  Valide loss=\",loss)\n",
    "            \n",
    "def lgbm_train(train_part, train_part_label, valide_part, valide_part_label, fold_seed,\n",
    "        fold = 5, train_weight = None, valide_weight = None, flags = None):\n",
    "    \"\"\"\n",
    "    LGBM Training\n",
    "    \"\"\"\n",
    "    print(\"-----LGBM training-----\")\n",
    "\n",
    "    d_train = lgb.Dataset(train_part, train_part_label) #, categorical_feature = CATEGORY_FEATURES) #, init_score = train_part[:, -1])\n",
    "    d_valide = lgb.Dataset(valide_part, valide_part_label) #, categorical_feature = CATEGORY_FEATURES) #, init_score = valide_part[:, -1])\n",
    "    params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt', #'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            # 'num_leaves':-1,\n",
    "            'min_sum_hessian_in_leaf':None,\n",
    "            'max_depth':7,\n",
    "            'learning_rate':0.005,\n",
    "            'feature_fraction':0.1,\n",
    "            'verbose':-1,\n",
    "            'num_boost_round':3000,\n",
    "            'drop_rate':None,\n",
    "            'bagging_fraction':0.6,\n",
    "            'bagging_freq':5,\n",
    "            'early_stopping_round':100,\n",
    "            # 'min_data_in_leaf':100,\n",
    "            'max_bin': None,\n",
    "            'scale_pos_weight':None,\n",
    "        }\n",
    "    print (\"lightgbm params: {0}\\n\".format(params))\n",
    "\n",
    "    bst = lgb.train(\n",
    "                    params ,\n",
    "                    d_train,\n",
    "                    verbose_eval = 200,\n",
    "                    valid_sets = [d_train, d_valide],\n",
    "                    # feature_name= keras_train.DENSE_FEATURE_LIST,\n",
    "                    #feval = gini_lgbm\n",
    "                    #num_boost_round = 1\n",
    "                    )\n",
    "    #pred = model_eval(bst, 'l', valide_part)\n",
    "    #print(pred[:10])\n",
    "    #print(valide_part_label[:10])\n",
    "    #print(valide_part[:10, -1])\n",
    "    # exit(0)\n",
    "    feature_imp = bst.feature_importance(importance_type = 'gain')\n",
    "    sort_ind = np.argsort(feature_imp)[::-1]\n",
    "    print (np.c_[np.array(FEATURE_LIST)[sort_ind], feature_imp[sort_ind]][:10])\n",
    "    # print (np.array(keras_train.FEATURE_LIST)[np.argsort(feature_imp)])\n",
    "    # exit(0)\n",
    "    # cv_result = lgb.cv(params, d_train, nfold=fold) #, feval = gini_lgbm)\n",
    "    # pd.DataFrame(cv_result).to_csv('cv_result', index = False)\n",
    "    # exit(0)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_y = pickle.load(handle)\n",
    "# img_model_flat = Model(input = img_model.input, output = img_model.get_layer(name = 'avg_pool').output)\n",
    "# train_data['target'] = list(train_y) #\n",
    "# train_data['target'] = list(img_model_flat.predict(train_img, verbose = 1))\n",
    "img_model_flat = pd.read_csv(path + 'model_sub/6_12_24_16_03252/sub_2018_09_07_14_53_24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model_flat.set_index('image_id', inplace = True)\n",
    "train_data['target'] = img_model_flat.apply(lambda s: np.asarray(s.astype(float)), axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1a8cc24518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_model_flat['1'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>emb</th>\n",
       "      <th>attr</th>\n",
       "      <th>img</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...</td>\n",
       "      <td>[-0.11140289, 0.03374281, -0.52496225, 0.31107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...</td>\n",
       "      <td>[-0.15818031, 0.21697168, -0.27058864, 0.10062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....</td>\n",
       "      <td>[0.14246145, -0.100540064, 0.39058790000000004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>7d93ef45972154aae150b4f9980a79c0.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....</td>\n",
       "      <td>[0.030461132999999998, -0.014244867, 0.0410932...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...</td>\n",
       "      <td>[0.50596607, -0.44599533, 0.017522344, 0.51942...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_id                               image_id class_name  \\\n",
       "0     ZJL1  a6394b0f513290f4651cc46792e5ac86.jpeg   goldfish   \n",
       "1     ZJL1  2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg   goldfish   \n",
       "2     ZJL1  eda9f3bef2bd8da038f6acbc8355fc25.jpeg   goldfish   \n",
       "3     ZJL1  7d93ef45972154aae150b4f9980a79c0.jpeg   goldfish   \n",
       "4     ZJL1  fb901b4f9a8e396c1d0155bccc5e5671.jpeg   goldfish   \n",
       "\n",
       "                                                 emb  \\\n",
       "0  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "1  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "2  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "3  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "4  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "\n",
       "                                                attr  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "\n",
       "                                                 img  \\\n",
       "0  [[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...   \n",
       "1  [[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...   \n",
       "2  [[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....   \n",
       "3  [[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....   \n",
       "4  [[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...   \n",
       "\n",
       "                                              target  \n",
       "0  [-0.11140289, 0.03374281, -0.52496225, 0.31107...  \n",
       "1  [-0.15818031, 0.21697168, -0.27058864, 0.10062...  \n",
       "2  [0.14246145, -0.100540064, 0.39058790000000004...  \n",
       "3  [0.030461132999999998, -0.014244867, 0.0410932...  \n",
       "4  [0.50596607, -0.44599533, 0.017522344, 0.51942...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 th train :-)\n",
      "Train size: 30502 Valide size: 7719\n",
      "Train category: 152 Valide category: 38\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_43 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_44 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 32)           960         input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 332)          0           input_44[0][0]                   \n",
      "                                                                 dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 332)          1328        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 2048)         681984      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2048)         8192        dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 1024)         2098176     batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1024)         4096        dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 1024)         1049600     batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 1024)         1049600     dense_57[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,893,936\n",
      "Trainable params: 4,887,128\n",
      "Non-trainable params: 6,808\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 30502 samples, validate on 7719 samples\n",
      "Epoch 1/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2659 - val_loss: 0.2900\n",
      "\n",
      " Accuracy epoch: 1 - score: 0.162715 \n",
      " 1256/7719\n",
      "Epoch 2/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2303 - val_loss: 0.2823\n",
      "\n",
      " Accuracy epoch: 2 - score: 0.190569 \n",
      " 1471/7719\n",
      "Epoch 3/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2272 - val_loss: 0.2798\n",
      "\n",
      " Accuracy epoch: 3 - score: 0.211426 \n",
      " 1632/7719\n",
      "Epoch 4/100\n",
      "30502/30502 [==============================] - 97s 3ms/step - loss: 0.2255 - val_loss: 0.2784\n",
      "\n",
      " Accuracy epoch: 4 - score: 0.201581 \n",
      " 1556/7719\n",
      "Epoch 5/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2246 - val_loss: 0.2795\n",
      "\n",
      " Accuracy epoch: 5 - score: 0.206374 \n",
      " 1593/7719\n",
      "Epoch 6/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2240 - val_loss: 0.2788\n",
      "\n",
      " Accuracy epoch: 6 - score: 0.217904 \n",
      " 1682/7719\n",
      "Epoch 7/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2236 - val_loss: 0.2796\n",
      "\n",
      " Accuracy epoch: 7 - score: 0.188496 \n",
      " 1455/7719\n",
      "Epoch 8/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2231 - val_loss: 0.2780\n",
      "\n",
      " Accuracy epoch: 8 - score: 0.200155 \n",
      " 1545/7719\n",
      "Epoch 9/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2229 - val_loss: 0.2774\n",
      "\n",
      " Accuracy epoch: 9 - score: 0.205208 \n",
      " 1584/7719\n",
      "Epoch 10/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2224 - val_loss: 0.2772\n",
      "\n",
      " Accuracy epoch: 10 - score: 0.217127 \n",
      " 1676/7719\n",
      "Epoch 11/100\n",
      "30502/30502 [==============================] - 98s 3ms/step - loss: 0.2222 - val_loss: 0.2773\n",
      "\n",
      " Accuracy epoch: 11 - score: 0.197824 \n",
      " 1527/7719\n",
      "Epoch 12/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2219 - val_loss: 0.2776\n",
      "\n",
      " Accuracy epoch: 12 - score: 0.215183 \n",
      " 1661/7719\n",
      "Epoch 13/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2217 - val_loss: 0.2777\n",
      "\n",
      " Accuracy epoch: 13 - score: 0.211038 \n",
      " 1629/7719\n",
      "Epoch 14/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2214 - val_loss: 0.2768\n",
      "\n",
      " Accuracy epoch: 14 - score: 0.211815 \n",
      " 1635/7719\n",
      "Epoch 15/100\n",
      "30502/30502 [==============================] - 94s 3ms/step - loss: 0.2212 - val_loss: 0.2786\n",
      "\n",
      " Accuracy epoch: 15 - score: 0.215054 \n",
      " 1660/7719\n",
      "Epoch 16/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2208 - val_loss: 0.2783\n",
      "\n",
      " Accuracy epoch: 16 - score: 0.196398 \n",
      " 1516/7719\n",
      "Epoch 17/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2207 - val_loss: 0.2775\n",
      "\n",
      " Accuracy epoch: 17 - score: 0.201969 \n",
      " 1559/7719\n",
      "Epoch 18/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2205 - val_loss: 0.2770\n",
      "\n",
      " Accuracy epoch: 18 - score: 0.203394 \n",
      " 1570/7719\n",
      "Epoch 19/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2204 - val_loss: 0.2775\n",
      "\n",
      " Accuracy epoch: 19 - score: 0.195103 \n",
      " 1506/7719\n",
      "Epoch 20/100\n",
      "30502/30502 [==============================] - 97s 3ms/step - loss: 0.2202 - val_loss: 0.2778\n",
      "\n",
      " Accuracy epoch: 20 - score: 0.204042 \n",
      " 1575/7719\n",
      "Epoch 21/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2201 - val_loss: 0.2783\n",
      "\n",
      " Accuracy epoch: 21 - score: 0.208706 \n",
      " 1611/7719\n",
      "Epoch 22/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2199 - val_loss: 0.2772\n",
      "\n",
      " Accuracy epoch: 22 - score: 0.201321 \n",
      " 1554/7719\n",
      "Epoch 23/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2198 - val_loss: 0.2776\n",
      "\n",
      " Accuracy epoch: 23 - score: 0.195233 \n",
      " 1507/7719\n",
      "Epoch 24/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2197 - val_loss: 0.2786\n",
      "\n",
      " Accuracy epoch: 24 - score: 0.182277 \n",
      " 1407/7719\n",
      "Epoch 25/100\n",
      "30502/30502 [==============================] - 94s 3ms/step - loss: 0.2196 - val_loss: 0.2786\n",
      "\n",
      " Accuracy epoch: 25 - score: 0.183055 \n",
      " 1413/7719\n",
      "Epoch 26/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2195 - val_loss: 0.2779\n",
      "\n",
      " Accuracy epoch: 26 - score: 0.191605 \n",
      " 1479/7719\n",
      "Epoch 27/100\n",
      "30502/30502 [==============================] - 94s 3ms/step - loss: 0.2194 - val_loss: 0.2782\n",
      "\n",
      " Accuracy epoch: 27 - score: 0.181630 \n",
      " 1402/7719\n",
      "Epoch 28/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2194 - val_loss: 0.2775\n",
      "\n",
      " Accuracy epoch: 28 - score: 0.189662 \n",
      " 1464/7719\n",
      "Epoch 29/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2193 - val_loss: 0.2787\n",
      "\n",
      " Accuracy epoch: 29 - score: 0.181241 \n",
      " 1399/7719\n",
      "Epoch 30/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2192 - val_loss: 0.2786\n",
      "\n",
      " Accuracy epoch: 30 - score: 0.183184 \n",
      " 1414/7719\n",
      "Epoch 31/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2192 - val_loss: 0.2795\n",
      "\n",
      " Accuracy epoch: 31 - score: 0.191087 \n",
      " 1475/7719\n",
      "Epoch 32/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2191 - val_loss: 0.2790\n",
      "\n",
      " Accuracy epoch: 32 - score: 0.185516 \n",
      " 1432/7719\n",
      "Epoch 33/100\n",
      "30502/30502 [==============================] - 94s 3ms/step - loss: 0.2191 - val_loss: 0.2778\n",
      "\n",
      " Accuracy epoch: 33 - score: 0.186553 \n",
      " 1440/7719\n",
      "Epoch 34/100\n",
      "30502/30502 [==============================] - 94s 3ms/step - loss: 0.2190 - val_loss: 0.2787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy epoch: 34 - score: 0.189403 \n",
      " 1462/7719\n",
      "Epoch 35/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2190 - val_loss: 0.2778\n",
      "\n",
      " Accuracy epoch: 35 - score: 0.190957 \n",
      " 1474/7719\n",
      "Epoch 36/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2189 - val_loss: 0.2775\n",
      "\n",
      " Accuracy epoch: 36 - score: 0.176707 \n",
      " 1364/7719\n",
      "Epoch 37/100\n",
      "30502/30502 [==============================] - 94s 3ms/step - loss: 0.2189 - val_loss: 0.2789\n",
      "\n",
      " Accuracy epoch: 37 - score: 0.190957 \n",
      " 1474/7719\n",
      "Epoch 38/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2188 - val_loss: 0.2784\n",
      "\n",
      " Accuracy epoch: 38 - score: 0.184869 \n",
      " 1427/7719\n",
      "Epoch 39/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2188 - val_loss: 0.2778\n",
      "\n",
      " Accuracy epoch: 39 - score: 0.187719 \n",
      " 1449/7719\n",
      "Epoch 40/100\n",
      "30502/30502 [==============================] - 93s 3ms/step - loss: 0.2188 - val_loss: 0.2782\n",
      "\n",
      " Accuracy epoch: 40 - score: 0.188496 \n",
      " 1455/7719\n",
      "Epoch 41/100\n",
      "30502/30502 [==============================] - 94s 3ms/step - loss: 0.2188 - val_loss: 0.2772\n",
      "\n",
      " Accuracy epoch: 41 - score: 0.191605 \n",
      " 1479/7719\n",
      "Epoch 42/100\n",
      "30502/30502 [==============================] - 95s 3ms/step - loss: 0.2188 - val_loss: 0.2768\n",
      "\n",
      " Accuracy epoch: 42 - score: 0.194455 \n",
      " 1501/7719\n",
      "Epoch 43/100\n",
      "30502/30502 [==============================] - 94s 3ms/step - loss: 0.2187 - val_loss: 0.2772\n",
      "\n",
      " Accuracy epoch: 43 - score: 0.194973 \n",
      " 1505/7719\n",
      "Epoch 44/100\n",
      "30502/30502 [==============================] - 96s 3ms/step - loss: 0.2187 - val_loss: 0.2780\n",
      "\n",
      " Accuracy epoch: 44 - score: 0.196398 \n",
      " 1516/7719\n",
      "fold: 1 th train :-)\n",
      "Train size: 30600 Valide size: 7621\n",
      "Train category: 152 Valide category: 38\n",
      "Train on 30600 samples, validate on 7621 samples\n",
      "Epoch 1/100\n",
      "30600/30600 [==============================] - 99s 3ms/step - loss: 0.2660 - val_loss: 0.2873\n",
      "\n",
      " Accuracy epoch: 1 - score: 0.194200 \n",
      " 1480/7621\n",
      "Epoch 2/100\n",
      "30600/30600 [==============================] - 83s 3ms/step - loss: 0.2302 - val_loss: 0.2828\n",
      "\n",
      " Accuracy epoch: 2 - score: 0.198530 \n",
      " 1513/7621\n",
      "Epoch 3/100\n",
      "30600/30600 [==============================] - 82s 3ms/step - loss: 0.2272 - val_loss: 0.2766\n",
      "\n",
      " Accuracy epoch: 3 - score: 0.227267 \n",
      " 1732/7621\n",
      "Epoch 4/100\n",
      "30600/30600 [==============================] - 83s 3ms/step - loss: 0.2255 - val_loss: 0.2753\n",
      "\n",
      " Accuracy epoch: 4 - score: 0.215851 \n",
      " 1645/7621\n",
      "Epoch 5/100\n",
      "30600/30600 [==============================] - 78s 3ms/step - loss: 0.2246 - val_loss: 0.2743\n",
      "\n",
      " Accuracy epoch: 5 - score: 0.237502 \n",
      " 1810/7621\n",
      "Epoch 6/100\n",
      "30600/30600 [==============================] - 86s 3ms/step - loss: 0.2241 - val_loss: 0.2746\n",
      "\n",
      " Accuracy epoch: 6 - score: 0.236452 \n",
      " 1802/7621\n",
      "Epoch 7/100\n",
      "30600/30600 [==============================] - 80s 3ms/step - loss: 0.2236 - val_loss: 0.2744\n",
      "\n",
      " Accuracy epoch: 7 - score: 0.243538 \n",
      " 1856/7621\n",
      "Epoch 8/100\n",
      "30600/30600 [==============================] - 83s 3ms/step - loss: 0.2233 - val_loss: 0.2744\n",
      "\n",
      " Accuracy epoch: 8 - score: 0.245506 \n",
      " 1871/7621\n",
      "Epoch 9/100\n",
      "30600/30600 [==============================] - 83s 3ms/step - loss: 0.2230 - val_loss: 0.2739\n",
      "\n",
      " Accuracy epoch: 9 - score: 0.214801 \n",
      " 1637/7621\n",
      "Epoch 10/100\n",
      "30600/30600 [==============================] - 80s 3ms/step - loss: 0.2224 - val_loss: 0.2728\n",
      "\n",
      " Accuracy epoch: 10 - score: 0.239601 \n",
      " 1826/7621\n",
      "Epoch 11/100\n",
      "30600/30600 [==============================] - 80s 3ms/step - loss: 0.2224 - val_loss: 0.2742\n",
      "\n",
      " Accuracy epoch: 11 - score: 0.226479 \n",
      " 1726/7621\n",
      "Epoch 12/100\n",
      "30600/30600 [==============================] - 85s 3ms/step - loss: 0.2218 - val_loss: 0.2732\n",
      "\n",
      " Accuracy epoch: 12 - score: 0.225692 \n",
      " 1720/7621\n",
      "Epoch 13/100\n",
      "30600/30600 [==============================] - 82s 3ms/step - loss: 0.2217 - val_loss: 0.2732\n",
      "\n",
      " Accuracy epoch: 13 - score: 0.230678 \n",
      " 1758/7621\n",
      "Epoch 14/100\n",
      "30600/30600 [==============================] - 83s 3ms/step - loss: 0.2214 - val_loss: 0.2724\n",
      "\n",
      " Accuracy epoch: 14 - score: 0.234090 \n",
      " 1784/7621\n",
      "Epoch 15/100\n",
      "30600/30600 [==============================] - 80s 3ms/step - loss: 0.2211 - val_loss: 0.2735\n",
      "\n",
      " Accuracy epoch: 15 - score: 0.239339 \n",
      " 1824/7621\n",
      "Epoch 16/100\n",
      "30600/30600 [==============================] - 83s 3ms/step - loss: 0.2210 - val_loss: 0.2736\n",
      "\n",
      " Accuracy epoch: 16 - score: 0.226348 \n",
      " 1725/7621\n",
      "Epoch 17/100\n",
      "30600/30600 [==============================] - 82s 3ms/step - loss: 0.2208 - val_loss: 0.2743\n",
      "\n",
      " Accuracy epoch: 17 - score: 0.225823 \n",
      " 1721/7621\n",
      "Epoch 18/100\n",
      "30600/30600 [==============================] - 83s 3ms/step - loss: 0.2206 - val_loss: 0.2743\n",
      "\n",
      " Accuracy epoch: 18 - score: 0.228973 \n",
      " 1745/7621\n",
      "Epoch 19/100\n",
      "30600/30600 [==============================] - 81s 3ms/step - loss: 0.2205 - val_loss: 0.2734\n",
      "\n",
      " Accuracy epoch: 19 - score: 0.226217 \n",
      " 1724/7621\n",
      "Epoch 20/100\n",
      "30600/30600 [==============================] - 83s 3ms/step - loss: 0.2202 - val_loss: 0.2734\n",
      "\n",
      " Accuracy epoch: 20 - score: 0.225561 \n",
      " 1719/7621\n",
      "Epoch 21/100\n",
      "30600/30600 [==============================] - 84s 3ms/step - loss: 0.2201 - val_loss: 0.2732\n",
      "\n",
      " Accuracy epoch: 21 - score: 0.248786 \n",
      " 1896/7621\n",
      "Epoch 22/100\n",
      "30600/30600 [==============================] - 81s 3ms/step - loss: 0.2199 - val_loss: 0.2743\n",
      "\n",
      " Accuracy epoch: 22 - score: 0.243144 \n",
      " 1853/7621\n",
      "Epoch 23/100\n",
      "30600/30600 [==============================] - 80s 3ms/step - loss: 0.2199 - val_loss: 0.2762\n",
      "\n",
      " Accuracy epoch: 23 - score: 0.233303 \n",
      " 1778/7621\n",
      "Epoch 24/100\n",
      "30600/30600 [==============================] - 80s 3ms/step - loss: 0.2197 - val_loss: 0.2739\n",
      "\n",
      " Accuracy epoch: 24 - score: 0.237502 \n",
      " 1810/7621\n",
      "Epoch 25/100\n",
      "30600/30600 [==============================] - 82s 3ms/step - loss: 0.2197 - val_loss: 0.2753\n",
      "\n",
      " Accuracy epoch: 25 - score: 0.226742 \n",
      " 1728/7621\n",
      "Epoch 26/100\n",
      "30600/30600 [==============================] - 77s 3ms/step - loss: 0.2196 - val_loss: 0.2760\n",
      "\n",
      " Accuracy epoch: 26 - score: 0.232253 \n",
      " 1770/7621\n",
      "Epoch 27/100\n",
      "30600/30600 [==============================] - 82s 3ms/step - loss: 0.2195 - val_loss: 0.2737\n",
      "\n",
      " Accuracy epoch: 27 - score: 0.239470 \n",
      " 1825/7621\n",
      "Epoch 28/100\n",
      "30600/30600 [==============================] - 80s 3ms/step - loss: 0.2194 - val_loss: 0.2748\n",
      "\n",
      " Accuracy epoch: 28 - score: 0.256397 \n",
      " 1954/7621\n",
      "Epoch 29/100\n",
      "30600/30600 [==============================] - 86s 3ms/step - loss: 0.2194 - val_loss: 0.2738\n",
      "\n",
      " Accuracy epoch: 29 - score: 0.253116 \n",
      " 1929/7621\n",
      "Epoch 30/100\n",
      "30600/30600 [==============================] - 80s 3ms/step - loss: 0.2193 - val_loss: 0.2752\n",
      "\n",
      " Accuracy epoch: 30 - score: 0.245506 \n",
      " 1871/7621\n",
      "Epoch 31/100\n",
      "30600/30600 [==============================] - 84s 3ms/step - loss: 0.2192 - val_loss: 0.2768\n",
      "\n",
      " Accuracy epoch: 31 - score: 0.232122 \n",
      " 1769/7621\n",
      "Epoch 32/100\n",
      "30600/30600 [==============================] - 82s 3ms/step - loss: 0.2191 - val_loss: 0.2772\n",
      "\n",
      " Accuracy epoch: 32 - score: 0.217688 \n",
      " 1659/7621\n",
      "Epoch 33/100\n",
      "30600/30600 [==============================] - 83s 3ms/step - loss: 0.2191 - val_loss: 0.2759\n",
      "\n",
      " Accuracy epoch: 33 - score: 0.225692 \n",
      " 1720/7621\n",
      "Epoch 34/100\n",
      "30600/30600 [==============================] - 81s 3ms/step - loss: 0.2191 - val_loss: 0.2752\n",
      "\n",
      " Accuracy epoch: 34 - score: 0.227267 \n",
      " 1732/7621\n",
      "Epoch 35/100\n",
      "30600/30600 [==============================] - 82s 3ms/step - loss: 0.2190 - val_loss: 0.2763\n",
      "\n",
      " Accuracy epoch: 35 - score: 0.224905 \n",
      " 1714/7621\n",
      "Epoch 36/100\n",
      "10496/30600 [=========>....................] - ETA: 50s - loss: 0.2190"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5a42ac3e8e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     model.fit(train_part_data, train_part_target,  validation_data=(validate_part_data, validate_part_target),\n\u001b[0;32m--> 104\u001b[0;31m                   epochs=100, batch_size = 64, shuffle=True, verbose = 1, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m#     model = lgbm_train(train_part_data[0], train_part_target, validate_part_data[0], validate_part_target, num_fold, fold)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def full_connect_layer(input, hidden_dim):\n",
    "    full_connect = input\n",
    "    for hn in hidden_dim:\n",
    "        fc_in = full_connect\n",
    "        # if self.full_connect_dropout > 0:\n",
    "        #     full_connect = Dropout(self.full_connect_dropout)(full_connect)\n",
    "        full_connect = BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "#         full_connect = Activation('relu')(full_connect)\n",
    "        # full_connect = Dense(hn, kernel_regularizer = l2(0.001), activity_regularizer = l1(0.001))(full_connect)\n",
    "#         full_connect = Concatenate()([Dense(hn, kernel_initializer='lecun_uniform', activation = 'relu')(full_connect), \n",
    "#             Dense(hn, kernel_initializer='lecun_uniform', activation = 'sigmoid')(full_connect)])\n",
    "        full_connect = Dense(hn, kernel_initializer='lecun_uniform', activation = 'relu')(full_connect)\n",
    "#         full_connect = BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "#         full_connect = Activation('relu')(full_connect)\n",
    "        # full_connect = self.act_blend(full_connect)\n",
    "        # if self.full_connect_dropout > 0:\n",
    "        #     full_connect = Dropout(self.full_connect_dropout)(full_connect) #Dropout(self.full_connect_dropout)(full_connect)\n",
    "#         full_connect = Concatenate()([fc_in, full_connect])\n",
    "    return full_connect\n",
    "\n",
    "def create_dnn():\n",
    "    alpha = 0.03\n",
    "    attr_input = Input(shape = (30,))\n",
    "    word_emb = Input(shape = (300,))\n",
    "    imag_classifier = Input(shape = (1024,))\n",
    "\n",
    "    attr_dense = Dense(32, use_bias = False)(attr_input)\n",
    "#     attr_dense = Dense(512)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(256)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(300, activation=\"relu\")(attr_dense)\n",
    "    # attr_dense = Dense(512, activation=\"relu\")(attr_dense)\n",
    "\n",
    "    attr_word_emb = Concatenate()([word_emb, attr_dense])\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb, hidden_dim = [2048, 1024, 1024])\n",
    "    attr_word_emb_dense = Dense(1024, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = attr_word_emb\n",
    "#     attr_word_emb_dense = Dense(4096, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(1024)(attr_word_emb)\n",
    "#     attr_word_emb_dense = LeakyReLU(alpha=alpha)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(512)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = LeakyReLU(alpha=alpha)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(256)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = LeakyReLU(alpha=alpha)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dropout(0.2)(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dense(512, activation=\"relu\")(attr_word_emb_dense)\n",
    "#     attr_word_emb_dense = Dropout(0.2)(attr_word_emb_dense)\n",
    "    # attr_word_emb_dense = Dense(2048, activation=\"sigmoid\", kernel_regularizer=keras.regularizers.l2(0.01))(attr_word_emb_dense)\n",
    "\n",
    "\n",
    "    # mse = Dense(6, activation=\"softmax\")(dense_output)\n",
    "#     vgg_input = vgg_model.input\n",
    "#     vgg_output = Flatten()(vgg_model.output)\n",
    "#     vgg_output = Dense(1024, activation=\"sigmoid\")(vgg_output)\n",
    "\n",
    "    # mse_loss = keras.losses.mean_squared_error(vgg_output, attr_word_emb_dense)\n",
    "\n",
    "    model = Model([attr_input, word_emb], outputs = attr_word_emb_dense) #, vgg_output])\n",
    "    # model.add_loss(mse_loss)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "#data.loc[class_id] #data_atten.loc[n]\n",
    "fold = 5\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "num_fold = 0\n",
    "class_ids = train_data['class_id'].unique() #[:5]\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "\n",
    "for train_index, test_index in kf.split(class_ids):\n",
    "    train_part_id = class_ids[train_index]\n",
    "    validate_part_id = class_ids[test_index]\n",
    "    \n",
    "    train_part_df = train_data[train_data['class_id'].isin(train_part_id)]\n",
    "    validate_part_df = train_data[train_data['class_id'].isin(validate_part_id)]\n",
    "\n",
    "    train_part_data = create_dnn_data(train_part_df)\n",
    "    train_part_target = extract_array_from_series(train_part_df['target'])\n",
    "    \n",
    "    validate_part_data = create_dnn_data(validate_part_df)\n",
    "    validate_part_target = extract_array_from_series(validate_part_df['target'])\n",
    "    \n",
    "    print('fold: %d th train :-)' % (num_fold))\n",
    "    print('Train size: {} Valide size: {}'.format(train_part_df.shape[0], validate_part_df.shape[0]))\n",
    "    print('Train category: {} Valide category: {}'.format(train_part_id.shape[0], validate_part_id.shape[0]))\n",
    "\n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=30, verbose=0),\n",
    "            AccuracyEvaluation(validation_data=(validate_part_data, validate_part_target), interval=1, \\\n",
    "                class_id_emb_attr = class_id_emb_attr.loc[validate_part_id], eval_df = validate_part_df)\n",
    "            ]\n",
    "    \n",
    "    model = create_dnn()\n",
    "    if num_fold == 0:\n",
    "        print (model.summary())\n",
    "    model.fit(train_part_data, train_part_target,  validation_data=(validate_part_data, validate_part_target),\n",
    "                  epochs=100, batch_size = 64, shuffle=True, verbose = 1, callbacks=callbacks)\n",
    "    \n",
    "#     model = lgbm_train(train_part_data[0], train_part_target, validate_part_data[0], validate_part_target, num_fold, fold)\n",
    "    num_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>emb</th>\n",
       "      <th>attr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZJL1</th>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJL10</th>\n",
       "      <td>tarantula</td>\n",
       "      <td>[-0.1564, 0.38850999999999997, -0.331580000000...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJL100</th>\n",
       "      <td>drumstick</td>\n",
       "      <td>[-0.15132, 0.18007, 0.12005, 0.21443, -0.40094...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJL101</th>\n",
       "      <td>dumbbell</td>\n",
       "      <td>[-0.3159, 0.15689, -0.037299, -0.2394800000000...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.1, 0.3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJL102</th>\n",
       "      <td>flagpole</td>\n",
       "      <td>[0.06352200000000001, -0.17278, 0.12012, -0.15...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class_name                                                emb  \\\n",
       "class_id                                                                 \n",
       "ZJL1       goldfish  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "ZJL10     tarantula  [-0.1564, 0.38850999999999997, -0.331580000000...   \n",
       "ZJL100    drumstick  [-0.15132, 0.18007, 0.12005, 0.21443, -0.40094...   \n",
       "ZJL101     dumbbell  [-0.3159, 0.15689, -0.037299, -0.2394800000000...   \n",
       "ZJL102     flagpole  [0.06352200000000001, -0.17278, 0.12012, -0.15...   \n",
       "\n",
       "                                                       attr  \n",
       "class_id                                                     \n",
       "ZJL1      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...  \n",
       "ZJL10     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, ...  \n",
       "ZJL100    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "ZJL101    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.1, 0.3, ...  \n",
       "ZJL102    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_id_emb_attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
