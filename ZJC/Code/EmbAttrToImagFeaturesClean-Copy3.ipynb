{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications import resnet50, vgg16\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from keras.regularizers import l1, l2\n",
    "# from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "path = '../Data/'\n",
    "\n",
    "# class_emb = pd.read_csv(path + '/DatasetA_train_20180813/class_wordembeddings.txt', \n",
    "#                         index_col = 0, sep = ' ', header = None)\n",
    "# class_emb.index.name = 'class_name'\n",
    "# # class_emb_vec = pd.DataFrame(index = class_emb.index)\n",
    "# class_emb = class_emb.apply(lambda s: np.array([float(x) for x in s]), axis = 1)\n",
    "\n",
    "# class_id_to_name = pd.read_csv(path + '/DatasetA_train_20180813/label_list.txt', \n",
    "#                                index_col = 'class_name', sep = '\\t', header = None, names = ['class_id', 'class_name'])\n",
    "\n",
    "# attr_list = pd.read_csv(path + '/DatasetA_train_20180813/attribute_list.txt', index_col = 0, sep = '\\t', header = None)\n",
    "\n",
    "# attributes_per_class = pd.read_csv(path + '/DatasetA_train_20180813/attributes_per_class.txt', \n",
    "#                                    index_col = 0, sep = '\\t', header = None)\n",
    "# attributes_per_class.index.name = 'class_id'\n",
    "# attributes_per_class = attributes_per_class.apply(lambda s: np.array([float(x) for x in s]), axis = 1)\n",
    "\n",
    "# class_id_emb_attr = class_id_to_name.copy()\n",
    "# class_id_emb_attr['emb'] = class_emb\n",
    "# class_id_emb_attr.reset_index(inplace = True)\n",
    "# class_id_emb_attr.set_index('class_id', inplace = True)\n",
    "# class_id_emb_attr['attr'] = attributes_per_class\n",
    "\n",
    "# with open(path + 'class_id_emb_attr.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(class_id_emb_attr, handle)\n",
    "def read_image(imag_path, image_id):\n",
    "    img = image.load_img(imag_path + image_id)\n",
    "    img = image.img_to_array(img)\n",
    "#     img= vgg16.preprocess_input(image.img_to_array(img))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd60ca45048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log = pd.read_csv(path + '/log_clean', header = None)\n",
    "log[20:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(path + '/DatasetA_train_20180813/train.txt', index_col = 'class_id', \n",
    "#                          sep = '\\t', header = None, names = ['image_id', 'class_id'])\n",
    "# train_data = train_data.merge(class_id_emb_attr, how = 'left', on = 'class_id')\n",
    "\n",
    "# imag_path = path + r'/DatasetA_train_20180813/train/'\n",
    "\n",
    "# train_data['img'] = train_data['image_id'].apply(lambda id: read_image(id))\n",
    "\n",
    "# train_data.reset_index(inplace = True)\n",
    "with open(path + 'class_id_emb_attr.pickle', 'rb') as handle:\n",
    "    class_id_emb_attr = pickle.load(handle)\n",
    "class_id_emb_attr.reset_index(inplace = True)    \n",
    "with open(path + '/train_img.pickle', 'rb') as handle:\n",
    "    train_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text =  pd.read_csv(path + '/FoundInFastText', \n",
    "                        index_col = 0, sep = ' ', header = None)\n",
    "fast_text.index.name = 'class_name'\n",
    "fast_text_df = pd.DataFrame(index = fast_text.index)\n",
    "fast_text_df['emb'] = fast_text.apply(lambda s: np.array([float(x) for x in s])[:300], axis = 1)\n",
    "\n",
    "train_data = train_data.merge(fast_text_df, how = 'left', on = 'class_name')\n",
    "\n",
    "train_data['emb'] = train_data.apply(lambda s: np.hstack([s['emb_x'], s['emb_y']]), axis = 1)\n",
    "\n",
    "class_id_emb_attr = class_id_emb_attr.merge(fast_text_df, how = 'left', on = 'class_name')\n",
    "class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb_x'], s['emb_y']]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>emb_x</th>\n",
       "      <th>attr</th>\n",
       "      <th>img</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>emb_y</th>\n",
       "      <th>emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...</td>\n",
       "      <td>[0.31291956, 0.06956484, 0.34872296, 0.0408261...</td>\n",
       "      <td>[0.0002583923, 1.3706127e-09, 4.1264484e-06, 7...</td>\n",
       "      <td>[0.10102, 0.1569, -0.56942, 0.2555300000000000...</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...</td>\n",
       "      <td>[0.41405687, 0.0, 0.42773584, 0.26566932, 0.09...</td>\n",
       "      <td>[8.528514e-05, 7.096203e-13, 2.6975513e-07, 0....</td>\n",
       "      <td>[0.10102, 0.1569, -0.56942, 0.2555300000000000...</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....</td>\n",
       "      <td>[0.47680363, 0.040604584, 0.3921131, 0.0505364...</td>\n",
       "      <td>[4.0051555e-07, 2.7406966e-10, 0.006872305, 1....</td>\n",
       "      <td>[0.10102, 0.1569, -0.56942, 0.2555300000000000...</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>7d93ef45972154aae150b4f9980a79c0.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....</td>\n",
       "      <td>[0.43787628, 0.22630945, 0.9117755, 0.37130392...</td>\n",
       "      <td>[4.478419e-06, 6.6335826e-15, 4.5222535e-07, 5...</td>\n",
       "      <td>[0.10102, 0.1569, -0.56942, 0.2555300000000000...</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...</td>\n",
       "      <td>[0.09672493, 0.02039393, 0.0, 0.063967526, 0.5...</td>\n",
       "      <td>[1.1269697e-05, 1.5967143e-12, 0.000112516616,...</td>\n",
       "      <td>[0.10102, 0.1569, -0.56942, 0.2555300000000000...</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_id                               image_id class_name  \\\n",
       "0     ZJL1  a6394b0f513290f4651cc46792e5ac86.jpeg   goldfish   \n",
       "1     ZJL1  2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg   goldfish   \n",
       "2     ZJL1  eda9f3bef2bd8da038f6acbc8355fc25.jpeg   goldfish   \n",
       "3     ZJL1  7d93ef45972154aae150b4f9980a79c0.jpeg   goldfish   \n",
       "4     ZJL1  fb901b4f9a8e396c1d0155bccc5e5671.jpeg   goldfish   \n",
       "\n",
       "                                               emb_x  \\\n",
       "0  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "1  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "2  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "3  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "4  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "\n",
       "                                                attr  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "\n",
       "                                                 img  \\\n",
       "0  [[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...   \n",
       "1  [[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...   \n",
       "2  [[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....   \n",
       "3  [[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....   \n",
       "4  [[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...   \n",
       "\n",
       "                                              target  \\\n",
       "0  [0.31291956, 0.06956484, 0.34872296, 0.0408261...   \n",
       "1  [0.41405687, 0.0, 0.42773584, 0.26566932, 0.09...   \n",
       "2  [0.47680363, 0.040604584, 0.3921131, 0.0505364...   \n",
       "3  [0.43787628, 0.22630945, 0.9117755, 0.37130392...   \n",
       "4  [0.09672493, 0.02039393, 0.0, 0.063967526, 0.5...   \n",
       "\n",
       "                                               preds  \\\n",
       "0  [0.0002583923, 1.3706127e-09, 4.1264484e-06, 7...   \n",
       "1  [8.528514e-05, 7.096203e-13, 2.6975513e-07, 0....   \n",
       "2  [4.0051555e-07, 2.7406966e-10, 0.006872305, 1....   \n",
       "3  [4.478419e-06, 6.6335826e-15, 4.5222535e-07, 5...   \n",
       "4  [1.1269697e-05, 1.5967143e-12, 0.000112516616,...   \n",
       "\n",
       "                                               emb_y  \\\n",
       "0  [0.10102, 0.1569, -0.56942, 0.2555300000000000...   \n",
       "1  [0.10102, 0.1569, -0.56942, 0.2555300000000000...   \n",
       "2  [0.10102, 0.1569, -0.56942, 0.2555300000000000...   \n",
       "3  [0.10102, 0.1569, -0.56942, 0.2555300000000000...   \n",
       "4  [0.10102, 0.1569, -0.56942, 0.2555300000000000...   \n",
       "\n",
       "                                                 emb  \n",
       "0  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...  \n",
       "1  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...  \n",
       "2  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...  \n",
       "3  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...  \n",
       "4  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = train_data['class_id'].unique()\n",
    "category_dict = dict((category[i], i) for i in range(category.shape[0]))\n",
    "\n",
    "# vgg_model = vgg16.VGG16(include_top=True, weights = None, input_shape=(64, 64, 3), classes = train_data['class_id'].unique().shape[0])\n",
    "\n",
    "\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_y = pickle.load(handle)\n",
    "\n",
    "# input = Input(shape = (2048, ))\n",
    "# dense = Dense(2048, activation=\"relu\")(input)\n",
    "# dense = Dropout(0.5)(dense)\n",
    "# dense = Dense(2048, activation=\"relu\")(input)\n",
    "# dense = Dense(1024, activation=\"relu\")(input)\n",
    "# dense = Dense(category.shape[0], activation=\"softmax\")(input)\n",
    "\n",
    "# vgg_model = Model(input, dense)\n",
    "\n",
    "# vgg_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "# print (vgg_model.summary())\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "# train_data['target'] = list(train_image_feature_map)\n",
    "\n",
    "def extract_array_from_series(s):\n",
    "    return np.asarray(list(s))\n",
    "\n",
    "class DenseNet:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, cat_max, blocks, weight_decay, kernel_initializer, reduction, init_filters, growth_rate):\n",
    "        self.cat_max = cat_max\n",
    "        self.blocks = blocks\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.model = self.small_densenet(\n",
    "                classes = self.cat_max,\n",
    "                blocks = self.blocks, \n",
    "                weight_decay = self.weight_decay, \n",
    "                kernel_initializer = self.kernel_initializer,\n",
    "                init_filters = init_filters,\n",
    "                reduction = reduction,\n",
    "                growth_rate = growth_rate)\n",
    "\n",
    "    def dense_block(self, x, blocks, name, weight_decay = 1e-4, kernel_initializer = 'he_normal', growth_rate = None):\n",
    "        \"\"\"A dense block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            blocks: integer, the number of building blocks.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            output tensor for the block.\n",
    "        \"\"\"\n",
    "        for i in range(blocks):\n",
    "            x = self.conv_block(x, growth_rate, name=name + '_block' + str(i + 1), \n",
    "                weight_decay = weight_decay,\n",
    "                kernel_initializer = kernel_initializer)\n",
    "        return x\n",
    "\n",
    "    def transition_block(self, x, reduction, name, weight_decay = 1e-4, kernel_initializer = 'he_normal'):\n",
    "        \"\"\"A transition block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            reduction: float, compression rate at transition layers.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            output tensor for the block.\n",
    "        \"\"\"\n",
    "        bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                    name=name + '_bn')(x)\n",
    "        x = layers.Activation('relu', name=name + '_relu')(x)\n",
    "        x = layers.Conv2D(int(K.int_shape(x)[bn_axis] * reduction), 1,\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_conv')(x)\n",
    "        x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "        return x\n",
    "\n",
    "    def conv_block(self, x, growth_rate, name, weight_decay = 1e-4, kernel_initializer = 'he_normal'):\n",
    "        \"\"\"A building block for a dense block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            growth_rate: float, growth rate at dense layers.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            Output tensor for the block.\n",
    "        \"\"\"\n",
    "        bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "        x1 = layers.BatchNormalization(axis=bn_axis,\n",
    "                                    epsilon=1.001e-5,\n",
    "                                    name=name + '_0_bn')(x)\n",
    "        x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n",
    "        x1 = layers.Conv2D(4 * growth_rate, 1,\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_1_conv')(x1)\n",
    "        x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                    name=name + '_1_bn')(x1)\n",
    "        x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n",
    "        x1 = layers.Conv2D(growth_rate, 3,\n",
    "                        padding='same',\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_2_conv')(x1)\n",
    "        x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n",
    "        return x\n",
    "\n",
    "    def small_densenet(self, classes = None, \n",
    "                       img_input_shape = (64, 64, 3), \n",
    "                       blocks = [6, 12, 24, 16], \n",
    "                       weight_decay = 1e-4, \n",
    "                       kernel_initializer = 'he_normal',\n",
    "                       reduction = 0.5, \n",
    "                       init_filters = None, \n",
    "                       growth_rate = None):\n",
    "        img_input = Input(shape = (img_input_shape))\n",
    "#         x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "#         x = layers.Conv2D(64, 3, strides=1, use_bias=False, \n",
    "#             kernel_initializer = kernel_initializer, \n",
    "#             kernel_regularizer = l2(weight_decay),\n",
    "#             name='conv1/conv')(img_input)\n",
    "#         x = layers.BatchNormalization(\n",
    "#             axis=3, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "#         x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "#         x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "#         x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "        \n",
    "        x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "        x = layers.Conv2D(init_filters, 3, strides=1, use_bias=False, \n",
    "            kernel_initializer = kernel_initializer, \n",
    "            kernel_regularizer = l2(weight_decay),\n",
    "            name='conv1/conv')(x)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=3, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "        x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "        x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "        x = layers.AveragePooling2D(3, strides=2, name='pool1')(x)\n",
    "        \n",
    "        for i, block in enumerate(blocks):\n",
    "            scope_num_str = str(i + 2)\n",
    "            x = self.dense_block(x, block, name='conv' + scope_num_str, \n",
    "                                 weight_decay = weight_decay, kernel_initializer = kernel_initializer, growth_rate = growth_rate)\n",
    "            if i != len(blocks) - 1:\n",
    "                x = self.transition_block(x, reduction, name='pool' + scope_num_str, \n",
    "                                          weight_decay = weight_decay, kernel_initializer = kernel_initializer)\n",
    "        \n",
    "        x = layers.BatchNormalization(\n",
    "            axis=3, epsilon=1.001e-5, name='bn')(x)\n",
    "        x = layers.Activation('relu', name='relu')(x)\n",
    "\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        # x = Lambda(lambda x: x, name = 'densenet_features')(x)\n",
    "        x = layers.Dense(classes, activation='softmax',\n",
    "            kernel_initializer = kernel_initializer, \n",
    "#             kernel_regularizer = l2(weight_decay), \n",
    "            name='fc')(x)\n",
    "        \n",
    "        model = Model(img_input, x)\n",
    "        print (model.summary())\n",
    "        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "        \n",
    "        return model\n",
    "# train_data = train_data[:1000]\n",
    "train_img = extract_array_from_series(train_data['img'])\n",
    "train_img = vgg16.preprocess_input(train_img)\n",
    "OneHotEncoder = sklearn.preprocessing.OneHotEncoder()\n",
    "train_target = train_data['class_id'].apply(lambda id: category_dict[id]).values\n",
    "train_target = OneHotEncoder.fit_transform(np.reshape(train_target, (-1, 1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train target nunique:  190 Validate target nuique:  190\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 62, 62, 64)   1728        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 62, 62, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 62, 62, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 62, 62, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 62, 62, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 62, 62, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 62, 62, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 62, 62, 96)   0           conv1/conv[0][0]                 \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 62, 62, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 62, 62, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 62, 62, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 62, 62, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 62, 62, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 62, 62, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 62, 62, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 62, 62, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 62, 62, 128)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 62, 62, 64)   8192        pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 31, 31, 64)   0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 31, 31, 64)   256         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 31, 31, 64)   0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 31, 31, 128)  8192        conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 31, 31, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 31, 31, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 31, 31, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 31, 31, 96)   0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 31, 31, 96)   384         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 31, 31, 96)   0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 31, 31, 128)  12288       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 31, 31, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 31, 31, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 31, 31, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 31, 31, 128)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 31, 31, 128)  512         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 31, 31, 128)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 31, 31, 64)   8192        pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 15, 15, 64)   0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 15, 15, 64)   256         pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 15, 15, 64)   0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 15, 15, 128)  8192        conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 15, 15, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 15, 15, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 15, 15, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 15, 15, 96)   0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 15, 15, 96)   384         conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 15, 15, 96)   0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 15, 15, 128)  12288       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 15, 15, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 15, 15, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 15, 15, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 15, 15, 128)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 15, 15, 128)  512         conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 15, 15, 128)  0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 15, 15, 64)   8192        pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 64)     0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 64)     256         pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 64)     0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    8192        conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 96)     0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 96)     384         conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 96)     0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    12288       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 128)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 128)    512         conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 128)    0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 128)          0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 190)          24510       avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 436,350\n",
      "Trainable params: 431,998\n",
      "Non-trainable params: 4,352\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30576 samples, validate on 7645 samples\n",
      "Epoch 1/100\n",
      "16128/30576 [==============>...............] - ETA: 2:11:36 - loss: 5.1581 - categorical_accuracy: 0.0287"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-19b82834cf52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     h = img_model.model.fit(train_part_img, train_part_target, validation_data=(validate_part_img, validate_part_target), \n\u001b[1;32m     47\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                   callbacks=[EarlyStopping(monitor='val_categorical_accuracy', patience=15, verbose=0)])\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fold = 5\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "num_fold = 0\n",
    "batch_size = 256\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "\n",
    "for train_index, test_index in kf.split(train_img):\n",
    "    train_part_img = train_img[train_index]\n",
    "    validate_part_img = train_img[test_index]\n",
    "    \n",
    "    train_part_target = train_target[train_index]\n",
    "    validate_part_target = train_target[test_index]\n",
    "    \n",
    "    print ('Train target nunique: ', np.unique(np.argwhere(train_part_target == 1)[:, 1]).shape[0], \n",
    "           'Validate target nuique: ', np.unique(np.argwhere(validate_part_target == 1)[:, 1]).shape[0])\n",
    "#     model = vgg16.VGG16(include_top=True, weights = None, input_shape=(64, 64, 3), classes = category.shape[0])\n",
    "#     model = resnet50.ResNet50(include_top=True, weights = None, input_shape=(224, 224, 3), classes = category.shape[0])\n",
    "#     print (model.summary())\n",
    "#     model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "    img_model = DenseNet(blocks = [2, 2, 2, 2], \n",
    "                                cat_max = train_target.shape[1],\n",
    "                                weight_decay = 1e-4, \n",
    "                                kernel_initializer = 'glorot_normal',\n",
    "                                reduction = 0.5) \n",
    "#     print (img_model.summary())\n",
    "    # img_model = small_vgg(img_input_shape = (64, 64, 3), classes = train_target.shape[1])\n",
    "#     datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "# #             featurewise_center=True,\n",
    "# #             featurewise_std_normalization=True,\n",
    "#             rotation_range=45,\n",
    "#             shear_range = 0.2,\n",
    "#             zoom_range=0.2,\n",
    "# #             width_shift_range=0.2,\n",
    "# #             height_shift_range=0.2,\n",
    "#             horizontal_flip=True)\n",
    "#     datagen.fit(train_part_img)\n",
    "#     h = img_model.model.fit_generator(datagen.flow(train_part_img, train_part_target, batch_size=batch_size), \n",
    "#                   validation_data=(validate_part_img, validate_part_target), \n",
    "#                   epochs=100, shuffle=True, verbose = 1, workers=1, use_multiprocessing=False, \n",
    "#                   callbacks=[EarlyStopping(monitor='val_categorical_accuracy', patience=25, verbose=0)],\n",
    "#                   steps_per_epoch = train_part_img.shape[0]//batch_size,)\n",
    "    h = img_model.model.fit(train_part_img, train_part_target, validation_data=(validate_part_img, validate_part_target), \n",
    "                  epochs=100, batch_size = 256, shuffle=True, verbose = 1, \n",
    "                  callbacks=[EarlyStopping(monitor='val_categorical_accuracy', patience=15, verbose=0)])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8e6b6548d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(h.history)[['val_categorical_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train target nunique:  190 Validate target nuique:  190\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 190)               194750    \n",
      "=================================================================\n",
      "Total params: 194,750\n",
      "Trainable params: 194,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 30576 samples, validate on 7645 samples\n",
      "Epoch 1/100\n",
      "30576/30576 [==============================] - 3s 110us/step - loss: 1.4284 - categorical_accuracy: 0.7520 - val_loss: 0.7710 - val_categorical_accuracy: 0.8599\n",
      "Epoch 2/100\n",
      "30576/30576 [==============================] - 3s 92us/step - loss: 0.6374 - categorical_accuracy: 0.8731 - val_loss: 0.7699 - val_categorical_accuracy: 0.8570\n",
      "Epoch 3/100\n",
      "30576/30576 [==============================] - 3s 99us/step - loss: 0.5348 - categorical_accuracy: 0.8864 - val_loss: 0.7764 - val_categorical_accuracy: 0.8581\n",
      "Epoch 4/100\n",
      "30576/30576 [==============================] - 3s 101us/step - loss: 0.4593 - categorical_accuracy: 0.8967 - val_loss: 0.7952 - val_categorical_accuracy: 0.8583\n"
     ]
    }
   ],
   "source": [
    "def small_dnn(classes = None, \n",
    "                       img_input_shape = (64, 64, 3), \n",
    "                       blocks = [6, 12, 24, 16], \n",
    "                       weight_decay = 1e-4, \n",
    "                       kernel_initializer = 'he_normal',\n",
    "                       reduction = 0.5):\n",
    "    img_input = Input(shape = (img_input_shape))\n",
    "    x = layers.Dense(classes, activation='softmax',\n",
    "        kernel_initializer = kernel_initializer, \n",
    "#             kernel_regularizer = l2(weight_decay), \n",
    "        name='fc')(img_input)\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    print (model.summary())\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "fold = 5\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "num_fold = 0\n",
    "batch_size = 256\n",
    "train_image_feature_map = extract_array_from_series(train_data['target'])\n",
    "\n",
    "for train_index, test_index in kf.split(train_img):\n",
    "    train_part_img = train_image_feature_map[train_index]\n",
    "    validate_part_img = train_image_feature_map[test_index]\n",
    "    \n",
    "    train_part_target = train_target[train_index]\n",
    "    validate_part_target = train_target[test_index]\n",
    "    \n",
    "    print ('Train target nunique: ', np.unique(np.argwhere(train_part_target == 1)[:, 1]).shape[0], \n",
    "           'Validate target nuique: ', np.unique(np.argwhere(validate_part_target == 1)[:, 1]).shape[0])\n",
    "\n",
    "    img_classifi_model = small_dnn(img_input_shape = (1024, ), \n",
    "                                classes = train_target.shape[1]) \n",
    "    \n",
    "    h = img_classifi_model.fit(train_part_img, train_part_target, validation_data=(validate_part_img, validate_part_target), \n",
    "                  epochs=100, batch_size = 64, shuffle=True, verbose = 1, \n",
    "                  callbacks=[EarlyStopping(monitor='val_categorical_accuracy', patience=3, verbose=0)])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38221/38221 [==============================] - 2s 45us/step\n"
     ]
    }
   ],
   "source": [
    "pred_class_probas = img_classifi_model.predict(train_image_feature_map, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_max_proba = pred_class_probas.max(axis = 1)\n",
    "pred_class_id = category[pred_class_probas.argmax(axis = 1)]\n",
    "# np.sum(pred_class_id == train_data['class_id']) / train_data.shape[0]\n",
    "train_data['pred_max_proba'] = pred_class_max_proba\n",
    "train_data['pred_class_id'] = pred_class_id\n",
    "# pred_class_max_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.973545127192473\n",
      "0.5555555555555556 0.9791893883566691\n",
      "0.6111111111111112 0.9839496930678245\n",
      "0.6666666666666666 0.9879055597867479\n",
      "0.7222222222222222 0.9910592325841301\n",
      "0.7777777777777778 0.9933481858688733\n",
      "0.8333333333333333 0.9950834818187818\n",
      "0.8888888888888888 0.9968510066164243\n",
      "0.9444444444444444 0.9981974428840914\n",
      "1.0 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for th in np.linspace(0.5, 1, 10):\n",
    "    precision = np.sum((train_data.pred_max_proba > th) & (train_data.pred_class_id == train_data.class_id)) \\\n",
    "        / np.sum(train_data.pred_max_proba > th)    \n",
    "    print (th, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['preds'] = list(pred_class_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-0662d19f6b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZJL1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZJL1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "category_dict[('ZJL1', 'ZJL1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n03598930', 'jigsaw_puzzle', 0.023861792), ('n02095314', 'wire-haired_fox_terrier', 0.022931756), ('n04589890', 'window_screen', 0.021361042)]\n"
     ]
    }
   ],
   "source": [
    "# np.asarray(list(train_data['img'])).shape\n",
    "# train_data[train_data['class_id'] == 'ZJL1']\n",
    "# train_data['class_id'].value_counts().hist()\n",
    "# train_data.head()\n",
    "# class_id_emb_attr.iloc[0].name\n",
    "# resnet50_model = ResNet50(weights='imagenet', input_shape=(224, 224, 3))\n",
    "img = image.load_img(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg', target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = vgg16.preprocess_input(img)\n",
    "preds = vgg_model.predict(np.expand_dims(img, axis=0))\n",
    "print('Predicted:', vgg16.decode_predictions(preds, top=3)[0])\n",
    "# imread(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg')\n",
    "# image.img_to_array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dnn_data(df):\n",
    "    return [extract_array_from_series(df['attr']), extract_array_from_series(df['emb'])]\n",
    "            \n",
    "def lgbm_train(train_part, train_part_label, valide_part, valide_part_label, fold_seed,\n",
    "        fold = 5, train_weight = None, valide_weight = None, flags = None):\n",
    "    \"\"\"\n",
    "    LGBM Training\n",
    "    \"\"\"\n",
    "    print(\"-----LGBM training-----\")\n",
    "\n",
    "    d_train = lgb.Dataset(train_part, train_part_label) #, categorical_feature = CATEGORY_FEATURES) #, init_score = train_part[:, -1])\n",
    "    d_valide = lgb.Dataset(valide_part, valide_part_label) #, categorical_feature = CATEGORY_FEATURES) #, init_score = valide_part[:, -1])\n",
    "    params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt', #'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            # 'num_leaves':-1,\n",
    "            'min_sum_hessian_in_leaf':None,\n",
    "            'max_depth':7,\n",
    "            'learning_rate':0.005,\n",
    "            'feature_fraction':0.1,\n",
    "            'verbose':-1,\n",
    "            'num_boost_round':3000,\n",
    "            'drop_rate':None,\n",
    "            'bagging_fraction':0.6,\n",
    "            'bagging_freq':5,\n",
    "            'early_stopping_round':100,\n",
    "            # 'min_data_in_leaf':100,\n",
    "            'max_bin': None,\n",
    "            'scale_pos_weight':None,\n",
    "        }\n",
    "    print (\"lightgbm params: {0}\\n\".format(params))\n",
    "\n",
    "    bst = lgb.train(\n",
    "                    params ,\n",
    "                    d_train,\n",
    "                    verbose_eval = 200,\n",
    "                    valid_sets = [d_train, d_valide],\n",
    "                    # feature_name= keras_train.DENSE_FEATURE_LIST,\n",
    "                    #feval = gini_lgbm\n",
    "                    #num_boost_round = 1\n",
    "                    )\n",
    "    #pred = model_eval(bst, 'l', valide_part)\n",
    "    #print(pred[:10])\n",
    "    #print(valide_part_label[:10])\n",
    "    #print(valide_part[:10, -1])\n",
    "    # exit(0)\n",
    "    feature_imp = bst.feature_importance(importance_type = 'gain')\n",
    "    sort_ind = np.argsort(feature_imp)[::-1]\n",
    "    print (np.c_[np.array(FEATURE_LIST)[sort_ind], feature_imp[sort_ind]][:10])\n",
    "    # print (np.array(keras_train.FEATURE_LIST)[np.argsort(feature_imp)])\n",
    "    # exit(0)\n",
    "    # cv_result = lgb.cv(params, d_train, nfold=fold) #, feval = gini_lgbm)\n",
    "    # pd.DataFrame(cv_result).to_csv('cv_result', index = False)\n",
    "    # exit(0)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D) (None, 70, 70, 3)     0           input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)              (None, 68, 68, 32)    864         zero_padding2d_5[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)    (None, 68, 68, 32)    128         conv1/conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1/relu (Activation)          (None, 68, 68, 32)    0           conv1/bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D) (None, 70, 70, 32)    0           conv1/relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool1 (AveragePooling2D)         (None, 34, 34, 32)    0           zero_padding2d_6[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormaliz (None, 34, 34, 32)    128         pool1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation) (None, 34, 34, 32)    0           conv2_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)     (None, 34, 34, 128)   4096        conv2_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormaliz (None, 34, 34, 128)   512         conv2_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation) (None, 34, 34, 128)   0           conv2_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)     (None, 34, 34, 32)    36864       conv2_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenate (None, 34, 34, 64)    0           pool1[0][0]                      \n",
      "                                                                   conv2_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation) (None, 34, 34, 64)    0           conv2_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)     (None, 34, 34, 128)   8192        conv2_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormaliz (None, 34, 34, 128)   512         conv2_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation) (None, 34, 34, 128)   0           conv2_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)     (None, 34, 34, 32)    36864       conv2_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenate (None, 34, 34, 96)    0           conv2_block1_concat[0][0]        \n",
      "                                                                   conv2_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormaliz (None, 34, 34, 96)    384         conv2_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation) (None, 34, 34, 96)    0           conv2_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)     (None, 34, 34, 128)   12288       conv2_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormaliz (None, 34, 34, 128)   512         conv2_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation) (None, 34, 34, 128)   0           conv2_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)     (None, 34, 34, 32)    36864       conv2_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenate (None, 34, 34, 128)   0           conv2_block2_concat[0][0]        \n",
      "                                                                   conv2_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormaliz (None, 34, 34, 128)   512         conv2_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation) (None, 34, 34, 128)   0           conv2_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)     (None, 34, 34, 128)   16384       conv2_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormaliz (None, 34, 34, 128)   512         conv2_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation) (None, 34, 34, 128)   0           conv2_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)     (None, 34, 34, 32)    36864       conv2_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenate (None, 34, 34, 160)   0           conv2_block3_concat[0][0]        \n",
      "                                                                   conv2_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormaliz (None, 34, 34, 160)   640         conv2_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation) (None, 34, 34, 160)   0           conv2_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)     (None, 34, 34, 128)   20480       conv2_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormaliz (None, 34, 34, 128)   512         conv2_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation) (None, 34, 34, 128)   0           conv2_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)     (None, 34, 34, 32)    36864       conv2_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenate (None, 34, 34, 192)   0           conv2_block4_concat[0][0]        \n",
      "                                                                   conv2_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormaliz (None, 34, 34, 192)   768         conv2_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation) (None, 34, 34, 192)   0           conv2_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)     (None, 34, 34, 128)   24576       conv2_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormaliz (None, 34, 34, 128)   512         conv2_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation) (None, 34, 34, 128)   0           conv2_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)     (None, 34, 34, 32)    36864       conv2_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenate (None, 34, 34, 224)   0           conv2_block5_concat[0][0]        \n",
      "                                                                   conv2_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)    (None, 34, 34, 224)   896         conv2_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "pool2_relu (Activation)          (None, 34, 34, 224)   0           pool2_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)              (None, 34, 34, 112)   25088       pool2_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)    (None, 17, 17, 112)   0           pool2_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormaliz (None, 17, 17, 112)   448         pool2_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation) (None, 17, 17, 112)   0           conv3_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)     (None, 17, 17, 128)   14336       conv3_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation) (None, 17, 17, 128)   0           conv3_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)     (None, 17, 17, 32)    36864       conv3_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenate (None, 17, 17, 144)   0           pool2_pool[0][0]                 \n",
      "                                                                   conv3_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormaliz (None, 17, 17, 144)   576         conv3_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation) (None, 17, 17, 144)   0           conv3_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)     (None, 17, 17, 128)   18432       conv3_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation) (None, 17, 17, 128)   0           conv3_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)     (None, 17, 17, 32)    36864       conv3_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenate (None, 17, 17, 176)   0           conv3_block1_concat[0][0]        \n",
      "                                                                   conv3_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormaliz (None, 17, 17, 176)   704         conv3_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation) (None, 17, 17, 176)   0           conv3_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)     (None, 17, 17, 128)   22528       conv3_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation) (None, 17, 17, 128)   0           conv3_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)     (None, 17, 17, 32)    36864       conv3_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenate (None, 17, 17, 208)   0           conv3_block2_concat[0][0]        \n",
      "                                                                   conv3_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormaliz (None, 17, 17, 208)   832         conv3_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation) (None, 17, 17, 208)   0           conv3_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)     (None, 17, 17, 128)   26624       conv3_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation) (None, 17, 17, 128)   0           conv3_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)     (None, 17, 17, 32)    36864       conv3_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenate (None, 17, 17, 240)   0           conv3_block3_concat[0][0]        \n",
      "                                                                   conv3_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormaliz (None, 17, 17, 240)   960         conv3_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation) (None, 17, 17, 240)   0           conv3_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)     (None, 17, 17, 128)   30720       conv3_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation) (None, 17, 17, 128)   0           conv3_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)     (None, 17, 17, 32)    36864       conv3_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenate (None, 17, 17, 272)   0           conv3_block4_concat[0][0]        \n",
      "                                                                   conv3_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormaliz (None, 17, 17, 272)   1088        conv3_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation) (None, 17, 17, 272)   0           conv3_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)     (None, 17, 17, 128)   34816       conv3_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation) (None, 17, 17, 128)   0           conv3_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)     (None, 17, 17, 32)    36864       conv3_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenate (None, 17, 17, 304)   0           conv3_block5_concat[0][0]        \n",
      "                                                                   conv3_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormaliz (None, 17, 17, 304)   1216        conv3_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation) (None, 17, 17, 304)   0           conv3_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)     (None, 17, 17, 128)   38912       conv3_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation) (None, 17, 17, 128)   0           conv3_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)     (None, 17, 17, 32)    36864       conv3_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenate (None, 17, 17, 336)   0           conv3_block6_concat[0][0]        \n",
      "                                                                   conv3_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormaliz (None, 17, 17, 336)   1344        conv3_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation) (None, 17, 17, 336)   0           conv3_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)     (None, 17, 17, 128)   43008       conv3_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation) (None, 17, 17, 128)   0           conv3_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)     (None, 17, 17, 32)    36864       conv3_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenate (None, 17, 17, 368)   0           conv3_block7_concat[0][0]        \n",
      "                                                                   conv3_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormaliz (None, 17, 17, 368)   1472        conv3_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation) (None, 17, 17, 368)   0           conv3_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)     (None, 17, 17, 128)   47104       conv3_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation) (None, 17, 17, 128)   0           conv3_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)     (None, 17, 17, 32)    36864       conv3_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenate (None, 17, 17, 400)   0           conv3_block8_concat[0][0]        \n",
      "                                                                   conv3_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormali (None, 17, 17, 400)   1600        conv3_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activation (None, 17, 17, 400)   0           conv3_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)    (None, 17, 17, 128)   51200       conv3_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormali (None, 17, 17, 128)   512         conv3_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activation (None, 17, 17, 128)   0           conv3_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)    (None, 17, 17, 32)    36864       conv3_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatenat (None, 17, 17, 432)   0           conv3_block9_concat[0][0]        \n",
      "                                                                   conv3_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormali (None, 17, 17, 432)   1728        conv3_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activation (None, 17, 17, 432)   0           conv3_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)    (None, 17, 17, 128)   55296       conv3_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormali (None, 17, 17, 128)   512         conv3_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activation (None, 17, 17, 128)   0           conv3_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)    (None, 17, 17, 32)    36864       conv3_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatenat (None, 17, 17, 464)   0           conv3_block10_concat[0][0]       \n",
      "                                                                   conv3_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormali (None, 17, 17, 464)   1856        conv3_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activation (None, 17, 17, 464)   0           conv3_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)    (None, 17, 17, 128)   59392       conv3_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormali (None, 17, 17, 128)   512         conv3_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activation (None, 17, 17, 128)   0           conv3_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)    (None, 17, 17, 32)    36864       conv3_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatenat (None, 17, 17, 496)   0           conv3_block11_concat[0][0]       \n",
      "                                                                   conv3_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)    (None, 17, 17, 496)   1984        conv3_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool3_relu (Activation)          (None, 17, 17, 496)   0           pool3_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)              (None, 17, 17, 248)   123008      pool3_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)    (None, 8, 8, 248)     0           pool3_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormaliz (None, 8, 8, 248)     992         pool3_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation) (None, 8, 8, 248)     0           conv4_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)     (None, 8, 8, 128)     31744       conv4_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormaliz (None, 8, 8, 128)     512         conv4_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation) (None, 8, 8, 128)     0           conv4_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)     (None, 8, 8, 32)      36864       conv4_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenate (None, 8, 8, 280)     0           pool3_pool[0][0]                 \n",
      "                                                                   conv4_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormaliz (None, 8, 8, 280)     1120        conv4_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation) (None, 8, 8, 280)     0           conv4_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)     (None, 8, 8, 128)     35840       conv4_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormaliz (None, 8, 8, 128)     512         conv4_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation) (None, 8, 8, 128)     0           conv4_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)     (None, 8, 8, 32)      36864       conv4_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenate (None, 8, 8, 312)     0           conv4_block1_concat[0][0]        \n",
      "                                                                   conv4_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormaliz (None, 8, 8, 312)     1248        conv4_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation) (None, 8, 8, 312)     0           conv4_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)     (None, 8, 8, 128)     39936       conv4_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormaliz (None, 8, 8, 128)     512         conv4_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation) (None, 8, 8, 128)     0           conv4_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)     (None, 8, 8, 32)      36864       conv4_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenate (None, 8, 8, 344)     0           conv4_block2_concat[0][0]        \n",
      "                                                                   conv4_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormaliz (None, 8, 8, 344)     1376        conv4_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation) (None, 8, 8, 344)     0           conv4_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)     (None, 8, 8, 128)     44032       conv4_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormaliz (None, 8, 8, 128)     512         conv4_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation) (None, 8, 8, 128)     0           conv4_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)     (None, 8, 8, 32)      36864       conv4_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenate (None, 8, 8, 376)     0           conv4_block3_concat[0][0]        \n",
      "                                                                   conv4_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormaliz (None, 8, 8, 376)     1504        conv4_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation) (None, 8, 8, 376)     0           conv4_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)     (None, 8, 8, 128)     48128       conv4_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormaliz (None, 8, 8, 128)     512         conv4_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation) (None, 8, 8, 128)     0           conv4_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)     (None, 8, 8, 32)      36864       conv4_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenate (None, 8, 8, 408)     0           conv4_block4_concat[0][0]        \n",
      "                                                                   conv4_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormaliz (None, 8, 8, 408)     1632        conv4_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation) (None, 8, 8, 408)     0           conv4_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)     (None, 8, 8, 128)     52224       conv4_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormaliz (None, 8, 8, 128)     512         conv4_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation) (None, 8, 8, 128)     0           conv4_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)     (None, 8, 8, 32)      36864       conv4_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenate (None, 8, 8, 440)     0           conv4_block5_concat[0][0]        \n",
      "                                                                   conv4_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormaliz (None, 8, 8, 440)     1760        conv4_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation) (None, 8, 8, 440)     0           conv4_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)     (None, 8, 8, 128)     56320       conv4_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormaliz (None, 8, 8, 128)     512         conv4_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation) (None, 8, 8, 128)     0           conv4_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)     (None, 8, 8, 32)      36864       conv4_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenate (None, 8, 8, 472)     0           conv4_block6_concat[0][0]        \n",
      "                                                                   conv4_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormaliz (None, 8, 8, 472)     1888        conv4_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation) (None, 8, 8, 472)     0           conv4_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)     (None, 8, 8, 128)     60416       conv4_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormaliz (None, 8, 8, 128)     512         conv4_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation) (None, 8, 8, 128)     0           conv4_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)     (None, 8, 8, 32)      36864       conv4_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenate (None, 8, 8, 504)     0           conv4_block7_concat[0][0]        \n",
      "                                                                   conv4_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormaliz (None, 8, 8, 504)     2016        conv4_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation) (None, 8, 8, 504)     0           conv4_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)     (None, 8, 8, 128)     64512       conv4_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormaliz (None, 8, 8, 128)     512         conv4_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation) (None, 8, 8, 128)     0           conv4_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)     (None, 8, 8, 32)      36864       conv4_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenate (None, 8, 8, 536)     0           conv4_block8_concat[0][0]        \n",
      "                                                                   conv4_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormali (None, 8, 8, 536)     2144        conv4_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activation (None, 8, 8, 536)     0           conv4_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)    (None, 8, 8, 128)     68608       conv4_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activation (None, 8, 8, 128)     0           conv4_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatenat (None, 8, 8, 568)     0           conv4_block9_concat[0][0]        \n",
      "                                                                   conv4_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormali (None, 8, 8, 568)     2272        conv4_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activation (None, 8, 8, 568)     0           conv4_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)    (None, 8, 8, 128)     72704       conv4_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activation (None, 8, 8, 128)     0           conv4_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatenat (None, 8, 8, 600)     0           conv4_block10_concat[0][0]       \n",
      "                                                                   conv4_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormali (None, 8, 8, 600)     2400        conv4_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activation (None, 8, 8, 600)     0           conv4_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)    (None, 8, 8, 128)     76800       conv4_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activation (None, 8, 8, 128)     0           conv4_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatenat (None, 8, 8, 632)     0           conv4_block11_concat[0][0]       \n",
      "                                                                   conv4_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormali (None, 8, 8, 632)     2528        conv4_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activation (None, 8, 8, 632)     0           conv4_block13_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)    (None, 8, 8, 128)     80896       conv4_block13_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block13_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activation (None, 8, 8, 128)     0           conv4_block13_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block13_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatenat (None, 8, 8, 664)     0           conv4_block12_concat[0][0]       \n",
      "                                                                   conv4_block13_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormali (None, 8, 8, 664)     2656        conv4_block13_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activation (None, 8, 8, 664)     0           conv4_block14_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)    (None, 8, 8, 128)     84992       conv4_block14_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block14_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activation (None, 8, 8, 128)     0           conv4_block14_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block14_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatenat (None, 8, 8, 696)     0           conv4_block13_concat[0][0]       \n",
      "                                                                   conv4_block14_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormali (None, 8, 8, 696)     2784        conv4_block14_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activation (None, 8, 8, 696)     0           conv4_block15_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)    (None, 8, 8, 128)     89088       conv4_block15_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block15_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activation (None, 8, 8, 128)     0           conv4_block15_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block15_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatenat (None, 8, 8, 728)     0           conv4_block14_concat[0][0]       \n",
      "                                                                   conv4_block15_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormali (None, 8, 8, 728)     2912        conv4_block15_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activation (None, 8, 8, 728)     0           conv4_block16_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)    (None, 8, 8, 128)     93184       conv4_block16_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block16_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activation (None, 8, 8, 128)     0           conv4_block16_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block16_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatenat (None, 8, 8, 760)     0           conv4_block15_concat[0][0]       \n",
      "                                                                   conv4_block16_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormali (None, 8, 8, 760)     3040        conv4_block16_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activation (None, 8, 8, 760)     0           conv4_block17_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)    (None, 8, 8, 128)     97280       conv4_block17_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block17_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activation (None, 8, 8, 128)     0           conv4_block17_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block17_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatenat (None, 8, 8, 792)     0           conv4_block16_concat[0][0]       \n",
      "                                                                   conv4_block17_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormali (None, 8, 8, 792)     3168        conv4_block17_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activation (None, 8, 8, 792)     0           conv4_block18_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)    (None, 8, 8, 128)     101376      conv4_block18_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block18_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activation (None, 8, 8, 128)     0           conv4_block18_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block18_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatenat (None, 8, 8, 824)     0           conv4_block17_concat[0][0]       \n",
      "                                                                   conv4_block18_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormali (None, 8, 8, 824)     3296        conv4_block18_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activation (None, 8, 8, 824)     0           conv4_block19_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)    (None, 8, 8, 128)     105472      conv4_block19_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block19_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activation (None, 8, 8, 128)     0           conv4_block19_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block19_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatenat (None, 8, 8, 856)     0           conv4_block18_concat[0][0]       \n",
      "                                                                   conv4_block19_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormali (None, 8, 8, 856)     3424        conv4_block19_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activation (None, 8, 8, 856)     0           conv4_block20_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)    (None, 8, 8, 128)     109568      conv4_block20_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block20_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activation (None, 8, 8, 128)     0           conv4_block20_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block20_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatenat (None, 8, 8, 888)     0           conv4_block19_concat[0][0]       \n",
      "                                                                   conv4_block20_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormali (None, 8, 8, 888)     3552        conv4_block20_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activation (None, 8, 8, 888)     0           conv4_block21_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)    (None, 8, 8, 128)     113664      conv4_block21_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block21_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activation (None, 8, 8, 128)     0           conv4_block21_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block21_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatenat (None, 8, 8, 920)     0           conv4_block20_concat[0][0]       \n",
      "                                                                   conv4_block21_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormali (None, 8, 8, 920)     3680        conv4_block21_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activation (None, 8, 8, 920)     0           conv4_block22_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)    (None, 8, 8, 128)     117760      conv4_block22_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block22_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activation (None, 8, 8, 128)     0           conv4_block22_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block22_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatenat (None, 8, 8, 952)     0           conv4_block21_concat[0][0]       \n",
      "                                                                   conv4_block22_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormali (None, 8, 8, 952)     3808        conv4_block22_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activation (None, 8, 8, 952)     0           conv4_block23_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)    (None, 8, 8, 128)     121856      conv4_block23_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block23_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activation (None, 8, 8, 128)     0           conv4_block23_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block23_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatenat (None, 8, 8, 984)     0           conv4_block22_concat[0][0]       \n",
      "                                                                   conv4_block23_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormali (None, 8, 8, 984)     3936        conv4_block23_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activation (None, 8, 8, 984)     0           conv4_block24_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)    (None, 8, 8, 128)     125952      conv4_block24_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormali (None, 8, 8, 128)     512         conv4_block24_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activation (None, 8, 8, 128)     0           conv4_block24_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)    (None, 8, 8, 32)      36864       conv4_block24_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatenat (None, 8, 8, 1016)    0           conv4_block23_concat[0][0]       \n",
      "                                                                   conv4_block24_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)    (None, 8, 8, 1016)    4064        conv4_block24_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool4_relu (Activation)          (None, 8, 8, 1016)    0           pool4_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)              (None, 8, 8, 508)     516128      pool4_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)    (None, 4, 4, 508)     0           pool4_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormaliz (None, 4, 4, 508)     2032        pool4_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation) (None, 4, 4, 508)     0           conv5_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)     (None, 4, 4, 128)     65024       conv5_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormaliz (None, 4, 4, 128)     512         conv5_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation) (None, 4, 4, 128)     0           conv5_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)     (None, 4, 4, 32)      36864       conv5_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenate (None, 4, 4, 540)     0           pool4_pool[0][0]                 \n",
      "                                                                   conv5_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormaliz (None, 4, 4, 540)     2160        conv5_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation) (None, 4, 4, 540)     0           conv5_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)     (None, 4, 4, 128)     69120       conv5_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormaliz (None, 4, 4, 128)     512         conv5_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation) (None, 4, 4, 128)     0           conv5_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)     (None, 4, 4, 32)      36864       conv5_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenate (None, 4, 4, 572)     0           conv5_block1_concat[0][0]        \n",
      "                                                                   conv5_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormaliz (None, 4, 4, 572)     2288        conv5_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation) (None, 4, 4, 572)     0           conv5_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)     (None, 4, 4, 128)     73216       conv5_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormaliz (None, 4, 4, 128)     512         conv5_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation) (None, 4, 4, 128)     0           conv5_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)     (None, 4, 4, 32)      36864       conv5_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenate (None, 4, 4, 604)     0           conv5_block2_concat[0][0]        \n",
      "                                                                   conv5_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormaliz (None, 4, 4, 604)     2416        conv5_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation) (None, 4, 4, 604)     0           conv5_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)     (None, 4, 4, 128)     77312       conv5_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormaliz (None, 4, 4, 128)     512         conv5_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation) (None, 4, 4, 128)     0           conv5_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)     (None, 4, 4, 32)      36864       conv5_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenate (None, 4, 4, 636)     0           conv5_block3_concat[0][0]        \n",
      "                                                                   conv5_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormaliz (None, 4, 4, 636)     2544        conv5_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation) (None, 4, 4, 636)     0           conv5_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)     (None, 4, 4, 128)     81408       conv5_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormaliz (None, 4, 4, 128)     512         conv5_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation) (None, 4, 4, 128)     0           conv5_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)     (None, 4, 4, 32)      36864       conv5_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenate (None, 4, 4, 668)     0           conv5_block4_concat[0][0]        \n",
      "                                                                   conv5_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormaliz (None, 4, 4, 668)     2672        conv5_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation) (None, 4, 4, 668)     0           conv5_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)     (None, 4, 4, 128)     85504       conv5_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormaliz (None, 4, 4, 128)     512         conv5_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation) (None, 4, 4, 128)     0           conv5_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)     (None, 4, 4, 32)      36864       conv5_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenate (None, 4, 4, 700)     0           conv5_block5_concat[0][0]        \n",
      "                                                                   conv5_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormaliz (None, 4, 4, 700)     2800        conv5_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation) (None, 4, 4, 700)     0           conv5_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)     (None, 4, 4, 128)     89600       conv5_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormaliz (None, 4, 4, 128)     512         conv5_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation) (None, 4, 4, 128)     0           conv5_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)     (None, 4, 4, 32)      36864       conv5_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenate (None, 4, 4, 732)     0           conv5_block6_concat[0][0]        \n",
      "                                                                   conv5_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormaliz (None, 4, 4, 732)     2928        conv5_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation) (None, 4, 4, 732)     0           conv5_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)     (None, 4, 4, 128)     93696       conv5_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormaliz (None, 4, 4, 128)     512         conv5_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation) (None, 4, 4, 128)     0           conv5_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)     (None, 4, 4, 32)      36864       conv5_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenate (None, 4, 4, 764)     0           conv5_block7_concat[0][0]        \n",
      "                                                                   conv5_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormaliz (None, 4, 4, 764)     3056        conv5_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation) (None, 4, 4, 764)     0           conv5_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)     (None, 4, 4, 128)     97792       conv5_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormaliz (None, 4, 4, 128)     512         conv5_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation) (None, 4, 4, 128)     0           conv5_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)     (None, 4, 4, 32)      36864       conv5_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenate (None, 4, 4, 796)     0           conv5_block8_concat[0][0]        \n",
      "                                                                   conv5_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormali (None, 4, 4, 796)     3184        conv5_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activation (None, 4, 4, 796)     0           conv5_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)    (None, 4, 4, 128)     101888      conv5_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormali (None, 4, 4, 128)     512         conv5_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activation (None, 4, 4, 128)     0           conv5_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)    (None, 4, 4, 32)      36864       conv5_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatenat (None, 4, 4, 828)     0           conv5_block9_concat[0][0]        \n",
      "                                                                   conv5_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormali (None, 4, 4, 828)     3312        conv5_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activation (None, 4, 4, 828)     0           conv5_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)    (None, 4, 4, 128)     105984      conv5_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormali (None, 4, 4, 128)     512         conv5_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activation (None, 4, 4, 128)     0           conv5_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)    (None, 4, 4, 32)      36864       conv5_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatenat (None, 4, 4, 860)     0           conv5_block10_concat[0][0]       \n",
      "                                                                   conv5_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormali (None, 4, 4, 860)     3440        conv5_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activation (None, 4, 4, 860)     0           conv5_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)    (None, 4, 4, 128)     110080      conv5_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormali (None, 4, 4, 128)     512         conv5_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activation (None, 4, 4, 128)     0           conv5_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)    (None, 4, 4, 32)      36864       conv5_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatenat (None, 4, 4, 892)     0           conv5_block11_concat[0][0]       \n",
      "                                                                   conv5_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormali (None, 4, 4, 892)     3568        conv5_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activation (None, 4, 4, 892)     0           conv5_block13_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)    (None, 4, 4, 128)     114176      conv5_block13_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormali (None, 4, 4, 128)     512         conv5_block13_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activation (None, 4, 4, 128)     0           conv5_block13_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)    (None, 4, 4, 32)      36864       conv5_block13_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatenat (None, 4, 4, 924)     0           conv5_block12_concat[0][0]       \n",
      "                                                                   conv5_block13_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormali (None, 4, 4, 924)     3696        conv5_block13_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activation (None, 4, 4, 924)     0           conv5_block14_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)    (None, 4, 4, 128)     118272      conv5_block14_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormali (None, 4, 4, 128)     512         conv5_block14_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activation (None, 4, 4, 128)     0           conv5_block14_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)    (None, 4, 4, 32)      36864       conv5_block14_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatenat (None, 4, 4, 956)     0           conv5_block13_concat[0][0]       \n",
      "                                                                   conv5_block14_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormali (None, 4, 4, 956)     3824        conv5_block14_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activation (None, 4, 4, 956)     0           conv5_block15_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)    (None, 4, 4, 128)     122368      conv5_block15_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormali (None, 4, 4, 128)     512         conv5_block15_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activation (None, 4, 4, 128)     0           conv5_block15_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)    (None, 4, 4, 32)      36864       conv5_block15_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatenat (None, 4, 4, 988)     0           conv5_block14_concat[0][0]       \n",
      "                                                                   conv5_block15_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormali (None, 4, 4, 988)     3952        conv5_block15_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activation (None, 4, 4, 988)     0           conv5_block16_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)    (None, 4, 4, 128)     126464      conv5_block16_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormali (None, 4, 4, 128)     512         conv5_block16_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activation (None, 4, 4, 128)     0           conv5_block16_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)    (None, 4, 4, 32)      36864       conv5_block16_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatenat (None, 4, 4, 1020)    0           conv5_block15_concat[0][0]       \n",
      "                                                                   conv5_block16_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "bn (BatchNormalization)          (None, 4, 4, 1020)    4080        conv5_block16_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "relu (Activation)                (None, 4, 4, 1020)    0           bn[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D (None, 1020)          0           relu[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "fc (Dense)                       (None, 190)           193990      avg_pool[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 7,114,198\n",
      "Trainable params: 7,032,014\n",
      "Non-trainable params: 82,184\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"av...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38221/38221 [==============================] - 126s   \n"
     ]
    }
   ],
   "source": [
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_y = pickle.load(handle)\n",
    "img_model = DenseNet(blocks = [6, 12, 24, 16], \n",
    "                                cat_max = 190,\n",
    "                                weight_decay = 1e-4, \n",
    "                                kernel_initializer = 'glorot_normal',\n",
    "                                reduction = 0.5)\n",
    "img_model.model.load_weights(path + '/model_sub/6_12_24_16_03869/model_0_2018_09_12_13_34_57.h5')\n",
    "img_model_flat = Model(input = img_model.model.input, output = img_model.model.get_layer(name = 'avg_pool').output)\n",
    "# train_data['target'] = list(train_y) #\n",
    "train_data['target'] = list(img_model_flat.predict(train_img, verbose = 1))\n",
    "# img_model_flat = pd.read_csv(path + '/model_sub/6_12_24_16_03274/sub_2018_09_07_20_58_46.csv')\n",
    "\n",
    "# img_model_flat.set_index('image_id', inplace = True)\n",
    "# train_data['target'] = img_model_flat.apply(lambda s: np.asarray(s.astype(float)), axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38221/38221 [==============================] - 126s   \n"
     ]
    }
   ],
   "source": [
    "train_data['preds'] = list(img_model.model.predict(train_img, verbose = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0]['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split by class id (34387, 10) (3834, 10)\n",
      "Add  171 seen class in validation:  (34387, 10) (3834, 10)\n",
      "fold: 0 th train :-)\n",
      "Train size: 34387 Valide size: 3834\n",
      "Seen category: 171 Unseen category: 19\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "wv (InputLayer)              (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 600)               2400      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 1536)              923136    \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 1536)              6144      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 1408)              2164096   \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 1408)              5632      \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1280)              1803520   \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 1280)              5120      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1020)              1306620   \n",
      "=================================================================\n",
      "Total params: 6,216,668\n",
      "Trainable params: 6,207,020\n",
      "Non-trainable params: 9,648\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 34387 samples, validate on 3834 samples\n",
      "Epoch 1/50\n",
      "34368/34387 [============================>.] - ETA: 0s - loss: 1.0831\n",
      "All_re: \t0.233698\t896\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.233698\t896\t3834\n",
      "34387/34387 [==============================] - 19s - loss: 1.0830 - val_loss: 0.8020\n",
      "Epoch 2/50\n",
      "  416/34387 [..............................] - ETA: 14s - loss: 0.8286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:56: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34336/34387 [============================>.] - ETA: 0s - loss: 0.6963\n",
      "All_re: \t0.258738\t992\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.258738\t992\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.6961 - val_loss: 0.5474\n",
      "Epoch 3/50\n",
      "34272/34387 [============================>.] - ETA: 0s - loss: 0.4534\n",
      "All_re: \t0.320814\t1230\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.320814\t1230\t3834\n",
      "34387/34387 [==============================] - 16s - loss: 0.4531 - val_loss: 0.3553\n",
      "Epoch 4/50\n",
      "34272/34387 [============================>.] - ETA: 0s - loss: 0.2981\n",
      "All_re: \t0.360720\t1383\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.360720\t1383\t3834\n",
      "34387/34387 [==============================] - 16s - loss: 0.2979 - val_loss: 0.2562\n",
      "Epoch 5/50\n",
      "34272/34387 [============================>.] - ETA: 0s - loss: 0.2245\n",
      "All_re: \t0.351591\t1348\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.351591\t1348\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.2244 - val_loss: 0.2118\n",
      "Epoch 6/50\n",
      "34336/34387 [============================>.] - ETA: 0s - loss: 0.1903\n",
      "All_re: \t0.348200\t1335\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.348200\t1335\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.1903 - val_loss: 0.1909\n",
      "Epoch 7/50\n",
      "34368/34387 [============================>.] - ETA: 0s - loss: 0.1726\n",
      "All_re: \t0.300209\t1151\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.300209\t1151\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.1726 - val_loss: 0.1810\n",
      "Epoch 8/50\n",
      "34336/34387 [============================>.] - ETA: 0s - loss: 0.1625\n",
      "All_re: \t0.317684\t1218\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.317684\t1218\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.1625 - val_loss: 0.1756\n",
      "Epoch 9/50\n",
      "34336/34387 [============================>.] - ETA: 0s - loss: 0.1564\n",
      "All_re: \t0.321596\t1233\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.321596\t1233\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.1564 - val_loss: 0.1717\n",
      "Epoch 10/50\n",
      "34336/34387 [============================>.] - ETA: 0s - loss: 0.1524\n",
      "All_re: \t0.311685\t1195\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.311685\t1195\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.1524 - val_loss: 0.1692\n",
      "Epoch 11/50\n",
      "34336/34387 [============================>.] - ETA: 0s - loss: 0.1499\n",
      "All_re: \t0.307773\t1180\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.307773\t1180\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.1499 - val_loss: 0.1685\n",
      "Epoch 12/50\n",
      "34336/34387 [============================>.] - ETA: 0s - loss: 0.1481\n",
      "All_re: \t0.333855\t1280\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.333855\t1280\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.1481 - val_loss: 0.1672\n",
      "Epoch 13/50\n",
      "34304/34387 [============================>.] - ETA: 0s - loss: 0.1470\n",
      "All_re: \t0.312207\t1197\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.312207\t1197\t3834\n",
      "34387/34387 [==============================] - 16s - loss: 0.1470 - val_loss: 0.1668\n",
      "Epoch 14/50\n",
      "34336/34387 [============================>.] - ETA: 0s - loss: 0.1461\n",
      "All_re: \t0.332812\t1276\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.332812\t1276\t3834\n",
      "34387/34387 [==============================] - 16s - loss: 0.1461 - val_loss: 0.1669\n",
      "Epoch 15/50\n",
      "34272/34387 [============================>.] - ETA: 0s - loss: 0.1456\n",
      "All_re: \t0.283255\t1086\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.283255\t1086\t3834\n",
      "34387/34387 [==============================] - 16s - loss: 0.1456 - val_loss: 0.1680\n",
      "Epoch 16/50\n",
      "34336/34387 [============================>.] - ETA: 0s - loss: 0.1452\n",
      "All_re: \t0.362024\t1388\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.362024\t1388\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.1452 - val_loss: 0.1654\n",
      "Epoch 17/50\n",
      "34368/34387 [============================>.] - ETA: 0s - loss: 0.1448\n",
      "All_re: \t0.319249\t1224\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.319249\t1224\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.1448 - val_loss: 0.1665\n",
      "Epoch 18/50\n",
      "34272/34387 [============================>.] - ETA: 0s - loss: 0.1446\n",
      "All_re: \t0.329421\t1263\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.329421\t1263\t3834\n",
      "34387/34387 [==============================] - 15s - loss: 0.1445 - val_loss: 0.1668\n",
      "Epoch 19/50\n",
      "34368/34387 [============================>.] - ETA: 0s - loss: 0.1443\n",
      "All_re: \t0.298644\t1145\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.298644\t1145\t3834\n",
      "34387/34387 [==============================] - 16s - loss: 0.1443 - val_loss: 0.1690\n",
      "Epoch 20/50\n",
      "34304/34387 [============================>.] - ETA: 0s - loss: 0.1441\n",
      "All_re: \t0.298644\t1145\t3834\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.298644\t1145\t3834\n",
      "34387/34387 [==============================] - 16s - loss: 0.1441 - val_loss: 0.1678\n"
     ]
    }
   ],
   "source": [
    "def find_nearest_class(class_id_emb_attr, model, eval_df, img_feature_map = None, \n",
    "                       threshold = None, gamma = None, seen_class = None):\n",
    "    if img_feature_map is None:\n",
    "        img_feature_map = np.reshape(vgg_model.predict(np.asarray(list(eval_df['img'])), verbose = 1), (eval_img.shape[0], -1))\n",
    "    cand_feature_map = model.predict(create_dnn_data(class_id_emb_attr))\n",
    "    # img_feature_map = np.repeat(img_feature_map, [cand_feature_map.shape[0]] * img_feature_map.shape[0], axis = 0)\n",
    "    nearest_class_id = ['ZJL'] * eval_df.shape[0]\n",
    "#     seen_class_bias = np.zeros(class_id_emb_attr.shape[0])\n",
    "#     seen_class_bias[class_id_emb_attr.class_id.isin(seen_class)] = gamma\n",
    "    \n",
    "#     seen_indice = [category_dict[c] for c in seen_class]\n",
    "#     preds = np.asarray(list(eval_df['preds']))[:, seen_indice]\n",
    "    for i in range(img_feature_map.shape[0]):\n",
    "        if False: #np.amax(preds[i]) > threshold:\n",
    "            nearest_class_id[i] = seen_class[np.argmax(preds[i])]\n",
    "        else:\n",
    "            img = img_feature_map[i]\n",
    "            dis = np.linalg.norm(img - cand_feature_map, axis = 1)\n",
    "#             print (dis)\n",
    "#             dis += seen_class_bias\n",
    "#             print(dis)\n",
    "#             plt.hist(dis)\n",
    "#             return\n",
    "            min_ind = np.where(dis == np.amin(dis))[0]\n",
    "            if len(min_ind) > 1:\n",
    "                print ('eval img id: ', eval_df.iloc[i]['class_id'], 'has multiple best candidates: ', len(min_ind), 'min val: ', np.amin(dis))\n",
    "    #         print (i, img, class_id_emb_attr.iloc[min_ind[0]].name)\n",
    "            nearest_class_id[i] = class_id_emb_attr.iloc[min_ind[0]]['class_id']\n",
    "#     print (nearest_class_id)\n",
    "    return np.asarray(nearest_class_id)\n",
    "\n",
    "class AccuracyEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_interval = 1000000, verbose = 2, \\\n",
    "            scores = [], class_id_emb_attr = None, eval_df = None, threshold = None, \\\n",
    "                 seen_class = None, unseen_class = None, gamma = None):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        # print(\"y_val shape:{0}\".format(self.y_val.shape))\n",
    "        self.batch_interval = batch_interval\n",
    "        self.verbose = verbose\n",
    "        self.scores = scores\n",
    "        self.class_id_emb_attr = class_id_emb_attr\n",
    "        self.eval_df = eval_df\n",
    "        self.threshold = threshold\n",
    "        self.seen_class = seen_class\n",
    "        self.unseen_class = unseen_class\n",
    "        self.gamma = gamma\n",
    "        seen_indice = [category_dict[c] for c in seen_class]\n",
    "        self.preds = np.asarray(list(eval_df['preds']))[:, seen_indice]\n",
    "#         self.img_feature_map = self.y_val\n",
    "    \n",
    "    def calc_accuracy(self, eval_df, eval_class, preds):\n",
    "        eval_mask = eval_df.class_id.isin(eval_class)\n",
    "        eval_num = np.sum(eval_mask)\n",
    "        right_num = np.sum(preds[eval_mask] == eval_df.class_id[eval_mask])\n",
    "        return right_num / np.sum(eval_mask), right_num, eval_num\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "#             zs_model = Model(inputs = self.model.inputs[:2], outputs = self.model.outpus[0])\n",
    "            pred_nearest_class_id = find_nearest_class(self.class_id_emb_attr, self.model, \n",
    "                                self.eval_df, self.y_val, self.threshold, self.gamma, self.seen_class)\n",
    "            all_re = self.calc_accuracy(self.eval_df, self.eval_df['class_id'].values, pred_nearest_class_id)\n",
    "            seen_re = self.calc_accuracy(self.eval_df, self.seen_class, pred_nearest_class_id)\n",
    "            unseen_re = self.calc_accuracy(self.eval_df, self.unseen_class, pred_nearest_class_id)\n",
    "#             true_class_id = self.eval_df['class_id'].values\n",
    "# #             print (pred_nearest_class_id, \"\\n\", true_class_id)\n",
    "#             right_num = np.sum(pred_nearest_class_id == true_class_id)\n",
    "#             score = right_num / true_class_id.shape[0]\n",
    "#             self.scores.append(\"epoch:{0} {1}\".format(epoch + 1, score))\n",
    "            print(\"\\nAll_re: \\t%.6f\\t%.0f\\t%.0f\" % all_re)\n",
    "            print(\"Seen_re: \\t%.6f\\t%.0f\\t%.0f\" % seen_re)\n",
    "            print(\"Unseen_re: \\t%.6f\\t%.0f\\t%.0f\" % unseen_re)\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "        if(self.verbose >= 2) and (batch % self.batch_interval == 0):\n",
    "            # y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            # loss = metrics.log_loss(self.y_val, y_pred)\n",
    "            print(\"Hi! on_batch_end() , batch=\",batch,\",logs:\",logs)\n",
    "            # print(\"Valide size=\",y_pred.shape[0], \"  Valide loss=\",loss)\n",
    "\n",
    "def full_connect_layer(input, hidden_dim):\n",
    "    full_connect = input\n",
    "    for hn in hidden_dim:\n",
    "        fc_in = full_connect\n",
    "        # if self.full_connect_dropout > 0:\n",
    "        full_connect = Dropout(0.2)(full_connect)\n",
    "        full_connect = BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "        # full_connect = Dense(hn, kernel_regularizer = l2(0.001), activity_regularizer = l1(0.001))(full_connect)\n",
    "#         full_connect = Concatenate()([Dense(hn, kernel_initializer='lecun_uniform', activation = 'relu')(full_connect), \n",
    "#             Dense(hn, kernel_initializer='lecun_uniform', activation = 'sigmoid')(full_connect)])\n",
    "        full_connect = Dense(hn, kernel_initializer='he_normal', activation = 'relu', kernel_regularizer = l2(1e-4))(full_connect)\n",
    "        # full_connect = self.act_blend(full_connect)\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#             full_connect = Dropout(self.full_connect_dropout)(full_connect) #Dropout(self.full_connect_dropout)(full_connect)\n",
    "#         full_connect = Concatenate()([fc_in, full_connect])\n",
    "    return full_connect\n",
    "\n",
    "def create_dnn():\n",
    "    alpha = 0.03\n",
    "    attr_input = Input(shape = (30,), name = 'attr')\n",
    "    word_emb = Input(shape = (600,), name = 'wv')\n",
    "    imag_classifier = Input(shape = (1024,), name = 'img')\n",
    "\n",
    "    attr_dense = Dense(256, use_bias = False, kernel_initializer='he_normal', kernel_regularizer = l2(1e-4))(attr_input)\n",
    "#     attr_dense = Dense(512)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(256)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(300, activation=\"relu\")(attr_dense)\n",
    "    # attr_dense = Dense(512, activation=\"relu\")(attr_dense)\n",
    "\n",
    "    attr_word_emb = word_emb #Concatenate()([word_emb, attr_input])\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb, hidden_dim = [1024 + 512, \n",
    "                                                                          1024 + 256 + 128, 1024 + 256, 1020])\n",
    "#     attr_word_emb_dense = full_connect_layer(attr_word_emb, hidden_dim = [1024])\n",
    "\n",
    "    model = Model([attr_input, word_emb], outputs = attr_word_emb_dense) #, vgg_output])\n",
    "    # model.add_loss(mse_loss)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-4), loss='mean_squared_error')\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "#data.loc[class_id] #data_atten.loc[n]\n",
    "fold = 5\n",
    "kf = KFold(n_splits=fold * 2, shuffle=True)\n",
    "kf_2 = KFold(n_splits=fold * 2 - 1, shuffle=True)\n",
    "num_fold = 0\n",
    "class_ids = train_data['class_id'].unique() #[:5]\n",
    "\n",
    "# train_image_feature_map = np.reshape(vgg_model.predict(train_data_part_img, verbose=  1), (train_data_part_length, -1))\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(train_y, handle)\n",
    "# with open(path + 'train_vgg16_img_div255.pickle', 'rb') as handle:\n",
    "#     train_image_feature_map = pickle.load(handle)\n",
    "\n",
    "for train_index, test_index in kf.split(class_ids):\n",
    "    train_part_id = class_ids[train_index]\n",
    "    validate_part_id = class_ids[test_index]\n",
    "    \n",
    "    train_part_df = train_data[train_data['class_id'].isin(train_part_id)]\n",
    "    validate_part_df = train_data[train_data['class_id'].isin(validate_part_id)]\n",
    "    print ('Split by class id', train_part_df.shape, validate_part_df.shape)\n",
    "#     for train_index2, test_index2 in kf_2.split(train_part_df):\n",
    "# #         print (train_index2)\n",
    "#         seen_class_in_validation = train_part_df.iloc[test_index2].class_id.unique().shape[0]\n",
    "#         validate_part_df = validate_part_df.append(train_part_df.iloc[test_index2])\n",
    "#         train_part_df = train_part_df.iloc[train_index2]\n",
    "#         break\n",
    "    print ('Add ', seen_class_in_validation, 'seen class in validation: ', train_part_df.shape, validate_part_df.shape)\n",
    "    \n",
    "    train_part_data = create_dnn_data(train_part_df)\n",
    "    train_part_target = extract_array_from_series(train_part_df['target'])\n",
    "    \n",
    "    validate_part_data = create_dnn_data(validate_part_df)\n",
    "    validate_part_target = extract_array_from_series(validate_part_df['target'])\n",
    "    \n",
    "    print('fold: %d th train :-)' % (num_fold))\n",
    "    print('Train size: {} Valide size: {}'.format(train_part_df.shape[0], validate_part_df.shape[0]))\n",
    "    print('Seen category: {} Unseen category: {}'.format(train_part_id.shape[0], validate_part_id.shape[0]))\n",
    "\n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "            AccuracyEvaluation(validation_data=(validate_part_data,  validate_part_target), interval=1, \\\n",
    "#                         class_id_emb_attr = class_id_emb_attr, \\\n",
    "                               eval_df = validate_part_df, threshold= 2, \\\n",
    "                              seen_class = train_part_id, unseen_class = validate_part_id, \\\n",
    "                class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(validate_part_id)], \\\n",
    "                              gamma = 0)\n",
    "            ]\n",
    "    \n",
    "    zs_model = create_dnn()\n",
    "    if num_fold == 0:\n",
    "        print (zs_model.summary())\n",
    "    zs_model.fit(train_part_data, train_part_target,  validation_data = (validate_part_data, validate_part_target),\n",
    "                  epochs=50, batch_size = 32, shuffle=True, verbose = 1, callbacks=callbacks)\n",
    "    break\n",
    "#     model = lgbm_train(train_part_data[0], train_part_target, validate_part_data[0], validate_part_target, num_fold, fold)\n",
    "    num_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>627420a22ddbd999d2ddacda932a76dc.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>491f90eb9e2f97fd4a7a30dd80bda5dd.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d0d484f15757cf4ed15cb466e59be729.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b1f605e2be20cc2790f00aa8f26edbe.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61153b22f676e3713596dce05fedcec7.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0\n",
       "0  627420a22ddbd999d2ddacda932a76dc.jpeg\n",
       "1  491f90eb9e2f97fd4a7a30dd80bda5dd.jpeg\n",
       "2  d0d484f15757cf4ed15cb466e59be729.jpeg\n",
       "3  4b1f605e2be20cc2790f00aa8f26edbe.jpeg\n",
       "4  61153b22f676e3713596dce05fedcec7.jpeg"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_nearest_class_id = find_nearest_class(class_id_emb_attr, zs_model, validate_part_df, validate_part_target, 2)\n",
    "# pred_nearest_class_id\n",
    "validate_part_img_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>emb</th>\n",
       "      <th>attr</th>\n",
       "      <th>img</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...</td>\n",
       "      <td>[0.31291956, 0.06956484, 0.34872296, 0.0408261...</td>\n",
       "      <td>[0.0002583923, 1.3706127e-09, 4.1264484e-06, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...</td>\n",
       "      <td>[0.41405687, 0.0, 0.42773584, 0.26566932, 0.09...</td>\n",
       "      <td>[8.528514e-05, 7.096203e-13, 2.6975513e-07, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....</td>\n",
       "      <td>[0.47680363, 0.040604584, 0.3921131, 0.0505364...</td>\n",
       "      <td>[4.0051555e-07, 2.7406966e-10, 0.006872305, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>7d93ef45972154aae150b4f9980a79c0.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....</td>\n",
       "      <td>[0.43787628, 0.22630945, 0.9117755, 0.37130392...</td>\n",
       "      <td>[4.478419e-06, 6.6335826e-15, 4.5222535e-07, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...</td>\n",
       "      <td>[0.09672493, 0.02039393, 0.0, 0.063967526, 0.5...</td>\n",
       "      <td>[1.1269697e-05, 1.5967143e-12, 0.000112516616,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_id                               image_id class_name  \\\n",
       "0     ZJL1  a6394b0f513290f4651cc46792e5ac86.jpeg   goldfish   \n",
       "1     ZJL1  2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg   goldfish   \n",
       "2     ZJL1  eda9f3bef2bd8da038f6acbc8355fc25.jpeg   goldfish   \n",
       "3     ZJL1  7d93ef45972154aae150b4f9980a79c0.jpeg   goldfish   \n",
       "4     ZJL1  fb901b4f9a8e396c1d0155bccc5e5671.jpeg   goldfish   \n",
       "\n",
       "                                                 emb  \\\n",
       "0  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "1  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "2  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "3  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "4  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "\n",
       "                                                attr  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "\n",
       "                                                 img  \\\n",
       "0  [[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...   \n",
       "1  [[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...   \n",
       "2  [[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....   \n",
       "3  [[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....   \n",
       "4  [[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...   \n",
       "\n",
       "                                              target  \\\n",
       "0  [0.31291956, 0.06956484, 0.34872296, 0.0408261...   \n",
       "1  [0.41405687, 0.0, 0.42773584, 0.26566932, 0.09...   \n",
       "2  [0.47680363, 0.040604584, 0.3921131, 0.0505364...   \n",
       "3  [0.43787628, 0.22630945, 0.9117755, 0.37130392...   \n",
       "4  [0.09672493, 0.02039393, 0.0, 0.063967526, 0.5...   \n",
       "\n",
       "                                               preds  \n",
       "0  [0.0002583923, 1.3706127e-09, 4.1264484e-06, 7...  \n",
       "1  [8.528514e-05, 7.096203e-13, 2.6975513e-07, 0....  \n",
       "2  [4.0051555e-07, 2.7406966e-10, 0.006872305, 1....  \n",
       "3  [4.478419e-06, 6.6335826e-15, 4.5222535e-07, 5...  \n",
       "4  [1.1269697e-05, 1.5967143e-12, 0.000112516616,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D) (None, 70, 70, 3)     0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)              (None, 68, 68, 64)    1728        zero_padding2d_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)    (None, 68, 68, 64)    256         conv1/conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1/relu (Activation)          (None, 68, 68, 64)    0           conv1/bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D) (None, 70, 70, 64)    0           conv1/relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool1 (AveragePooling2D)         (None, 34, 34, 64)    0           zero_padding2d_2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormaliz (None, 34, 34, 64)    256         pool1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation) (None, 34, 34, 64)    0           conv2_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)     (None, 34, 34, 64)    4096        conv2_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenate (None, 34, 34, 80)    0           pool1[0][0]                      \n",
      "                                                                   conv2_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormaliz (None, 34, 34, 80)    320         conv2_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation) (None, 34, 34, 80)    0           conv2_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)     (None, 34, 34, 64)    5120        conv2_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenate (None, 34, 34, 96)    0           conv2_block1_concat[0][0]        \n",
      "                                                                   conv2_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormaliz (None, 34, 34, 96)    384         conv2_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation) (None, 34, 34, 96)    0           conv2_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)     (None, 34, 34, 64)    6144        conv2_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenate (None, 34, 34, 112)   0           conv2_block2_concat[0][0]        \n",
      "                                                                   conv2_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormaliz (None, 34, 34, 112)   448         conv2_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation) (None, 34, 34, 112)   0           conv2_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)     (None, 34, 34, 64)    7168        conv2_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenate (None, 34, 34, 128)   0           conv2_block3_concat[0][0]        \n",
      "                                                                   conv2_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormaliz (None, 34, 34, 128)   512         conv2_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation) (None, 34, 34, 128)   0           conv2_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)     (None, 34, 34, 64)    8192        conv2_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenate (None, 34, 34, 144)   0           conv2_block4_concat[0][0]        \n",
      "                                                                   conv2_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormaliz (None, 34, 34, 144)   576         conv2_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation) (None, 34, 34, 144)   0           conv2_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)     (None, 34, 34, 64)    9216        conv2_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenate (None, 34, 34, 160)   0           conv2_block5_concat[0][0]        \n",
      "                                                                   conv2_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)    (None, 34, 34, 160)   640         conv2_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "pool2_relu (Activation)          (None, 34, 34, 160)   0           pool2_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)              (None, 34, 34, 80)    12800       pool2_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)    (None, 17, 17, 80)    0           pool2_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormaliz (None, 17, 17, 80)    320         pool2_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation) (None, 17, 17, 80)    0           conv3_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)     (None, 17, 17, 64)    5120        conv3_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenate (None, 17, 17, 96)    0           pool2_pool[0][0]                 \n",
      "                                                                   conv3_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormaliz (None, 17, 17, 96)    384         conv3_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation) (None, 17, 17, 96)    0           conv3_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)     (None, 17, 17, 64)    6144        conv3_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenate (None, 17, 17, 112)   0           conv3_block1_concat[0][0]        \n",
      "                                                                   conv3_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormaliz (None, 17, 17, 112)   448         conv3_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation) (None, 17, 17, 112)   0           conv3_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)     (None, 17, 17, 64)    7168        conv3_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenate (None, 17, 17, 128)   0           conv3_block2_concat[0][0]        \n",
      "                                                                   conv3_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation) (None, 17, 17, 128)   0           conv3_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)     (None, 17, 17, 64)    8192        conv3_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenate (None, 17, 17, 144)   0           conv3_block3_concat[0][0]        \n",
      "                                                                   conv3_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormaliz (None, 17, 17, 144)   576         conv3_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation) (None, 17, 17, 144)   0           conv3_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)     (None, 17, 17, 64)    9216        conv3_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenate (None, 17, 17, 160)   0           conv3_block4_concat[0][0]        \n",
      "                                                                   conv3_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormaliz (None, 17, 17, 160)   640         conv3_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation) (None, 17, 17, 160)   0           conv3_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)     (None, 17, 17, 64)    10240       conv3_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenate (None, 17, 17, 176)   0           conv3_block5_concat[0][0]        \n",
      "                                                                   conv3_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormaliz (None, 17, 17, 176)   704         conv3_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation) (None, 17, 17, 176)   0           conv3_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)     (None, 17, 17, 64)    11264       conv3_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenate (None, 17, 17, 192)   0           conv3_block6_concat[0][0]        \n",
      "                                                                   conv3_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormaliz (None, 17, 17, 192)   768         conv3_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation) (None, 17, 17, 192)   0           conv3_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)     (None, 17, 17, 64)    12288       conv3_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenate (None, 17, 17, 208)   0           conv3_block7_concat[0][0]        \n",
      "                                                                   conv3_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormaliz (None, 17, 17, 208)   832         conv3_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation) (None, 17, 17, 208)   0           conv3_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)     (None, 17, 17, 64)    13312       conv3_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenate (None, 17, 17, 224)   0           conv3_block8_concat[0][0]        \n",
      "                                                                   conv3_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormali (None, 17, 17, 224)   896         conv3_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activation (None, 17, 17, 224)   0           conv3_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)    (None, 17, 17, 64)    14336       conv3_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormali (None, 17, 17, 64)    256         conv3_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activation (None, 17, 17, 64)    0           conv3_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)    (None, 17, 17, 16)    9216        conv3_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatenat (None, 17, 17, 240)   0           conv3_block9_concat[0][0]        \n",
      "                                                                   conv3_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormali (None, 17, 17, 240)   960         conv3_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activation (None, 17, 17, 240)   0           conv3_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)    (None, 17, 17, 64)    15360       conv3_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormali (None, 17, 17, 64)    256         conv3_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activation (None, 17, 17, 64)    0           conv3_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)    (None, 17, 17, 16)    9216        conv3_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatenat (None, 17, 17, 256)   0           conv3_block10_concat[0][0]       \n",
      "                                                                   conv3_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormali (None, 17, 17, 256)   1024        conv3_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activation (None, 17, 17, 256)   0           conv3_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)    (None, 17, 17, 64)    16384       conv3_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormali (None, 17, 17, 64)    256         conv3_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activation (None, 17, 17, 64)    0           conv3_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)    (None, 17, 17, 16)    9216        conv3_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatenat (None, 17, 17, 272)   0           conv3_block11_concat[0][0]       \n",
      "                                                                   conv3_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)    (None, 17, 17, 272)   1088        conv3_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool3_relu (Activation)          (None, 17, 17, 272)   0           pool3_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)              (None, 17, 17, 136)   36992       pool3_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)    (None, 8, 8, 136)     0           pool3_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormaliz (None, 8, 8, 136)     544         pool3_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation) (None, 8, 8, 136)     0           conv4_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)     (None, 8, 8, 64)      8704        conv4_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenate (None, 8, 8, 152)     0           pool3_pool[0][0]                 \n",
      "                                                                   conv4_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormaliz (None, 8, 8, 152)     608         conv4_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation) (None, 8, 8, 152)     0           conv4_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)     (None, 8, 8, 64)      9728        conv4_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenate (None, 8, 8, 168)     0           conv4_block1_concat[0][0]        \n",
      "                                                                   conv4_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormaliz (None, 8, 8, 168)     672         conv4_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation) (None, 8, 8, 168)     0           conv4_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)     (None, 8, 8, 64)      10752       conv4_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenate (None, 8, 8, 184)     0           conv4_block2_concat[0][0]        \n",
      "                                                                   conv4_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormaliz (None, 8, 8, 184)     736         conv4_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation) (None, 8, 8, 184)     0           conv4_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)     (None, 8, 8, 64)      11776       conv4_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenate (None, 8, 8, 200)     0           conv4_block3_concat[0][0]        \n",
      "                                                                   conv4_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormaliz (None, 8, 8, 200)     800         conv4_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation) (None, 8, 8, 200)     0           conv4_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)     (None, 8, 8, 64)      12800       conv4_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenate (None, 8, 8, 216)     0           conv4_block4_concat[0][0]        \n",
      "                                                                   conv4_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormaliz (None, 8, 8, 216)     864         conv4_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation) (None, 8, 8, 216)     0           conv4_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)     (None, 8, 8, 64)      13824       conv4_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenate (None, 8, 8, 232)     0           conv4_block5_concat[0][0]        \n",
      "                                                                   conv4_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormaliz (None, 8, 8, 232)     928         conv4_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation) (None, 8, 8, 232)     0           conv4_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)     (None, 8, 8, 64)      14848       conv4_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenate (None, 8, 8, 248)     0           conv4_block6_concat[0][0]        \n",
      "                                                                   conv4_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormaliz (None, 8, 8, 248)     992         conv4_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation) (None, 8, 8, 248)     0           conv4_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)     (None, 8, 8, 64)      15872       conv4_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenate (None, 8, 8, 264)     0           conv4_block7_concat[0][0]        \n",
      "                                                                   conv4_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormaliz (None, 8, 8, 264)     1056        conv4_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation) (None, 8, 8, 264)     0           conv4_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)     (None, 8, 8, 64)      16896       conv4_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenate (None, 8, 8, 280)     0           conv4_block8_concat[0][0]        \n",
      "                                                                   conv4_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormali (None, 8, 8, 280)     1120        conv4_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activation (None, 8, 8, 280)     0           conv4_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)    (None, 8, 8, 64)      17920       conv4_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activation (None, 8, 8, 64)      0           conv4_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatenat (None, 8, 8, 296)     0           conv4_block9_concat[0][0]        \n",
      "                                                                   conv4_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormali (None, 8, 8, 296)     1184        conv4_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activation (None, 8, 8, 296)     0           conv4_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)    (None, 8, 8, 64)      18944       conv4_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activation (None, 8, 8, 64)      0           conv4_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatenat (None, 8, 8, 312)     0           conv4_block10_concat[0][0]       \n",
      "                                                                   conv4_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormali (None, 8, 8, 312)     1248        conv4_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activation (None, 8, 8, 312)     0           conv4_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)    (None, 8, 8, 64)      19968       conv4_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activation (None, 8, 8, 64)      0           conv4_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatenat (None, 8, 8, 328)     0           conv4_block11_concat[0][0]       \n",
      "                                                                   conv4_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormali (None, 8, 8, 328)     1312        conv4_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activation (None, 8, 8, 328)     0           conv4_block13_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)    (None, 8, 8, 64)      20992       conv4_block13_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block13_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activation (None, 8, 8, 64)      0           conv4_block13_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block13_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatenat (None, 8, 8, 344)     0           conv4_block12_concat[0][0]       \n",
      "                                                                   conv4_block13_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormali (None, 8, 8, 344)     1376        conv4_block13_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activation (None, 8, 8, 344)     0           conv4_block14_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)    (None, 8, 8, 64)      22016       conv4_block14_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block14_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activation (None, 8, 8, 64)      0           conv4_block14_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block14_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatenat (None, 8, 8, 360)     0           conv4_block13_concat[0][0]       \n",
      "                                                                   conv4_block14_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormali (None, 8, 8, 360)     1440        conv4_block14_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activation (None, 8, 8, 360)     0           conv4_block15_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)    (None, 8, 8, 64)      23040       conv4_block15_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block15_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activation (None, 8, 8, 64)      0           conv4_block15_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block15_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatenat (None, 8, 8, 376)     0           conv4_block14_concat[0][0]       \n",
      "                                                                   conv4_block15_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormali (None, 8, 8, 376)     1504        conv4_block15_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activation (None, 8, 8, 376)     0           conv4_block16_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)    (None, 8, 8, 64)      24064       conv4_block16_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block16_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activation (None, 8, 8, 64)      0           conv4_block16_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block16_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatenat (None, 8, 8, 392)     0           conv4_block15_concat[0][0]       \n",
      "                                                                   conv4_block16_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormali (None, 8, 8, 392)     1568        conv4_block16_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activation (None, 8, 8, 392)     0           conv4_block17_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)    (None, 8, 8, 64)      25088       conv4_block17_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block17_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activation (None, 8, 8, 64)      0           conv4_block17_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block17_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatenat (None, 8, 8, 408)     0           conv4_block16_concat[0][0]       \n",
      "                                                                   conv4_block17_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormali (None, 8, 8, 408)     1632        conv4_block17_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activation (None, 8, 8, 408)     0           conv4_block18_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)    (None, 8, 8, 64)      26112       conv4_block18_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block18_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activation (None, 8, 8, 64)      0           conv4_block18_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block18_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatenat (None, 8, 8, 424)     0           conv4_block17_concat[0][0]       \n",
      "                                                                   conv4_block18_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormali (None, 8, 8, 424)     1696        conv4_block18_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activation (None, 8, 8, 424)     0           conv4_block19_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)    (None, 8, 8, 64)      27136       conv4_block19_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block19_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activation (None, 8, 8, 64)      0           conv4_block19_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block19_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatenat (None, 8, 8, 440)     0           conv4_block18_concat[0][0]       \n",
      "                                                                   conv4_block19_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormali (None, 8, 8, 440)     1760        conv4_block19_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activation (None, 8, 8, 440)     0           conv4_block20_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)    (None, 8, 8, 64)      28160       conv4_block20_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block20_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activation (None, 8, 8, 64)      0           conv4_block20_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block20_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatenat (None, 8, 8, 456)     0           conv4_block19_concat[0][0]       \n",
      "                                                                   conv4_block20_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormali (None, 8, 8, 456)     1824        conv4_block20_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activation (None, 8, 8, 456)     0           conv4_block21_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)    (None, 8, 8, 64)      29184       conv4_block21_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block21_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activation (None, 8, 8, 64)      0           conv4_block21_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block21_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatenat (None, 8, 8, 472)     0           conv4_block20_concat[0][0]       \n",
      "                                                                   conv4_block21_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormali (None, 8, 8, 472)     1888        conv4_block21_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activation (None, 8, 8, 472)     0           conv4_block22_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)    (None, 8, 8, 64)      30208       conv4_block22_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block22_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activation (None, 8, 8, 64)      0           conv4_block22_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block22_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatenat (None, 8, 8, 488)     0           conv4_block21_concat[0][0]       \n",
      "                                                                   conv4_block22_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormali (None, 8, 8, 488)     1952        conv4_block22_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activation (None, 8, 8, 488)     0           conv4_block23_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)    (None, 8, 8, 64)      31232       conv4_block23_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block23_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activation (None, 8, 8, 64)      0           conv4_block23_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block23_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatenat (None, 8, 8, 504)     0           conv4_block22_concat[0][0]       \n",
      "                                                                   conv4_block23_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormali (None, 8, 8, 504)     2016        conv4_block23_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activation (None, 8, 8, 504)     0           conv4_block24_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)    (None, 8, 8, 64)      32256       conv4_block24_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block24_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activation (None, 8, 8, 64)      0           conv4_block24_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block24_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatenat (None, 8, 8, 520)     0           conv4_block23_concat[0][0]       \n",
      "                                                                   conv4_block24_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)    (None, 8, 8, 520)     2080        conv4_block24_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool4_relu (Activation)          (None, 8, 8, 520)     0           pool4_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)              (None, 8, 8, 260)     135200      pool4_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)    (None, 4, 4, 260)     0           pool4_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormaliz (None, 4, 4, 260)     1040        pool4_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation) (None, 4, 4, 260)     0           conv5_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)     (None, 4, 4, 64)      16640       conv5_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenate (None, 4, 4, 276)     0           pool4_pool[0][0]                 \n",
      "                                                                   conv5_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormaliz (None, 4, 4, 276)     1104        conv5_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation) (None, 4, 4, 276)     0           conv5_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)     (None, 4, 4, 64)      17664       conv5_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenate (None, 4, 4, 292)     0           conv5_block1_concat[0][0]        \n",
      "                                                                   conv5_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormaliz (None, 4, 4, 292)     1168        conv5_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation) (None, 4, 4, 292)     0           conv5_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)     (None, 4, 4, 64)      18688       conv5_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenate (None, 4, 4, 308)     0           conv5_block2_concat[0][0]        \n",
      "                                                                   conv5_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormaliz (None, 4, 4, 308)     1232        conv5_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation) (None, 4, 4, 308)     0           conv5_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)     (None, 4, 4, 64)      19712       conv5_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenate (None, 4, 4, 324)     0           conv5_block3_concat[0][0]        \n",
      "                                                                   conv5_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormaliz (None, 4, 4, 324)     1296        conv5_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation) (None, 4, 4, 324)     0           conv5_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)     (None, 4, 4, 64)      20736       conv5_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenate (None, 4, 4, 340)     0           conv5_block4_concat[0][0]        \n",
      "                                                                   conv5_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormaliz (None, 4, 4, 340)     1360        conv5_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation) (None, 4, 4, 340)     0           conv5_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)     (None, 4, 4, 64)      21760       conv5_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenate (None, 4, 4, 356)     0           conv5_block5_concat[0][0]        \n",
      "                                                                   conv5_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormaliz (None, 4, 4, 356)     1424        conv5_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation) (None, 4, 4, 356)     0           conv5_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)     (None, 4, 4, 64)      22784       conv5_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenate (None, 4, 4, 372)     0           conv5_block6_concat[0][0]        \n",
      "                                                                   conv5_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormaliz (None, 4, 4, 372)     1488        conv5_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation) (None, 4, 4, 372)     0           conv5_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)     (None, 4, 4, 64)      23808       conv5_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenate (None, 4, 4, 388)     0           conv5_block7_concat[0][0]        \n",
      "                                                                   conv5_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormaliz (None, 4, 4, 388)     1552        conv5_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation) (None, 4, 4, 388)     0           conv5_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)     (None, 4, 4, 64)      24832       conv5_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenate (None, 4, 4, 404)     0           conv5_block8_concat[0][0]        \n",
      "                                                                   conv5_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormali (None, 4, 4, 404)     1616        conv5_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activation (None, 4, 4, 404)     0           conv5_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)    (None, 4, 4, 64)      25856       conv5_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activation (None, 4, 4, 64)      0           conv5_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatenat (None, 4, 4, 420)     0           conv5_block9_concat[0][0]        \n",
      "                                                                   conv5_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormali (None, 4, 4, 420)     1680        conv5_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activation (None, 4, 4, 420)     0           conv5_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)    (None, 4, 4, 64)      26880       conv5_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activation (None, 4, 4, 64)      0           conv5_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatenat (None, 4, 4, 436)     0           conv5_block10_concat[0][0]       \n",
      "                                                                   conv5_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormali (None, 4, 4, 436)     1744        conv5_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activation (None, 4, 4, 436)     0           conv5_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)    (None, 4, 4, 64)      27904       conv5_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activation (None, 4, 4, 64)      0           conv5_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatenat (None, 4, 4, 452)     0           conv5_block11_concat[0][0]       \n",
      "                                                                   conv5_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormali (None, 4, 4, 452)     1808        conv5_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activation (None, 4, 4, 452)     0           conv5_block13_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)    (None, 4, 4, 64)      28928       conv5_block13_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block13_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activation (None, 4, 4, 64)      0           conv5_block13_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block13_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatenat (None, 4, 4, 468)     0           conv5_block12_concat[0][0]       \n",
      "                                                                   conv5_block13_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormali (None, 4, 4, 468)     1872        conv5_block13_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activation (None, 4, 4, 468)     0           conv5_block14_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)    (None, 4, 4, 64)      29952       conv5_block14_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block14_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activation (None, 4, 4, 64)      0           conv5_block14_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block14_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatenat (None, 4, 4, 484)     0           conv5_block13_concat[0][0]       \n",
      "                                                                   conv5_block14_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormali (None, 4, 4, 484)     1936        conv5_block14_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activation (None, 4, 4, 484)     0           conv5_block15_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)    (None, 4, 4, 64)      30976       conv5_block15_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block15_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activation (None, 4, 4, 64)      0           conv5_block15_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block15_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatenat (None, 4, 4, 500)     0           conv5_block14_concat[0][0]       \n",
      "                                                                   conv5_block15_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormali (None, 4, 4, 500)     2000        conv5_block15_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activation (None, 4, 4, 500)     0           conv5_block16_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)    (None, 4, 4, 64)      32000       conv5_block16_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block16_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activation (None, 4, 4, 64)      0           conv5_block16_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block16_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatenat (None, 4, 4, 516)     0           conv5_block15_concat[0][0]       \n",
      "                                                                   conv5_block16_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "bn (BatchNormalization)          (None, 4, 4, 516)     2064        conv5_block16_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "relu (Activation)                (None, 4, 4, 516)     0           bn[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D (None, 516)           0           relu[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "fc (Dense)                       (None, 171)           88407       avg_pool[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1,945,831\n",
      "Trainable params: 1,902,543\n",
      "Non-trainable params: 43,288\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"av...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38208/38221 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "img_model = DenseNet(blocks = [6, 12, 24, 16], \n",
    "                                cat_max = 171,\n",
    "                                weight_decay = 1e-4, \n",
    "                                kernel_initializer = 'glorot_normal',\n",
    "                                reduction = 0.5, \n",
    "                                init_filters = 64, \n",
    "                                growth_rate = 16).model\n",
    "img_model.load_weights(path + 'model_sub/6_12_24_16_ini64_growth16_02962/model_0_2018_09_13_08_23_48.h5')\n",
    "img_model_flat = Model(input = img_model.input, output = img_model.get_layer(name = 'avg_pool').output)\n",
    "train_data['target'] = list(img_model_flat.predict(train_img, verbose = 1))\n",
    "train_data['preds'] = list(img_model.predict(train_img, verbose = 1))\n",
    "# train_data['target'] = list(train_y) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_img_id = pd.read_csv(path + '/model_sub/6_12_24_16_ini64_growth16_02962/train_part_img_id_0.csv', header = None)\n",
    "validate_part_img_id = pd.read_csv(path + '/model_sub/6_12_24_16_ini64_growth16_02962/validate_part_img_id_0.csv', header = None)\n",
    "train_part_img_id = train_part_img_id[0].values\n",
    "validate_part_img_id = validate_part_img_id[0].values\n",
    "\n",
    "train_part_df = train_data[train_data['image_id'].isin(train_part_img_id)]\n",
    "validate_part_df = train_data[train_data['image_id'].isin(validate_part_img_id)]\n",
    "\n",
    "seen_class = train_part_df.append(validate_part_df).class_id.unique()\n",
    "\n",
    "unseen_class_df = train_data[~train_data['class_id'].isin(seen_class)]\n",
    "unseen_class = unseen_class_df.class_id.unique()\n",
    "\n",
    "validate_part_df = validate_part_df.append(unseen_class_df)\n",
    "\n",
    "train_part_data = create_dnn_data(train_part_df)\n",
    "train_part_target = extract_array_from_series(train_part_df['target'])\n",
    "\n",
    "validate_part_data = create_dnn_data(validate_part_df)\n",
    "validate_part_target = extract_array_from_series(validate_part_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "wv (InputLayer)              (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 600)               2400      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1024)              615424    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 768)               787200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 516)               396804    \n",
      "=================================================================\n",
      "Total params: 1,808,996\n",
      "Trainable params: 1,804,212\n",
      "Non-trainable params: 4,784\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 30595 samples, validate on 7626 samples\n",
      "Epoch 1/150\n",
      "30528/30595 [============================>.] - ETA: 0s - loss: 0.5773\n",
      "All_re: \t0.046420\t354\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.093133\t354\t3801\n",
      "30595/30595 [==============================] - 8s - loss: 0.5772 - val_loss: 0.5529\n",
      "Epoch 2/150\n",
      "30368/30595 [============================>.] - ETA: 0s - loss: 0.4539\n",
      "All_re: \t0.069761\t532\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.139963\t532\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.4536 - val_loss: 0.4563\n",
      "Epoch 3/150\n",
      "30528/30595 [============================>.] - ETA: 0s - loss: 0.3835\n",
      "All_re: \t0.071728\t547\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.143909\t547\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.3834 - val_loss: 0.3804\n",
      "Epoch 4/150\n",
      "30560/30595 [============================>.] - ETA: 0s - loss: 0.3207\n",
      "All_re: \t0.086939\t663\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.174428\t663\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.3207 - val_loss: 0.3160\n",
      "Epoch 5/150\n",
      "30336/30595 [============================>.] - ETA: 0s - loss: 0.2674\n",
      "All_re: \t0.091267\t696\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.183110\t696\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.2673 - val_loss: 0.2655\n",
      "Epoch 6/150\n",
      "30336/30595 [============================>.] - ETA: 0s - loss: 0.2266\n",
      "All_re: \t0.094283\t719\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.189161\t719\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.2264 - val_loss: 0.2276\n",
      "Epoch 7/150\n",
      "30368/30595 [============================>.] - ETA: 0s - loss: 0.1977\n",
      "All_re: \t0.089169\t680\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.178900\t680\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.1977 - val_loss: 0.2012\n",
      "Epoch 8/150\n",
      "30528/30595 [============================>.] - ETA: 0s - loss: 0.1772\n",
      "All_re: \t0.098479\t751\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.197580\t751\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1772 - val_loss: 0.1820\n",
      "Epoch 9/150\n",
      "30368/30595 [============================>.] - ETA: 0s - loss: 0.1627\n",
      "All_re: \t0.104904\t800\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.210471\t800\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1627 - val_loss: 0.1686\n",
      "Epoch 10/150\n",
      "30464/30595 [============================>.] - ETA: 0s - loss: 0.1525\n",
      "All_re: \t0.109625\t836\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.219942\t836\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1525 - val_loss: 0.1590\n",
      "Epoch 11/150\n",
      "30432/30595 [============================>.] - ETA: 0s - loss: 0.1453\n",
      "All_re: \t0.106347\t811\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.213365\t811\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.1453 - val_loss: 0.1535\n",
      "Epoch 12/150\n",
      "30432/30595 [============================>.] - ETA: 0s - loss: 0.1403\n",
      "All_re: \t0.117099\t893\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.234938\t893\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.1403 - val_loss: 0.1480\n",
      "Epoch 13/150\n",
      "30528/30595 [============================>.] - ETA: 0s - loss: 0.1369\n",
      "All_re: \t0.112116\t855\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.224941\t855\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.1369 - val_loss: 0.1459\n",
      "Epoch 14/150\n",
      "30432/30595 [============================>.] - ETA: 0s - loss: 0.1345\n",
      "All_re: \t0.114477\t873\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.229676\t873\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.1345 - val_loss: 0.1439\n",
      "Epoch 15/150\n",
      "30464/30595 [============================>.] - ETA: 0s - loss: 0.1328\n",
      "All_re: \t0.117362\t895\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.235464\t895\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1328 - val_loss: 0.1420\n",
      "Epoch 16/150\n",
      "30336/30595 [============================>.] - ETA: 0s - loss: 0.1315\n",
      "All_re: \t0.111854\t853\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.224415\t853\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1315 - val_loss: 0.1415\n",
      "Epoch 17/150\n",
      "30304/30595 [============================>.] - ETA: 0s - loss: 0.1305\n",
      "All_re: \t0.110805\t845\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.222310\t845\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1306 - val_loss: 0.1410\n",
      "Epoch 18/150\n",
      "30432/30595 [============================>.] - ETA: 0s - loss: 0.1297\n",
      "All_re: \t0.108183\t825\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.217048\t825\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1297 - val_loss: 0.1400\n",
      "Epoch 19/150\n",
      "30592/30595 [============================>.] - ETA: 0s - loss: 0.1292\n",
      "All_re: \t0.116181\t886\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.233097\t886\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1292 - val_loss: 0.1393\n",
      "Epoch 20/150\n",
      "30464/30595 [============================>.] - ETA: 0s - loss: 0.1286\n",
      "All_re: \t0.107133\t817\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.214943\t817\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1286 - val_loss: 0.1390\n",
      "Epoch 21/150\n",
      "30368/30595 [============================>.] - ETA: 0s - loss: 0.1282\n",
      "All_re: \t0.109100\t832\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.218890\t832\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1282 - val_loss: 0.1387\n",
      "Epoch 22/150\n",
      "30528/30595 [============================>.] - ETA: 0s - loss: 0.1280\n",
      "All_re: \t0.107133\t817\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.214943\t817\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1280 - val_loss: 0.1386\n",
      "Epoch 23/150\n",
      "30400/30595 [============================>.] - ETA: 0s - loss: 0.1278\n",
      "All_re: \t0.109100\t832\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.218890\t832\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1278 - val_loss: 0.1381\n",
      "Epoch 24/150\n",
      "30464/30595 [============================>.] - ETA: 0s - loss: 0.1275\n",
      "All_re: \t0.108707\t829\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.218100\t829\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1275 - val_loss: 0.1379\n",
      "Epoch 25/150\n",
      "30560/30595 [============================>.] - ETA: 0s - loss: 0.1272\n",
      "All_re: \t0.114215\t871\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.229150\t871\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1272 - val_loss: 0.1370\n",
      "Epoch 26/150\n",
      "30560/30595 [============================>.] - ETA: 0s - loss: 0.1271\n",
      "All_re: \t0.114870\t876\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.230466\t876\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1271 - val_loss: 0.1370\n",
      "Epoch 27/150\n",
      "30528/30595 [============================>.] - ETA: 0s - loss: 0.1269\n",
      "All_re: \t0.106740\t814\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.214154\t814\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1269 - val_loss: 0.1372\n",
      "Epoch 28/150\n",
      "30464/30595 [============================>.] - ETA: 0s - loss: 0.1267\n",
      "All_re: \t0.099790\t761\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.200210\t761\t3801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30595/30595 [==============================] - 7s - loss: 0.1267 - val_loss: 0.1373\n",
      "Epoch 29/150\n",
      "30304/30595 [============================>.] - ETA: 0s - loss: 0.1267\n",
      "All_re: \t0.113428\t865\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.227572\t865\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.1268 - val_loss: 0.1378\n",
      "Epoch 30/150\n",
      "30528/30595 [============================>.] - ETA: 0s - loss: 0.1266\n",
      "All_re: \t0.111723\t852\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.224152\t852\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1266 - val_loss: 0.1371\n",
      "Epoch 31/150\n",
      "30368/30595 [============================>.] - ETA: 0s - loss: 0.1264\n",
      "All_re: \t0.111199\t848\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.223099\t848\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1264 - val_loss: 0.1368\n",
      "Epoch 32/150\n",
      "30560/30595 [============================>.] - ETA: 0s - loss: 0.1264\n",
      "All_re: \t0.115264\t879\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.231255\t879\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1264 - val_loss: 0.1368\n",
      "Epoch 33/150\n",
      "30496/30595 [============================>.] - ETA: 0s - loss: 0.1263\n",
      "All_re: \t0.112116\t855\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.224941\t855\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.1263 - val_loss: 0.1369\n",
      "Epoch 34/150\n",
      "30400/30595 [============================>.] - ETA: 0s - loss: 0.1262\n",
      "All_re: \t0.101888\t777\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.204420\t777\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.1262 - val_loss: 0.1370\n",
      "Epoch 35/150\n",
      "30464/30595 [============================>.] - ETA: 0s - loss: 0.1262\n",
      "All_re: \t0.100446\t766\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.201526\t766\t3801\n",
      "30595/30595 [==============================] - 6s - loss: 0.1262 - val_loss: 0.1378\n",
      "Epoch 36/150\n",
      "30400/30595 [============================>.] - ETA: 0s - loss: 0.1262\n",
      "All_re: \t0.103593\t790\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.207840\t790\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1262 - val_loss: 0.1368\n",
      "Epoch 37/150\n",
      "30464/30595 [============================>.] - ETA: 0s - loss: 0.1261\n",
      "All_re: \t0.107396\t819\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.215470\t819\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1261 - val_loss: 0.1367\n",
      "Epoch 38/150\n",
      "30368/30595 [============================>.] - ETA: 0s - loss: 0.1261\n",
      "All_re: \t0.097561\t744\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.195738\t744\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1261 - val_loss: 0.1369\n",
      "Epoch 39/150\n",
      "30368/30595 [============================>.] - ETA: 0s - loss: 0.1260\n",
      "All_re: \t0.107002\t816\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.214680\t816\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1260 - val_loss: 0.1363\n",
      "Epoch 40/150\n",
      "30496/30595 [============================>.] - ETA: 0s - loss: 0.1260\n",
      "All_re: \t0.107527\t820\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.215733\t820\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1259 - val_loss: 0.1365\n",
      "Epoch 41/150\n",
      "30400/30595 [============================>.] - ETA: 0s - loss: 0.1260\n",
      "All_re: \t0.107658\t821\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.215996\t821\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1260 - val_loss: 0.1366\n",
      "Epoch 42/150\n",
      "30368/30595 [============================>.] - ETA: 0s - loss: 0.1258\n",
      "All_re: \t0.108838\t830\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.218364\t830\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1258 - val_loss: 0.1365\n",
      "Epoch 43/150\n",
      "30368/30595 [============================>.] - ETA: 0s - loss: 0.1258\n",
      "All_re: \t0.110149\t840\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.220994\t840\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1258 - val_loss: 0.1365\n",
      "Epoch 44/150\n",
      "30400/30595 [============================>.] - ETA: 0s - loss: 0.1258\n",
      "All_re: \t0.110149\t840\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.220994\t840\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1258 - val_loss: 0.1364\n",
      "Epoch 45/150\n",
      "30432/30595 [============================>.] - ETA: 0s - loss: 0.1258\n",
      "All_re: \t0.110805\t845\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.222310\t845\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1258 - val_loss: 0.1364\n",
      "Epoch 46/150\n",
      "30336/30595 [============================>.] - ETA: 0s - loss: 0.1257\n",
      "All_re: \t0.107920\t823\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.216522\t823\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1257 - val_loss: 0.1363\n",
      "Epoch 47/150\n",
      "30432/30595 [============================>.] - ETA: 0s - loss: 0.1257\n",
      "All_re: \t0.106871\t815\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.214417\t815\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1257 - val_loss: 0.1364\n",
      "Epoch 48/150\n",
      "30400/30595 [============================>.] - ETA: 0s - loss: 0.1256\n",
      "All_re: \t0.108314\t826\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.217311\t826\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1256 - val_loss: 0.1364\n",
      "Epoch 49/150\n",
      "30400/30595 [============================>.] - ETA: 0s - loss: 0.1256\n",
      "All_re: \t0.105691\t806\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.212049\t806\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1256 - val_loss: 0.1365\n",
      "Epoch 50/150\n",
      "30336/30595 [============================>.] - ETA: 0s - loss: 0.1256\n",
      "All_re: \t0.104511\t797\t7626\n",
      "Seen_re: \t0.000000\t0\t3825\n",
      "Unseen_re: \t0.209682\t797\t3801\n",
      "30595/30595 [==============================] - 7s - loss: 0.1256 - val_loss: 0.1366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f903a1311d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "def find_nearest_class(class_id_emb_attr, model, eval_df, img_feature_map = None, \n",
    "                       threshold = None, gamma = None, seen_class = None):\n",
    "    if img_feature_map is None:\n",
    "        img_feature_map = np.reshape(vgg_model.predict(np.asarray(list(eval_df['img'])), verbose = 1), (eval_img.shape[0], -1))\n",
    "    cand_feature_map = model.predict(create_dnn_data(class_id_emb_attr))\n",
    "    # img_feature_map = np.repeat(img_feature_map, [cand_feature_map.shape[0]] * img_feature_map.shape[0], axis = 0)\n",
    "    nearest_class_id = ['ZJL'] * eval_df.shape[0]\n",
    "#     seen_class_bias = np.zeros(class_id_emb_attr.shape[0])\n",
    "#     seen_class_bias[class_id_emb_attr.class_id.isin(seen_class)] = gamma\n",
    "    \n",
    "#     seen_indice = [category_dict[c] for c in seen_class]\n",
    "#     preds = np.asarray(list(eval_df['preds']))[:, seen_indice]\n",
    "    for i in range(img_feature_map.shape[0]):\n",
    "        if False: #np.amax(preds[i]) > threshold:\n",
    "            nearest_class_id[i] = seen_class[np.argmax(preds[i])]\n",
    "        else:\n",
    "            img = img_feature_map[i]\n",
    "            dis = np.linalg.norm(img - cand_feature_map, axis = 1)\n",
    "#             print (dis)\n",
    "#             dis += seen_class_bias\n",
    "#             print(dis)\n",
    "#             plt.hist(dis)\n",
    "#             return\n",
    "            min_ind = np.where(dis == np.amin(dis))[0]\n",
    "            if len(min_ind) > 1:\n",
    "                print ('eval img id: ', eval_df.iloc[i]['class_id'], 'has multiple best candidates: ', len(min_ind), 'min val: ', np.amin(dis))\n",
    "    #         print (i, img, class_id_emb_attr.iloc[min_ind[0]].name)\n",
    "            nearest_class_id[i] = class_id_emb_attr.iloc[min_ind[0]]['class_id']\n",
    "#     print (nearest_class_id)\n",
    "    return np.asarray(nearest_class_id)\n",
    "\n",
    "class AccuracyEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_interval = 1000000, verbose = 2, \\\n",
    "            scores = [], class_id_emb_attr = None, eval_df = None, threshold = None, \\\n",
    "                 seen_class = None, unseen_class = None, gamma = None):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        # print(\"y_val shape:{0}\".format(self.y_val.shape))\n",
    "        self.batch_interval = batch_interval\n",
    "        self.verbose = verbose\n",
    "        self.scores = scores\n",
    "        self.class_id_emb_attr = class_id_emb_attr\n",
    "        self.eval_df = eval_df\n",
    "        self.threshold = threshold\n",
    "        self.seen_class = seen_class\n",
    "        self.unseen_class = unseen_class\n",
    "        self.gamma = gamma\n",
    "#         seen_indice = [category_dict[c] for c in seen_class]\n",
    "#         self.preds = np.asarray(list(eval_df['preds']))[:, seen_indice]\n",
    "#         self.img_feature_map = self.y_val\n",
    "    \n",
    "    def calc_accuracy(self, eval_df, eval_class, preds):\n",
    "        eval_mask = eval_df.class_id.isin(eval_class)\n",
    "        eval_num = np.sum(eval_mask)\n",
    "        right_num = np.sum(preds[eval_mask] == eval_df.class_id[eval_mask])\n",
    "        return right_num / np.sum(eval_mask), right_num, eval_num\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "#             zs_model = Model(inputs = self.model.inputs[:2], outputs = self.model.outpus[0])\n",
    "            pred_nearest_class_id = find_nearest_class(self.class_id_emb_attr, self.model, \n",
    "                                self.eval_df, self.y_val, self.threshold, self.gamma, self.seen_class)\n",
    "            all_re = self.calc_accuracy(self.eval_df, self.eval_df['class_id'].values, pred_nearest_class_id)\n",
    "            seen_re = self.calc_accuracy(self.eval_df, self.seen_class, pred_nearest_class_id)\n",
    "            unseen_re = self.calc_accuracy(self.eval_df, self.unseen_class, pred_nearest_class_id)\n",
    "#             true_class_id = self.eval_df['class_id'].values\n",
    "# #             print (pred_nearest_class_id, \"\\n\", true_class_id)\n",
    "#             right_num = np.sum(pred_nearest_class_id == true_class_id)\n",
    "#             score = right_num / true_class_id.shape[0]\n",
    "#             self.scores.append(\"epoch:{0} {1}\".format(epoch + 1, score))\n",
    "            print(\"\\nAll_re: \\t%.6f\\t%.0f\\t%.0f\" % all_re)\n",
    "            print(\"Seen_re: \\t%.6f\\t%.0f\\t%.0f\" % seen_re)\n",
    "            print(\"Unseen_re: \\t%.6f\\t%.0f\\t%.0f\" % unseen_re)\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "        if(self.verbose >= 2) and (batch % self.batch_interval == 0):\n",
    "            # y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            # loss = metrics.log_loss(self.y_val, y_pred)\n",
    "            print(\"Hi! on_batch_end() , batch=\",batch,\",logs:\",logs)\n",
    "            # print(\"Valide size=\",y_pred.shape[0], \"  Valide loss=\",loss)\n",
    "\n",
    "def full_connect_layer(input, hidden_dim):\n",
    "    full_connect = input\n",
    "    for hn in hidden_dim:\n",
    "        fc_in = full_connect\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#         full_connect = Dropout(0.2)(full_connect)\n",
    "        full_connect = BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "        # full_connect = Dense(hn, kernel_regularizer = l2(0.001), activity_regularizer = l1(0.001))(full_connect)\n",
    "#         full_connect = Concatenate()([Dense(hn, kernel_initializer='lecun_uniform', activation = 'relu')(full_connect), \n",
    "#             Dense(hn, kernel_initializer='lecun_uniform', activation = 'sigmoid')(full_connect)])\n",
    "        full_connect = Dense(hn, kernel_initializer='he_normal', activation = 'relu', kernel_regularizer = l2(1e-4))(full_connect)\n",
    "        # full_connect = self.act_blend(full_connect)\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#             full_connect = Dropout(self.full_connect_dropout)(full_connect) #Dropout(self.full_connect_dropout)(full_connect)\n",
    "#         full_connect = Concatenate()([fc_in, full_connect])\n",
    "    return full_connect\n",
    "\n",
    "def create_dnn():\n",
    "    alpha = 0.03\n",
    "    attr_input = Input(shape = (30,), name = 'attr')\n",
    "    word_emb = Input(shape = (600,), name = 'wv')\n",
    "    imag_classifier = Input(shape = (1024,), name = 'img')\n",
    "\n",
    "    attr_dense = Dense(256, use_bias = False, kernel_initializer='he_normal', kernel_regularizer = l2(1e-4))(attr_input)\n",
    "#     attr_dense = Dense(512)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(256)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(300, activation=\"relu\")(attr_dense)\n",
    "    # attr_dense = Dense(512, activation=\"relu\")(attr_dense)\n",
    "\n",
    "    attr_word_emb = word_emb #Concatenate()([word_emb, attr_dense])\n",
    "#     attr_word_emb_dense = full_connect_layer(attr_word_emb, hidden_dim = [516 + 512, 516 + 256 + 128, 516 + 256, 516])\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb, hidden_dim = [1024, 768, 516])\n",
    "\n",
    "    model = Model([attr_input, word_emb], outputs = attr_word_emb_dense) #, vgg_output])\n",
    "    # model.add_loss(mse_loss)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-4), loss='mean_squared_error')\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "        AccuracyEvaluation(validation_data=(validate_part_data,  validate_part_target), interval=1, \\\n",
    "#                         class_id_emb_attr = class_id_emb_attr, \\\n",
    "                           eval_df = validate_part_df, threshold= 2, \\\n",
    "                          seen_class = seen_class, unseen_class = unseen_class, \\\n",
    "            class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \\\n",
    "                          gamma = 0)\n",
    "        ]\n",
    "\n",
    "zs_model = create_dnn()\n",
    "print (zs_model.summary())\n",
    "zs_model.fit(train_part_data, train_part_target,  validation_data = (validate_part_data, validate_part_target),\n",
    "              epochs=150, batch_size = 32, shuffle=True, verbose = 1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>emb</th>\n",
       "      <th>attr</th>\n",
       "      <th>img</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...</td>\n",
       "      <td>[0.31291956, 0.06956484, 0.34872296, 0.0408261...</td>\n",
       "      <td>[0.00025839373, 1.3706203e-09, 4.1264393e-06, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...</td>\n",
       "      <td>[0.41405693, 0.0, 0.42773598, 0.26566917, 0.09...</td>\n",
       "      <td>[8.528581e-05, 7.096258e-13, 2.6975647e-07, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....</td>\n",
       "      <td>[0.47680375, 0.040604595, 0.3921133, 0.0505364...</td>\n",
       "      <td>[4.005173e-07, 2.7407113e-10, 0.006872308, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>7d93ef45972154aae150b4f9980a79c0.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....</td>\n",
       "      <td>[0.43787614, 0.22630948, 0.91177577, 0.3713039...</td>\n",
       "      <td>[4.478436e-06, 6.6336076e-15, 4.5222535e-07, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>[-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...</td>\n",
       "      <td>[[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...</td>\n",
       "      <td>[0.09672495, 0.020393938, 0.0, 0.06396753, 0.5...</td>\n",
       "      <td>[1.12697035e-05, 1.5967139e-12, 0.0001125168, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_id                               image_id class_name  \\\n",
       "0     ZJL1  a6394b0f513290f4651cc46792e5ac86.jpeg   goldfish   \n",
       "1     ZJL1  2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg   goldfish   \n",
       "2     ZJL1  eda9f3bef2bd8da038f6acbc8355fc25.jpeg   goldfish   \n",
       "3     ZJL1  7d93ef45972154aae150b4f9980a79c0.jpeg   goldfish   \n",
       "4     ZJL1  fb901b4f9a8e396c1d0155bccc5e5671.jpeg   goldfish   \n",
       "\n",
       "                                                 emb  \\\n",
       "0  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "1  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "2  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "3  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "4  [-0.036463, 0.34304, -0.32295, 0.36496, 0.5080...   \n",
       "\n",
       "                                                attr  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, ...   \n",
       "\n",
       "                                                 img  \\\n",
       "0  [[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...   \n",
       "1  [[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...   \n",
       "2  [[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....   \n",
       "3  [[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....   \n",
       "4  [[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...   \n",
       "\n",
       "                                              target  \\\n",
       "0  [0.31291956, 0.06956484, 0.34872296, 0.0408261...   \n",
       "1  [0.41405693, 0.0, 0.42773598, 0.26566917, 0.09...   \n",
       "2  [0.47680375, 0.040604595, 0.3921133, 0.0505364...   \n",
       "3  [0.43787614, 0.22630948, 0.91177577, 0.3713039...   \n",
       "4  [0.09672495, 0.020393938, 0.0, 0.06396753, 0.5...   \n",
       "\n",
       "                                               preds  \n",
       "0  [0.00025839373, 1.3706203e-09, 4.1264393e-06, ...  \n",
       "1  [8.528581e-05, 7.096258e-13, 2.6975647e-07, 0....  \n",
       "2  [4.005173e-07, 2.7407113e-10, 0.006872308, 1.0...  \n",
       "3  [4.478436e-06, 6.6336076e-15, 4.5222535e-07, 5...  \n",
       "4  [1.12697035e-05, 1.5967139e-12, 0.0001125168, ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path + '/DatasetA_test_20180813/DatasetA_test/image.txt', header = None, names = ['img_id'])\n",
    "imag_path = path + '/DatasetA_test_20180813/DatasetA_test/test/'\n",
    "test_data['img'] = test_data['img_id'].apply(lambda id: read_image(imag_path, id))\n",
    "# with open(path + 'test_data.pickle', 'rb') as handle:\n",
    "#     test_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.12423625, 0.1190791, 0.7566846]\n",
       "1       [1.7260123e-13, 2.1865514e-08, 1.0]\n",
       "2       [0.2117803, 0.17989996, 0.60831976]\n",
       "3        [0.2420589, 0.17926142, 0.5786797]\n",
       "4    [0.041276723, 0.95284086, 0.005882429]\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(path + 'test_data.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(test_data, handle)\n",
    "# test_data.head()\n",
    "with open(path + '/model_sub/stacking_train_label_2018_09_12_12_10_06.pickle', 'rb') as handle:\n",
    "    stacking_train_data = pickle.load(handle)\n",
    "stacking_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 70, 70, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 68, 68, 64)   1728        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 68, 68, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 68, 68, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 70, 70, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (AveragePooling2D)        (None, 34, 34, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 34, 34, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 34, 34, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 34, 34, 64)   4096        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 34, 34, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 34, 34, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 34, 34, 16)   9216        conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 34, 34, 80)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 34, 34, 80)   320         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 34, 34, 80)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 34, 34, 64)   5120        conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 34, 34, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 34, 34, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 34, 34, 16)   9216        conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 34, 34, 96)   0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 34, 34, 96)   384         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 34, 34, 96)   0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 34, 34, 64)   6144        conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 34, 34, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 34, 34, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 34, 34, 16)   9216        conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 34, 34, 112)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 34, 34, 112)  448         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 34, 34, 112)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 34, 34, 64)   7168        conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 34, 34, 64)   256         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 34, 34, 64)   0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 34, 34, 16)   9216        conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 34, 34, 128)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 34, 34, 128)  512         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 34, 34, 128)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 34, 34, 64)   8192        conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 34, 34, 64)   256         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 34, 34, 64)   0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 34, 34, 16)   9216        conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 34, 34, 144)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 34, 34, 144)  576         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 34, 34, 144)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 34, 34, 64)   9216        conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 34, 34, 64)   256         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 34, 34, 64)   0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 34, 34, 16)   9216        conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 34, 34, 160)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 34, 34, 160)  640         conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 34, 34, 160)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 34, 34, 80)   12800       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 17, 17, 80)   0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 17, 17, 80)   320         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 17, 17, 80)   0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 17, 17, 64)   5120        conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 17, 17, 64)   256         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 17, 17, 64)   0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 17, 17, 16)   9216        conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 17, 17, 96)   0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 17, 17, 96)   384         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 17, 17, 96)   0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 17, 17, 64)   6144        conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 17, 17, 64)   256         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 17, 17, 64)   0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 17, 17, 16)   9216        conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 17, 17, 112)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 17, 17, 112)  448         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 17, 17, 112)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 17, 17, 64)   7168        conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 17, 17, 64)   256         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 17, 17, 64)   0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 17, 17, 16)   9216        conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 17, 17, 128)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 17, 17, 128)  512         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 17, 17, 128)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 17, 17, 64)   8192        conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 17, 17, 64)   256         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 17, 17, 64)   0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 17, 17, 16)   9216        conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 17, 17, 144)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 17, 17, 144)  576         conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 17, 17, 144)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 17, 17, 64)   9216        conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 17, 17, 64)   256         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 17, 17, 64)   0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 17, 17, 16)   9216        conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 17, 17, 160)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 17, 17, 160)  640         conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 17, 17, 160)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 17, 17, 64)   10240       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 17, 17, 64)   256         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 17, 17, 64)   0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 17, 17, 16)   9216        conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 17, 17, 176)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 17, 17, 176)  704         conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 17, 17, 176)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 17, 17, 64)   11264       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 17, 17, 64)   256         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 17, 17, 64)   0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 17, 17, 16)   9216        conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 17, 17, 192)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 17, 17, 192)  768         conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 17, 17, 192)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 17, 17, 64)   12288       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 17, 17, 64)   256         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 17, 17, 64)   0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 17, 17, 16)   9216        conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 17, 17, 208)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 17, 17, 208)  832         conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 17, 17, 208)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 17, 17, 64)   13312       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 17, 17, 64)   256         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 17, 17, 64)   0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 17, 17, 16)   9216        conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 17, 17, 224)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 17, 17, 224)  896         conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 17, 17, 224)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 17, 17, 64)   14336       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 17, 17, 64)   256         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 17, 17, 64)   0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 17, 17, 16)   9216        conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 17, 17, 240)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 17, 17, 240)  960         conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 17, 17, 240)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 17, 17, 64)   15360       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 17, 17, 64)   256         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 17, 17, 64)   0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 17, 17, 16)   9216        conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 17, 17, 256)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 17, 17, 256)  1024        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 17, 17, 256)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 17, 17, 64)   16384       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 17, 17, 64)   256         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 17, 17, 64)   0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 17, 17, 16)   9216        conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 17, 17, 272)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 17, 17, 272)  1088        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 17, 17, 272)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 17, 17, 136)  36992       pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 8, 8, 136)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 136)    544         pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 8, 8, 136)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 64)     8704        conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 64)     0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 16)     9216        conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 8, 8, 152)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 8, 8, 152)    608         conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 8, 8, 152)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 64)     9728        conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 64)     0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 16)     9216        conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 8, 8, 168)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 8, 8, 168)    672         conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 8, 8, 168)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 64)     10752       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 64)     0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 16)     9216        conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 8, 8, 184)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 8, 8, 184)    736         conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 8, 8, 184)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 64)     11776       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 64)     256         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 64)     0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 16)     9216        conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 8, 8, 200)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 8, 8, 200)    800         conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 8, 8, 200)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 64)     12800       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 64)     256         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 64)     0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 16)     9216        conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 8, 8, 216)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 8, 8, 216)    864         conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 8, 8, 216)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 64)     13824       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 64)     256         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 64)     0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 16)     9216        conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 8, 8, 232)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 8, 8, 232)    928         conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 8, 8, 232)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 8, 8, 64)     14848       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 8, 8, 64)     256         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 8, 8, 64)     0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 8, 8, 16)     9216        conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 8, 8, 248)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 8, 8, 248)    992         conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 8, 8, 248)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 8, 8, 64)     15872       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 8, 8, 64)     256         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 8, 8, 64)     0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 8, 8, 16)     9216        conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 8, 8, 264)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 8, 8, 264)    1056        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 8, 8, 264)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 8, 8, 64)     16896       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 8, 8, 64)     256         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 8, 8, 64)     0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 8, 8, 16)     9216        conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 8, 8, 280)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 8, 8, 280)    1120        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 8, 8, 280)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 8, 8, 64)     17920       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 8, 8, 296)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 8, 8, 296)    1184        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 8, 8, 296)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 8, 8, 64)     18944       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 8, 8, 312)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 8, 8, 312)    1248        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 8, 8, 312)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 8, 8, 64)     19968       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 8, 8, 328)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 8, 8, 328)    1312        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 8, 8, 328)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 8, 8, 64)     20992       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 8, 8, 344)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 8, 8, 344)    1376        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 8, 8, 344)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 8, 8, 64)     22016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 8, 8, 360)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 8, 8, 360)    1440        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 8, 8, 360)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 8, 8, 64)     23040       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 8, 8, 376)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 8, 8, 376)    1504        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 8, 8, 376)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 8, 8, 64)     24064       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 8, 8, 392)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 8, 8, 392)    1568        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 8, 8, 392)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 8, 8, 64)     25088       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 8, 8, 408)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 8, 8, 408)    1632        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 8, 8, 408)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 8, 8, 64)     26112       conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 8, 8, 424)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 8, 8, 424)    1696        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 8, 8, 424)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 8, 8, 64)     27136       conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 8, 8, 440)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 8, 8, 440)    1760        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 8, 8, 440)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 8, 8, 64)     28160       conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 8, 8, 456)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 8, 8, 456)    1824        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 8, 8, 456)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 8, 8, 64)     29184       conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 8, 8, 472)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 8, 8, 472)    1888        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 8, 8, 472)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 8, 8, 64)     30208       conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 8, 8, 488)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 8, 8, 488)    1952        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 8, 8, 488)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 8, 8, 64)     31232       conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 8, 8, 504)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 8, 8, 504)    2016        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 8, 8, 504)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 8, 8, 64)     32256       conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 8, 8, 64)     256         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 8, 8, 64)     0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 8, 8, 16)     9216        conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 8, 8, 520)    0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 8, 8, 520)    2080        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 8, 8, 520)    0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 8, 8, 260)    135200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 4, 4, 260)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 260)    1040        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 4, 4, 260)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 64)     16640       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 64)     256         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 64)     0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 16)     9216        conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 4, 4, 276)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 4, 4, 276)    1104        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 4, 4, 276)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 64)     17664       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 64)     256         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 64)     0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 16)     9216        conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 4, 4, 292)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 4, 4, 292)    1168        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 4, 4, 292)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 64)     18688       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 64)     256         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 64)     0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 16)     9216        conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 4, 4, 308)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 4, 4, 308)    1232        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 4, 4, 308)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 4, 4, 64)     19712       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 4, 4, 64)     256         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 4, 4, 64)     0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 4, 4, 16)     9216        conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 4, 4, 324)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 4, 4, 324)    1296        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 4, 4, 324)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 4, 4, 64)     20736       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 4, 4, 64)     256         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 4, 4, 64)     0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 4, 4, 16)     9216        conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 4, 4, 340)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 4, 4, 340)    1360        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 4, 4, 340)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 4, 4, 64)     21760       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 4, 4, 64)     256         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 4, 4, 64)     0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 4, 4, 16)     9216        conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 4, 4, 356)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 4, 4, 356)    1424        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 4, 4, 356)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 4, 4, 64)     22784       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 4, 4, 64)     256         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 4, 4, 64)     0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 4, 4, 16)     9216        conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 4, 4, 372)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 4, 4, 372)    1488        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 4, 4, 372)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 4, 4, 64)     23808       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 4, 4, 64)     256         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 4, 4, 64)     0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 4, 4, 16)     9216        conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 4, 4, 388)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 4, 4, 388)    1552        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 4, 4, 388)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 4, 4, 64)     24832       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 4, 4, 64)     256         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 4, 4, 64)     0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 4, 4, 16)     9216        conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 4, 4, 404)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 4, 4, 404)    1616        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 4, 4, 404)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 4, 4, 64)     25856       conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 4, 4, 64)     256         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 4, 4, 64)     0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 4, 4, 16)     9216        conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 4, 4, 420)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 4, 4, 420)    1680        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 4, 4, 420)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 4, 4, 64)     26880       conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 4, 4, 64)     256         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 4, 4, 64)     0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 4, 4, 16)     9216        conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 4, 4, 436)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 4, 4, 436)    1744        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 4, 4, 436)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 4, 4, 64)     27904       conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 4, 4, 64)     256         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 4, 4, 64)     0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 4, 4, 16)     9216        conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 4, 4, 452)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 4, 4, 452)    1808        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 4, 4, 452)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 4, 4, 64)     28928       conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 4, 4, 64)     256         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 4, 4, 64)     0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 4, 4, 16)     9216        conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 4, 4, 468)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 4, 4, 468)    1872        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 4, 4, 468)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 4, 4, 64)     29952       conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 4, 4, 64)     256         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 4, 4, 64)     0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 4, 4, 16)     9216        conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 4, 4, 484)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 4, 4, 484)    1936        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 4, 4, 484)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 4, 4, 64)     30976       conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 4, 4, 64)     256         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 4, 4, 64)     0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 4, 4, 16)     9216        conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 4, 4, 500)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 4, 4, 500)    2000        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 4, 4, 500)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 4, 4, 64)     32000       conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 4, 4, 64)     256         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 4, 4, 64)     0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 4, 4, 16)     9216        conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 4, 4, 516)    0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 4, 516)    2064        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, 4, 516)    0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 516)          0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 171)          88407       avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,945,831\n",
      "Trainable params: 1,902,543\n",
      "Non-trainable params: 43,288\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"av...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "img_model = DenseNet(blocks = [6, 12, 24, 16], \n",
    "                                cat_max = 171,\n",
    "                                weight_decay = 1e-4, \n",
    "                                kernel_initializer = 'glorot_normal',\n",
    "                                reduction = 0.5, \n",
    "                                init_filters = 64, \n",
    "                                growth_rate = 16).model\n",
    "img_model.load_weights(path + 'model_sub/6_12_24_16_ini64_growth16_02962/model_0_2018_09_13_08_23_48.h5')\n",
    "img_model_flat = Model(input = img_model.input, output = img_model.get_layer(name = 'avg_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14624/14633 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "test_img = extract_array_from_series(test_data['img'])\n",
    "test_img = vgg16.preprocess_input(test_img)\n",
    "test_img_feature_map = img_model_flat.predict(test_img, verbose = 1)\n",
    "\n",
    "train_id = train_data['class_id'].unique()\n",
    "class_id_emb_attr.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_partial_model = Model(inputs = zs_model.inputs[:2], outputs = zs_model.outputs[0])\n",
    "test_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)]\n",
    "pred_nearest_class_id = find_nearest_class(test_class_id_emb_attr, zs_partial_model, test_data, test_img_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_label = time.strftime('_%Y_%m_%d_%H_%M_%S', time.gmtime())\n",
    "sub_name = path + '/model_sub/sub' + time_label + '.txt'\n",
    "sub = pd.DataFrame(pred_nearest_class_id, index = test_data['img_id'])\n",
    "sub.to_csv(sub_name, header = False, sep = '\\t')\n",
    "zs_model.save(path + 'zs_model' + time_label + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ZJL1', 'ZJL10', 'ZJL100', 'ZJL101', 'ZJL102', 'ZJL103', 'ZJL104',\n",
       "       'ZJL105', 'ZJL106', 'ZJL107', 'ZJL108', 'ZJL109', 'ZJL11',\n",
       "       'ZJL110', 'ZJL111', 'ZJL113', 'ZJL114', 'ZJL115', 'ZJL116',\n",
       "       'ZJL117', 'ZJL118', 'ZJL119', 'ZJL12', 'ZJL120', 'ZJL121',\n",
       "       'ZJL122', 'ZJL123', 'ZJL124', 'ZJL125', 'ZJL126', 'ZJL127',\n",
       "       'ZJL128', 'ZJL129', 'ZJL13', 'ZJL130', 'ZJL131', 'ZJL132',\n",
       "       'ZJL133', 'ZJL135', 'ZJL137', 'ZJL138', 'ZJL139', 'ZJL14',\n",
       "       'ZJL140', 'ZJL141', 'ZJL142', 'ZJL143', 'ZJL144', 'ZJL145',\n",
       "       'ZJL146', 'ZJL147', 'ZJL149', 'ZJL15', 'ZJL150', 'ZJL151',\n",
       "       'ZJL152', 'ZJL153', 'ZJL154', 'ZJL156', 'ZJL157', 'ZJL158',\n",
       "       'ZJL159', 'ZJL16', 'ZJL18', 'ZJL19', 'ZJL2', 'ZJL21', 'ZJL22',\n",
       "       'ZJL23', 'ZJL24', 'ZJL25', 'ZJL26', 'ZJL28', 'ZJL29', 'ZJL3',\n",
       "       'ZJL30', 'ZJL31', 'ZJL32', 'ZJL34', 'ZJL35', 'ZJL36', 'ZJL37',\n",
       "       'ZJL38', 'ZJL39', 'ZJL4', 'ZJL40', 'ZJL41', 'ZJL42', 'ZJL43',\n",
       "       'ZJL44', 'ZJL45', 'ZJL46', 'ZJL47', 'ZJL48', 'ZJL49', 'ZJL5',\n",
       "       'ZJL50', 'ZJL51', 'ZJL52', 'ZJL53', 'ZJL54', 'ZJL55', 'ZJL56',\n",
       "       'ZJL57', 'ZJL58', 'ZJL59', 'ZJL6', 'ZJL60', 'ZJL61', 'ZJL62',\n",
       "       'ZJL63', 'ZJL64', 'ZJL65', 'ZJL66', 'ZJL67', 'ZJL68', 'ZJL69',\n",
       "       'ZJL7', 'ZJL70', 'ZJL71', 'ZJL72', 'ZJL73', 'ZJL75', 'ZJL76',\n",
       "       'ZJL77', 'ZJL78', 'ZJL79', 'ZJL8', 'ZJL80', 'ZJL81', 'ZJL82',\n",
       "       'ZJL83', 'ZJL84', 'ZJL85', 'ZJL86', 'ZJL87', 'ZJL88', 'ZJL89',\n",
       "       'ZJL9', 'ZJL90', 'ZJL91', 'ZJL92', 'ZJL93', 'ZJL94', 'ZJL95',\n",
       "       'ZJL96', 'ZJL97', 'ZJL98', 'ZJL99', 'ZJL160', 'ZJL161', 'ZJL162',\n",
       "       'ZJL163', 'ZJL164', 'ZJL165', 'ZJL166', 'ZJL167', 'ZJL168',\n",
       "       'ZJL169', 'ZJL170', 'ZJL171', 'ZJL172', 'ZJL173', 'ZJL174',\n",
       "       'ZJL175', 'ZJL176', 'ZJL177', 'ZJL178', 'ZJL179', 'ZJL180',\n",
       "       'ZJL181', 'ZJL182', 'ZJL183', 'ZJL184', 'ZJL185', 'ZJL186',\n",
       "       'ZJL187', 'ZJL188', 'ZJL189', 'ZJL190', 'ZJL191', 'ZJL192',\n",
       "       'ZJL193', 'ZJL194', 'ZJL195', 'ZJL196', 'ZJL197', 'ZJL198',\n",
       "       'ZJL199', 'ZJL200'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
