{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import glob\n",
    "import gc\n",
    "import sklearn\n",
    "from DenseNet import DenseNet\n",
    "from DEM import DEM\n",
    "from sklearn.model_selection import KFold\n",
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "from sklearn import metrics, preprocessing, pipeline, \\\n",
    "    feature_extraction, decomposition, model_selection\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator\n",
    "from tensorflow.python.keras import layers, preprocessing\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.python.keras.regularizers import l1, l2\n",
    "from tensorflow.python.keras.optimizers import SGD, RMSprop, Adam, Nadam\n",
    "from tensorflow.python.keras.losses import mean_squared_error, binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.python.keras.applications import vgg16\n",
    "\n",
    "# from keras.preprocessing import image\n",
    "# from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator\n",
    "# from keras import layers, preprocessing\n",
    "# from keras import backend as K\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.callbacks import EarlyStopping, Callback\n",
    "# from keras.regularizers import l1, l2\n",
    "# from keras.optimizers import SGD, RMSprop, Adam, Nadam\n",
    "# from keras.losses import mean_squared_error, binary_crossentropy\n",
    "# from keras.applications import vgg16\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "import numpy as np\n",
    "# np.random.seed(seed = 100)\n",
    "import json\n",
    "import scipy \n",
    "import lightgbm as lgb\n",
    "\n",
    "import gensim\n",
    "import os\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.models.wrappers.fasttext import FastText\n",
    "\n",
    "path = '../data/'\n",
    "\n",
    "def read_image(imag_path, image_id):\n",
    "    img = image.load_img(imag_path + image_id)\n",
    "    img = image.img_to_array(img)\n",
    "#     img= vgg16.preprocess_input(image.img_to_array(img))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextAddArgs(FastText):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def train(cls, ft_path, corpus_file, output_file=None, model='cbow', size=100, alpha=0.025, window=5, min_count=5,\n",
    "              word_ngrams=1, loss='ns', sample=1e-3, negative=5, iter=5, min_n=3, max_n=6, sorted_vocab=1, threads=12,\n",
    "             verbose = 2):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        ft_path = ft_path\n",
    "        output_file = output_file or os.path.join(tempfile.gettempdir(), 'ft_model')\n",
    "        ft_args = {\n",
    "            'input': corpus_file,\n",
    "            'output': output_file,\n",
    "            'lr': alpha,\n",
    "            'dim': size,\n",
    "            'ws': window,\n",
    "            'epoch': iter,\n",
    "            'minCount': min_count,\n",
    "            'wordNgrams': word_ngrams,\n",
    "            'neg': negative,\n",
    "            'loss': loss,\n",
    "            'minn': min_n,\n",
    "            'maxn': max_n,\n",
    "            'thread': threads,\n",
    "            't': sample,\n",
    "            'verbose': verbose,\n",
    "        }\n",
    "        cmd = [ft_path, model]\n",
    "        for option, value in ft_args.items():\n",
    "            cmd.append(\"-%s\" % option)\n",
    "            cmd.append(str(value))\n",
    "\n",
    "        gensim.utils.check_output(args=cmd)\n",
    "        model = cls.load_fasttext_format(output_file)\n",
    "        cls.delete_training_files(output_file)\n",
    "        return model\n",
    "    \n",
    "    def __getitem__(self, words):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if isinstance(words, str):\n",
    "            ind = self.model.wv.vocab[words].index\n",
    "            print (ind)\n",
    "            # allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\n",
    "            return self.vectors[ind]\n",
    "\n",
    "        return np.vstack([self.vectors[self.model.wv.vocab[word].index] for word in words])\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, dir):\n",
    "        ft = FastTextAddArgs()\n",
    "        with open(dir + '/ft', 'rb') as handle:\n",
    "            ft.model = pickle.load(handle)\n",
    "        ft.vectors = np.load(dir + '/ft.wv.syn0.npy')\n",
    "        return ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e50d3a95b230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# adj_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# class_id_emb_attr['attr'].values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'../../zero-shot-gcn/data/imagenet_graph.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mimagenet_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'../../zero-shot-gcn/data/list/invdict_wordntext.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "# attr_list = pd.read_csv(path + '/DatasetA_train_20180813/attribute_list.txt', index_col = 0, sep = '\\t', header = None)\n",
    "# attr_list = attr_list.apply(lambda s: s[1].replace(' ', '_'), axis = 1)\n",
    "# attributes_per_class = pd.read_csv(path + '/DatasetA_train_20180813/attributes_per_class.txt', \n",
    "#                                    index_col = 0, sep = '\\t', header = None)\n",
    "# adj_graph\n",
    "# attr = np.array(list(class_id_emb_attr['attr']))\n",
    "# adj_graph = sklearn.metrics.pairwise.pairwise_distances(attr, metric = 'l2')\n",
    "# np.argsort(adj_graph[0])\n",
    "# adj_graph\n",
    "# class_id_emb_attr['attr'].values\n",
    "with open(path + '../../zero-shot-gcn/data/imagenet_graph.pkl', 'rb') as handle:\n",
    "    imagenet_graph = pickle.load(handle)\n",
    "with open(path + '../../zero-shot-gcn/data/list/invdict_wordntext.json', 'r') as fp:\n",
    "    words = json.load(fp)\n",
    "class_names = class_id_emb_attr[class_id_emb_attr.class_id.isin(round2_class_id)]['class_name'].values\n",
    "class_name_to_id = dict([(c, i) for i, c in enumerate(class_names)])\n",
    "class_wns = [[]] * class_names.shape[0]\n",
    "class_neighbor_wns = [[]] * class_names.shape[0]\n",
    "words_array = np.asarray(words)\n",
    "for i, word in enumerate(words):\n",
    "    for w in word.split(', '):\n",
    "        if w in class_name_to_id:\n",
    "#             print (class_name_to_id[w], i)\n",
    "            if len(class_wns[class_name_to_id[w]]) == 0:\n",
    "                class_wns[class_name_to_id[w]] = []\n",
    "            class_wns[class_name_to_id[w]].append(i)\n",
    "#             print (class_wns)\n",
    "            if len(class_neighbor_wns[class_name_to_id[w]]) == 0:\n",
    "                class_neighbor_wns[class_name_to_id[w]] = []\n",
    "            class_neighbor_wns[class_name_to_id[w]].extend(imagenet_graph[i])\n",
    "#             print (word, words_array[imagenet_graph[i]])\n",
    "#             print (i, w)\n",
    "#             if w not in class_dict:\n",
    "#                 class_dict[w] = 0\n",
    "#             class_dict[w] += 1\n",
    "# print (class_wns)\n",
    "wn_to_class = dict()\n",
    "for i, wns in enumerate(class_wns):\n",
    "    for wn in wns:\n",
    "        if wn not in wn_to_class:\n",
    "            wn_to_class[wn] = []\n",
    "        wn_to_class[wn].append(i)\n",
    "        \n",
    "adj_graph = scipy.eye(class_names.shape[0])\n",
    "# for i, neighbor_wns in enumerate(class_neighbor_wns):\n",
    "#     for j, wns in enumerate(class_wns):\n",
    "#         if i == j:\n",
    "#             continue\n",
    "#         for neighbor in neighbor_wns:\n",
    "#             if neighbor in wns:\n",
    "#                 adj_graph[i, j] = 1\n",
    "#                 adj_graph[j, i] = 1\n",
    "# #                 print(class_names[i], class_names[j])\n",
    "#                 break\n",
    "\n",
    "def find_adj(root, current_wn, remain_depth):\n",
    "    if current_wn in wn_to_class:\n",
    "        for adj_class in wn_to_class[current_wn]:\n",
    "            adj_graph[root][adj_class] = 1\n",
    "            adj_graph[adj_class][root] = 1\n",
    "    if remain_depth == 0:\n",
    "        return\n",
    "    for wn in imagenet_graph[current_wn]:\n",
    "        find_adj(root, wn, remain_depth - 1)\n",
    "        \n",
    "for i, wns in enumerate(class_wns):\n",
    "    for wn in wns:\n",
    "        find_adj(i, wn, 2)\n",
    "adj_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-99543f24aaa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "loaded_model['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del setA_train_data, setB_train_data\n",
    "# with open(path + 'setB_class_id_emb_attr.pickle', 'rb') as handle:\n",
    "#     class_id_emb_attr = pickle.load(handle)\n",
    "# with open(path + '/setA_train_data.pickle', 'rb') as handle:\n",
    "#     setA_train_data = pickle.load(handle)\n",
    "# with open(path + '/setB_train_data.pickle', 'rb') as handle:\n",
    "#     setB_train_data = pickle.load(handle)\n",
    "# with open(path + 'setB_test_data.pickle', 'rb') as handle:\n",
    "#     test_data = pickle.load(handle)\n",
    "    \n",
    "# train_data = setA_train_data.append(setB_train_data)\n",
    "# del setA_train_data, setB_train_data\n",
    "# with open(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/flat_train_re_2018_09_24_03_07_15.pickle', 'rb') as handle:\n",
    "#     flat_train_re = pickle.load(handle)\n",
    "# train_data['target'] = list(flat_train_re)\n",
    "# with open(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/flat_test_re_2018_09_24_03_07_15.pickle', 'rb') as handle:\n",
    "#     flat_test_re = pickle.load(handle)\n",
    "# test_data['target'] = list(flat_test_re)\n",
    "# train_data.drop(columns = ['img_id'], inplace = True)\n",
    "\n",
    "# with open(path + '/model_sub/6_12_24_16_ini64_growth32_inistride1_augdata_05010/train_data_2018_09_23_10_47_03.pickle', 'rb') as handle:\n",
    "#     train_data = pickle.load(handle)\n",
    "# with open(path + '/model_sub/6_12_24_16_ini64_growth32_inistride1_augdata_05010/test_data_2018_09_23_10_47_03.pickle', 'rb') as handle:\n",
    "#     test_data = pickle.load(handle)\n",
    "    \n",
    "with open(path + 'pix72/round2B_class_id_emb_attr_ft1300_encodedAttr.pkl', 'rb') as handle:\n",
    "    class_id_emb_attr = pickle.load(handle)\n",
    "#     class_id_emb_attr['emb'] = class_id_emb_attr['emb_glove']\n",
    "#     class_id_emb_attr.drop(columns = ['emb_glove', 'emb_fasttext', 'emb_glove_crawl', 'emb_glove_crawl_42B'], inplace = True)\n",
    "# del loaded_model\n",
    "emb_path = path + 'ft_class_embs/'\n",
    "ft_files = [\n",
    "#             path + '/skipgram_100_5Epoch/',\n",
    "#             path + '/skipgram_200_5Epoch/',\n",
    "# #             path + 'skipgram_300_5Epoch/',\n",
    "# #             path + 'skipgram_300_5Epoch_24Thread/',\n",
    "#             emb_path + 'skipgram_100_10Epoch',\n",
    "#             emb_path + 'skipgram_300_10Epoch',\n",
    "# # #             emb_path + 'cbow_300_10Epoch/',\n",
    "#             emb_path + 'skipgram_100_10Epoch_NewNorm',\n",
    "#             emb_path + 'LatestCorpus_skipgram_100_5Epoch',\n",
    "#               emb_path + 'skipgram_300_10Epoch_NewNorm',\n",
    "            emb_path + 'skipgram_100_15Epoch_NewNorm',\n",
    "            emb_path + 'skipgram_300_15Epoch_NewNorm',\n",
    "            emb_path + 'skipgram_300_15Epoch_NewNorm_LrUpdate3e4',\n",
    "            emb_path + 'skipgram_200_15Epoch_NewNorm',\n",
    "            emb_path + 'skipgram_300_15Epoch_NewNorm_LrUpdate2e4',\n",
    "#             emb_path + 'LatestCorpus_skipgram_100_10Epoch',\n",
    "#             emb_path + 'LatestCorpus_skipgram_100_15Epoch',\n",
    "#             emb_path + 'LatestCorpus_skipgram_100_15Epoch_shuf',\n",
    "# #             emb_path + 'LatestCorpus_skipgram_300_5Epoch',\n",
    "# #             emb_path + 'LatestCorpus_skipgram_300_5Epoch',\n",
    "#             emb_path + 'LatestCorpus_skipgram_200_10Epoch',\n",
    "#             emb_path + 'LatestCorpus_skipgram_200_10Epoch_shuf',\n",
    "#            path + 'documents_utf8_filtered_20pageviews_rmurl_lower_norm_skipgram/ft',\n",
    "           ]\n",
    "# glove_files =  [\n",
    "#             emb_path + 'LatestCorpus_glove_100',\n",
    "#             emb_path + 'LatestCorpus_glove_200',\n",
    "#            ]\n",
    "for ft_dir in ft_files:\n",
    "#     loaded_model = FastText.load(ft_dir + '/ft')\n",
    "    class_emb = pd.read_csv(ft_dir, index_col = 0)\n",
    "#     print (class_emb.loc['goldfish'].FT)\n",
    "    class_id_emb_attr['FT'] = class_id_emb_attr.class_name.apply( \\\n",
    "                lambda c: np.array([float(x) for x in class_emb.loc[c].FT.split(' ')]))\n",
    "#     class_id_emb_attr['FT'] = class_id_emb_attr['class_name'].apply(lambda c: loaded_model[c]).apply(lambda s: ' '.join(str(f) for f in s))\n",
    "#     ft_prefix = ft_dir.split('/')[-1]\n",
    "#     class_id_emb_attr[['class_name', 'FT']].to_csv(path + 'ft_class_embs/' + ft_prefix, index = False)\n",
    "#     del loaded_model\n",
    "    class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb'], s['FT']]), axis = 1)\n",
    "\n",
    "# for ft_dir in glove_files:\n",
    "# #     loaded_model = FastText.load(ft_dir + '/ft')\n",
    "#     class_emb = pd.read_csv(ft_dir, index_col = 0)\n",
    "# #     print (class_emb.loc['goldfish'].FT)\n",
    "#     class_id_emb_attr['FT'] = class_id_emb_attr.class_name.apply( \\\n",
    "#                 lambda c: np.array([float(x) for x in class_emb.loc[c].Glove.split(' ')]))\n",
    "# #     class_id_emb_attr['FT'] = class_id_emb_attr['class_name'].apply(lambda c: loaded_model[c]).apply(lambda s: ' '.join(str(f) for f in s))\n",
    "# #     ft_prefix = ft_dir.split('/')[-1]\n",
    "# #     class_id_emb_attr[['class_name', 'FT']].to_csv(path + 'ft_class_embs/' + ft_prefix, index = False)\n",
    "# #     del loaded_model\n",
    "#     class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb'], s['FT']]), axis = 1)\n",
    "    \n",
    "# class_names = class_id_emb_attr.class_name.values\n",
    "# glove_dict = {}\n",
    "# with open(path + 'GloveEmb/vectors_200.txt') as f:\n",
    "#     for line in f:\n",
    "#         ls = line.split(' ')\n",
    "#         if ls[0] in class_names:\n",
    "#             glove_dict[ls[0]] = np.array([float(x) for x in ls[1:]])\n",
    "#             if len(glove_dict) == class_names.shape[0]:\n",
    "#                 print ('done')\n",
    "\n",
    "# class_id_emb_attr['Glove'] = class_id_emb_attr['class_name'].apply(lambda c: glove_dict[c])\n",
    "# class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb'], s['Glove']]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_id_emb_attr.iloc[0].emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_array_from_series(s):\n",
    "    return np.asarray(list(s))\n",
    "\n",
    "attr1_list = pd.read_csv(path + '/DatasetA/attribute_list.txt', index_col = 0, sep = '\\t', header = None)\n",
    "attr2_list = pd.read_csv(path + '/semifinal_image_phase2/attribute_list.txt', index_col = 0, sep = '\\t', header = None)\n",
    "attr_dict ={}\n",
    "round2_class_id = ['ZJL' + str(i) for i in range(296, 521)]\n",
    "round1_class_id = list(set(class_id_emb_attr.class_id.unique()) - set(round2_class_id))\n",
    "round1_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(round1_class_id)]\n",
    "round2_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(round2_class_id)]\n",
    "round1_attr_value = extract_array_from_series(round1_class_id_emb_attr['attr'])\n",
    "round2_attr_value = extract_array_from_series(round2_class_id_emb_attr['attr'])\n",
    "round1_attrs = attr1_list[1].values\n",
    "round2_attrs = attr2_list[1].values\n",
    "# round1_attr_to_ind = {}\n",
    "# round2_attr_to_ind = {}\n",
    "for i, attr in enumerate(list(attr1_list[1].values)):\n",
    "    if attr not in attr_dict:\n",
    "        attr_dict[attr] = set()\n",
    "    attr_dict[attr].update(set(round1_attr_value[:, i]))\n",
    "#     round1_attr_to_ind[attr] = i\n",
    "    \n",
    "for i, attr in enumerate(list(attr2_list[1].values)):\n",
    "    if attr not in attr_dict:\n",
    "        attr_dict[attr] = set()\n",
    "    attr_dict[attr].update(set(round2_attr_value[:, i]))\n",
    "#     round2_attr_to_ind[attr] = i\n",
    "    \n",
    "consant_attr = [attr for attr in attr_dict if len(attr_dict[attr]) == 1 ]\n",
    "# merge_attr_value = np.zeros((class_id_emb_attr.shape[0], len(attr_dict) - len(consant_attr)))\n",
    "# attr_ind = 0\n",
    "# attrs = []\n",
    "# for attr in attr_dict:\n",
    "#     if attr in consant_attr:\n",
    "#         continue\n",
    "#     if attr in attr1_list[1].values:\n",
    "#         round1_attr_array = round1_attr_value[:, round1_attr_to_ind[attr]]\n",
    "#     else:\n",
    "#         round1_attr_array = np.zeros(round1_attr_value.shape[0])\n",
    "#         round1_attr_array[:] = -1\n",
    "#     if attr in attr2_list[1].values:\n",
    "#         round2_attr_array = round2_attr_value[:, round2_attr_to_ind[attr]]\n",
    "#     else:\n",
    "#         round2_attr_array = np.zeros(round2_attr_value.shape[0])\n",
    "#         round2_attr_array[:] = -1\n",
    "#     merge_attr_value[:, attr_ind] = np.c_[round1_attr_array, round2_attr_array]\n",
    "#     attrs.append(attr)\n",
    "# sum(len(attr_dict[attr]) for attr in attr_dict)\n",
    "# merge_attr_value\n",
    "# sum(len(attr_dict[attr]) == 1 for attr in attr_dict)\n",
    "\n",
    "intersect_attrs = np.intersect1d(round1_attrs, round2_attrs)\n",
    "round1_attr_df = pd.DataFrame(round1_attr_value, columns = round1_attrs)\n",
    "round2_attr_df = pd.DataFrame(round2_attr_value, columns = round2_attrs)\n",
    "attr_df = pd.concat([round1_attr_df, round2_attr_df], sort = False).fillna(-1).drop(columns = consant_attr) #.astype('str')\n",
    "class_id_emb_attr['encoded_attr'] = list(attr_df[intersect_attrs].values)\n",
    "# attr_df = attr_df.apply(lambda s: s.name + '_' + s, axis = 0)\n",
    "# attr_df.values\n",
    "# attr_value_dict = dict((v, i) for i, v in enumerate(set(attr_df.values.flatten())))\n",
    "# encoded_attr_df = attr_df.apply(lambda s: [attr_value_dict[v] for v in s], axis = 0)\n",
    "# class_id_emb_attr['encoded_attr'] = list(encoded_attr_df[intersect_attrs].values)\n",
    "# encode_attr_min = encoded_attr_df.min().min()\n",
    "# encode_attr_max = encoded_attr_df.max().max()\n",
    "# encode_attr_min, encode_attr_max\n",
    "# class_id_emb_attr\n",
    "# encoded_attr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + '/pix72/round2B_class_id_emb_attr_ft1300_encodedAttr.pkl', 'wb') as handle:\n",
    "    pickle.dump(class_id_emb_attr, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'can be driven',\n",
       " 'can be eaten directly',\n",
       " 'can dive',\n",
       " 'can float',\n",
       " 'can fly',\n",
       " 'can make lights',\n",
       " 'can make sound',\n",
       " 'has scales',\n",
       " 'has shells',\n",
       " 'has wings',\n",
       " 'is building',\n",
       " 'is cubic',\n",
       " 'is cylindrical',\n",
       " 'is flat',\n",
       " 'is food',\n",
       " 'is furniture',\n",
       " 'is globular',\n",
       " 'is kitchenware',\n",
       " 'is made of cloth',\n",
       " 'is made of galss',\n",
       " 'is made of metal',\n",
       " 'is made of plastic',\n",
       " 'is made of wood',\n",
       " 'is musical instrument',\n",
       " 'is schistose',\n",
       " 'is star-shaped',\n",
       " 'is violet'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(round2_attrs) - set(intersect_attrs) - set(consant_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 0. , 0. , 1. , 0.5, 0. , 0. , 0. , 0. , 0. , 1. , 0. ,\n",
       "       0. , 0. , 0. , 1. , 0. , 0. , 0. , 1. , 1. ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_id_emb_attr.iloc[0].encoded_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_data\n",
    "gc.collect()\n",
    "\n",
    "with open(path + '/pix72/round1A_train_img.pkl', 'rb') as handle:\n",
    "    round1_train_img_part0 = pickle.load(handle)\n",
    "with open(path + '/pix72/round1B_train_img.pkl', 'rb') as handle:\n",
    "    round1_train_img_part1 = pickle.load(handle)\n",
    "with open(path + '/pix72/round2A_train_img.pkl', 'rb') as handle:\n",
    "    round2_train_img = pickle.load(handle)\n",
    "with open(path + '/pix72/round2B_train_img.pkl', 'rb') as handle:\n",
    "    round2B_train_img = pickle.load(handle)\n",
    "# with open(path + '/round2B_test_img.pkl', 'rb') as handle:\n",
    "#     test_data = pickle.load(handle)\n",
    "with open(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_TF14_DensetNetProcess_05332/train_data_img_flat_20181026_204002.pickle', 'rb') as handle:\n",
    "    train_img_flat = pickle.load(handle)\n",
    "# with open(path + '/test_data_img_flat_20181025_175212.pickle', 'rb') as handle:\n",
    "#     test_img_flat = pickle.load(handle)\n",
    "round2_class_id = ['ZJL' + str(i) for i in range(296, 521)]\n",
    "round2_train_class_id = round2_train_img.class_id.unique()\n",
    "train_data = pd.concat([\n",
    "            round1_train_img_part0, \n",
    "            round1_train_img_part1, \n",
    "            round2_train_img, \n",
    "            round2B_train_img,\n",
    "            ], axis = 0, sort = False).drop(columns = 'img')\n",
    "train_data['target'] = list(train_img_flat)\n",
    "# test_data['target'] = list(test_img_flat)\n",
    "del round1_train_img_part0, round1_train_img_part1, round2_train_img , train_img_flat, round2B_train_img, \n",
    "gc.collect()\n",
    "train_data = train_data.merge(class_id_emb_attr, how = 'left', on = 'class_id')\n",
    "# , test_img_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + '/LatestCorpus_skipgram_300_10Epoch/ft', 'rb') as handle:\n",
    "    x = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FT_wrapper.load(path + 'skipgram_100_5Epoch/ft')\n",
    "with open(path + '/skipgram_100_5Epoch/ft', 'rb') as handle:\n",
    "    x = pickle.load(handle)\n",
    "wv = np.load(path + '/skipgram_100_5Epoch/ft.wv.syn0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.09040380e-01  1.11234330e-01 -1.31364942e-01 -2.40413949e-01\n",
      " -6.56542957e-01  6.49268210e-01 -6.97245747e-02 -7.49304473e-01\n",
      " -1.66116267e-01 -8.87370035e-02  9.09353122e-02  2.30383918e-01\n",
      " -3.38174015e-01  2.52917588e-01 -1.93259716e-01  2.93105751e-01\n",
      " -2.07798615e-01 -4.01901901e-01 -3.68933499e-01  7.67533243e-01\n",
      " -4.34223443e-01  1.20399781e-01  1.52300090e-01 -7.04429820e-02\n",
      " -2.53654003e-01 -5.27127564e-01 -1.16924211e-01 -4.42832232e-01\n",
      " -3.87937069e-01 -4.84300375e-01  3.45141262e-01  3.14605445e-01\n",
      "  4.17714179e-01  6.73706830e-01  3.31445426e-01 -2.11866632e-01\n",
      "  3.86182517e-01 -3.00689459e-01  9.04410034e-02  8.40417519e-02\n",
      "  7.23508671e-02  2.69937336e-01  3.63668859e-01  4.70794022e-01\n",
      "  2.61800200e-01 -5.43986559e-02  4.38031852e-01  1.28935650e-01\n",
      " -9.60382894e-02  1.34000137e-01  1.71759084e-01  2.81420559e-01\n",
      "  2.61964463e-02  5.48272487e-03 -2.89064944e-01 -3.72019500e-01\n",
      " -1.88706145e-01  4.30663615e-01  1.10802874e-01  2.01654434e-03\n",
      " -7.43592829e-02 -1.44771591e-01  8.00061375e-02 -5.58324039e-01\n",
      "  1.77625492e-01  3.26593429e-01  1.92055851e-01  1.33128166e-02\n",
      " -2.58253187e-01  6.45932555e-03  1.60499811e-01 -3.20937932e-01\n",
      " -2.73907870e-01  1.36184255e-02  7.00507522e-01  1.53124064e-01\n",
      "  2.82606274e-01  2.42699698e-01  3.20277005e-01  2.54793167e-01\n",
      " -7.68080354e-05  8.29303682e-01 -2.02922791e-01 -2.95911394e-02\n",
      "  1.34638892e-02  6.02278590e-01  9.89160165e-02 -2.26610705e-01\n",
      "  2.70858437e-01 -6.34950399e-03  3.64189535e-01  1.87124699e-01\n",
      " -8.43796879e-02 -1.00580156e-01 -8.15561856e-04  3.37709278e-01\n",
      "  8.06939229e-02 -6.21385649e-02 -3.47359151e-01 -2.36557931e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-6.09040380e-01,  1.11234330e-01, -1.31364942e-01, -2.40413949e-01,\n",
       "       -6.56542957e-01,  6.49268210e-01, -6.97245747e-02, -7.49304473e-01,\n",
       "       -1.66116267e-01, -8.87370035e-02,  9.09353122e-02,  2.30383918e-01,\n",
       "       -3.38174015e-01,  2.52917588e-01, -1.93259716e-01,  2.93105751e-01,\n",
       "       -2.07798615e-01, -4.01901901e-01, -3.68933499e-01,  7.67533243e-01,\n",
       "       -4.34223443e-01,  1.20399781e-01,  1.52300090e-01, -7.04429820e-02,\n",
       "       -2.53654003e-01, -5.27127564e-01, -1.16924211e-01, -4.42832232e-01,\n",
       "       -3.87937069e-01, -4.84300375e-01,  3.45141262e-01,  3.14605445e-01,\n",
       "        4.17714179e-01,  6.73706830e-01,  3.31445426e-01, -2.11866632e-01,\n",
       "        3.86182517e-01, -3.00689459e-01,  9.04410034e-02,  8.40417519e-02,\n",
       "        7.23508671e-02,  2.69937336e-01,  3.63668859e-01,  4.70794022e-01,\n",
       "        2.61800200e-01, -5.43986559e-02,  4.38031852e-01,  1.28935650e-01,\n",
       "       -9.60382894e-02,  1.34000137e-01,  1.71759084e-01,  2.81420559e-01,\n",
       "        2.61964463e-02,  5.48272487e-03, -2.89064944e-01, -3.72019500e-01,\n",
       "       -1.88706145e-01,  4.30663615e-01,  1.10802874e-01,  2.01654434e-03,\n",
       "       -7.43592829e-02, -1.44771591e-01,  8.00061375e-02, -5.58324039e-01,\n",
       "        1.77625492e-01,  3.26593429e-01,  1.92055851e-01,  1.33128166e-02,\n",
       "       -2.58253187e-01,  6.45932555e-03,  1.60499811e-01, -3.20937932e-01,\n",
       "       -2.73907870e-01,  1.36184255e-02,  7.00507522e-01,  1.53124064e-01,\n",
       "        2.82606274e-01,  2.42699698e-01,  3.20277005e-01,  2.54793167e-01,\n",
       "       -7.68080354e-05,  8.29303682e-01, -2.02922791e-01, -2.95911394e-02,\n",
       "        1.34638892e-02,  6.02278590e-01,  9.89160165e-02, -2.26610705e-01,\n",
       "        2.70858437e-01, -6.34950399e-03,  3.64189535e-01,  1.87124699e-01,\n",
       "       -8.43796879e-02, -1.00580156e-01, -8.15561856e-04,  3.37709278e-01,\n",
       "        8.06939229e-02, -6.21385649e-02, -3.47359151e-01, -2.36557931e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (model['cat'])\n",
    "wv[x.wv.vocab['cat'].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../data//semifinal_image_phase2/class_wordembeddings.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c5aa2f399ec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclass_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mglove_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_class_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/semifinal_image_phase2/class_wordembeddings.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# fasttext_emb =  read_class_emb(path + '/External/class_wordembeddings_fasttext')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-c5aa2f399ec6>\u001b[0m in \u001b[0;36mread_class_emb\u001b[0;34m(class_emb_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_class_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_emb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mclass_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_emb_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mclass_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'class_name'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclass_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclass_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../data//semifinal_image_phase2/class_wordembeddings.txt' does not exist"
     ]
    }
   ],
   "source": [
    "def read_class_emb(class_emb_path):\n",
    "    class_emb = pd.read_csv(class_emb_path, index_col = 0, sep = ' ', header = None)\n",
    "    class_emb.index.name = 'class_name'\n",
    "    class_emb = class_emb.apply(lambda s: np.array([float(x) for x in s])[:300], axis = 1)\n",
    "    return class_emb\n",
    "\n",
    "glove_emb = read_class_emb(path + '/semifinal_image_phase2/class_wordembeddings.txt')\n",
    "# fasttext_emb =  read_class_emb(path + '/External/class_wordembeddings_fasttext')\n",
    "\n",
    "class_id_to_name = pd.read_csv(path + '/semifinal_image_phase2/label_list.txt', \n",
    "                            index_col = 'class_name', sep = '\\t', header = None, names = ['class_id', 'class_name'])\n",
    "\n",
    "attr_list = pd.read_csv(path + '/semifinal_image_phase2/attribute_list.txt', index_col = 0, sep = '\\t', header = None)\n",
    "\n",
    "attributes_per_class = pd.read_csv(path + '/semifinal_image_phase2/attributes_per_class.txt', \n",
    "                                index_col = 0, sep = '\\t', header = None)\n",
    "attributes_per_class.index.name = 'class_id'\n",
    "attributes_per_class = attributes_per_class.apply(lambda s: np.array([float(x) for x in s]), axis = 1)\n",
    "\n",
    "round2B_class_id_emb_attr = class_id_to_name.copy()\n",
    "round2B_class_id_emb_attr['emb'] = glove_emb\n",
    "# class_id_emb_attr['emb_fasttext'] = fasttext_emb\n",
    "# class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb_glove'], s['emb_fasttext']]), axis = 1)\n",
    "round2B_class_id_emb_attr.reset_index(inplace = True)\n",
    "round2B_class_id_emb_attr.set_index('class_id', inplace = True)\n",
    "round2B_class_id_emb_attr['attr'] = attributes_per_class\n",
    "round2B_class_id_emb_attr.reset_index(inplace = True)\n",
    "# print ('Load class_id_emb_attr Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round2_class_id = ['ZJL' + str(i) for i in range(296, 501)]\n",
    "# round2B_class_id_emb_attr = pd.concat([class_id_emb_attr[~class_id_emb_attr.class_id.isin(round2_class_id)], round2B_class_id_emb_attr])\n",
    "with open(path + 'round2_class_id_emb_attr_ft1300.pkl', 'wb') as handle:\n",
    "    pickle.dump(class_id_emb_attr, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31979"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(round2B_train_img.img_id) - set(round2_train_img.img_id))\n",
    "# round2B_train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 83/38221 [00:00<00:46, 824.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load setA_train_data ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38221/38221 [00:39<00:00, 973.13it/s]\n",
      "  0%|          | 104/49028 [00:00<00:47, 1039.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load setB_train_data ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49028/49028 [00:48<00:00, 1003.10it/s]\n",
      "100%|██████████| 31896/31896 [04:28<00:00, 118.90it/s]\n",
      "100%|██████████| 31979/31979 [01:54<00:00, 164.07it/s]\n",
      "  0%|          | 20/8024 [00:00<00:42, 190.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test_data ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8024/8024 [00:59<00:00, 135.04it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_image_data(img_id_path, imag_path, cols, debug):\n",
    "    img_data = pd.read_csv(img_id_path, sep = '\\t', header = None, names = cols)\n",
    "    if debug:\n",
    "        img_data = img_data[:2000]\n",
    "    img_data['img'] = img_data['img_id'].progress_apply(lambda id: \n",
    "                            image.img_to_array(image.load_img(imag_path + id, target_size = (72, 72, 3))))\n",
    "    return img_data\n",
    "\n",
    "print ('Load setA_train_data ----')\n",
    "setA_train_data = read_image_data(img_id_path = path + '/DatasetA/train.txt', imag_path = path + '/DatasetA/train/', \n",
    "            cols = ['img_id', 'class_id'], debug = False)\n",
    "print ('Load setB_train_data ----')\n",
    "setB_train_data = read_image_data(img_id_path = path + '/DatasetB/train.txt', imag_path = path + '/DatasetB/train/', \n",
    "            cols = ['img_id', 'class_id'], debug = False)\n",
    "                                  \n",
    "round2A_train_data = read_image_data(img_id_path = path + '/round2_DatasetA_20180927/train.txt', \n",
    "                                  imag_path = path + '/round2_DatasetA_20180927/train/', \n",
    "            cols = ['img_id', 'class_id'], debug = False)\n",
    "\n",
    "round2B_train_data = read_image_data(img_id_path = path + '/semifinal_image_phase2/train.txt', \n",
    "                                  imag_path = path + '/semifinal_image_phase2/train/', \n",
    "            cols = ['img_id', 'class_id'], debug = False)\n",
    "# print ('Load setB_train_data ----')\n",
    "# setB_train_data = read_image_data(img_id_path = path + '/DatasetB/train.txt', imag_path = path + '/DatasetB/train/', \n",
    "#             cols = ['img_id', 'class_id'], debug = FLAGS.debug)\n",
    "# train_data = setA_train_data.append(setB_train_data)\n",
    "# del setA_train_data, setB_train_data\n",
    "# train_data = train_data.merge(class_id_emb_attr, how = 'left', on = 'class_id')\n",
    "\n",
    "print ('Load test_data ----')\n",
    "test_data = read_image_data(img_id_path = path + '/semifinal_image_phase2/image.txt', \n",
    "                            imag_path = path + '/semifinal_image_phase2/test/', \n",
    "            cols = ['img_id'], debug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'pix72/round1A_train_img.pkl', 'wb') as handle:\n",
    "    pickle.dump(setA_train_data, handle)\n",
    "with open(path + 'pix72/round1B_train_img.pkl', 'wb') as handle:\n",
    "    pickle.dump(setB_train_data, handle)\n",
    "with open(path + 'pix72/round2A_train_img.pkl', 'wb') as handle:\n",
    "    pickle.dump(round2A_train_data, handle)\n",
    "with open(path + 'pix72/round2B_train_data.pkl', 'wb') as handle:\n",
    "    pickle.dump(round2B_train_data, handle)\n",
    "with open(path + 'pix72/round2B_test_data.pkl', 'wb') as handle:\n",
    "    pickle.dump(test_data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text =  pd.read_csv(path + '/External/class_wordembeddings_glove', \n",
    "                        index_col = 0, sep = ' ', header = None)\n",
    "fast_text.index.name = 'class_name'\n",
    "fast_text_df = pd.DataFrame(index = fast_text.index)\n",
    "fast_text_df['emb_glove_crawl'] = fast_text.apply(lambda s: np.array([float(x) for x in s])[:300], axis = 1)\n",
    "\n",
    "train_data = train_data.merge(fast_text_df, how = 'left', on = 'class_name')\n",
    "\n",
    "# train_data['emb'] = train_data.apply(lambda s: np.hstack([s['emb'], s['emb_glove_crawl']]), axis = 1)\n",
    "\n",
    "class_id_emb_attr = class_id_emb_attr.merge(fast_text_df, how = 'left', on = 'class_name')\n",
    "class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb'], s['emb_glove_crawl']]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class_names = class_id_emb_attr.class_name.values\n",
    "glove_dict = {}\n",
    "with open(path + 'GloveEmb/vectors_200.txt') as f:\n",
    "    for line in f:\n",
    "        ls = line.split(' ')\n",
    "        if ls[0] in class_names:\n",
    "            glove_dict[ls[0]] = np.array([float(x) for x in ls[1:]])\n",
    "            if len(glove_dict) == class_names.shape[0]:\n",
    "                print ('done')\n",
    "\n",
    "class_id_emb_attr['Glove'] = class_id_emb_attr['class_name'].apply(lambda c: glove_dict[c])\n",
    "class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb'], s['Glove']]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_id_emb_attr.iloc[0].emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'round2_class_id_emb_attr_add_golve_crawl.pkl', 'wb') as handle:\n",
    "    pickle.dump(class_id_emb_attr, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, scores = None, cat_max = None, flags = None, model_type = None):\n",
    "        self.batch_size = 128 #flags.densenet_batch_size\n",
    "        self.epochs = 200 #flags.densenet_epochs\n",
    "        self.patience = 30 #flags.densenet_patience\n",
    "        self.scores = scores\n",
    "        self.cat_max = cat_max\n",
    "        self.model_type = model_type\n",
    "        self.aug_data = True #flags.aug_data\n",
    "        self.lr = 1e-3 #flags.lr\n",
    "        self.verbose = 2 #flags.train_verbose\n",
    "        self.OneHotEncoder = sklearn.preprocessing.OneHotEncoder()\n",
    "        self.model = self.small_densenet(\n",
    "                blocks = [6, 12, 24, 16], #[int(b.strip()) for b in flags.blocks.strip().split(',')], \n",
    "                weight_decay = 1e-4, #flags.weight_decay, \n",
    "                kernel_initializer = 'he_normal', #flags.kernel_initializer,\n",
    "                init_filters = 128, #flags.init_filters,\n",
    "                reduction = 0.5, #flags.reduction,\n",
    "                growth_rate = 32, #flags.growth_rate,\n",
    "                init_stride = 1 #flags.init_stride\n",
    "                )\n",
    "\n",
    "    def dense_block(self, x, blocks, name, \n",
    "            weight_decay = 1e-4, \n",
    "            kernel_initializer = 'he_normal',\n",
    "            growth_rate = None):\n",
    "        \"\"\"A dense block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            blocks: integer, the number of building blocks.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            output tensor for the block.\n",
    "        \"\"\"\n",
    "        for i in range(blocks):\n",
    "            x = self.conv_block(x, growth_rate, name=name + '_block' + str(i + 1), \n",
    "                weight_decay = weight_decay,\n",
    "                kernel_initializer = kernel_initializer)\n",
    "        return x\n",
    "\n",
    "    def transition_block(self, x, reduction, name, weight_decay = 1e-4, kernel_initializer = 'he_normal'):\n",
    "        \"\"\"A transition block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            reduction: float, compression rate at transition layers.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            output tensor for the block.\n",
    "        \"\"\"\n",
    "        bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                    name=name + '_bn')(x)\n",
    "        x = layers.Activation('relu', name=name + '_relu')(x)\n",
    "        x = layers.Conv2D(int(K.int_shape(x)[bn_axis] * reduction), 1,\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_conv')(x)\n",
    "        x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "        return x\n",
    "\n",
    "    def conv_block(self, x, growth_rate, name, weight_decay = 1e-4, kernel_initializer = 'he_normal'):\n",
    "        \"\"\"A building block for a dense block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            growth_rate: float, growth rate at dense layers.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            Output tensor for the block.\n",
    "        \"\"\"\n",
    "        bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "        x1 = layers.BatchNormalization(axis=bn_axis,\n",
    "                                    epsilon=1.001e-5,\n",
    "                                    name=name + '_0_bn')(x)\n",
    "        x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n",
    "        x1 = layers.Conv2D(4 * growth_rate, 1,\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_1_conv')(x1)\n",
    "        x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                    name=name + '_1_bn')(x1)\n",
    "        x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n",
    "        x1 = layers.Conv2D(growth_rate, 3,\n",
    "                        padding='same',\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_2_conv')(x1)\n",
    "        x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n",
    "        return x\n",
    "\n",
    "    def small_densenet(self, img_input_shape = (72, 72, 3), \n",
    "        blocks = [6, 12, 24, 16], \n",
    "        weight_decay = 1e-4, \n",
    "        kernel_initializer = 'he_normal',\n",
    "        init_filters = None,\n",
    "        reduction = None,\n",
    "        growth_rate = None,\n",
    "        init_stride = None\n",
    "        ):\n",
    "        img_input = layers.Input(shape = (img_input_shape))\n",
    "\n",
    "        x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "        x = layers.Conv2D(init_filters, 3, strides=init_stride, use_bias=False, \n",
    "            kernel_initializer = kernel_initializer, \n",
    "            kernel_regularizer = l2(weight_decay),\n",
    "            name='conv1/conv')(x)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=3, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "        x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "        x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "        x = layers.AveragePooling2D(3, strides=2, name='pool1')(x)\n",
    "        \n",
    "        for i, block in enumerate(blocks):\n",
    "            scope_num_str = str(i + 2)\n",
    "            x = self.dense_block(x, block, name='conv' + scope_num_str, \n",
    "                                 growth_rate = growth_rate,\n",
    "                                 weight_decay = weight_decay, \n",
    "                                 kernel_initializer = kernel_initializer)\n",
    "            if i != len(blocks) - 1:\n",
    "                x = self.transition_block(x, reduction, name='pool' + scope_num_str, \n",
    "                                          weight_decay = weight_decay, kernel_initializer = kernel_initializer)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=3, epsilon=1.001e-5, name='bn')(x)\n",
    "        x = layers.Activation('relu', name='relu')(x)\n",
    "\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = layers.Dense(self.cat_max, activation='softmax',\n",
    "            kernel_initializer = kernel_initializer, \n",
    "            name='fc')(x)\n",
    "        \n",
    "        model = Model(img_input, x)\n",
    "        model.compile(optimizer = Adam(lr=self.lr), loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def DNN_DataSet(self, df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return preprocess_img(df['img'])\n",
    "\n",
    "    def train(self, train_part_df, train_part_label, validate_part_df, validate_part_label):\n",
    "        \"\"\"\n",
    "        Keras Training\n",
    "        \"\"\"\n",
    "        print(\"-----DNN training-----\")\n",
    "\n",
    "        DNN_Train_Data = self.DNN_DataSet(train_part_df)\n",
    "        DNN_validate_Data = self.DNN_DataSet(validate_part_df)\n",
    "\n",
    "        callbacks = [\n",
    "                EarlyStopping(monitor='val_categorical_accuracy', patience=self.patience, verbose=0),\n",
    "                ]\n",
    "        if self.aug_data:\n",
    "            datagen = preprocessing.image.ImageDataGenerator(\n",
    "                    rotation_range=45,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "\n",
    "            datagen.fit(DNN_Train_Data)\n",
    "\n",
    "            h = self.model.fit_generator(datagen.flow(DNN_Train_Data, train_part_label, batch_size=self.batch_size), \n",
    "                    validation_data=(DNN_validate_Data, validate_part_label), steps_per_epoch = DNN_Train_Data.shape[0]//self.batch_size,\n",
    "                    epochs=self.epochs, shuffle=True, verbose = self.verbose, workers=1, use_multiprocessing=False, \n",
    "                    callbacks=callbacks)\n",
    "        else:\n",
    "            h = self.model.fit(DNN_Train_Data, train_part_label, batch_size=self.batch_size, epochs=self.epochs,\n",
    "                        shuffle=True, verbose=self.verbose,\n",
    "                        validation_data=(DNN_validate_Data, validate_part_label)\n",
    "                        , callbacks=callbacks\n",
    "                        )\n",
    "        self.scores.append(pd.DataFrame(h.history))\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, test_part, batch_size = 1024, verbose=2):\n",
    "        \"\"\"\n",
    "        Keras Training\n",
    "        \"\"\"\n",
    "        print(\"-----DNN Test-----\")\n",
    "        pred = self.model.predict(self.DNN_DataSet(test_part), verbose=verbose)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145/119145 [==============================] - 12271s \n",
      "7817/7817 [==============================] - 817s   \n"
     ]
    }
   ],
   "source": [
    "img_model = DenseNet(scores = None, \n",
    "                     cat_max = 205, #flags.cat_max, \n",
    "                     flags = None, \n",
    "                     model_type = 'DenseNet').model\n",
    "# model_file_name = glob.glob(model_path + '/imgmodel_*.h5')[0]\n",
    "# print ('Model file name: ', model_file_name)\n",
    "# img_model.load_weights(model_file_name)\n",
    "img_model.load_weights('../../Data/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/model_0_2018_09_24_03_07_15.h5')\n",
    "# img_model_flat = Model(input = img_model.input, output = img_model.get_layer(name = 'avg_pool').output)\n",
    "train_data['target'] = list(model_eval(img_model, 'DenseNet', train_data))\n",
    "test_data['target'] = list(model_eval(img_model, 'DenseNet', test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 7],\n",
       "       [2, 8, 6],\n",
       "       [7, 6, 4]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(1, 10, (3, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-724ce3e98dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "np.random.choice(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_id_emb_attr.iloc[0].emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def extract_array_from_series(s):\n",
    "    return np.asarray(list(s))\n",
    "\n",
    "def create_dem_data(df, only_emb = False, emb_len = 1200):\n",
    "    if only_emb:\n",
    "        emb = extract_array_from_series(df['emb'])[:, -1200:]\n",
    "        attr = np.zeros((emb.shape[0], 53))\n",
    "        return [attr, emb]\n",
    "    else:\n",
    "        return [extract_array_from_series(df['encoded_attr'])[:, :], extract_array_from_series(df['emb'])[:, -1600:]]\n",
    "\n",
    "def create_gcn_data(df, class_to_id):\n",
    "    return np.array([class_to_id[c] for c in df['class_id'].values]).astype('int32')\n",
    "\n",
    "def create_qfsl_data(df, class_to_id, categories = 205, ns = None):\n",
    "    OneHotEncoder = sklearn.preprocessing.OneHotEncoder(n_values = categories )\n",
    "    train_target = df['class_id'].apply(lambda c: class_to_id[c]).values\n",
    "    train_target = OneHotEncoder.fit_transform(np.reshape(train_target, (-1, 1))).toarray()\n",
    "    class_weight = np.ones(train_target.shape)\n",
    "    if ns is not None:\n",
    "#         in_loss_proba = (ns + 1)/ train_target.shape[1]\n",
    "        class_weight = np.random.choice([0, 1], train_target.shape, p = [1 - ns, ns])\n",
    "        class_weight[np.argwhere(train_target == 1).T] = 1\n",
    "    return [extract_array_from_series(df['target']), train_target, class_weight]\n",
    "\n",
    "def neg_aug_data(pos_data, train_class_id, class_id_emb_attr = None, c2c_neg_cnt = None, only_emb = False):\n",
    "    if c2c_neg_cnt is None:\n",
    "        pos_len = pos_data[0].shape[0]\n",
    "        ind_array = np.array(range(pos_len))\n",
    "    #     rs = np.random.RandomState(seed=420)\n",
    "    #     perm_ind_array = rs.permutation(rs.permutation(rs.permutation(rs.permutation(ind_array))))\n",
    "        perm_ind_array = np.random.permutation(ind_array)\n",
    "        perm_label = np.zeros(pos_len, dtype = 'float')\n",
    "        perm_label[train_class_id == train_class_id[perm_ind_array]] = 1\n",
    "        perm_img_feature_map = pos_data[0][perm_ind_array] \n",
    "        perm_label = perm_label.reshape((pos_len, 1))\n",
    "#         print (perm_label.shape)\n",
    "        neg_data = [perm_img_feature_map] + pos_data[1:3] + [perm_label]\n",
    "    else:\n",
    "        train_class_id_uniq = np.unique(train_class_id)\n",
    "        attr_embs = create_dem_data(class_id_emb_attr, only_emb)\n",
    "        neg_attrs = []\n",
    "        neg_embs = []\n",
    "        neg_imgs = []\n",
    "        img_origin_ind = np.array(range(train_class_id.shape[0]))\n",
    "        for i, class_id in enumerate(list(class_id_emb_attr.class_id)):\n",
    "            per_class_attrs,  per_class_embs = attr_embs[0][i], attr_embs[1][i]\n",
    "            per_class_neg_imgs = []\n",
    "            for have_img_clas_id in train_class_id_uniq:\n",
    "                if class_id == have_img_clas_id:\n",
    "                    continue\n",
    "                imgs_ind = img_origin_ind[train_class_id == have_img_clas_id]\n",
    "                per_class_neg_imgs.extend(list(pos_data[0][np.random.choice(imgs_ind, c2c_neg_cnt)]))\n",
    "            per_class_neg_len = len(per_class_neg_imgs)\n",
    "#             print ('Class_id, neg', class_id, per_class_neg_len)\n",
    "            neg_attrs.extend([per_class_attrs] * per_class_neg_len)\n",
    "            neg_embs.extend([per_class_embs] * per_class_neg_len)\n",
    "            neg_imgs.extend(per_class_neg_imgs)\n",
    "        neg_data = [np.array(neg_imgs), np.array(neg_attrs), np.array(neg_embs), np.zeros(len(neg_imgs))]\n",
    "    return neg_data\n",
    "        \n",
    "def create_dem_bc_data(df, neg_aug = 0, only_emb = False, class_id_emb_attr = None, c2c_neg_cnt = None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    train_data = [extract_array_from_series(df['target'])] + create_dem_data(df, only_emb)\n",
    "    train_len = train_data[0].shape[0]\n",
    "    train_data = train_data + [np.ones((train_len, 1), dtype = 'float')]\n",
    "    merge_data = train_data\n",
    "    if neg_aug > 0:\n",
    "        train_class_id = extract_array_from_series(df['class_id'])\n",
    "        for i in range(neg_aug):\n",
    "            neg_data = neg_aug_data(train_data, train_class_id, \n",
    "                                    class_id_emb_attr = class_id_emb_attr, \n",
    "                                    c2c_neg_cnt = c2c_neg_cnt,\n",
    "                                    only_emb = only_emb)\n",
    "            merge_data = [np.r_[merge_data[i], neg_data[i]] for i in range(len(merge_data))]\n",
    "        print ('DEM BC Data Train Len, Pos, Neg:', train_len, np.sum(merge_data[-1]), np.sum(merge_data[-1] == 0))\n",
    "        return merge_data\n",
    "    else:\n",
    "        return train_data\n",
    "\n",
    "def create_dem_bc_aug_data(df, neg_aug = 0, only_emb = False, class_id_emb_attr = None, c2c_neg_cnt = None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    train_data = [extract_array_from_series(df['img'])] + create_dem_data(df, only_emb)\n",
    "    train_len = train_data[0].shape[0]\n",
    "    train_data = train_data + [np.ones((train_len, 1), dtype = 'float')]\n",
    "    merge_data = train_data\n",
    "    if neg_aug > 0:\n",
    "        train_class_id = extract_array_from_series(df['class_id'])\n",
    "        for i in range(neg_aug):\n",
    "            neg_data = neg_aug_data(train_data, train_class_id, \n",
    "                                    class_id_emb_attr = class_id_emb_attr, \n",
    "                                    c2c_neg_cnt = c2c_neg_cnt,\n",
    "                                    only_emb = only_emb)\n",
    "            merge_data = [np.r_[merge_data[i], neg_data[i]] for i in range(len(merge_data))]\n",
    "        print ('DEM BC Data Train Len, Pos, Neg:', train_len, np.sum(merge_data[-1]), np.sum(merge_data[-1] == 0))\n",
    "        return merge_data\n",
    "    else:\n",
    "        return train_data\n",
    "    \n",
    "def preprocess_numpy_input(x, data_format = 'channels_last', mode = 'torch', **kwargs):\n",
    "    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n",
    "\n",
    "    # Arguments\n",
    "        x: Input array, 3D or 4D.\n",
    "        data_format: Data format of the image array.\n",
    "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
    "            - caffe: will convert the images from RGB to BGR,\n",
    "                then will zero-center each color channel with\n",
    "                respect to the ImageNet dataset,\n",
    "                without scaling.\n",
    "            - tf: will scale pixels between -1 and 1,\n",
    "                sample-wise.\n",
    "            - torch: will scale pixels between 0 and 1 and then\n",
    "                will normalize each channel with respect to the\n",
    "                ImageNet dataset.\n",
    "\n",
    "    # Returns\n",
    "        Preprocessed Numpy array.\n",
    "    \"\"\"\n",
    "    if not issubclass(x.dtype.type, np.floating):\n",
    "        x = x.astype(K.floatx(), copy=False)\n",
    "\n",
    "    if mode == 'tf':\n",
    "        x /= 127.5\n",
    "        x -= 1.\n",
    "        return x\n",
    "\n",
    "    if mode == 'torch':\n",
    "        x /= 255.\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "    else:\n",
    "        if data_format == 'channels_first':\n",
    "            # 'RGB'->'BGR'\n",
    "            if x.ndim == 3:\n",
    "                x = x[::-1, ...]\n",
    "            else:\n",
    "                x = x[:, ::-1, ...]\n",
    "        else:\n",
    "            # 'RGB'->'BGR'\n",
    "            x = x[..., ::-1]\n",
    "        mean = [103.939, 116.779, 123.68]\n",
    "        std = None\n",
    "\n",
    "    # Zero-center by mean pixel\n",
    "    if data_format == 'channels_first':\n",
    "        if x.ndim == 3:\n",
    "            x[0, :, :] -= mean[0]\n",
    "            x[1, :, :] -= mean[1]\n",
    "            x[2, :, :] -= mean[2]\n",
    "            if std is not None:\n",
    "                x[0, :, :] /= std[0]\n",
    "                x[1, :, :] /= std[1]\n",
    "                x[2, :, :] /= std[2]\n",
    "        else:\n",
    "            x[:, 0, :, :] -= mean[0]\n",
    "            x[:, 1, :, :] -= mean[1]\n",
    "            x[:, 2, :, :] -= mean[2]\n",
    "            if std is not None:\n",
    "                x[:, 0, :, :] /= std[0]\n",
    "                x[:, 1, :, :] /= std[1]\n",
    "                x[:, 2, :, :] /= std[2]\n",
    "    else:\n",
    "        x[..., 0] -= mean[0]\n",
    "        x[..., 1] -= mean[1]\n",
    "        x[..., 2] -= mean[2]\n",
    "        if std is not None:\n",
    "            x[..., 0] /= std[0]\n",
    "            x[..., 1] /= std[1]\n",
    "            x[..., 2] /= std[2]\n",
    "    return x\n",
    "\n",
    "def preprocess_img(img_series):\n",
    "    return preprocess_numpy_input(extract_array_from_series(img_series))\n",
    "\n",
    "def multi_labels_cross_entropy(y_true, y_preds, eps = 1e-6):\n",
    "#     multi_labels_loss = [sklearn.metrics.log_loss]\n",
    "#     y_preds_clip = max(eps, min(1 - eps, y_preds))\n",
    "    y_preds_clip = np.clip(y_preds, eps, 1- eps)\n",
    "    multi_loss = -(y_true * np.log(y_preds_clip) + (1 - y_true) * np.log(1 - y_preds_clip))\n",
    "    return np.mean(multi_loss, axis = -1)\n",
    "\n",
    "def find_nearest_class(class_id_emb_attr, eval_df, cand_feature_map = None, img_feature_map = None,\n",
    "                      model_type = None, attr_preds = None, zs_model = None, dis_arr = None):\n",
    "    nearest_class_id = ['ZJL'] * img_feature_map.shape[0]\n",
    "    for i in range(img_feature_map.shape[0]):\n",
    "        if model_type == 'I2A':\n",
    "            dis = multi_labels_cross_entropy(extract_array_from_series(class_id_emb_attr['attr'])[:, :50],\n",
    "                                            attr_preds[i])\n",
    "        elif model_type == 'DEM_BC' or model_type == 'DEM_BC_AUG':\n",
    "            img = img_feature_map[i]\n",
    "            pred_data = cand_feature_map * img\n",
    "#             pred_data = np.c_[cand_feature_map, [img] * cand_feature_map.shape[0]]\n",
    "            dis = 1 - zs_model.predict(pred_data)\n",
    "        elif model_type == 'lgb':\n",
    "            img = img_feature_map[i]\n",
    "            pred_data = cand_feature_map * img\n",
    "            dis = 1 - zs_model.predict(pred_data, num_iteration = -1)\n",
    "        elif model_type == 'QFSL':\n",
    "            dis = 1 - dis_arr[i]\n",
    "        else:\n",
    "            img = img_feature_map[i]\n",
    "            dis = np.linalg.norm(img - cand_feature_map, axis = 1)\n",
    "        min_ind = np.where(dis == np.amin(dis))[0]\n",
    "        nearest_class_id[i] = class_id_emb_attr.iloc[min_ind[0]]['class_id']\n",
    "    return np.asarray(nearest_class_id)\n",
    "        \n",
    "def calc_accuracy(eval_df, eval_class, preds):\n",
    "    eval_mask = eval_df.class_id.isin(eval_class)\n",
    "    eval_num = np.sum(eval_mask)\n",
    "    right_num = np.sum(preds[eval_mask] == eval_df.class_id[eval_mask])\n",
    "    return right_num / np.sum(eval_mask), right_num, eval_num\n",
    "    \n",
    "def calc_detailed_accuracy(eval_df, preds, class_id_dict):\n",
    "    print (\"\\n\")\n",
    "    for class_set_name in sorted(class_id_dict):\n",
    "        class_set = class_id_dict[class_set_name]\n",
    "        re = calc_accuracy(eval_df, class_set, preds)\n",
    "        print(\"%s: \\t%.6f\\t%.0f\\t%.0f\" % ((class_set_name,) + re))\n",
    "#     print (\"\\n\")\n",
    "\n",
    "def multi_preds_vote(preds):\n",
    "    vote_preds = []\n",
    "    for single_img_vote in preds:\n",
    "        uniq_val, counts = np.unique(single_img_vote, return_counts = True)\n",
    "        vote_preds.append(uniq_val[np.argmax(counts)])\n",
    "    vote_preds = np.asarray(vote_preds)\n",
    "    return vote_preds\n",
    "    \n",
    "def multi_models_vote(models, eval_df = None, cand_class_id_emb_attr = None, img_feature_map = None, \n",
    "                      class_id_dict = None):\n",
    "    print ('cand shape: ', cand_class_id_emb_attr.shape[0])\n",
    "    preds = models_eval(models, eval_df, cand_class_id_emb_attr, img_feature_map, \n",
    "                class_id_dict)\n",
    "    preds = np.asarray(preds).T\n",
    "    vote_preds = multi_preds_vote(preds)\n",
    "    # print (vote_preds)\n",
    "    print ('Multi model votes results:')\n",
    "    if 'class_id' in eval_df.columns: \n",
    "        calc_detailed_accuracy(eval_df, vote_preds, class_id_dict)\n",
    "    return vote_preds\n",
    "\n",
    "def model_eval(model, model_type, eval_df, cand_class_id_emb_attr = None, img_feature_map = None, \n",
    "                class_id_dict = None, class_to_id = None, TTA = None, img_model = None, only_emb = None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if model_type == 'DenseNet':\n",
    "        flat_model = Model(inputs = model.inputs, outputs = model.get_layer(name = 'avg_pool').output)\n",
    "        pred = flat_model.predict(preprocess_img(eval_df['img']), verbose = 1)\n",
    "    elif model_type == 'DEM' or model_type == 'AE':\n",
    "        zs_model = Model(inputs = model.inputs[:2], outputs = model.outputs[0])\n",
    "        cand_feature_map = zs_model.predict(create_dem_data(cand_class_id_emb_attr), verbose = 2)\n",
    "        if TTA is not None:\n",
    "            batch_size = 32\n",
    "            datagen = MixedImageDataGenerator(\n",
    "                    rotation_range=20,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "            img_feature_map = img_model.predict_generator(\n",
    "                datagen.flow((preprocess_img(eval_df['img'])), None, shuffle = False, batch_size = batch_size), \n",
    "                steps = np.ceil(eval_df.shape[0] / batch_size) * TTA, verbose = 1)\n",
    "            pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map, img_feature_map)\n",
    "            pred = np.reshape(pred, (TTA, eval_df.shape[0])).T\n",
    "            pred = multi_preds_vote(pred)\n",
    "        else:\n",
    "            pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map, img_feature_map)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'DEM_BC' or model_type == 'RES_DEM_BC':\n",
    "        zs_model = Model(inputs = model.inputs[1:3], outputs = model.outputs[0])\n",
    "        cand_feature_map = zs_model.predict(create_dem_data(cand_class_id_emb_attr, only_emb = only_emb), verbose = 1)\n",
    "        zs_model = Model(inputs = model.get_layer('attr_x_img_model').inputs, \n",
    "                         outputs = model.get_layer('attr_x_img_model').outputs)\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map = cand_feature_map, img_feature_map = img_feature_map,\n",
    "                                zs_model = zs_model, model_type = model_type)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'GCN':\n",
    "        zs_model = Model(inputs = model.inputs[2:], outputs = model.outputs[0])\n",
    "        cand_class_to_id = [class_to_id[c] for c in cand_class_id_emb_attr.class_id.values]\n",
    "        cand_feature_map = zs_model.predict(None, steps = 1)[cand_class_to_id]\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map, img_feature_map)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'QFSL':\n",
    "        cand_class_to_id = [class_to_id[c] for c in cand_class_id_emb_attr.class_id.values]\n",
    "        zs_model = Model(inputs = [model.inputs[0]] + model.inputs[3:], outputs = model.outputs[0])\n",
    "        dis_arr = zs_model.predict(img_feature_map, verbose = 2)[:, cand_class_to_id]\n",
    "#         print (dis_arr[:2])\n",
    "#         print (dis_arr[:2, cand_class_to_id])\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, model_type = model_type, dis_arr = dis_arr,\n",
    "                                 img_feature_map = img_feature_map)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'I2A':\n",
    "        zs_model = Model(inputs = model.inputs[-1], outputs = model.outputs[0])\n",
    "        attr_preds = zs_model.predict(extract_array_from_series(img_feature_map), verbose = 2)\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, None, img_feature_map, \n",
    "                                  model_type, attr_preds)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'DEM_AUG':\n",
    "        img_model = Model(inputs = model.inputs[0], outputs = model.outputs[-1])\n",
    "        img_feature_map = img_model.predict(preprocess_img(eval_df['img']), verbose = 2)\n",
    "        zs_model = Model(inputs = model.inputs[1:], outputs = model.outputs[0])\n",
    "        cand_feature_map = zs_model.predict(create_dem_data(cand_class_id_emb_attr), verbose = 2)\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map, img_feature_map)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'DEM_BC_AUG':\n",
    "        img_model = Model(inputs = model.inputs[0], outputs = model.outputs[-1])\n",
    "        img_feature_map = img_model.predict(preprocess_img(eval_df['img']), verbose = 2)\n",
    "        zs_model = Model(inputs = model.inputs[1:3], outputs = model.outputs[0])\n",
    "        cand_feature_map = zs_model.predict(create_dem_data(cand_class_id_emb_attr, only_emb = only_emb), verbose = 2)\n",
    "        zs_model = Model(inputs = model.get_layer('attr_x_img_model').inputs, \n",
    "                         outputs = model.get_layer('attr_x_img_model').outputs)\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map = cand_feature_map, img_feature_map = img_feature_map,\n",
    "                                zs_model = zs_model, model_type = model_type)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'WV2ATTR':\n",
    "        pred = model.predict(create_dem_data(eval_df, only_emb = False))\n",
    "    return pred\n",
    "\n",
    "def models_eval(models, eval_df, cand_class_id_emb_attr = None, img_feature_map = None, \n",
    "                class_id_dict = None, class_to_id = None, img_model = None):\n",
    "    preds = []\n",
    "    for (model, model_type) in models:\n",
    "        pred = model_eval(model, model_type, eval_df = eval_df, cand_class_id_emb_attr = cand_class_id_emb_attr, \n",
    "            img_feature_map = img_feature_map, class_id_dict = class_id_dict, class_to_id = class_to_id,\n",
    "            img_model = img_model)\n",
    "        preds.append(pred)\n",
    "    return preds\n",
    "\n",
    "class MixedImageDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MixedImageDataGenerator, self).__init__(**kwargs)\n",
    "        \n",
    "    def flow(self,\n",
    "           x,\n",
    "           y=None,\n",
    "           batch_size=32,\n",
    "           shuffle=True,\n",
    "           seed=None,\n",
    "           save_to_dir=None,\n",
    "           save_prefix='',\n",
    "           save_format='png'):\n",
    "        return MixedNumpyArrayIterator(\n",
    "        x,\n",
    "        y,\n",
    "        self,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        seed=seed,\n",
    "        data_format=self.data_format,\n",
    "        save_to_dir=save_to_dir,\n",
    "        save_prefix=save_prefix,\n",
    "        save_format=save_format)\n",
    "\n",
    "\n",
    "class MixedNumpyArrayIterator(NumpyArrayIterator):\n",
    "    \"\"\"Iterator yielding data from a Numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               x,\n",
    "               y,\n",
    "               image_data_generator,\n",
    "               **kwargs):\n",
    "        self.x_misc = None\n",
    "        if (type(x) is list) or (type(x) is tuple):\n",
    "            super(MixedNumpyArrayIterator, self).__init__(x[0],\n",
    "                   y,\n",
    "                   image_data_generator,\n",
    "                   **kwargs)\n",
    "            self.x_misc = [np.asarray(xx) for xx in x[1]]\n",
    "        else:\n",
    "            super(MixedNumpyArrayIterator, self).__init__(x,\n",
    "               y,\n",
    "               image_data_generator,\n",
    "               **kwargs)\n",
    "            \n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "\n",
    "        Returns:\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(\n",
    "              self.index_generator)\n",
    "#         print (index_array)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        batch_x = np.zeros(\n",
    "            tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())\n",
    "        for i, j in enumerate(index_array):\n",
    "            x = self.x[j]\n",
    "#             x_bak = x\n",
    "            x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "#             print (np.all(x_bak == x))\n",
    "            batch_x[i] = x\n",
    "        if self.x_misc is None:\n",
    "            batch_x = [batch_x]\n",
    "        else:\n",
    "            batch_x_miscs = [xx[index_array] for xx in self.x_misc]\n",
    "            batch_x = [batch_x] + batch_x_miscs\n",
    "#             for y in batch_x:\n",
    "#                 print (y.shape)\n",
    "        return (batch_x, None, None)\n",
    "    \n",
    "#     def next(self):\n",
    "#         \"\"\"For python 2.x.\n",
    "\n",
    "#         Returns:\n",
    "#             The next batch.\n",
    "#         \"\"\"\n",
    "#         with self.lock:\n",
    "#             index_array, current_index, current_batch_size = next(\n",
    "#               self.index_generator)\n",
    "# #         print (index_array)\n",
    "#         # The transformation of images is not under thread lock\n",
    "#         # so it can be done in parallel\n",
    "#         batch_x = np.zeros(\n",
    "#             tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())\n",
    "#         for i, j in enumerate(index_array):\n",
    "#             x = self.x[j]\n",
    "# #             x_bak = x\n",
    "#             x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n",
    "#             x = self.image_data_generator.standardize(x)\n",
    "# #             print (np.all(x_bak == x))\n",
    "#             batch_x[i] = x\n",
    "#         if self.x_misc is None:\n",
    "#             batch_x = [batch_x]\n",
    "#         else:\n",
    "#             batch_x_miscs = [xx[index_array] for xx in self.x_misc]\n",
    "#             batch_x = [batch_x] + batch_x_miscs\n",
    "#         return (batch_x, None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over all training size:\n",
      "(151124, 8)\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 138\n",
      "Fold:  0\n",
      "Seen unseen Classes:  328 37\n",
      "Seen round1, round2:  185 143\n",
      "Unseen round1, round2:  20 17\n",
      "WARNING:tensorflow:Output \"activation_9\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"activation_9\" during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"activation_9\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"activation_9\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"attr_x_img_model\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"attr_x_img_model\" during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"attr_x_img_model\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"attr_x_img_model\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "attr (InputLayer)                (None, 22)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "wv (InputLayer)                  (None, 1600)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "attr_dense (Dense)               (None, 1600)          36800       attr[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "attr_word_emb (Concatenate)      (None, 3200)          0           wv[0][0]                         \n",
      "                                                                   attr_dense[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 3200)          0           attr_word_emb[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 3200)          12800       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 2064)          6606864     batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 2064)          0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 2064)          0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 2064)          8256        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1548)          3196620     batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 1548)          0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 1548)          0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 1548)          6192        dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1290)          1998210     batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 1290)          0           dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 1290)          0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 1290)          5160        dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1032)          1332312     batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 1032)          0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "img (InputLayer)                 (None, 1032)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "attr_x_img (Lambda)              (None, 1032)          0           activation_9[0][0]               \n",
      "                                                                   img[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "attr_x_img_model (Model)         (None, 1)             5161        attr_x_img[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 13,208,375\n",
      "Trainable params: 13,190,107\n",
      "Non-trainable params: 18,268\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "-----DNN training-----\n",
      "DEM BC Data Train Len, Pos, Neg: 135542 135961.0 135123\n",
      "Train on 271084 samples, validate on 15582 samples\n",
      "Epoch 1/15\n",
      "133384/271084 [=============>................] - ETA: 399s - loss: 2.8638"
     ]
    }
   ],
   "source": [
    "class AccuracyEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_interval = 1000000, verbose = 2, \\\n",
    "            scores = [], cand_class_id_emb_attr = None, eval_df = None, threshold = None, \\\n",
    "                 seen_class = None, unseen_class = None, gamma = None, model_type = None, \n",
    "                 class_id_dict = None, class_to_id = None, TTA = None, img_model = None,\n",
    "                only_emb = None):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        # print (validation_data)\n",
    "#         self.X_val, _, \n",
    "        self.y_val = None\n",
    "        if model_type == 'DEM_BC':\n",
    "            self.y_val = validation_data[0]\n",
    "        elif model_type == 'QFSL':\n",
    "            self.y_val = validation_data[0]\n",
    "        self.verbose = verbose\n",
    "        self.scores = scores\n",
    "        self.cand_class_id_emb_attr = cand_class_id_emb_attr\n",
    "        self.eval_df = eval_df\n",
    "        self.seen_class = seen_class\n",
    "        self.unseen_class = unseen_class\n",
    "        self.model_type = model_type\n",
    "        self.class_id_dict = class_id_dict\n",
    "        self.class_to_id = class_to_id\n",
    "        self.TTA = TTA\n",
    "        self.img_model = img_model\n",
    "        self.only_emb = only_emb\n",
    "#         self.class_id_dict['All'] = self.eval_df.class_id.unique()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            model_eval(self.model, self.model_type, self.eval_df, self.cand_class_id_emb_attr, \n",
    "#                 seen_class = self.seen_class, \n",
    "#                 unseen_class = self.unseen_class, \n",
    "                img_feature_map = self.y_val,\n",
    "                class_id_dict = self.class_id_dict,\n",
    "                class_to_id = self.class_to_id,\n",
    "                TTA = self.TTA,\n",
    "                img_model = self.img_model,\n",
    "                      only_emb = self.only_emb)\n",
    "\n",
    "class DEM:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, scores = None, flags = None, model_type = None, seen_class = None, \n",
    "            unseen_class = None, class_id_emb_attr = None, img_flat_len = None, \n",
    "                    unseen_round1_id = None,\n",
    "                    unseen_round2_id = None,\n",
    "                    img_model = None,\n",
    "                    only_emb = False,\n",
    "                    c2c_neg_cnt = None):\n",
    "        self.batch_size = 8 #flags.dem_batch_size\n",
    "        self.epochs = 15 #flags.dem_epochs\n",
    "        self.patience = 100 #flags.dem_patience\n",
    "        self.scores = scores\n",
    "        self.model_type = model_type\n",
    "        self.verbose = 1 #flags.train_verbose\n",
    "        self.seen_class = seen_class\n",
    "        self.unseen_class = unseen_class\n",
    "        self.cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)]\n",
    "        self.class_id_emb_attr = class_id_emb_attr\n",
    "        class_ids = class_id_emb_attr.class_id.values\n",
    "        self.class_to_id = dict([(c, i) for i, c in enumerate(class_ids)])\n",
    "        self.img_flat_len = img_flat_len\n",
    "        self.TTA = None #flags.TTA\n",
    "        self.img_model = img_model\n",
    "        self.only_emb = only_emb\n",
    "        self.c2c_neg_cnt = c2c_neg_cnt\n",
    "        if model_type == 'DEM':\n",
    "            self.model = self.create_dem(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'GCN':\n",
    "            self.model = self.create_gcn(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'I2A':\n",
    "            self.model = self.create_img2attr(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'AE':\n",
    "            self.model = self.create_ae(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'DEM_AUG':\n",
    "            self.model = self.create_dem_aug(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'DEM_BC':\n",
    "            self.model = self.create_dem_bc(img_flat_len = img_flat_len, only_emb = self.only_emb)\n",
    "        elif model_type == 'DEM_BC_AUG':\n",
    "            self.model = self.create_dem_bc_aug(img_flat_len = img_flat_len, only_emb = self.only_emb)\n",
    "        elif model_type == 'RES_DEM_BC':\n",
    "            self.model = self.create_res_dem_bc(img_flat_len = img_flat_len, only_emb = self.only_emb)\n",
    "        elif model_type == 'QFSL':\n",
    "            self.model = self.create_qfsl(img_flat_len = img_flat_len, only_emb = self.only_emb)\n",
    "        elif model_type == 'WV2ATTR':\n",
    "            self.model = self.create_wv2attr()\n",
    "        self.class_id_dict = {\n",
    "#                              'seen_class': seen_class,\n",
    "                             'Unseen_class': unseen_class,\n",
    "                             'Unseen_round1_id': unseen_round1_id,\n",
    "                             'Unseen_round2_id': unseen_round2_id,}\n",
    "\n",
    "    def create_dem(self, kernel_initializer = 'he_normal', img_flat_len = 1024):\n",
    "        attr_input = layers.Input(shape = (50,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (300,), name = 'wv')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "        \n",
    "        attr_dense = layers.Dense(1300, use_bias = True, kernel_initializer=kernel_initializer, \n",
    "                        kernel_regularizer = l2(1e-4), name = 'attr_dense')(attr_input)\n",
    "        attr_word_emb = word_emb #layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "                                                                            int(img_flat_len * 2),\n",
    "                                                                            int(img_flat_len * 1.5), \n",
    "                                                                            int(img_flat_len * 1.25), \n",
    "                                                                            int(img_flat_len),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "#         attr_word_emb_dense = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "#                                                 activation = 'relu')\n",
    "\n",
    "        mse_loss = K.mean(mean_squared_error(imag_classifier, attr_word_emb_dense))\n",
    "        \n",
    "        model = Model([attr_input, word_emb, imag_classifier], outputs = attr_word_emb_dense) #, vgg_output])\n",
    "        model.add_loss(mse_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "        return model\n",
    "\n",
    "    def create_dem_bc(self, kernel_initializer = 'he_normal', img_flat_len = 1024, only_emb = False):\n",
    "        attr_input = layers.Input(shape = (22,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (1600,), name = 'wv')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "        label = layers.Input(shape = (1,), name = 'label')\n",
    "        \n",
    "#         attr_emb = layers.Embedding(294, 30)(attr_input)\n",
    "#         attr_dense = layers.Flatten()(attr_emb) #layers.GlobalAveragePooling1D()(attr_emb)\n",
    "        attr_dense = layers.Dense(1600, use_bias = True, kernel_initializer=kernel_initializer, \n",
    "                        kernel_regularizer = l2(1e-4), name = 'attr_dense')(attr_input)\n",
    "        if only_emb:\n",
    "            attr_word_emb = word_emb\n",
    "        else:\n",
    "            attr_word_emb = layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "#                                                                             int(img_flat_len * 4),\n",
    "                                                                            int(img_flat_len * 2),\n",
    "                                                                            int(img_flat_len * 1.5), \n",
    "                                                                            int(img_flat_len * 1.25), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "                                                                            int(img_flat_len)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "#         attr_word_emb_dense = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "#                                                 activation = 'relu')\n",
    "        \n",
    "        attr_x_img = layers.Lambda(lambda x: x[0] * x[1], name = 'attr_x_img')([attr_word_emb_dense, imag_classifier])\n",
    "#         attr_x_img = layers.Concatenate(name = 'attr_x_img')([attr_word_emb_dense, imag_classifier])\n",
    "    \n",
    "        attr_img_input = layers.Input(shape = (img_flat_len,), name = 'attr_img_input')\n",
    "#         attr_img_input = layers.Input(shape = (img_flat_len * 2,), name = 'attr_img_input')\n",
    "        proba = self.full_connect_layer(attr_img_input, hidden_dim = [1], activation = 'sigmoid')\n",
    "        attr_img_model = Model(inputs = attr_img_input, outputs = proba, name = 'attr_x_img_model')\n",
    "        \n",
    "        out = attr_img_model([attr_x_img])\n",
    "        \n",
    "        bc_loss = K.mean(binary_crossentropy(label, out))\n",
    "        model = Model([imag_classifier, attr_input, word_emb, label], outputs = [attr_word_emb_dense, out])\n",
    "        model.add_loss(bc_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "        return model\n",
    "    \n",
    "    def create_dem_bc_aug(self, kernel_initializer = 'he_normal', img_flat_len = 1024, only_emb = False):\n",
    "        attr_input = layers.Input(shape = (53,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (2800,), name = 'wv')\n",
    "        img_input = layers.Input(shape = (72, 72, 3))\n",
    "        label = layers.Input(shape = (1,), name = 'label')\n",
    "        \n",
    "        imag_classifier = self.img_model(img_input)\n",
    "        if only_emb:\n",
    "            attr_word_emb = word_emb\n",
    "        else:\n",
    "            attr_word_emb = layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "#                                                                             int(img_flat_len * 4),\n",
    "                                                                            int(img_flat_len * 2),\n",
    "                                                                            int(img_flat_len * 1.5), \n",
    "                                                                            int(img_flat_len * 1.25), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "                                                                            int(img_flat_len)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "#         attr_word_emb_dense = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "#                                                 activation = 'relu')\n",
    "        \n",
    "        attr_x_img = layers.Lambda(lambda x: x[0] * x[1], name = 'attr_x_img')([attr_word_emb_dense, imag_classifier])\n",
    "#         attr_x_img = layers.Concatenate(name = 'attr_x_img')([attr_word_emb_dense, imag_classifier])\n",
    "    \n",
    "        attr_img_input = layers.Input(shape = (img_flat_len,), name = 'attr_img_input')\n",
    "#         attr_img_input = layers.Input(shape = (img_flat_len * 2,), name = 'attr_img_input')\n",
    "        proba = self.full_connect_layer(attr_img_input, hidden_dim = [1], activation = 'sigmoid')\n",
    "        attr_img_model = Model(inputs = attr_img_input, outputs = proba, name = 'attr_x_img_model')\n",
    "        \n",
    "        out = attr_img_model([attr_x_img])\n",
    "        \n",
    "#         dem_bc_model = self.create_dem_bc(kernel_initializer = 'he_normal', \n",
    "#                                            img_flat_len = img_flat_len, \n",
    "#                                            only_emb = only_emb)\n",
    "#         attr_word_emb_dense, out = dem_bc_model([imag_classifier, attr_input, word_emb, label])\n",
    "        \n",
    "        bc_loss = K.mean(binary_crossentropy(label, out))\n",
    "        model = Model([img_input, attr_input, word_emb, label], outputs = [attr_word_emb_dense, out])\n",
    "        model.add_loss(bc_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "        return model\n",
    "    \n",
    "    def create_res_dem_bc(self, kernel_initializer = 'he_normal', img_flat_len = 1024, only_emb = False):\n",
    "        attr_input = layers.Input(shape = (50,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (1600,), name = 'wv')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "        label = layers.Input(shape = (1,), name = 'label')\n",
    "        \n",
    "        attr_dense = layers.Dense(1600, use_bias = True, kernel_initializer=kernel_initializer, \n",
    "                        kernel_regularizer = l2(1e-4), name = 'attr_dense')(attr_input)\n",
    "        \n",
    "        ini_dem_model = self.create_dem_bc(kernel_initializer = 'he_normal', \n",
    "                                           img_flat_len = img_flat_len, \n",
    "                                           only_emb = True)\n",
    "#         print (ini_dem_model.summary())\n",
    "        ini_dem_model.load_weights('./only_emb.h5')\n",
    "        ini_dem_model_part = Model(inputs = ini_dem_model.inputs[2], \n",
    "                                   outputs = ini_dem_model.outputs[0])\n",
    "        ini_dem_model_part.trainable = False\n",
    "        ini_attr_word_emb_dense = ini_dem_model_part([word_emb])\n",
    "        \n",
    "        if only_emb:\n",
    "            attr_word_emb = word_emb\n",
    "        else:\n",
    "            attr_word_emb = attr_dense #layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "                                                                            int(img_flat_len * 2),\n",
    "                                                                            int(img_flat_len * 1.5), \n",
    "                                                                            int(img_flat_len * 1.25),\n",
    "                                                                            int(img_flat_len)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "        attr_word_emb_dense = layers.Lambda(lambda x: x[0] + x[1])([attr_word_emb_dense, ini_attr_word_emb_dense])\n",
    "        \n",
    "        attr_x_img = layers.Lambda(lambda x: x[0] * x[1], name = 'attr_x_img')([attr_word_emb_dense, imag_classifier])\n",
    "#         attr_x_img = layers.Concatenate(name = 'attr_x_img')([attr_word_emb_dense, imag_classifier])\n",
    "    \n",
    "        attr_img_input = layers.Input(shape = (img_flat_len,), name = 'attr_img_input')\n",
    "#         attr_img_input = layers.Input(shape = (img_flat_len * 2,), name = 'attr_img_input')\n",
    "        proba = self.full_connect_layer(attr_img_input, hidden_dim = [1], activation = 'sigmoid')\n",
    "        attr_img_model = Model(inputs = attr_img_input, outputs = proba, name = 'attr_x_img_model')\n",
    "        \n",
    "        out = attr_img_model([attr_x_img])\n",
    "        \n",
    "        bc_loss = K.mean(binary_crossentropy(label, out))\n",
    "        model = Model([imag_classifier, attr_input, word_emb, label], outputs = [attr_word_emb_dense, out])\n",
    "        model.add_loss(bc_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "        return model\n",
    "    \n",
    "    def create_dem_aug(self, kernel_initializer = 'he_normal', img_flat_len = 1024):\n",
    "        attr_input = layers.Input(shape = (50,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (300,), name = 'wv')\n",
    "        img_input = layers.Input(shape = (64, 64, 3))\n",
    "#         imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "        img_model = DenseNet(scores = None, \n",
    "                     cat_max = 365, #flags.cat_max, \n",
    "                     flags = None, \n",
    "                     model_type = 'DenseNet').model\n",
    "#         print ('Load DenseNet Weights---')\n",
    "        img_model.load_weights(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05108_TF14_DensetNetProcess/imgmodel_20181013_092715.h5')\n",
    "        img_flat_model = Model(inputs = img_model.inputs, outputs = img_model.get_layer(name = 'avg_pool').output)\n",
    "        img_flat_model.trainable = False\n",
    "        imag_classifier = img_flat_model(img_input)\n",
    "        \n",
    "        attr_dense = layers.Dense(1200, use_bias = True, kernel_initializer=kernel_initializer, \n",
    "                        kernel_regularizer = l2(1e-4), name = 'attr_dense')(attr_input)\n",
    "        attr_word_emb = layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "                                                                            int(img_flat_len * 2),\n",
    "#                                                                             int(img_flat_len * 1.5), \n",
    "#                                                                             int(img_flat_len * 1.25), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "                                                activation = 'relu')\n",
    "\n",
    "        mse_loss = K.mean(mean_squared_error(imag_classifier, attr_word_emb_dense))\n",
    "        \n",
    "        model = Model([img_input, attr_input, word_emb], outputs = [attr_word_emb_dense, imag_classifier]) #, vgg_output])\n",
    "        model.add_loss(mse_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "        return model\n",
    "    \n",
    "    def create_img2attr(self, kernel_initializer = 'he_normal', img_flat_len = 1024):\n",
    "        attr_input = layers.Input(shape = (50,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (600,), name = 'wv')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "        attr_dense = layers.Dense(600, use_bias = True, kernel_initializer=kernel_initializer, \n",
    "                        kernel_regularizer = l2(1e-4), name = 'attr_dense')(attr_input)\n",
    "        attr_word_emb = layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        out_size = 50\n",
    "        \n",
    "        attr_preds = self.full_connect_layer(imag_classifier, hidden_dim = [\n",
    "                                                                            int(out_size * 20),\n",
    "                                                                            int(out_size * 15), \n",
    "#                                                                             int(out_size * 7), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "        attr_preds = self.full_connect_layer(attr_preds, hidden_dim = [out_size], activation = 'sigmoid')\n",
    "        log_loss = K.mean(binary_crossentropy(attr_input, attr_preds))\n",
    "        \n",
    "        model = Model([attr_input, word_emb, imag_classifier], outputs = [attr_preds]) #, vgg_output])\n",
    "        model.add_loss(log_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-5), loss=None)\n",
    "        return model\n",
    "    \n",
    "    def create_wv2attr(self, kernel_initializer = 'he_normal'):\n",
    "        attr_input = layers.Input(shape = (50,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (2800,), name = 'wv')\n",
    "        out_size = 50\n",
    "        \n",
    "        attr_from_wv = self.full_connect_layer(word_emb, hidden_dim = [\n",
    "                                                                            int(out_size * 4),\n",
    "                                                                            int(out_size * 3), \n",
    "#                                                                             int(out_size), \n",
    "                                                                            int(out_size * 2),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'sigmoid', resnet = False, drop_out_ratio = 0.2)\n",
    "        attr_preds = self.full_connect_layer(attr_from_wv, hidden_dim = [out_size], activation = 'sigmoid')\n",
    "        log_loss = K.mean(K.mean(binary_crossentropy(attr_input, attr_preds)))\n",
    "        \n",
    "        model = Model([attr_input, word_emb], outputs = [attr_preds]) #, vgg_output])\n",
    "        model.add_loss(log_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-5), loss=None)\n",
    "        return model\n",
    "\n",
    "    def create_qfsl(self, img_flat_len = 1024, only_emb = False):\n",
    "        class_num = self.class_id_emb_attr.shape[0]\n",
    "        print ('Class name in model: ', class_num)\n",
    "        unseen_mask = np.ones(class_num)\n",
    "#         unseen_mask[[self.class_to_id[c] for c in self.unseen_class]] = 0\n",
    "        all_word_emb = layers.Input(tensor=\n",
    "                        tf.constant(extract_array_from_series(self.class_id_emb_attr['emb']), \n",
    "                                    dtype = 'float32'), name = 'wv') #Input(shape = (230, 300,), name = 'wv')\n",
    "        classes = layers.Input(shape = (class_num, ), name = 'classes')\n",
    "        classe_weight = layers.Input(shape = (class_num, ), name = 'classe_weight')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "        if only_emb:\n",
    "            attr_word_emb = all_word_emb\n",
    "            attr_input = layers.Input(tensor=\n",
    "                            tf.constant(0), name = 'attr')\n",
    "        else:\n",
    "            attr_input = layers.Input(tensor=\n",
    "                            tf.constant(np.array(list(self.class_id_emb_attr['attr']), \n",
    "                                                 dtype = 'float32')), name = 'attr')\n",
    "            attr_dense = layers.Dense(1200, use_bias = False, kernel_initializer='he_normal', \n",
    "                        kernel_regularizer = l2(1e-4))(attr_input)\n",
    "            attr_word_emb  = layers.Concatenate()([all_word_emb, attr_dense])\n",
    "#         attr_word_emb_size = 2400\n",
    "        \n",
    "        img_from_attr_emb = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "                                                                            int(img_flat_len * 2),\n",
    "                                                                            int(img_flat_len * 1.5), \n",
    "                                                                            int(img_flat_len * 1.25), \n",
    "                                                                            int(img_flat_len),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "#         img_from_attr_emb = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "#                                                 activation = 'relu')\n",
    "        \n",
    "#         imag_classifier = layers.Reahpe((img_flat_len, 1))(imag_classifier)\n",
    "#         scoring_sub = layers.Conv1D(filters = class_num, \n",
    "#                                     kernel_size = 1, \n",
    "#                                     use_bias = False,\n",
    "#                                     weights = )(imag_classifier)\n",
    "        scoring_sub = layers.Lambda(lambda x: K.reshape(tf.tile(x[0], [1, class_num]), [-1, class_num, img_flat_len]) *  x[1],\n",
    "                    name = 'scoring_sub')([imag_classifier, img_from_attr_emb])\n",
    "#         out = layers.Dense(1, activation=\"sigmoid\")(scoring_sub)\n",
    "#         out = layers.Flatten()(out)\n",
    "#         out_mask = layers.Lambda(lambda x: x * unseen_mask, name = 'unseen_class_mask')(out)\n",
    "        scoring_sub = layers.GlobalAveragePooling1D()(scoring_sub)\n",
    "        scoring_sub = layers.Flatten()(scoring_sub)\n",
    "        out = self.full_connect_layer(scoring_sub, hidden_dim = [class_num], \n",
    "                                    activation = 'softmax')\n",
    "\n",
    "        log_loss = K.sum(K.sum(K.categorical_crossentropy(classes, out)))\n",
    "\n",
    "        model = Model([imag_classifier, classes, classe_weight, attr_input, all_word_emb], outputs = [out])\n",
    "        model.add_loss(log_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "    #     model.summary()\n",
    "        return model\n",
    "        \n",
    "    def full_connect_layer(self, input, hidden_dim, activation, resnet = False, adj_graphs = None, \n",
    "                        drop_out_ratio = None, kernel_initializer = 'he_normal'):\n",
    "        full_connect = input\n",
    "        for i, hn in enumerate(hidden_dim):\n",
    "            fc_in = full_connect\n",
    "            if drop_out_ratio is not None:\n",
    "                full_connect = layers.Dropout(drop_out_ratio)(full_connect)\n",
    "            full_connect = layers.BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "            full_connect = layers.Dense(hn, kernel_initializer=kernel_initializer, kernel_regularizer = l2(1e-4), \n",
    "                    activation = None)(full_connect)\n",
    "            if adj_graphs is not None:\n",
    "                full_connect = layers.Lambda(lambda x: K.dot(x[1], x[0]))([full_connect, adj_graphs])\n",
    "            full_connect = layers.Activation(activation)(full_connect)\n",
    "            if resnet:\n",
    "                full_connect = layers.Concatenate()([fc_in, full_connect])\n",
    "        return full_connect\n",
    "\n",
    "    def DNN_DataSet(self, df, neg_aug = 0):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if self.model_type == 'DEM' or self.model_type == 'I2A' or self.model_type == 'AE':\n",
    "#             return create_dem_data(df) + [extract_array_from_series(df['target'])]\n",
    "            return create_dem_data(df) + [sklearn.preprocessing.normalize(extract_array_from_series(df['target']))]\n",
    "        elif self.model_type == 'DEM_AUG':\n",
    "            return [preprocess_img(df['img'])] + create_dem_data(df)\n",
    "        elif self.model_type == 'GCN':\n",
    "            return [create_gcn_data(df, self.class_to_id), \n",
    "                    sklearn.preprocessing.normalize(extract_array_from_series(df['target']))]\n",
    "        elif self.model_type == 'DEM_BC' or self.model_type == 'RES_DEM_BC':\n",
    "            return create_dem_bc_data(df, neg_aug, self.only_emb, \n",
    "                class_id_emb_attr = self.class_id_emb_attr[self.class_id_emb_attr.class_id.isin(self.seen_class)],\n",
    "                c2c_neg_cnt = self.c2c_neg_cnt)\n",
    "        elif self.model_type == 'QFSL':\n",
    "            return create_qfsl_data(df, self.class_to_id, categories = self.class_id_emb_attr.shape[0], \n",
    "                                    ns = 1)\n",
    "        elif self.model_type == 'DEM_BC_AUG':\n",
    "            return create_dem_bc_aug_data(df, neg_aug, self.only_emb, \n",
    "                class_id_emb_attr = self.class_id_emb_attr[self.class_id_emb_attr.class_id.isin(self.seen_class)],\n",
    "                c2c_neg_cnt = self.c2c_neg_cnt)\n",
    "        elif self.model_type == 'WV2ATTR':\n",
    "            return create_dem_data(df, only_emb = False)\n",
    "\n",
    "    def lgbm_train(self, train_part, train_part_label, valide_part, valide_part_label, fold_seed = None,\n",
    "        fold = 5, train_weight = None, valide_weight = None, flags = None):\n",
    "        \"\"\"\n",
    "        LGBM Training\n",
    "        \"\"\"\n",
    "        print(\"-----LGBM training-----\")\n",
    "\n",
    "        d_train = lgb.Dataset(train_part, train_part_label)\n",
    "        d_valide = lgb.Dataset(valide_part, valide_part_label)\n",
    "        params = {\n",
    "                'task': 'train',\n",
    "                'boosting_type': 'gbdt', #'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': ['auc', 'binary_logloss'],\n",
    "                'num_leaves': 7, #60, #40, # 60,\n",
    "#                 'min_sum_hessian_in_leaf': 10,\n",
    "                'max_depth': 3,#12, #6, # 10,\n",
    "                'learning_rate': 1, # 0.025,\n",
    "               # 'feature_fraction': 0.5,#0.35, # 0.6\n",
    "                'verbose': 0,\n",
    "                'num_boost_round': 800, #361,\n",
    "#                 'feature_fraction_seed': fold_seed,\n",
    "                #'drop_rate': 0.05,\n",
    "                # 'bagging_fraction': 0.8,\n",
    "                # 'bagging_freq': 20,\n",
    "                # 'bagging_seed': fold_seed,\n",
    "                 'early_stopping_round': 1500,\n",
    "                # 'random_state': 10\n",
    "                # 'verbose_eval': 20\n",
    "                #'min_data_in_leaf': 665\n",
    "            }\n",
    "#         params.update(config.all_params)\n",
    "        print (\"lightgbm params: {0}\\n\".format(params))\n",
    "\n",
    "        bst = lgb.train(\n",
    "                        params ,\n",
    "                        d_train,\n",
    "                        verbose_eval = 200,\n",
    "                        valid_sets = [d_train, d_valide],\n",
    "                        # feature_name= keras_train.DENSE_FEATURE_LIST,\n",
    "                        #feval = gini_lgbm\n",
    "                        #num_boost_round = 1\n",
    "                        )\n",
    "        return bst\n",
    "\n",
    "    def train(self, train_part_df, validate_part_df):\n",
    "        \"\"\"\n",
    "        Keras Training\n",
    "        \"\"\"\n",
    "        print(\"-----DNN training-----\")\n",
    "\n",
    "        DNN_Train_Data = self.DNN_DataSet(train_part_df, neg_aug = 1)\n",
    "        DNN_validate_Data = self.DNN_DataSet(validate_part_df)\n",
    "        \n",
    "        callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=self.patience, verbose=0),\n",
    "        ]\n",
    "        if self.model_type != 'WV2ATTR':\n",
    "            callbacks += [AccuracyEvaluation(validation_data=DNN_validate_Data, interval=1,\n",
    "                            cand_class_id_emb_attr = self.cand_class_id_emb_attr,\n",
    "                            eval_df = validate_part_df,\n",
    "                            model_type = self.model_type,\n",
    "                            class_id_dict = self.class_id_dict,\n",
    "                            class_to_id = self.class_to_id,\n",
    "                            TTA = self.TTA,\n",
    "                            img_model = self.img_model,\n",
    "                          only_emb = self.only_emb)\n",
    "                        ]\n",
    "        if self.model_type == 'DEM_BC_AUG':\n",
    "            datagen = MixedImageDataGenerator(\n",
    "                    rotation_range=20,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "            datagen.fit(DNN_Train_Data[0])\n",
    "#             print (DNN_Train_Data[0])\n",
    "            h = self.model.fit_generator(\n",
    "                    datagen.flow((DNN_Train_Data[0], DNN_Train_Data[1:]), None, batch_size=self.batch_size), \n",
    "                    validation_data=(DNN_validate_Data, None), steps_per_epoch = DNN_Train_Data[0].shape[0]//self.batch_size,\n",
    "                    epochs=self.epochs, shuffle=True, verbose = self.verbose, workers=1, use_multiprocessing=False, \n",
    "                    callbacks=callbacks)\n",
    "#         elif self.model_type == 'DEM_BC':\n",
    "#             h = self.model.fit(DNN_Train_Data[0],  DNN_Train_Data[1], validation_data = DNN_validate_Data,\n",
    "#                         epochs=self.epochs, batch_size = self.batch_size, shuffle=True, verbose = self.verbose, callbacks=callbacks)\n",
    "        else:\n",
    "            h = self.model.fit(DNN_Train_Data,  validation_data = (DNN_validate_Data, None),\n",
    "                        epochs=self.epochs, batch_size = self.batch_size, shuffle=True, verbose = self.verbose, callbacks=callbacks)\n",
    "        self.scores.append(pd.DataFrame(h.history))\n",
    "        \n",
    "#         print (DNN_validate_Data[0])\n",
    "#         print (self.model.predict(DNN_validate_Data))\n",
    "#         zs_model = Model(inputs = self.model.inputs[1:3], outputs = self.model.outputs[0])\n",
    "#         train_attr_x_img = zs_model.predict(DNN_Train_Data[1:3], verbose = 1)\n",
    "#         train_label = DNN_Train_Data[-1].flatten()\n",
    "#         validate_attr_x_img = zs_model.predict(DNN_validate_Data[1:3], verbose = 1)\n",
    "#         validate_label = DNN_validate_Data[-1].flatten()\n",
    "# #         print (train_label)\n",
    "# #         print (validate_label)\n",
    "#         bst = self.lgbm_train(train_attr_x_img, train_label, validate_attr_x_img, validate_label)\n",
    "        \n",
    "#         cand_feature_map = zs_model.predict(create_dem_data(self.cand_class_id_emb_attr, only_emb = self.only_emb), \n",
    "#                                             verbose = 1)\n",
    "        \n",
    "#         attr_x_img_model = Model(inputs = self.model.get_layer('attr_x_img_model').inputs, \n",
    "#                          outputs = self.model.get_layer('attr_x_img_model').outputs)\n",
    "#         pred = find_nearest_class(self.cand_class_id_emb_attr, \n",
    "#                                   validate_part_df, \n",
    "#                                   cand_feature_map = cand_feature_map, \n",
    "#                                 img_feature_map = DNN_validate_Data[0],\n",
    "#                                 zs_model = bst, model_type = 'lgb')\n",
    "#         calc_detailed_accuracy(validate_part_df, pred, self.class_id_dict)\n",
    "        \n",
    "        return self.model\n",
    "\n",
    "    def predict(self, test_part, batch_size = 1024, verbose=2):\n",
    "        \"\"\"\n",
    "        Keras Training\n",
    "        \"\"\"\n",
    "        print(\"-----DNN Test-----\")\n",
    "        pred = self.model.predict(self.DNN_DataSet(test_part), verbose=verbose)\n",
    "        if self.model_type == 'r':\n",
    "            pred = pred[:, -1]\n",
    "        return pred\n",
    "\n",
    "def train_zs_model(train_data, class_id_emb_attr, flags, img_flat_len,\n",
    "                   round1_class_id = None,\n",
    "                   round2_class_id = None,\n",
    "                   img_model = None):\n",
    "    print(\"Over all training size:\")\n",
    "    print(train_data.shape)\n",
    "\n",
    "    fold = 10 #flags.dem_nfold\n",
    "    ensemble_nfold = 10 #flags.dem_ensemble_nfold\n",
    "    kf = KFold(n_splits=fold, shuffle=True, random_state = 100)\n",
    "    num_fold = 0\n",
    "    models = []\n",
    "    model_type = 'DEM_BC'\n",
    "    if model_type == 'WV2ATTR':\n",
    "        train_data = class_id_emb_attr\n",
    "    scores = []\n",
    "    classes = train_data.class_id.unique()\n",
    "    model_file_names_0 = glob.glob(path + '../submit/image_05108_10fold_zs_DEMBC_02161/zsmodel_*.h5')\n",
    "    model_file_names_1 = glob.glob(path + '../submit/image_05108_10fold_zs_DEMBC_negaug5_/zsmodel_*.h5')\n",
    "    model_file_names_2 = glob.glob(path + '../submit/image_05108_10fold_zs_DEMBC_negaug2_/zsmodel_*.h5')\n",
    "    model_file_names = [model_file_names_0, model_file_names_1, model_file_names_2]\n",
    "    \n",
    "    for train_index, test_index in kf.split(classes):\n",
    "        print ('Fold: ', num_fold)\n",
    "        seen_class = classes[train_index]\n",
    "        unseen_class = classes[test_index]\n",
    "        \n",
    "        train_part_df = train_data[train_data.class_id.isin(seen_class)]\n",
    "        validate_part_df = train_data[train_data.class_id.isin(unseen_class)]\n",
    "\n",
    "        seen_round1_id = np.intersect1d(seen_class, round1_class_id)\n",
    "        seen_round2_id = np.intersect1d(seen_class, round2_class_id)\n",
    "        unseen_round1_id = np.intersect1d(unseen_class, round1_class_id)\n",
    "        unseen_round2_id = np.intersect1d(unseen_class, round2_class_id)\n",
    "        print ('Seen unseen Classes: ', seen_class.shape[0], unseen_class.shape[0])\n",
    "        print ('Seen round1, round2: ', seen_round1_id.shape[0], seen_round2_id.shape[0])\n",
    "        print ('Unseen round1, round2: ', unseen_round1_id.shape[0], unseen_round2_id.shape[0])\n",
    "\n",
    "        zs_model = DEM(scores = scores, flags = flags, model_type = model_type, \n",
    "                    seen_class = seen_class, img_flat_len = img_flat_len, \n",
    "                    unseen_class = unseen_class,\n",
    "                    class_id_emb_attr = class_id_emb_attr,\n",
    "                    unseen_round1_id = unseen_round1_id,\n",
    "                    unseen_round2_id = unseen_round2_id,\n",
    "                    img_model = img_model,\n",
    "                    only_emb = False,\n",
    "                      c2c_neg_cnt = None)\n",
    "        \n",
    "        if num_fold == 0:\n",
    "            print (zs_model.model.summary())\n",
    "        zs_model.train(train_part_df, validate_part_df)\n",
    "        models.append((zs_model.model, model_type))\n",
    "#         zs_model.model.save('./only_emb.h5')\n",
    "#         for model_files in model_file_names:\n",
    "#             zs_model = DEM(scores = scores, flags = flags, model_type = model_type, \n",
    "#                         seen_class = seen_class, img_flat_len = img_flat_len, \n",
    "#                         unseen_class = unseen_class,\n",
    "#                         class_id_emb_attr = class_id_emb_attr,\n",
    "#                         unseen_round1_id = unseen_round1_id,\n",
    "#                         unseen_round2_id = unseen_round2_id,\n",
    "#                         img_model = img_model)\n",
    "#             print ('model file name: ', model_files[num_fold])\n",
    "#             zs_model.model.load_weights(model_files[num_fold])\n",
    "#             zs_model.model.trainable = False\n",
    "# #             model_eval(zs_model.model, model_type, validate_part_df, \n",
    "# #                        cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \n",
    "# #                     img_feature_map = extract_array_from_series(validate_part_df['target']),\n",
    "# #                     class_id_dict = {\n",
    "# #     #                              'seen_class': seen_class,\n",
    "# #                                  'Unseen_class': unseen_class,\n",
    "# #     #                              'Unseen_round1_id': unseen_round1_id,\n",
    "# #                                  'Unseen_round2_id': unseen_round2_id,},\n",
    "# #                     class_to_id = dict([(c, i) for i, c in enumerate(class_id_emb_attr.class_id.values)]))\n",
    "#             models.append((zs_model.model, model_type))\n",
    "#         print ('Multi models votes-------')\n",
    "#         multi_models_vote(models = models[-3:], \n",
    "#                       eval_df = validate_part_df,\n",
    "#                     cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)],\n",
    "#                     img_feature_map = extract_array_from_series(validate_part_df['target']), \n",
    "#                     class_id_dict = {\n",
    "#                          'Unseen_class': unseen_class,\n",
    "#                          'Unseen_round2_id': unseen_round2_id,})\n",
    "        \n",
    "        num_fold += 1\n",
    "        if num_fold == ensemble_nfold:\n",
    "            break\n",
    "    return models\n",
    "\n",
    "# img_model = DenseNet(scores = None, \n",
    "#              cat_max = 365, #flags.cat_max, \n",
    "#              flags = None, \n",
    "#              model_type = 'DenseNet').model\n",
    "# img_model.load_weights(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05108_TF14_DensetNetProcess/imgmodel_20181013_092715.h5')\n",
    "# img_flat_model = Model(inputs = img_model.inputs, outputs = img_model.get_layer(name = 'avg_pool').output)\n",
    "img_flat_model = None\n",
    "\n",
    "round1_class_id = list(set(train_data.class_id.unique()) - set(round2_class_id))\n",
    "zs_models = train_zs_model(train_data, #[train_data.class_id.isin(round2_class_id)], \n",
    "       class_id_emb_attr = class_id_emb_attr, #[class_id_emb_attr.class_id.isin(round2_class_id)], \n",
    "       flags = None, \n",
    "       img_flat_len = 1032,                     \n",
    "       round1_class_id = round1_class_id,\n",
    "       round2_class_id = round2_class_id,\n",
    "       img_model = img_flat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(round2_class_id)]\n",
    "cand_class_id_emb_attr = cand_class_id_emb_attr[~cand_class_id_emb_attr.class_id.isin(train_data.class_id.unique())]\n",
    "vote_preds = multi_models_vote(models = zs_models[-3:], \n",
    "                      eval_df = test_data,\n",
    "                    cand_class_id_emb_attr = cand_class_id_emb_attr,\n",
    "                    img_feature_map = extract_array_from_series(test_data['target']))\n",
    "sub = pd.DataFrame(vote_preds, index = test_data['img_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_label = time.strftime('%Y%m%d_%H%M%S')\n",
    "sub.to_csv(path + \"../submit/submit_\"+ time_label + \".txt\", header = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_wv_to_attr():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0266666666666666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 154 * 8 / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((2, 2)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Re</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.203936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.198558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.191348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.184690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.209449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.202758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Re\n",
       "Epoch          \n",
       "1      0.203635\n",
       "2      0.203936\n",
       "3      0.205168\n",
       "4      0.198558\n",
       "5      0.191348\n",
       "6      0.184690\n",
       "7      0.202381\n",
       "8      0.209449\n",
       "9      0.202758"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log = pd.read_csv(path + 'log_ft1300', header = None, names = ['Epoch', 'Re'], sep = ' ')\n",
    "log.groupby('Epoch').agg({'Re': ['mean', 'median']}).plot(grid = True, title = 'mean')\n",
    "log.groupby('Epoch').agg({'Re': 'std'}).plot(grid = True, title = 'std')\n",
    "# log.groupby('Epoch').agg({'Re': 'median'}).plot(grid = True, title = 'median')\n",
    "# log.groupby('Epoch').agg({'Re': 'count'}).plot(grid = True)\n",
    "log.groupby('Epoch').agg({'Re': 'mean'})\n",
    "# log[log.Fold == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cand shape:  16\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.377448\t1195\t3166\n",
      "\n",
      "\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.263108\t833\t3166\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unseen_class: \t0.385028\t1219\t3166\n",
      "\n",
      "\n",
      "cand shape:  16\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.612995\t1934\t3155\n",
      "\n",
      "\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.556894\t1757\t3155\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unseen_class: \t0.584152\t1843\t3155\n",
      "\n",
      "\n",
      "cand shape:  16\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.590740\t1901\t3218\n",
      "\n",
      "\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.631137\t2031\t3218\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unseen_class: \t0.628962\t2024\t3218\n",
      "\n",
      "\n",
      "cand shape:  16\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.572295\t1793\t3133\n",
      "\n",
      "\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.575806\t1804\t3133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unseen_class: \t0.547399\t1715\t3133\n",
      "\n",
      "\n",
      "cand shape:  16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b714bdda1934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     multi_models_vote(models = zs_model_list, eval_df = validate_part_df,             cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr['class_id'].isin(unseen_class)],             img_feature_map = extract_array_from_series(validate_part_df['target']),\n\u001b[1;32m     20\u001b[0m             class_id_dict = {\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0;34m'Unseen_class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munseen_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             })\n",
      "\u001b[0;32m<ipython-input-26-6ca63de5e674>\u001b[0m in \u001b[0;36mmulti_models_vote\u001b[0;34m(models, eval_df, cand_class_id_emb_attr, img_feature_map, class_id_dict)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'cand shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcand_class_id_emb_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     preds = models_eval(models, eval_df, cand_class_id_emb_attr, img_feature_map, \n\u001b[0;32m---> 41\u001b[0;31m                 class_id_dict)\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# print (preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-6ca63de5e674>\u001b[0m in \u001b[0;36mmodels_eval\u001b[0;34m(models, eval_df, cand_class_id_emb_attr, img_feature_map, class_id_dict, class_to_id)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         pred = model_eval(model, model_type, eval_df = eval_df, cand_class_id_emb_attr = cand_class_id_emb_attr, \n\u001b[0;32m---> 81\u001b[0;31m             img_feature_map = img_feature_map, class_id_dict = class_id_dict, class_to_id = class_to_id)\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-6ca63de5e674>\u001b[0m in \u001b[0;36mmodel_eval\u001b[0;34m(model, model_type, eval_df, cand_class_id_emb_attr, img_feature_map, class_id_dict, class_to_id)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DEM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mzs_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mcand_feature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_dem_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand_class_id_emb_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_nearest_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand_class_id_emb_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcand_feature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_feature_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'class_id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     return self._predict_loop(\n\u001b[0;32m-> 1739\u001b[0;31m         f, ins, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m           \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m         **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 run_metadata):\n\u001b[1;32m   1292\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1354\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def lgbm_train(train_part, train_part_label, valide_part, valide_part_label, fold_seed,\n",
    "        fold = 5, train_weight = None, valide_weight = None, flags = None):\n",
    "    \"\"\"\n",
    "    LGBM Training\n",
    "    \"\"\"\n",
    "    if flags.stacking:\n",
    "        FEATURE_LIST += ['emb_' + str(i) for i in range(len(CATEGORY_FEATURES) * 5)] + ['k_pred']\n",
    "    print(\"-----LGBM training-----\")\n",
    "\n",
    "    d_train = lgb.Dataset(train_part[FEATURE_LIST].values, train_part_label, weight = train_weight, \n",
    "            feature_name = FEATURE_LIST, categorical_feature = CATEGORY_FEATURES,)#, init_score = train_part[:, -1])\n",
    "    d_valide = lgb.Dataset(valide_part[FEATURE_LIST].values, valide_part_label, weight = valide_weight,\n",
    "            feature_name = FEATURE_LIST, categorical_feature = CATEGORY_FEATURES,)#, init_score = valide_part[:, -1])\n",
    "    params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt', #'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'num_leaves': 240, #60, #40, # 60,\n",
    "            'min_sum_hessian_in_leaf': 10,\n",
    "            'max_depth': 50,#12, #6, # 10,\n",
    "            'learning_rate': 0.025, # 0.025,\n",
    "           # 'feature_fraction': 0.5,#0.35, # 0.6\n",
    "            'verbose': 0,\n",
    "            'num_boost_round': 500, #361,\n",
    "            'feature_fraction_seed': fold_seed,\n",
    "            #'drop_rate': 0.05,\n",
    "            # 'bagging_fraction': 0.8,\n",
    "            # 'bagging_freq': 20,\n",
    "            # 'bagging_seed': fold_seed,\n",
    "             'early_stopping_round': 1500,\n",
    "            # 'random_state': 10\n",
    "            # 'verbose_eval': 20\n",
    "            #'min_data_in_leaf': 665\n",
    "        }\n",
    "    params.update(config.all_params)\n",
    "    print (\"lightgbm params: {0}\\n\".format(params))\n",
    "\n",
    "    bst = lgb.train(\n",
    "                    params ,\n",
    "                    d_train,\n",
    "                    verbose_eval = 50,\n",
    "                    valid_sets = [d_train, d_valide],\n",
    "                    # feature_name= keras_train.DENSE_FEATURE_LIST,\n",
    "                    #feval = gini_lgbm\n",
    "                    #num_boost_round = 1\n",
    "                    )\n",
    "    #pred = model_eval(bst, 'l', valide_part)\n",
    "    #print(pred[:10])\n",
    "    #print(valide_part_label[:10])\n",
    "    #print(valide_part[:10, -1])\n",
    "    # exit(0)\n",
    "    feature_imp = bst.feature_importance(importance_type = 'gain')\n",
    "    sort_ind = np.argsort(feature_imp)[::-1]\n",
    "    print (np.c_[np.array(FEATURE_LIST)[sort_ind], feature_imp[sort_ind]])\n",
    "    # print (np.array(keras_train.FEATURE_LIST)[np.argsort(feature_imp)])\n",
    "    # exit(0)\n",
    "    # cv_result = lgb.cv(params, d_train, nfold=fold) #, feval = gini_lgbm)\n",
    "    # pd.DataFrame(cv_result).to_csv('cv_result', index = False)\n",
    "    # exit(0)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cand shape:  45\n",
      "32/45 [====================>.........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "def sub(models, train_data, test_data, class_id_emb_attr, img_model, output_model_path):\n",
    "    train_id = train_data['class_id'].unique()\n",
    "    test_img_feature_map = extract_array_from_series(test_data['target'])\n",
    "    preds = multi_models_vote(models = models, eval_df = test_data, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)], \\\n",
    "            img_feature_map = test_img_feature_map)\n",
    "    sub = pd.DataFrame(preds, index = test_data['img_id'])\n",
    "    time_label = time.strftime('%Y%m%d_%H%M%S')\n",
    "    tmp_model_dir = \"./model_sub/\"\n",
    "    if not os.path.isdir(tmp_model_dir):\n",
    "        os.makedirs(tmp_model_dir, exist_ok=True)\n",
    "    sub_name = tmp_model_dir + \"/submit_\"+ time_label + \".txt\"\n",
    "    sub.to_csv(sub_name, header = False, sep = '\\t')\n",
    "\n",
    "#     model_name = tmp_model_dir + \"imgmodel_\" + time_label + \".h5\"\n",
    "#     img_model[0].save(model_name)\n",
    "#     for i, model in enumerate(models):\n",
    "#         model_name = tmp_model_dir + \"zsmodel_\" + str(i) + time_label + \".h5\"\n",
    "#         model[0].save(model_name)\n",
    "\n",
    "    if not os.path.isdir(output_model_path):\n",
    "        os.makedirs(output_model_path, exist_ok=True)\n",
    "    for fileName in os.listdir(tmp_model_dir):\n",
    "        dst_file = os.path.join(output_model_path, fileName)\n",
    "        if os.path.exists(dst_file):\n",
    "            os.remove(dst_file)\n",
    "        shutil.move(os.path.join(tmp_model_dir, fileName), output_model_path)\n",
    "        \n",
    "cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(round2_class_id)]\n",
    "sub(models = zs_models, train_data = train_data, test_data = test_data, \n",
    "        class_id_emb_attr = cand_class_id_emb_attr, img_model = img_model, \n",
    "        output_model_path = '../submit/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model_dir = path + \"./model_dir/6_12_24_16_ini_64_grow_32_03535/\"\n",
    "# time_label = time.strftime('_%Y_%m_%d_%H_%M_%S', time.gmtime())\n",
    "# if not os.path.isdir(tmp_model_dir):\n",
    "#     os.makedirs(tmp_model_dir, exist_ok=True)\n",
    "# model_name = tmp_model_dir + \"model\" + time_label + \".h5\"\n",
    "# img_model.model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38221/38221 [==============================] - 2s 45us/step\n"
     ]
    }
   ],
   "source": [
    "pred_class_probas = img_classifi_model.predict(train_image_feature_map, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['preds'] = list(pred_class_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "891 * 80 / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n03598930', 'jigsaw_puzzle', 0.023861792), ('n02095314', 'wire-haired_fox_terrier', 0.022931756), ('n04589890', 'window_screen', 0.021361042)]\n"
     ]
    }
   ],
   "source": [
    "# np.asarray(list(train_data['img'])).shape\n",
    "# train_data[train_data['class_id'] == 'ZJL1']\n",
    "# train_data['class_id'].value_counts().hist()\n",
    "# train_data.head()\n",
    "# class_id_emb_attr.iloc[0].name\n",
    "# resnet50_model = ResNet50(weights='imagenet', input_shape=(224, 224, 3))\n",
    "img = image.load_img(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg', target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = vgg16.preprocess_input(img)\n",
    "preds = vgg_model.predict(np.expand_dims(img, axis=0))\n",
    "print('Predicted:', vgg16.decode_predictions(preds, top=3)[0])\n",
    "# imread(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg')\n",
    "# image.img_to_array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = setA_train_data\n",
    "\n",
    "img_model = DenseNet(blocks = [6, 12, 24, 16], \n",
    "                                cat_max = 205,\n",
    "                                weight_decay = 1e-4, \n",
    "                                kernel_initializer = 'glorot_normal',\n",
    "                                reduction = 0.5, \n",
    "                                init_filters = 128, \n",
    "                                growth_rate = 32).model\n",
    "img_model.load_weights(path + '/model_sub/6_12_24_16_ini64_growth32_inistride2_03621/model_0_2018_09_21_21_10_59.h5')\n",
    "img_model_flat = Model(input = img_model.input, output = img_model.get_layer(name = 'avg_pool').output)\n",
    "train_data['target'] = list(img_model_flat.predict(preprocess_img(train_data['img']), verbose = 1))\n",
    "# train_data['preds'] = list(img_model.predict(train_img, verbose = 1))\n",
    "# train_data['target'] = list(train_y) #\n",
    "# with open('../..//Data/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/model_0_2018_09_24_03_07_15.h5', 'rb') as handle:\n",
    "#     flat_train_re = pickle.load(handle)\n",
    "# train_data['target'] = list(flat_train_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0262023 , 1.0496653 , 0.42650044, ..., 0.09345146, 0.14242867,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_train_re[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2266190e+00, 1.6327184e-01, 2.8384233e-01, ..., 4.1941926e-04,\n",
       "       3.3683911e-02, 7.6473856e-01], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['target'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_part_img_id = pd.read_csv(path + '/model_sub/6_12_24_16_ini64_growth16_02962/train_part_img_id_0.csv', header = None)\n",
    "validate_part_img_id = pd.read_csv(path + '/model_sub/6_12_24_16_ini64_growth16_02962/validate_part_img_id_0.csv', header = None)\n",
    "train_part_img_id = train_part_img_id[0].values\n",
    "validate_part_img_id = validate_part_img_id[0].values\n",
    "\n",
    "train_part_df = train_data[train_data['img_id'].isin(train_part_img_id)]\n",
    "validate_part_df = train_data[train_data['img_id'].isin(validate_part_img_id)]\n",
    "\n",
    "seen_class = train_part_df.append(validate_part_df).class_id.unique()\n",
    "\n",
    "train_part_df = train_data[train_data['class_id'].isin(seen_class)]\n",
    "validate_part_df = train_data[~train_data['class_id'].isin(seen_class)]\n",
    "# unseen_class_df = train_data[~train_data['class_id'].isin(seen_class)]\n",
    "unseen_class = validate_part_df.class_id.unique()\n",
    "\n",
    "# validate_part_df = validate_part_df.append(unseen_class_df)\n",
    "# train_part_df = train_part_df.append(validate_part_df)\n",
    "# validate_part_df = unseen_class_df\n",
    "\n",
    "train_part_data = create_dnn_data(train_part_df)\n",
    "train_part_target = extract_array_from_series(train_part_df['target'])\n",
    "\n",
    "validate_part_data = create_dnn_data(validate_part_df)\n",
    "validate_part_target = extract_array_from_series(validate_part_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39184, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setB_train_data[setB_train_data.class_id.isin(seen_class)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3713906765013109"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 / 10.77032961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 6 4]\n",
      " [8 7 1]\n",
      " [2 2 5]\n",
      " [2 1 5]]\n",
      "[10.77032961 10.67707825  5.74456265  5.47722558]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.74278135, 0.55708601, 0.37139068],\n",
       "       [0.74926865, 0.65561007, 0.09365858],\n",
       "       [0.34815531, 0.34815531, 0.87038828],\n",
       "       [0.36514837, 0.18257419, 0.91287093]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(1, 10, (4,3))\n",
    "print (x)\n",
    "print (np.linalg.norm(x, axis = 1))\n",
    "sklearn.preprocessing.normalize(x, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "        \n",
    "def find_nearest_class(class_id_emb_attr, model, eval_df, cand_feature_map, img_feature_map, \n",
    "                       threshold = None, gamma = None, seen_class = None):\n",
    "#     cand_feature_map = model.predict(create_dnn_data(class_id_emb_attr))\n",
    "    # img_feature_map = np.repeat(img_feature_map, [cand_feature_map.shape[0]] * img_feature_map.shape[0], axis = 0)\n",
    "    nearest_class_id = ['ZJL'] * eval_df.shape[0]\n",
    "#     seen_class_bias = np.zeros(class_id_emb_attr.shape[0])\n",
    "#     seen_class_bias[class_id_emb_attr.class_id.isin(seen_class)] = gamma\n",
    "    \n",
    "#     seen_indice = [category_dict[c] for c in seen_class]\n",
    "#     preds = np.asarray(list(eval_df['preds']))[:, seen_indice]\n",
    "    for i in range(img_feature_map.shape[0]):\n",
    "        if False: #np.amax(preds[i]) > threshold:\n",
    "            nearest_class_id[i] = seen_class[np.argmax(preds[i])]\n",
    "        else:\n",
    "            img = img_feature_map[i]\n",
    "#             dis = 1 - sklearn.metrics.pairwise.cosine_similarity([img], \n",
    "#                                     cand_feature_map).reshape((cand_feature_map.shape[0]))\n",
    "            dis = np.linalg.norm(img - cand_feature_map, axis = 1)\n",
    "#             print (dis.shape)\n",
    "#             if np.amin(dis[class_id_emb_attr.class_id.isin(seen_class)]) > \\\n",
    "#                     gamma * np.amin(dis[~class_id_emb_attr.class_id.isin(seen_class)]):\n",
    "#                 dis[class_id_emb_attr.class_id.isin(seen_class)] = 200\n",
    "#             dis += seen_class_bias\n",
    "#             print(dis)\n",
    "#             plt.hist(dis)\n",
    "#             return\n",
    "            min_ind = np.where(dis == np.amin(dis))[0]\n",
    "            if len(min_ind) > 1:\n",
    "                print ('eval img id: ', eval_df.iloc[i]['class_id'], 'has multiple best candidates: ', len(min_ind), 'min val: ', np.amin(dis))\n",
    "    #         print (i, img, class_id_emb_attr.iloc[min_ind[0]].name)\n",
    "            nearest_class_id[i] = class_id_emb_attr.iloc[min_ind[0]]['class_id']\n",
    "#     print (nearest_class_id)\n",
    "    return np.asarray(nearest_class_id)\n",
    "        \n",
    "def calc_accuracy(eval_df, eval_class, preds):\n",
    "    eval_mask = eval_df.class_id.isin(eval_class)\n",
    "    eval_num = np.sum(eval_mask)\n",
    "    right_num = np.sum(preds[eval_mask] == eval_df.class_id[eval_mask])\n",
    "    return right_num / np.sum(eval_mask), right_num, eval_num\n",
    "    \n",
    "def calc_detailed_accuracy(eval_df, preds, seen_class, unseen_class):\n",
    "    all_re = calc_accuracy(eval_df, eval_df['class_id'].values, preds)\n",
    "    seen_re = calc_accuracy(eval_df, seen_class, preds)\n",
    "    unseen_re = calc_accuracy(eval_df, unseen_class, preds)\n",
    "    print(\"\\nAll_re: \\t%.6f\\t%.0f\\t%.0f\" % all_re)\n",
    "    print(\"Seen_re: \\t%.6f\\t%.0f\\t%.0f\" % seen_re)\n",
    "    print(\"Unseen_re: \\t%.6f\\t%.0f\\t%.0f\" % unseen_re)\n",
    "\n",
    "def model_eval(model, model_type, eval_df, cand_class_id_emb_attr, img_feature_map, seen_class = None, unseen_class = None):\n",
    "    if model_type == 'DEM':\n",
    "        zs_model = Model(inputs = model.inputs[:2], outputs = model.outputs[0])\n",
    "        cand_feature_map = zs_model.predict(create_dnn_data(cand_class_id_emb_attr))\n",
    "    elif model_type == 'GCN':\n",
    "        zs_model = Model(inputs = model.inputs[2:], outputs = model.outputs[0])\n",
    "        cand_class_to_id = [class_to_id[c] for c in cand_class_id_emb_attr.class_id.values]\n",
    "        cand_feature_map = zs_model.predict(None, steps = 1)[cand_class_to_id]\n",
    "    preds = find_nearest_class(cand_class_id_emb_attr, zs_model, eval_df, cand_feature_map, \n",
    "                               img_feature_map)\n",
    "    if 'class_id' in eval_df.columns:\n",
    "        calc_detailed_accuracy(eval_df, preds, seen_class, unseen_class)\n",
    "    return preds\n",
    "\n",
    "def models_eval(models, eval_df, cand_class_id_emb_attr, img_feature_map, \n",
    "                seen_class = None, unseen_class = None):\n",
    "    preds = []\n",
    "    for model, model_type in models:\n",
    "        pred = model_eval(model, model_type, eval_df, cand_class_id_emb_attr, img_feature_map, \n",
    "                          seen_class, unseen_class)\n",
    "        preds.append(pred)\n",
    "    return preds\n",
    "        \n",
    "def multi_models_vote(models, eval_df = None, cand_class_id_emb_attr = None, img_feature_map = None, \n",
    "                      seen_class = None, unseen_class = None):\n",
    "    preds = models_eval(models, eval_df, cand_class_id_emb_attr, img_feature_map, \n",
    "                seen_class, unseen_class)\n",
    "    preds = np.asarray(preds).T\n",
    "    print (preds)\n",
    "    vote_preds = []\n",
    "    for single_img_vote in preds:\n",
    "        uniq_val, counts = np.unique(single_img_vote, return_counts = True)\n",
    "        vote_preds.append(uniq_val[np.argmax(counts)])\n",
    "    vote_preds = np.asarray(vote_preds)\n",
    "    print (vote_preds)\n",
    "    if 'class_id' in eval_df.columns: \n",
    "        calc_detailed_accuracy(eval_df, vote_preds, seen_class, unseen_class)\n",
    "    return vote_preds\n",
    "    \n",
    "class AccuracyEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_interval = 1000000, verbose = 2, \\\n",
    "            scores = [], class_id_emb_attr = None, eval_df = None, threshold = None, \\\n",
    "                 seen_class = None, unseen_class = None, gamma = None, model_type = None):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        # print(\"y_val shape:{0}\".format(self.y_val.shape))\n",
    "        self.batch_interval = batch_interval\n",
    "        self.verbose = verbose\n",
    "        self.scores = scores\n",
    "        self.class_id_emb_attr = class_id_emb_attr\n",
    "        self.eval_df = eval_df\n",
    "        self.threshold = threshold\n",
    "        self.seen_class = seen_class\n",
    "        self.unseen_class = unseen_class\n",
    "        self.gamma = gamma\n",
    "        self.model_type = model_type\n",
    "#         seen_indice = [category_dict[c] for c in seen_class]\n",
    "#         self.preds = np.asarray(list(eval_df['preds']))[:, seen_indice]\n",
    "#         self.img_feature_map = self.y_val\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            model_eval(self.model, self.model_type, self.eval_df, self.class_id_emb_attr, \n",
    "                seen_class = self.seen_class, unseen_class = self.unseen_class, img_feature_map = self.y_val)\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "        if(self.verbose >= 2) and (batch % self.batch_interval == 0):\n",
    "            # y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            # loss = metrics.log_loss(self.y_val, y_pred)\n",
    "            print(\"Hi! on_batch_end() , batch=\",batch,\",logs:\",logs)\n",
    "            # print(\"Valide size=\",y_pred.shape[0], \"  Valide loss=\",loss)\n",
    "\n",
    "def full_connect_layer(input, hidden_dim, activation, resnet = False, adj_graphs = None, \n",
    "                       drop_out_ratio = None, kernel_initializer = 'he_normal'):\n",
    "    full_connect = input\n",
    "    for i, hn in enumerate(hidden_dim):\n",
    "        fc_in = full_connect\n",
    "        if drop_out_ratio is not None:\n",
    "            full_connect = Dropout(drop_out_ratio)(full_connect)\n",
    "        full_connect = BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "        # full_connect = Dense(hn, kernel_regularizer = l2(0.001), activity_regularizer = l1(0.001))(full_connect)\n",
    "#         full_connect = Concatenate()([Dense(hn, kernel_initializer='lecun_uniform', activation = 'relu')(full_connect), \n",
    "#             Dense(hn, kernel_initializer='lecun_uniform', activation = 'sigmoid')(full_connect)])\n",
    "        full_connect = Dense(hn, kernel_initializer=kernel_initializer, kernel_regularizer = l2(1e-4), activation = activation)(full_connect)\n",
    "#         full_connect = LeakyReLU(alpha=0.02)(full_connect)\n",
    "        # full_connect = self.act_blend(full_connect)\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#             full_connect = Dropout(self.full_connect_dropout)(full_connect) #Dropout(self.full_connect_dropout)(full_connect)\n",
    "        if adj_graphs is not None:\n",
    "            full_connect = Lambda(lambda x: K.dot(x[1], x[0]), \\\n",
    "                                  name = 'rela_' + str(i))([full_connect, adj_graphs])\n",
    "        if resnet:\n",
    "            full_connect = Concatenate()([fc_in, full_connect])\n",
    "    return full_connect\n",
    "\n",
    "def extract_array_from_series(s):\n",
    "    return np.asarray(list(s))\n",
    "\n",
    "def create_dnn_data(df):\n",
    "    # return [extract_array_from_series(df['attr']), extract_array_from_series(df['emb'])[:, :]]\n",
    "    return [extract_array_from_series(df['attr']), extract_array_from_series(df['emb'])[:, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD...\n"
     ]
    }
   ],
   "source": [
    "print ('SVD...')\n",
    "svd = decomposition.TruncatedSVD(n_components=10, n_iter=50, random_state=12)\n",
    "svd_features = svd.fit_transform(extract_array_from_series(class_id_emb_attr['attr']))\n",
    "class_id_emb_attr['svd_attr'] = list(svd_features)\n",
    "train_data = train_data.merge(class_id_emb_attr[['class_id', 'svd_attr']], how = 'left', on = 'class_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87249, 10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen unseen Classes:  164 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_140\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_140\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attr (InputLayer)               (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wv (InputLayer)                 (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 300)          9000        attr[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 900)          0           wv[0][0]                         \n",
      "                                                                 dense_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 900)          0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 900)          3600        dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_139 (Dense)               (None, 1536)         1383936     batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 1536)         6144        dense_139[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 1024)         1573888     batch_normalization_92[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 2,976,568\n",
      "Trainable params: 2,971,696\n",
      "Non-trainable params: 4,872\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 70408 samples, validate on 16841 samples\n",
      "Epoch 1/50\n",
      "70408/70408 [==============================] - 104s 1ms/step - loss: 0.5655 - val_loss: 0.4114\n",
      "\n",
      "All_re: \t0.199216\t3355\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.199216\t3355\t16841\n",
      "Epoch 2/50\n",
      "  128/70408 [..............................] - ETA: 1:08 - loss: 0.3791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70408/70408 [==============================] - 31s 436us/step - loss: 0.3235 - val_loss: 0.3294\n",
      "\n",
      "All_re: \t0.219999\t3705\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.219999\t3705\t16841\n",
      "Epoch 3/50\n",
      "70408/70408 [==============================] - 28s 394us/step - loss: 0.2883 - val_loss: 0.3257\n",
      "\n",
      "All_re: \t0.207945\t3502\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.207945\t3502\t16841\n",
      "Epoch 4/50\n",
      "70408/70408 [==============================] - 29s 418us/step - loss: 0.2808 - val_loss: 0.3216\n",
      "\n",
      "All_re: \t0.222315\t3744\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.222315\t3744\t16841\n",
      "Epoch 5/50\n",
      "70408/70408 [==============================] - 28s 402us/step - loss: 0.2787 - val_loss: 0.3213\n",
      "\n",
      "All_re: \t0.235972\t3974\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.235972\t3974\t16841\n",
      "Epoch 6/50\n",
      "70408/70408 [==============================] - 32s 449us/step - loss: 0.2776 - val_loss: 0.3168\n",
      "\n",
      "All_re: \t0.238525\t4017\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.238525\t4017\t16841\n",
      "Epoch 7/50\n",
      "70408/70408 [==============================] - 28s 399us/step - loss: 0.2766 - val_loss: 0.3047\n",
      "\n",
      "All_re: \t0.234547\t3950\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.234547\t3950\t16841\n",
      "Epoch 8/50\n",
      "70408/70408 [==============================] - 30s 432us/step - loss: 0.2744 - val_loss: 0.3047\n",
      "\n",
      "All_re: \t0.231993\t3907\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.231993\t3907\t16841\n",
      "Epoch 9/50\n",
      "70408/70408 [==============================] - 28s 396us/step - loss: 0.2723 - val_loss: 0.3039\n",
      "\n",
      "All_re: \t0.211626\t3564\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.211626\t3564\t16841\n",
      "Epoch 10/50\n",
      "70408/70408 [==============================] - 32s 451us/step - loss: 0.2705 - val_loss: 0.3030\n",
      "\n",
      "All_re: \t0.229321\t3862\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.229321\t3862\t16841\n",
      "Epoch 11/50\n",
      "70408/70408 [==============================] - 28s 402us/step - loss: 0.2700 - val_loss: 0.3027\n",
      "\n",
      "All_re: \t0.223621\t3766\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.223621\t3766\t16841\n",
      "Epoch 12/50\n",
      "70408/70408 [==============================] - 30s 420us/step - loss: 0.2694 - val_loss: 0.3019\n",
      "\n",
      "All_re: \t0.212695\t3582\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.212695\t3582\t16841\n",
      "Epoch 13/50\n",
      "70408/70408 [==============================] - 28s 394us/step - loss: 0.2692 - val_loss: 0.3031\n",
      "\n",
      "All_re: \t0.211033\t3554\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.211033\t3554\t16841\n",
      "Seen unseen Classes:  164 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_144\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_144\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 71411 samples, validate on 15838 samples\n",
      "Epoch 1/50\n",
      "71411/71411 [==============================] - 106s 1ms/step - loss: 0.5631 - val_loss: 0.4024\n",
      "\n",
      "All_re: \t0.194090\t3074\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.194090\t3074\t15838\n",
      "Epoch 2/50\n",
      "71411/71411 [==============================] - 28s 398us/step - loss: 0.3217 - val_loss: 0.3223\n",
      "\n",
      "All_re: \t0.224081\t3549\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.224081\t3549\t15838\n",
      "Epoch 3/50\n",
      "71411/71411 [==============================] - 29s 402us/step - loss: 0.2867 - val_loss: 0.3117\n",
      "\n",
      "All_re: \t0.208675\t3305\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.208675\t3305\t15838\n",
      "Epoch 4/50\n",
      "71411/71411 [==============================] - 29s 401us/step - loss: 0.2788 - val_loss: 0.3085\n",
      "\n",
      "All_re: \t0.203687\t3226\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.203687\t3226\t15838\n",
      "Epoch 5/50\n",
      "71411/71411 [==============================] - 28s 393us/step - loss: 0.2757 - val_loss: 0.3052\n",
      "\n",
      "All_re: \t0.207791\t3291\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.207791\t3291\t15838\n",
      "Epoch 6/50\n",
      "71411/71411 [==============================] - 28s 395us/step - loss: 0.2735 - val_loss: 0.3035\n",
      "\n",
      "All_re: \t0.218146\t3455\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.218146\t3455\t15838\n",
      "Epoch 7/50\n",
      "71411/71411 [==============================] - 28s 396us/step - loss: 0.2720 - val_loss: 0.3026\n",
      "\n",
      "All_re: \t0.229385\t3633\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.229385\t3633\t15838\n",
      "Epoch 8/50\n",
      "71411/71411 [==============================] - 29s 400us/step - loss: 0.2711 - val_loss: 0.3006\n",
      "\n",
      "All_re: \t0.231216\t3662\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.231216\t3662\t15838\n",
      "Epoch 9/50\n",
      "71411/71411 [==============================] - 28s 396us/step - loss: 0.2706 - val_loss: 0.3014\n",
      "\n",
      "All_re: \t0.245107\t3882\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.245107\t3882\t15838\n",
      "Seen unseen Classes:  164 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_148\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_148\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69141 samples, validate on 18108 samples\n",
      "Epoch 1/50\n",
      "69141/69141 [==============================] - 107s 2ms/step - loss: 0.5679 - val_loss: 0.4168\n",
      "\n",
      "All_re: \t0.197095\t3569\t18108\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.197095\t3569\t18108\n",
      "Epoch 2/50\n",
      "69141/69141 [==============================] - 30s 439us/step - loss: 0.3233 - val_loss: 0.3322\n",
      "\n",
      "All_re: \t0.204385\t3701\t18108\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.204385\t3701\t18108\n",
      "Epoch 3/50\n",
      "69141/69141 [==============================] - 30s 438us/step - loss: 0.2866 - val_loss: 0.3208\n",
      "\n",
      "All_re: \t0.193837\t3510\t18108\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.193837\t3510\t18108\n",
      "Epoch 4/50\n",
      "69141/69141 [==============================] - 30s 436us/step - loss: 0.2784 - val_loss: 0.3116\n",
      "\n",
      "All_re: \t0.206980\t3748\t18108\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.206980\t3748\t18108\n",
      "Epoch 5/50\n",
      "69141/69141 [==============================] - 30s 433us/step - loss: 0.2749 - val_loss: 0.3123\n",
      "\n",
      "All_re: \t0.200961\t3639\t18108\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.200961\t3639\t18108\n",
      "Seen unseen Classes:  164 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_152\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_152\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69739 samples, validate on 17510 samples\n",
      "Epoch 1/50\n",
      "69739/69739 [==============================] - 108s 2ms/step - loss: 0.5657 - val_loss: 0.4218\n",
      "\n",
      "All_re: \t0.141005\t2469\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.141005\t2469\t17510\n",
      "Epoch 2/50\n",
      "69739/69739 [==============================] - 30s 434us/step - loss: 0.3225 - val_loss: 0.3367\n",
      "\n",
      "All_re: \t0.165677\t2901\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.165677\t2901\t17510\n",
      "Epoch 3/50\n",
      "69739/69739 [==============================] - 30s 430us/step - loss: 0.2867 - val_loss: 0.3231\n",
      "\n",
      "All_re: \t0.139406\t2441\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.139406\t2441\t17510\n",
      "Epoch 4/50\n",
      "69739/69739 [==============================] - 30s 425us/step - loss: 0.2796 - val_loss: 0.3168\n",
      "\n",
      "All_re: \t0.153113\t2681\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.153113\t2681\t17510\n",
      "Epoch 5/50\n",
      "69739/69739 [==============================] - 29s 419us/step - loss: 0.2770 - val_loss: 0.3163\n",
      "\n",
      "All_re: \t0.141576\t2479\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.141576\t2479\t17510\n",
      "Epoch 6/50\n",
      "69739/69739 [==============================] - 30s 430us/step - loss: 0.2748 - val_loss: 0.3158\n",
      "\n",
      "All_re: \t0.171845\t3009\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.171845\t3009\t17510\n",
      "Epoch 7/50\n",
      "69739/69739 [==============================] - 30s 431us/step - loss: 0.2740 - val_loss: 0.3157\n",
      "\n",
      "All_re: \t0.150885\t2642\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.150885\t2642\t17510\n",
      "Epoch 8/50\n",
      "69739/69739 [==============================] - 30s 426us/step - loss: 0.2720 - val_loss: 0.3145\n",
      "\n",
      "All_re: \t0.170017\t2977\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.170017\t2977\t17510\n",
      "Epoch 9/50\n",
      "69739/69739 [==============================] - 30s 425us/step - loss: 0.2700 - val_loss: 0.3129\n",
      "\n",
      "All_re: \t0.168247\t2946\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.168247\t2946\t17510\n",
      "Epoch 10/50\n",
      "69739/69739 [==============================] - 30s 433us/step - loss: 0.2690 - val_loss: 0.3129\n",
      "\n",
      "All_re: \t0.159794\t2798\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.159794\t2798\t17510\n",
      "Seen unseen Classes:  164 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_156\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_156\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68297 samples, validate on 18952 samples\n",
      "Epoch 1/50\n",
      "68297/68297 [==============================] - 97s 1ms/step - loss: 0.5718 - val_loss: 0.4250\n",
      "\n",
      "All_re: \t0.190903\t3618\t18952\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.190903\t3618\t18952\n",
      "Epoch 2/50\n",
      "68297/68297 [==============================] - 30s 441us/step - loss: 0.3240 - val_loss: 0.3366\n",
      "\n",
      "All_re: \t0.209529\t3971\t18952\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.209529\t3971\t18952\n",
      "Epoch 3/50\n",
      "68297/68297 [==============================] - 30s 433us/step - loss: 0.2860 - val_loss: 0.3216\n",
      "\n",
      "All_re: \t0.201192\t3813\t18952\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.201192\t3813\t18952\n",
      "Epoch 4/50\n",
      "68297/68297 [==============================] - 29s 432us/step - loss: 0.2777 - val_loss: 0.3179\n",
      "\n",
      "All_re: \t0.212854\t4034\t18952\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.212854\t4034\t18952\n",
      "Epoch 5/50\n",
      "68297/68297 [==============================] - 29s 430us/step - loss: 0.2744 - val_loss: 0.3180\n",
      "\n",
      "All_re: \t0.206205\t3908\t18952\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.206205\t3908\t18952\n"
     ]
    }
   ],
   "source": [
    "def create_dnn(kernel_initializer = 'he_normal', img_flat_len = 1024):\n",
    "    alpha = 0.03\n",
    "    img_flat_len = img_flat_len\n",
    "    attr_input = Input(shape = (30,), name = 'attr')\n",
    "    word_emb = Input(shape = (600,), name = 'wv')\n",
    "    imag_classifier = Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "    attr_dense = Dense(300, use_bias = False, kernel_initializer=kernel_initializer, \n",
    "                       kernel_regularizer = l2(1e-4))(attr_input)\n",
    "#     attr_dense = Dense(512)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(256)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(300, activation=\"relu\")(attr_dense)\n",
    "    # attr_dense = Dense(512, activation=\"relu\")(attr_dense)\n",
    "    word_emb_dense = Dense(300, use_bias = False, kernel_initializer=kernel_initializer, \n",
    "                           kernel_regularizer = l2(1e-4))(word_emb)\n",
    "\n",
    "    attr_word_emb = Concatenate()([word_emb, attr_dense])\n",
    "#     attr_word_emb = word_emb #Add()([word_emb_dense, attr_dense])\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb, hidden_dim = [int(img_flat_len * 1.5), \n",
    "#                                                                           int(img_flat_len * 1.25), \n",
    "#                                                                           int(img_flat_len * 1.125),\n",
    "#                                                                           int(img_flat_len * 0.5)\n",
    "                                                                         ], \\\n",
    "                                             activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "                                             activation = 'relu')\n",
    "\n",
    "    mse_loss = K.mean(keras.losses.mean_squared_error(imag_classifier, attr_word_emb_dense))\n",
    "    \n",
    "    model = Model([attr_input, word_emb, imag_classifier], outputs = attr_word_emb_dense) #, vgg_output])\n",
    "    model.add_loss(mse_loss)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=5e-4), loss=None)\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 100)\n",
    "num_fold = 0\n",
    "zs_model_list = []\n",
    "classes = train_data.class_id.unique()\n",
    "\n",
    "for train_index, test_index in kf.split(classes):\n",
    "    seen_class = classes[train_index]\n",
    "    unseen_class = classes[test_index]\n",
    "    \n",
    "    train_part_df = train_data[train_data.class_id.isin(seen_class)]\n",
    "    validate_part_df = train_data[train_data.class_id.isin(unseen_class)]\n",
    "    \n",
    "    train_part_data = create_dnn_data(train_part_df)\n",
    "    validate_part_data = create_dnn_data(validate_part_df)\n",
    "    \n",
    "    train_part_target = extract_array_from_series(train_part_df['target']) #sklearn.preprocessing.normalize(extract_array_from_series(train_part_df['target']), norm='l2')\n",
    "    validate_part_target = extract_array_from_series(validate_part_df['target']) #sklearn.preprocessing.normalize(extract_array_from_series(validate_part_df['target']), norm='l2')\n",
    "\n",
    "#     print ('Train Validation Classes: ', train_part_df.class_id.unique().shape[0], \n",
    "#            validate_part_df.class_id.unique().shape[0])\n",
    "    print ('Seen unseen Classes: ', seen_class.shape[0], unseen_class.shape[0])\n",
    "\n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=1, verbose=0),\n",
    "            AccuracyEvaluation(validation_data=(validate_part_data,  validate_part_target), interval=1, \\\n",
    "    #                         class_id_emb_attr = class_id_emb_attr, \\\n",
    "                               eval_df = validate_part_df, threshold= 0.3, \\\n",
    "                              seen_class = seen_class, unseen_class = unseen_class, \\\n",
    "                class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \\\n",
    "                              gamma = 0.8, model_type = 'DEM')\n",
    "            ]\n",
    "#     for i in range(5):\n",
    "    zs_model = create_dnn(kernel_initializer = 'he_normal', img_flat_len = 1024)\n",
    "    if num_fold == 0:\n",
    "        print (zs_model.summary())\n",
    "    zs_model.fit(train_part_data + [train_part_target],  validation_data = (validate_part_data + [validate_part_target], None),\n",
    "                  epochs=50, batch_size = 128, shuffle=True, verbose = 1, callbacks=callbacks)\n",
    "    zs_model_list.append((zs_model, 'DEM'))\n",
    "    num_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(zs_model_list):\n",
    "    model_name = path + '/model_sub/zs_model_' + str(i) + \"_05011.txt\"\n",
    "    zs_model_list[i][0].save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All_re: \t0.213811\t3570\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.213811\t3570\t16697\n",
      "\n",
      "All_re: \t0.227226\t3794\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.227226\t3794\t16697\n",
      "\n",
      "All_re: \t0.235911\t3939\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.235911\t3939\t16697\n",
      "\n",
      "All_re: \t0.216566\t3616\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.216566\t3616\t16697\n",
      "\n",
      "All_re: \t0.070492\t1177\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.070492\t1177\t16697\n",
      "[['ZJL200' 'ZJL200' 'ZJL200' 'ZJL19' 'ZJL101']\n",
      " ['ZJL4' 'ZJL100' 'ZJL41' 'ZJL4' 'ZJL101']\n",
      " ['ZJL192' 'ZJL192' 'ZJL192' 'ZJL192' 'ZJL101']\n",
      " ...\n",
      " ['ZJL261' 'ZJL102' 'ZJL254' 'ZJL254' 'ZJL261']\n",
      " ['ZJL254' 'ZJL254' 'ZJL261' 'ZJL254' 'ZJL137']\n",
      " ['ZJL261' 'ZJL261' 'ZJL261' 'ZJL254' 'ZJL261']]\n",
      "['ZJL200' 'ZJL4' 'ZJL192' ... 'ZJL254' 'ZJL254' 'ZJL261']\n",
      "\n",
      "All_re: \t0.234533\t3916\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.234533\t3916\t16697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ZJL200', 'ZJL4', 'ZJL192', ..., 'ZJL254', 'ZJL254', 'ZJL261'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_models_vote(models = zs_model_list, eval_df = validate_part_df, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \\\n",
    "            img_feature_map = validate_part_target, seen_class = seen_class, unseen_class = unseen_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 5, 9],\n",
       "       [8, 7, 7],\n",
       "       [1, 1, 7],\n",
       "       [7, 1, 9]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(1, 10, (4, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 7 8 9] [3 1 4 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_val, counts = np.unique(x, return_counts = True)\n",
    "print (uniq_val, counts)\n",
    "# uniq_val[np.argmax(counts)]\n",
    "np.argmin(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = np.array(list(class_id_emb_attr['attr']))\n",
    "# adj_graph = scipy.eye(attr.shape[0]) #1 - sklearn.metrics.pairwise.pairwise_distances(attr, metric = 'cosine')\n",
    "adj_graph = 1 - sklearn.metrics.pairwise.pairwise_distances(\n",
    "    np.array(list(class_id_emb_attr['emb'])), metric = 'cosine')\n",
    "# th = 0.99999\n",
    "# adj_graph[adj_graph > th] = 1\n",
    "# adj_graph[adj_graph <= th] = 0\n",
    "# adj_graph = adj_graph / np.linalg.norm(adj_graph)\n",
    "# adj_graph = adj_graph[:, np.argsort(adj_graph)[:]]\n",
    "# adj_graph[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = class_id_emb_attr.class_id.values\n",
    "class_to_id = dict([(c, i) for i, c in enumerate(class_ids)])\n",
    "# class_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen unseen Classes:  164 41\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_32 (InputLayer)            (285, 30)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_33 (InputLayer)            (285, 300)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_84 (Dense)                 (285, 300)            9000        input_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)     (285, 600)            0           input_33[0][0]                   \n",
      "                                                                   dense_84[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (285, 600)            2400        concatenate_15[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_85 (Dense)                 (285, 1548)           930348      batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "input_34 (InputLayer)            (285, 285)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "rela_0 (Lambda)                  (285, 1548)           0           dense_85[0][0]                   \n",
      "                                                                   input_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (285, 1548)           6192        rela_0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_86 (Dense)                 (285, 1290)           1998210     batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "rela_1 (Lambda)                  (285, 1290)           0           dense_86[0][0]                   \n",
      "                                                                   input_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (285, 1290)           5160        rela_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_87 (Dense)                 (285, 1032)           1332312     batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "rela_2 (Lambda)                  (285, 1032)           0           dense_87[0][0]                   \n",
      "                                                                   input_34[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 4,283,622\n",
      "Trainable params: 4,276,746\n",
      "Non-trainable params: 6,876\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:32: UserWarning: Output \"rela_2\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"rela_2\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69913 samples, validate on 17336 samples\n",
      "Epoch 1/25\n",
      "69792/69913 [============================>.] - ETA: 0s - loss: 1.7330eval img id:  ZJL263 has multiple best candidates:  2 min val:  18.49614\n",
      "\n",
      "All_re: \t0.038417\t666\t17336\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.038417\t666\t17336\n",
      "69913/69913 [==============================] - 33s - loss: 1.7317 - val_loss: 1.0597\n",
      "Epoch 2/25\n",
      "  416/69913 [..............................] - ETA: 29s - loss: 0.9983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69856/69913 [============================>.] - ETA: 0s - loss: 0.9736\n",
      "All_re: \t0.068066\t1180\t17336\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.068066\t1180\t17336\n",
      "69913/69913 [==============================] - 32s - loss: 0.9736 - val_loss: 1.0059\n",
      "Epoch 3/25\n",
      "69792/69913 [============================>.] - ETA: 0s - loss: 0.8904\n",
      "All_re: \t0.082603\t1432\t17336\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.082603\t1432\t17336\n",
      "69913/69913 [==============================] - 32s - loss: 0.8903 - val_loss: 0.9059\n",
      "Epoch 4/25\n",
      " 9536/69913 [===>..........................] - ETA: 24s - loss: 0.8300"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4eef8651ed11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     zs_model.fit([train_part_data, train_part_target],  \n\u001b[1;32m     74\u001b[0m                  \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidate_part_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_part_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                   epochs=25, batch_size = 32, shuffle=True, verbose = 1, callbacks=callbacks)\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mzs_model_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GCN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mnum_fold\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# adj_graph = 1 - sklearn.metrics.pairwise.pairwise_distances(\n",
    "#     np.array(list(class_id_emb_attr['emb']))[:, :300], metric = 'cosine')\n",
    "\n",
    "def create_gcn():\n",
    "    alpha = 0.03\n",
    "    img_flat_len = 1032\n",
    "    attr_input = Input(tensor=tf.constant(np.array(list(class_id_emb_attr['attr']), dtype = 'float32')))\n",
    "    all_word_emb = Input(tensor=tf.constant(np.array(list(class_id_emb_attr['emb']))[:, :300], dtype = 'float32')) #Input(shape = (230, 300,), name = 'wv')\n",
    "    class_index = Input(shape = (1, ), name = 'class_index', dtype = 'int32')\n",
    "    adj_graphs = Input(tensor=tf.constant(adj_graph, dtype = 'float32')) #Input(shape = (230, 230,), name = 'adj_graph')\n",
    "    imag_classifier = Input(shape = (img_flat_len,), name = 'img')\n",
    "    \n",
    "    attr_dense = Dense(300, use_bias = False, kernel_initializer='he_normal', \n",
    "                    kernel_regularizer = l2(1e-4))(attr_input)\n",
    "    attr_word_emb = Concatenate()([all_word_emb, attr_dense])\n",
    "#     x = Lambda(lambda xx: all_word_emb)(class_index)\n",
    "#     x = Dense(516, kernel_initializer='he_normal', kernel_regularizer = l2(1e-4), \n",
    "#               activation = 'relu', name = 'conv')(all_word_emb)\n",
    "#     all_classifier = Lambda(lambda x: K.dot(x[1], x[0]), name = 'rela')([x, adj_graphs])\n",
    "    all_classifier = full_connect_layer(attr_word_emb, hidden_dim = [int(img_flat_len * 1.5), \n",
    "                                                                    int(img_flat_len * 1.25 ),\n",
    "                                                                    img_flat_len], \n",
    "                                activation = 'relu', adj_graphs = adj_graphs)\n",
    "    x = tf.gather_nd(all_classifier, class_index)\n",
    "\n",
    "    mse_loss = K.mean(keras.losses.mean_squared_error(imag_classifier, x))\n",
    "    \n",
    "    model = Model([class_index, imag_classifier, attr_input, all_word_emb, adj_graphs], outputs = [all_classifier]) #, vgg_output])\n",
    "    model.add_loss(mse_loss)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-4), loss=None)\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 1)\n",
    "num_fold = 0\n",
    "zs_model_list = []\n",
    "classes = train_data.class_id.unique()\n",
    "class_ids = class_id_emb_attr.class_id.values\n",
    "class_to_id = dict([(c, i) for i, c in enumerate(class_ids)])\n",
    "\n",
    "for train_index, test_index in kf.split(classes):\n",
    "#     print (train_index)\n",
    "    seen_class = classes[train_index]\n",
    "    unseen_class = classes[test_index]\n",
    "    \n",
    "    train_part_df = train_data[train_data.class_id.isin(seen_class)]\n",
    "    validate_part_df = train_data[train_data.class_id.isin(unseen_class)]\n",
    "    \n",
    "    train_part_data = np.array([class_to_id[c] for c in train_part_df['class_id'].values]).astype('int32')\n",
    "    validate_part_data = np.array([class_to_id[c] for c in validate_part_df['class_id'].values]).astype('int32')\n",
    "\n",
    "    train_part_target = extract_array_from_series(train_part_df['target'])\n",
    "    validate_part_target = extract_array_from_series(validate_part_df['target'])\n",
    "\n",
    "#     print ('Train Validation Classes: ', train_part_df.class_id.unique().shape[0], \n",
    "#            validate_part_df.class_id.unique().shape[0])\n",
    "    print ('Seen unseen Classes: ', seen_class.shape[0], unseen_class.shape[0])\n",
    "\n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=50, verbose=0),\n",
    "            AccuracyEvaluation(validation_data=(validate_part_data,  validate_part_target), interval=1, \\\n",
    "    #                         class_id_emb_attr = class_id_emb_attr, \\\n",
    "                               eval_df = validate_part_df, threshold= 0.3, \\\n",
    "                              seen_class = seen_class, unseen_class = unseen_class, \\\n",
    "                class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \\\n",
    "                              gamma = 0.8, model_type = 'GCN')\n",
    "            ]\n",
    "    zs_model = create_gcn()\n",
    "    if num_fold == 0:\n",
    "        print (zs_model.summary())\n",
    "    zs_model.fit([train_part_data, train_part_target],  \n",
    "                 validation_data = ([validate_part_data, validate_part_target], None),\n",
    "                  epochs=25, batch_size = 32, shuffle=True, verbose = 1, callbacks=callbacks)\n",
    "    zs_model_list.append((zs_model, 'GCN'))\n",
    "    num_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All_re: \t0.156834\t2140\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.156834\t2140\t13645\n",
      "\n",
      "All_re: \t0.155148\t2117\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.155148\t2117\t13645\n",
      "\n",
      "All_re: \t0.151118\t2062\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.151118\t2062\t13645\n",
      "\n",
      "All_re: \t0.153316\t2092\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.153316\t2092\t13645\n",
      "\n",
      "All_re: \t0.157640\t2151\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.157640\t2151\t13645\n",
      "[['ZJL264' 'ZJL264' 'ZJL264' 'ZJL264' 'ZJL264']\n",
      " ['ZJL102' 'ZJL102' 'ZJL102' 'ZJL102' 'ZJL102']\n",
      " ['ZJL254' 'ZJL276' 'ZJL254' 'ZJL254' 'ZJL254']\n",
      " ...\n",
      " ['ZJL254' 'ZJL254' 'ZJL276' 'ZJL254' 'ZJL254']\n",
      " ['ZJL276' 'ZJL276' 'ZJL276' 'ZJL276' 'ZJL254']\n",
      " ['ZJL168' 'ZJL125' 'ZJL50' 'ZJL168' 'ZJL254']]\n",
      "['ZJL264' 'ZJL102' 'ZJL254' ... 'ZJL254' 'ZJL276' 'ZJL168']\n",
      "\n",
      "All_re: \t0.166215\t2268\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.166215\t2268\t13645\n"
     ]
    }
   ],
   "source": [
    "multi_models_vote(models = zs_model_list, eval_df = validate_part_df, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \\\n",
    "            img_feature_map = validate_part_target, seen_class = seen_class, unseen_class = unseen_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'model_sub/train_data_2018_09_23_10_32_21.pickle', 'rb') as handle:\n",
    "    test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>img_id</th>\n",
       "      <th>img</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>[[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...</td>\n",
       "      <td>[2.2266192, 0.16327204, 0.2838421, 0.2219766, ...</td>\n",
       "      <td>[0.9520665, 4.647786e-09, 7.417136e-08, 3.9506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</td>\n",
       "      <td>[[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...</td>\n",
       "      <td>[0.17702743, 0.55263615, 0.0, 0.030876435, 1.2...</td>\n",
       "      <td>[1.30949e-05, 5.735788e-10, 6.5571693e-12, 5.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</td>\n",
       "      <td>[[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....</td>\n",
       "      <td>[0.0, 0.42584094, 0.0, 0.034428038, 0.527664, ...</td>\n",
       "      <td>[0.9993531, 4.2289447e-09, 1.2198088e-07, 3.68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>7d93ef45972154aae150b4f9980a79c0.jpeg</td>\n",
       "      <td>[[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....</td>\n",
       "      <td>[0.6332717, 0.23473893, 0.0, 0.779357, 1.38354...</td>\n",
       "      <td>[0.9999671, 4.578459e-10, 6.6002594e-12, 8.168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</td>\n",
       "      <td>[[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...</td>\n",
       "      <td>[0.37087774, 1.1033719, 0.0, 0.23497638, 3.003...</td>\n",
       "      <td>[0.86532485, 3.0740804e-08, 3.727919e-08, 1.21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_id                                 img_id  \\\n",
       "0     ZJL1  a6394b0f513290f4651cc46792e5ac86.jpeg   \n",
       "1     ZJL1  2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg   \n",
       "2     ZJL1  eda9f3bef2bd8da038f6acbc8355fc25.jpeg   \n",
       "3     ZJL1  7d93ef45972154aae150b4f9980a79c0.jpeg   \n",
       "4     ZJL1  fb901b4f9a8e396c1d0155bccc5e5671.jpeg   \n",
       "\n",
       "                                                 img  \\\n",
       "0  [[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...   \n",
       "1  [[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...   \n",
       "2  [[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....   \n",
       "3  [[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....   \n",
       "4  [[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...   \n",
       "\n",
       "                                              target  \\\n",
       "0  [2.2266192, 0.16327204, 0.2838421, 0.2219766, ...   \n",
       "1  [0.17702743, 0.55263615, 0.0, 0.030876435, 1.2...   \n",
       "2  [0.0, 0.42584094, 0.0, 0.034428038, 0.527664, ...   \n",
       "3  [0.6332717, 0.23473893, 0.0, 0.779357, 1.38354...   \n",
       "4  [0.37087774, 1.1033719, 0.0, 0.23497638, 3.003...   \n",
       "\n",
       "                                               preds  \n",
       "0  [0.9520665, 4.647786e-09, 7.417136e-08, 3.9506...  \n",
       "1  [1.30949e-05, 5.735788e-10, 6.5571693e-12, 5.9...  \n",
       "2  [0.9993531, 4.2289447e-09, 1.2198088e-07, 3.68...  \n",
       "3  [0.9999671, 4.578459e-10, 6.6002594e-12, 8.168...  \n",
       "4  [0.86532485, 3.0740804e-08, 3.727919e-08, 1.21...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path + '/DatasetA_test_20180813/DatasetA_test/image.txt', header = None, names = ['img_id'])\n",
    "imag_path = path + '/DatasetA_test_20180813/DatasetA_test/test/'\n",
    "test_data['img'] = test_data['img_id'].apply(lambda id: read_image(imag_path, id))\n",
    "# with open(path + 'test_data.pickle', 'rb') as handle:\n",
    "#     test_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.12423625, 0.1190791, 0.7566846]\n",
       "1       [1.7260123e-13, 2.1865514e-08, 1.0]\n",
       "2       [0.2117803, 0.17989996, 0.60831976]\n",
       "3        [0.2420589, 0.17926142, 0.5786797]\n",
       "4    [0.041276723, 0.95284086, 0.005882429]\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(path + 'test_data.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(test_data, handle)\n",
    "# test_data.head()\n",
    "with open(path + '/model_sub/stacking_train_label_2018_09_12_12_10_06.pickle', 'rb') as handle:\n",
    "    stacking_train_data = pickle.load(handle)\n",
    "stacking_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_17 (InputLayer)            (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D) (None, 70, 70, 3)     0           input_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)              (None, 68, 68, 64)    1728        zero_padding2d_3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)    (None, 68, 68, 64)    256         conv1/conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1/relu (Activation)          (None, 68, 68, 64)    0           conv1/bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D) (None, 70, 70, 64)    0           conv1/relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool1 (AveragePooling2D)         (None, 34, 34, 64)    0           zero_padding2d_4[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormaliz (None, 34, 34, 64)    256         pool1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation) (None, 34, 34, 64)    0           conv2_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)     (None, 34, 34, 64)    4096        conv2_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenate (None, 34, 34, 80)    0           pool1[0][0]                      \n",
      "                                                                   conv2_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormaliz (None, 34, 34, 80)    320         conv2_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation) (None, 34, 34, 80)    0           conv2_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)     (None, 34, 34, 64)    5120        conv2_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenate (None, 34, 34, 96)    0           conv2_block1_concat[0][0]        \n",
      "                                                                   conv2_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormaliz (None, 34, 34, 96)    384         conv2_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation) (None, 34, 34, 96)    0           conv2_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)     (None, 34, 34, 64)    6144        conv2_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenate (None, 34, 34, 112)   0           conv2_block2_concat[0][0]        \n",
      "                                                                   conv2_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormaliz (None, 34, 34, 112)   448         conv2_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation) (None, 34, 34, 112)   0           conv2_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)     (None, 34, 34, 64)    7168        conv2_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenate (None, 34, 34, 128)   0           conv2_block3_concat[0][0]        \n",
      "                                                                   conv2_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormaliz (None, 34, 34, 128)   512         conv2_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation) (None, 34, 34, 128)   0           conv2_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)     (None, 34, 34, 64)    8192        conv2_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenate (None, 34, 34, 144)   0           conv2_block4_concat[0][0]        \n",
      "                                                                   conv2_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormaliz (None, 34, 34, 144)   576         conv2_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation) (None, 34, 34, 144)   0           conv2_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)     (None, 34, 34, 64)    9216        conv2_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenate (None, 34, 34, 160)   0           conv2_block5_concat[0][0]        \n",
      "                                                                   conv2_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)    (None, 34, 34, 160)   640         conv2_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "pool2_relu (Activation)          (None, 34, 34, 160)   0           pool2_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)              (None, 34, 34, 80)    12800       pool2_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)    (None, 17, 17, 80)    0           pool2_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormaliz (None, 17, 17, 80)    320         pool2_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation) (None, 17, 17, 80)    0           conv3_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)     (None, 17, 17, 64)    5120        conv3_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenate (None, 17, 17, 96)    0           pool2_pool[0][0]                 \n",
      "                                                                   conv3_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormaliz (None, 17, 17, 96)    384         conv3_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation) (None, 17, 17, 96)    0           conv3_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)     (None, 17, 17, 64)    6144        conv3_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenate (None, 17, 17, 112)   0           conv3_block1_concat[0][0]        \n",
      "                                                                   conv3_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormaliz (None, 17, 17, 112)   448         conv3_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation) (None, 17, 17, 112)   0           conv3_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)     (None, 17, 17, 64)    7168        conv3_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenate (None, 17, 17, 128)   0           conv3_block2_concat[0][0]        \n",
      "                                                                   conv3_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation) (None, 17, 17, 128)   0           conv3_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)     (None, 17, 17, 64)    8192        conv3_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenate (None, 17, 17, 144)   0           conv3_block3_concat[0][0]        \n",
      "                                                                   conv3_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormaliz (None, 17, 17, 144)   576         conv3_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation) (None, 17, 17, 144)   0           conv3_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)     (None, 17, 17, 64)    9216        conv3_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenate (None, 17, 17, 160)   0           conv3_block4_concat[0][0]        \n",
      "                                                                   conv3_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormaliz (None, 17, 17, 160)   640         conv3_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation) (None, 17, 17, 160)   0           conv3_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)     (None, 17, 17, 64)    10240       conv3_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenate (None, 17, 17, 176)   0           conv3_block5_concat[0][0]        \n",
      "                                                                   conv3_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormaliz (None, 17, 17, 176)   704         conv3_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation) (None, 17, 17, 176)   0           conv3_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)     (None, 17, 17, 64)    11264       conv3_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenate (None, 17, 17, 192)   0           conv3_block6_concat[0][0]        \n",
      "                                                                   conv3_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormaliz (None, 17, 17, 192)   768         conv3_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation) (None, 17, 17, 192)   0           conv3_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)     (None, 17, 17, 64)    12288       conv3_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenate (None, 17, 17, 208)   0           conv3_block7_concat[0][0]        \n",
      "                                                                   conv3_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormaliz (None, 17, 17, 208)   832         conv3_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation) (None, 17, 17, 208)   0           conv3_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)     (None, 17, 17, 64)    13312       conv3_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenate (None, 17, 17, 224)   0           conv3_block8_concat[0][0]        \n",
      "                                                                   conv3_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormali (None, 17, 17, 224)   896         conv3_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activation (None, 17, 17, 224)   0           conv3_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)    (None, 17, 17, 64)    14336       conv3_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormali (None, 17, 17, 64)    256         conv3_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activation (None, 17, 17, 64)    0           conv3_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)    (None, 17, 17, 16)    9216        conv3_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatenat (None, 17, 17, 240)   0           conv3_block9_concat[0][0]        \n",
      "                                                                   conv3_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormali (None, 17, 17, 240)   960         conv3_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activation (None, 17, 17, 240)   0           conv3_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)    (None, 17, 17, 64)    15360       conv3_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormali (None, 17, 17, 64)    256         conv3_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activation (None, 17, 17, 64)    0           conv3_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)    (None, 17, 17, 16)    9216        conv3_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatenat (None, 17, 17, 256)   0           conv3_block10_concat[0][0]       \n",
      "                                                                   conv3_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormali (None, 17, 17, 256)   1024        conv3_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activation (None, 17, 17, 256)   0           conv3_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)    (None, 17, 17, 64)    16384       conv3_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormali (None, 17, 17, 64)    256         conv3_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activation (None, 17, 17, 64)    0           conv3_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)    (None, 17, 17, 16)    9216        conv3_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatenat (None, 17, 17, 272)   0           conv3_block11_concat[0][0]       \n",
      "                                                                   conv3_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)    (None, 17, 17, 272)   1088        conv3_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool3_relu (Activation)          (None, 17, 17, 272)   0           pool3_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)              (None, 17, 17, 136)   36992       pool3_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)    (None, 8, 8, 136)     0           pool3_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormaliz (None, 8, 8, 136)     544         pool3_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation) (None, 8, 8, 136)     0           conv4_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)     (None, 8, 8, 64)      8704        conv4_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenate (None, 8, 8, 152)     0           pool3_pool[0][0]                 \n",
      "                                                                   conv4_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormaliz (None, 8, 8, 152)     608         conv4_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation) (None, 8, 8, 152)     0           conv4_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)     (None, 8, 8, 64)      9728        conv4_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenate (None, 8, 8, 168)     0           conv4_block1_concat[0][0]        \n",
      "                                                                   conv4_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormaliz (None, 8, 8, 168)     672         conv4_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation) (None, 8, 8, 168)     0           conv4_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)     (None, 8, 8, 64)      10752       conv4_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenate (None, 8, 8, 184)     0           conv4_block2_concat[0][0]        \n",
      "                                                                   conv4_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormaliz (None, 8, 8, 184)     736         conv4_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation) (None, 8, 8, 184)     0           conv4_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)     (None, 8, 8, 64)      11776       conv4_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenate (None, 8, 8, 200)     0           conv4_block3_concat[0][0]        \n",
      "                                                                   conv4_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormaliz (None, 8, 8, 200)     800         conv4_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation) (None, 8, 8, 200)     0           conv4_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)     (None, 8, 8, 64)      12800       conv4_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenate (None, 8, 8, 216)     0           conv4_block4_concat[0][0]        \n",
      "                                                                   conv4_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormaliz (None, 8, 8, 216)     864         conv4_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation) (None, 8, 8, 216)     0           conv4_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)     (None, 8, 8, 64)      13824       conv4_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenate (None, 8, 8, 232)     0           conv4_block5_concat[0][0]        \n",
      "                                                                   conv4_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormaliz (None, 8, 8, 232)     928         conv4_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation) (None, 8, 8, 232)     0           conv4_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)     (None, 8, 8, 64)      14848       conv4_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenate (None, 8, 8, 248)     0           conv4_block6_concat[0][0]        \n",
      "                                                                   conv4_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormaliz (None, 8, 8, 248)     992         conv4_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation) (None, 8, 8, 248)     0           conv4_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)     (None, 8, 8, 64)      15872       conv4_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenate (None, 8, 8, 264)     0           conv4_block7_concat[0][0]        \n",
      "                                                                   conv4_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormaliz (None, 8, 8, 264)     1056        conv4_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation) (None, 8, 8, 264)     0           conv4_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)     (None, 8, 8, 64)      16896       conv4_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenate (None, 8, 8, 280)     0           conv4_block8_concat[0][0]        \n",
      "                                                                   conv4_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormali (None, 8, 8, 280)     1120        conv4_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activation (None, 8, 8, 280)     0           conv4_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)    (None, 8, 8, 64)      17920       conv4_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activation (None, 8, 8, 64)      0           conv4_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatenat (None, 8, 8, 296)     0           conv4_block9_concat[0][0]        \n",
      "                                                                   conv4_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormali (None, 8, 8, 296)     1184        conv4_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activation (None, 8, 8, 296)     0           conv4_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)    (None, 8, 8, 64)      18944       conv4_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activation (None, 8, 8, 64)      0           conv4_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatenat (None, 8, 8, 312)     0           conv4_block10_concat[0][0]       \n",
      "                                                                   conv4_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormali (None, 8, 8, 312)     1248        conv4_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activation (None, 8, 8, 312)     0           conv4_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)    (None, 8, 8, 64)      19968       conv4_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activation (None, 8, 8, 64)      0           conv4_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatenat (None, 8, 8, 328)     0           conv4_block11_concat[0][0]       \n",
      "                                                                   conv4_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormali (None, 8, 8, 328)     1312        conv4_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activation (None, 8, 8, 328)     0           conv4_block13_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)    (None, 8, 8, 64)      20992       conv4_block13_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block13_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activation (None, 8, 8, 64)      0           conv4_block13_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block13_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatenat (None, 8, 8, 344)     0           conv4_block12_concat[0][0]       \n",
      "                                                                   conv4_block13_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormali (None, 8, 8, 344)     1376        conv4_block13_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activation (None, 8, 8, 344)     0           conv4_block14_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)    (None, 8, 8, 64)      22016       conv4_block14_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block14_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activation (None, 8, 8, 64)      0           conv4_block14_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block14_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatenat (None, 8, 8, 360)     0           conv4_block13_concat[0][0]       \n",
      "                                                                   conv4_block14_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormali (None, 8, 8, 360)     1440        conv4_block14_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activation (None, 8, 8, 360)     0           conv4_block15_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)    (None, 8, 8, 64)      23040       conv4_block15_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block15_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activation (None, 8, 8, 64)      0           conv4_block15_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block15_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatenat (None, 8, 8, 376)     0           conv4_block14_concat[0][0]       \n",
      "                                                                   conv4_block15_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormali (None, 8, 8, 376)     1504        conv4_block15_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activation (None, 8, 8, 376)     0           conv4_block16_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)    (None, 8, 8, 64)      24064       conv4_block16_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block16_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activation (None, 8, 8, 64)      0           conv4_block16_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block16_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatenat (None, 8, 8, 392)     0           conv4_block15_concat[0][0]       \n",
      "                                                                   conv4_block16_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormali (None, 8, 8, 392)     1568        conv4_block16_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activation (None, 8, 8, 392)     0           conv4_block17_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)    (None, 8, 8, 64)      25088       conv4_block17_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block17_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activation (None, 8, 8, 64)      0           conv4_block17_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block17_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatenat (None, 8, 8, 408)     0           conv4_block16_concat[0][0]       \n",
      "                                                                   conv4_block17_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormali (None, 8, 8, 408)     1632        conv4_block17_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activation (None, 8, 8, 408)     0           conv4_block18_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)    (None, 8, 8, 64)      26112       conv4_block18_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block18_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activation (None, 8, 8, 64)      0           conv4_block18_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block18_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatenat (None, 8, 8, 424)     0           conv4_block17_concat[0][0]       \n",
      "                                                                   conv4_block18_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormali (None, 8, 8, 424)     1696        conv4_block18_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activation (None, 8, 8, 424)     0           conv4_block19_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)    (None, 8, 8, 64)      27136       conv4_block19_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block19_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activation (None, 8, 8, 64)      0           conv4_block19_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block19_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatenat (None, 8, 8, 440)     0           conv4_block18_concat[0][0]       \n",
      "                                                                   conv4_block19_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormali (None, 8, 8, 440)     1760        conv4_block19_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activation (None, 8, 8, 440)     0           conv4_block20_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)    (None, 8, 8, 64)      28160       conv4_block20_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block20_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activation (None, 8, 8, 64)      0           conv4_block20_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block20_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatenat (None, 8, 8, 456)     0           conv4_block19_concat[0][0]       \n",
      "                                                                   conv4_block20_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormali (None, 8, 8, 456)     1824        conv4_block20_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activation (None, 8, 8, 456)     0           conv4_block21_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)    (None, 8, 8, 64)      29184       conv4_block21_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block21_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activation (None, 8, 8, 64)      0           conv4_block21_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block21_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatenat (None, 8, 8, 472)     0           conv4_block20_concat[0][0]       \n",
      "                                                                   conv4_block21_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormali (None, 8, 8, 472)     1888        conv4_block21_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activation (None, 8, 8, 472)     0           conv4_block22_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)    (None, 8, 8, 64)      30208       conv4_block22_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block22_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activation (None, 8, 8, 64)      0           conv4_block22_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block22_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatenat (None, 8, 8, 488)     0           conv4_block21_concat[0][0]       \n",
      "                                                                   conv4_block22_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormali (None, 8, 8, 488)     1952        conv4_block22_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activation (None, 8, 8, 488)     0           conv4_block23_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)    (None, 8, 8, 64)      31232       conv4_block23_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block23_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activation (None, 8, 8, 64)      0           conv4_block23_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block23_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatenat (None, 8, 8, 504)     0           conv4_block22_concat[0][0]       \n",
      "                                                                   conv4_block23_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormali (None, 8, 8, 504)     2016        conv4_block23_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activation (None, 8, 8, 504)     0           conv4_block24_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)    (None, 8, 8, 64)      32256       conv4_block24_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block24_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activation (None, 8, 8, 64)      0           conv4_block24_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block24_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatenat (None, 8, 8, 520)     0           conv4_block23_concat[0][0]       \n",
      "                                                                   conv4_block24_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)    (None, 8, 8, 520)     2080        conv4_block24_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool4_relu (Activation)          (None, 8, 8, 520)     0           pool4_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)              (None, 8, 8, 260)     135200      pool4_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)    (None, 4, 4, 260)     0           pool4_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormaliz (None, 4, 4, 260)     1040        pool4_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation) (None, 4, 4, 260)     0           conv5_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)     (None, 4, 4, 64)      16640       conv5_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenate (None, 4, 4, 276)     0           pool4_pool[0][0]                 \n",
      "                                                                   conv5_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormaliz (None, 4, 4, 276)     1104        conv5_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation) (None, 4, 4, 276)     0           conv5_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)     (None, 4, 4, 64)      17664       conv5_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenate (None, 4, 4, 292)     0           conv5_block1_concat[0][0]        \n",
      "                                                                   conv5_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormaliz (None, 4, 4, 292)     1168        conv5_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation) (None, 4, 4, 292)     0           conv5_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)     (None, 4, 4, 64)      18688       conv5_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenate (None, 4, 4, 308)     0           conv5_block2_concat[0][0]        \n",
      "                                                                   conv5_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormaliz (None, 4, 4, 308)     1232        conv5_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation) (None, 4, 4, 308)     0           conv5_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)     (None, 4, 4, 64)      19712       conv5_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenate (None, 4, 4, 324)     0           conv5_block3_concat[0][0]        \n",
      "                                                                   conv5_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormaliz (None, 4, 4, 324)     1296        conv5_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation) (None, 4, 4, 324)     0           conv5_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)     (None, 4, 4, 64)      20736       conv5_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenate (None, 4, 4, 340)     0           conv5_block4_concat[0][0]        \n",
      "                                                                   conv5_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormaliz (None, 4, 4, 340)     1360        conv5_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation) (None, 4, 4, 340)     0           conv5_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)     (None, 4, 4, 64)      21760       conv5_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenate (None, 4, 4, 356)     0           conv5_block5_concat[0][0]        \n",
      "                                                                   conv5_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormaliz (None, 4, 4, 356)     1424        conv5_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation) (None, 4, 4, 356)     0           conv5_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)     (None, 4, 4, 64)      22784       conv5_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenate (None, 4, 4, 372)     0           conv5_block6_concat[0][0]        \n",
      "                                                                   conv5_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormaliz (None, 4, 4, 372)     1488        conv5_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation) (None, 4, 4, 372)     0           conv5_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)     (None, 4, 4, 64)      23808       conv5_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenate (None, 4, 4, 388)     0           conv5_block7_concat[0][0]        \n",
      "                                                                   conv5_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormaliz (None, 4, 4, 388)     1552        conv5_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation) (None, 4, 4, 388)     0           conv5_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)     (None, 4, 4, 64)      24832       conv5_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenate (None, 4, 4, 404)     0           conv5_block8_concat[0][0]        \n",
      "                                                                   conv5_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormali (None, 4, 4, 404)     1616        conv5_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activation (None, 4, 4, 404)     0           conv5_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)    (None, 4, 4, 64)      25856       conv5_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activation (None, 4, 4, 64)      0           conv5_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatenat (None, 4, 4, 420)     0           conv5_block9_concat[0][0]        \n",
      "                                                                   conv5_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormali (None, 4, 4, 420)     1680        conv5_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activation (None, 4, 4, 420)     0           conv5_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)    (None, 4, 4, 64)      26880       conv5_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activation (None, 4, 4, 64)      0           conv5_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatenat (None, 4, 4, 436)     0           conv5_block10_concat[0][0]       \n",
      "                                                                   conv5_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormali (None, 4, 4, 436)     1744        conv5_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activation (None, 4, 4, 436)     0           conv5_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)    (None, 4, 4, 64)      27904       conv5_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activation (None, 4, 4, 64)      0           conv5_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatenat (None, 4, 4, 452)     0           conv5_block11_concat[0][0]       \n",
      "                                                                   conv5_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormali (None, 4, 4, 452)     1808        conv5_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activation (None, 4, 4, 452)     0           conv5_block13_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)    (None, 4, 4, 64)      28928       conv5_block13_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block13_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activation (None, 4, 4, 64)      0           conv5_block13_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block13_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatenat (None, 4, 4, 468)     0           conv5_block12_concat[0][0]       \n",
      "                                                                   conv5_block13_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormali (None, 4, 4, 468)     1872        conv5_block13_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activation (None, 4, 4, 468)     0           conv5_block14_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)    (None, 4, 4, 64)      29952       conv5_block14_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block14_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activation (None, 4, 4, 64)      0           conv5_block14_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block14_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatenat (None, 4, 4, 484)     0           conv5_block13_concat[0][0]       \n",
      "                                                                   conv5_block14_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormali (None, 4, 4, 484)     1936        conv5_block14_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activation (None, 4, 4, 484)     0           conv5_block15_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)    (None, 4, 4, 64)      30976       conv5_block15_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block15_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activation (None, 4, 4, 64)      0           conv5_block15_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block15_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatenat (None, 4, 4, 500)     0           conv5_block14_concat[0][0]       \n",
      "                                                                   conv5_block15_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormali (None, 4, 4, 500)     2000        conv5_block15_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activation (None, 4, 4, 500)     0           conv5_block16_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)    (None, 4, 4, 64)      32000       conv5_block16_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block16_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activation (None, 4, 4, 64)      0           conv5_block16_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block16_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatenat (None, 4, 4, 516)     0           conv5_block15_concat[0][0]       \n",
      "                                                                   conv5_block16_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "bn (BatchNormalization)          (None, 4, 4, 516)     2064        conv5_block16_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "relu (Activation)                (None, 4, 4, 516)     0           bn[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D (None, 516)           0           relu[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "fc (Dense)                       (None, 171)           88407       avg_pool[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1,945,831\n",
      "Trainable params: 1,902,543\n",
      "Non-trainable params: 43,288\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"av...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "img_model = DenseNet(blocks = [6, 12, 24, 16], \n",
    "                                cat_max = 171,\n",
    "                                weight_decay = 1e-4, \n",
    "                                kernel_initializer = 'glorot_normal',\n",
    "                                reduction = 0.5, \n",
    "                                init_filters = 64, \n",
    "                                growth_rate = 16).model\n",
    "img_model.load_weights(path + 'model_sub/6_12_24_16_ini64_growth16_02962/model_0_2018_09_13_08_23_48.h5')\n",
    "img_model_flat = Model(input = img_model.input, output = img_model.get_layer(name = 'avg_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = setB_test_data\n",
    "# # test_img = extract_array_from_series(test_data['img'])\n",
    "# # test_img = vgg16.preprocess_input(test_img)\n",
    "# # test_img_feature_map = img_model_flat.predict(test_img, verbose = 1)\n",
    "\n",
    "# with open(path + '/model_sub/6_12_24_16_ini64_growth32_inistride1_augdata_05010/flat_test_re_2018_09_22_19_24_38.pickle', 'rb') as handle:\n",
    "#     test_img_feature_map = pickle.load(handle)\n",
    "train_id = train_data['class_id'].unique()\n",
    "test_img_feature_map = extract_array_from_series(test_data['target'])\n",
    "# class_id_emb_attr.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_partial_model = Model(inputs = zs_model.inputs[2:], outputs = zs_model.outputs[0])\n",
    "test_class_id_emb_attr = class_id_emb_attr #[~class_id_emb_attr['class_id'].isin(train_id)]\n",
    "# pred_nearest_class_id = find_nearest_class(test_class_id_emb_attr, zs_partial_model, test_data, test_img_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_05011 = models_eval(models = zs_model_list, eval_df = test_data, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)], \\\n",
    "            img_feature_map = test_img_feature_map)\n",
    "preds_05011 = np.asarray(preds_05011).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ed5117811f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_05077\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "preds_05077.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_102\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_102\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_108\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_108\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_114\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_114\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_120\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_120\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_126\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_126\" during training.\n"
     ]
    }
   ],
   "source": [
    "with open(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/flat_test_re_2018_09_24_03_07_15.pickle', 'rb') as handle:\n",
    "    flat_test_re = pickle.load(handle)\n",
    "zs_model_05077_list = []\n",
    "for i in range(5):\n",
    "    zs_model = create_dnn(kernel_initializer = 'he_normal', img_flat_len = 1032)\n",
    "    zs_model_name = path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/zs_model_' + str(i) +'_2018_09_25_01_01_31.txt'\n",
    "    zs_model.load_weights(zs_model_name)\n",
    "    zs_model_05077_list.append((zs_model, 'DEM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-086b73470e3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds_05077\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzs_model_05077_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mcand_class_id_emb_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_id_emb_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mclass_id_emb_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mimg_feature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_test_re\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds_05011\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_05077\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "preds_05077 = models_eval(models = zs_model_05077_list, eval_df = test_data, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)], \\\n",
    "            img_feature_map = flat_test_re)\n",
    "preds_05011 = np.asarray(preds_05011).T\n",
    "preds = np.c_[preds_05011, preds_05077]\n",
    "print (preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_preds = []\n",
    "for single_img_vote in preds:\n",
    "    uniq_val, counts = np.unique(single_img_vote, return_counts = True)\n",
    "    vote_preds.append(uniq_val[np.argmax(counts)])\n",
    "vote_preds = np.asarray(vote_preds)\n",
    "print (vote_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ZJL272' 'ZJL224' 'ZJL242' 'ZJL243' 'ZJL272']\n",
      " ['ZJL243' 'ZJL288' 'ZJL239' 'ZJL243' 'ZJL239']\n",
      " ['ZJL255' 'ZJL255' 'ZJL255' 'ZJL255' 'ZJL253']\n",
      " ...\n",
      " ['ZJL286' 'ZJL259' 'ZJL249' 'ZJL259' 'ZJL287']\n",
      " ['ZJL270' 'ZJL253' 'ZJL253' 'ZJL253' 'ZJL253']\n",
      " ['ZJL270' 'ZJL288' 'ZJL288' 'ZJL288' 'ZJL253']]\n",
      "['ZJL272' 'ZJL239' 'ZJL255' ... 'ZJL259' 'ZJL253' 'ZJL288']\n"
     ]
    }
   ],
   "source": [
    "pred_nearest_class_id = multi_models_vote(models = zs_model_list, eval_df = test_data, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)], \\\n",
    "            img_feature_map = test_img_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_label = time.strftime('_%Y_%m_%d_%H_%M_%S', time.gmtime())\n",
    "sub_name = path + '/model_sub/sub' + time_label + '.txt'\n",
    "sub = pd.DataFrame(pred_nearest_class_id, index = test_data['img_id'])\n",
    "sub.to_csv(sub_name, header = False, sep = '\\t')\n",
    "# zs_model.save(path + 'zs_model' + time_label + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.444444444444445"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "152 * 200 / 3600"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
