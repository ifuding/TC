{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import glob\n",
    "import gc\n",
    "import sklearn\n",
    "from DenseNet import DenseNet\n",
    "from DEM import DEM\n",
    "from sklearn.model_selection import KFold\n",
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "from sklearn import metrics, preprocessing, pipeline, \\\n",
    "    feature_extraction, decomposition, model_selection\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator\n",
    "from tensorflow.python.keras import layers, preprocessing\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.python.keras.regularizers import l1, l2\n",
    "from tensorflow.python.keras.optimizers import SGD, RMSprop, Adam, Nadam\n",
    "from tensorflow.python.keras.losses import mean_squared_error, binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.python.keras.applications import vgg16\n",
    "\n",
    "# from keras.preprocessing import image\n",
    "# from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator\n",
    "# from keras import layers, preprocessing\n",
    "# from keras import backend as K\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.callbacks import EarlyStopping, Callback\n",
    "# from keras.regularizers import l1, l2\n",
    "# from keras.optimizers import SGD, RMSprop, Adam, Nadam\n",
    "# from keras.losses import mean_squared_error, binary_crossentropy\n",
    "# from keras.applications import vgg16\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "import numpy as np\n",
    "# np.random.seed(seed = 100)\n",
    "import json\n",
    "import scipy \n",
    "import lightgbm as lgb\n",
    "\n",
    "import gensim\n",
    "import os\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.models.wrappers.fasttext import FastText as FT_wrapper\n",
    "\n",
    "path = '../data/'\n",
    "\n",
    "def read_image(imag_path, image_id):\n",
    "    img = image.load_img(imag_path + image_id)\n",
    "    img = image.img_to_array(img)\n",
    "#     img= vgg16.preprocess_input(image.img_to_array(img))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attr_list = pd.read_csv(path + '/DatasetA_train_20180813/attribute_list.txt', index_col = 0, sep = '\\t', header = None)\n",
    "# attr_list = attr_list.apply(lambda s: s[1].replace(' ', '_'), axis = 1)\n",
    "# attributes_per_class = pd.read_csv(path + '/DatasetA_train_20180813/attributes_per_class.txt', \n",
    "#                                    index_col = 0, sep = '\\t', header = None)\n",
    "# adj_graph\n",
    "# attr = np.array(list(class_id_emb_attr['attr']))\n",
    "# adj_graph = sklearn.metrics.pairwise.pairwise_distances(attr, metric = 'l2')\n",
    "# np.argsort(adj_graph[0])\n",
    "# adj_graph\n",
    "# class_id_emb_attr['attr'].values\n",
    "with open(path + '../../zero-shot-gcn/data/imagenet_graph.pkl', 'rb') as handle:\n",
    "    imagenet_graph = pickle.load(handle)\n",
    "with open(path + '../../zero-shot-gcn/data/list/invdict_wordntext.json', 'r') as fp:\n",
    "    words = json.load(fp)\n",
    "class_names = class_id_emb_attr[class_id_emb_attr.class_id.isin(round2_class_id)]['class_name'].values\n",
    "class_name_to_id = dict([(c, i) for i, c in enumerate(class_names)])\n",
    "class_wns = [[]] * class_names.shape[0]\n",
    "class_neighbor_wns = [[]] * class_names.shape[0]\n",
    "words_array = np.asarray(words)\n",
    "for i, word in enumerate(words):\n",
    "    for w in word.split(', '):\n",
    "        if w in class_name_to_id:\n",
    "#             print (class_name_to_id[w], i)\n",
    "            if len(class_wns[class_name_to_id[w]]) == 0:\n",
    "                class_wns[class_name_to_id[w]] = []\n",
    "            class_wns[class_name_to_id[w]].append(i)\n",
    "#             print (class_wns)\n",
    "            if len(class_neighbor_wns[class_name_to_id[w]]) == 0:\n",
    "                class_neighbor_wns[class_name_to_id[w]] = []\n",
    "            class_neighbor_wns[class_name_to_id[w]].extend(imagenet_graph[i])\n",
    "#             print (word, words_array[imagenet_graph[i]])\n",
    "#             print (i, w)\n",
    "#             if w not in class_dict:\n",
    "#                 class_dict[w] = 0\n",
    "#             class_dict[w] += 1\n",
    "# print (class_wns)\n",
    "wn_to_class = dict()\n",
    "for i, wns in enumerate(class_wns):\n",
    "    for wn in wns:\n",
    "        if wn not in wn_to_class:\n",
    "            wn_to_class[wn] = []\n",
    "        wn_to_class[wn].append(i)\n",
    "        \n",
    "adj_graph = scipy.eye(class_names.shape[0])\n",
    "# for i, neighbor_wns in enumerate(class_neighbor_wns):\n",
    "#     for j, wns in enumerate(class_wns):\n",
    "#         if i == j:\n",
    "#             continue\n",
    "#         for neighbor in neighbor_wns:\n",
    "#             if neighbor in wns:\n",
    "#                 adj_graph[i, j] = 1\n",
    "#                 adj_graph[j, i] = 1\n",
    "# #                 print(class_names[i], class_names[j])\n",
    "#                 break\n",
    "\n",
    "def find_adj(root, current_wn, remain_depth):\n",
    "    if current_wn in wn_to_class:\n",
    "        for adj_class in wn_to_class[current_wn]:\n",
    "            adj_graph[root][adj_class] = 1\n",
    "            adj_graph[adj_class][root] = 1\n",
    "    if remain_depth == 0:\n",
    "        return\n",
    "    for wn in imagenet_graph[current_wn]:\n",
    "        find_adj(root, wn, remain_depth - 1)\n",
    "        \n",
    "for i, wns in enumerate(class_wns):\n",
    "    for wn in wns:\n",
    "        find_adj(i, wn, 2)\n",
    "adj_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  3.,  5.,  1.,  3.,  2.,  2.,  3., 19.,  1.,  2.,  2.,\n",
       "        2., 19.,  5., 20., 19.,  2.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,\n",
       "       22.,  3.,  1.,  1.,  2., 19.,  1.,  1.,  2.,  2.,  1.,  1.,  1.,\n",
       "        1.,  1., 22.,  2.,  1.,  1.,  2.,  1.,  1.,  1.,  3.,  1.,  2.,\n",
       "        2.,  1.,  2.,  3.,  1.,  3.,  3.,  2.,  3.,  2.,  1.,  1., 19.,\n",
       "        1.,  1.,  4.,  2.,  1.,  1.,  1.,  4.,  1.,  3.,  2.,  1.,  1.,\n",
       "        3.,  1.,  1.,  1.,  2.,  1., 19.,  1.,  1.,  3.,  1.,  1.,  1.,\n",
       "        1.,  4.,  2.,  2.,  2.,  1.,  7.,  1.,  1.,  4.,  2.,  1.,  1.,\n",
       "        1.,  4.,  2.,  1.,  1., 19.,  2.,  1.,  1.,  1.,  1., 19.,  2.,\n",
       "        2.,  2.,  2.,  1., 19.,  1.,  1.,  1.,  2.,  1.,  2.,  2., 23.,\n",
       "        1.,  2.,  1.,  1.,  2.,  2.,  1.,  2., 22.,  1.,  7.,  1.,  2.,\n",
       "        2.,  2.,  1.,  1.,  1.,  1.,  2.,  4.,  1.,  4.,  1.,  4.,  1.,\n",
       "        2.,  2.,  3., 19.,  4.,  1.,  2.,  3.,  3.,  5.,  4., 19.,  2.,\n",
       "        1.,  2.,  4.,  1., 19.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  2.,\n",
       "        2.,  2.,  1.,  1.,  3., 19.,  1.,  3., 19.,  1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_graph.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del setA_train_data, setB_train_data\n",
    "# with open(path + 'setB_class_id_emb_attr.pickle', 'rb') as handle:\n",
    "#     class_id_emb_attr = pickle.load(handle)\n",
    "# with open(path + '/setA_train_data.pickle', 'rb') as handle:\n",
    "#     setA_train_data = pickle.load(handle)\n",
    "# with open(path + '/setB_train_data.pickle', 'rb') as handle:\n",
    "#     setB_train_data = pickle.load(handle)\n",
    "# with open(path + 'setB_test_data.pickle', 'rb') as handle:\n",
    "#     test_data = pickle.load(handle)\n",
    "    \n",
    "# train_data = setA_train_data.append(setB_train_data)\n",
    "# del setA_train_data, setB_train_data\n",
    "# with open(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/flat_train_re_2018_09_24_03_07_15.pickle', 'rb') as handle:\n",
    "#     flat_train_re = pickle.load(handle)\n",
    "# train_data['target'] = list(flat_train_re)\n",
    "# with open(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/flat_test_re_2018_09_24_03_07_15.pickle', 'rb') as handle:\n",
    "#     flat_test_re = pickle.load(handle)\n",
    "# test_data['target'] = list(flat_test_re)\n",
    "# train_data.drop(columns = ['img_id'], inplace = True)\n",
    "\n",
    "# with open(path + '/model_sub/6_12_24_16_ini64_growth32_inistride1_augdata_05010/train_data_2018_09_23_10_47_03.pickle', 'rb') as handle:\n",
    "#     train_data = pickle.load(handle)\n",
    "# with open(path + '/model_sub/6_12_24_16_ini64_growth32_inistride1_augdata_05010/test_data_2018_09_23_10_47_03.pickle', 'rb') as handle:\n",
    "#     test_data = pickle.load(handle)\n",
    "    \n",
    "with open(path + 'round2_class_id_emb_attr_add_golve_crawl_42B.pkl', 'rb') as handle:\n",
    "    class_id_emb_attr = pickle.load(handle)\n",
    "    class_id_emb_attr['emb'] = class_id_emb_attr['emb_glove']\n",
    "    class_id_emb_attr.drop(columns = ['emb_glove', 'emb_fasttext', 'emb_glove_crawl', 'emb_glove_crawl_42B'], inplace = True)\n",
    "# del loaded_model\n",
    "ft_files = [\n",
    "#             path + '/skipgram_100_5Epoch/',\n",
    "#             path + '/skipgram_200_5Epoch/',\n",
    "# #             path + 'skipgram_300_5Epoch/',\n",
    "# #             path + 'skipgram_300_5Epoch_24Thread/',\n",
    "#             path + 'skipgram_100_10Epoch/',\n",
    "            path + 'skipgram_300_10Epoch/',\n",
    "# #             path + 'cbow_300_10Epoch/',\n",
    "#             path + 'skipgram_100_10Epoch_NewNorm/',\n",
    "            path + 'LatestCorpus_skipgram_100_5Epoch/',\n",
    "            path + 'skipgram_300_10Epoch_NewNorm/',\n",
    "            path + 'skipgram_100_10Epoch_NewNorm/'\n",
    "#            path + 'documents_utf8_filtered_20pageviews_rmurl_lower_norm_skipgram/ft',\n",
    "           ]\n",
    "for ft_dir in ft_files:\n",
    "    loaded_model = FT_wrapper.load(ft_dir + '/ft')\n",
    "    class_id_emb_attr['FT'] = class_id_emb_attr['class_name'].apply(lambda c: loaded_model[c]).apply(lambda s: ' '.join(str(f) for f in s))\n",
    "    ft_prefix = ft_dir.split('/')[-2]\n",
    "    class_id_emb_attr[['class_name', 'FT']].to_csv(path + 'ft_class_embs/' + ft_prefix, index = False)\n",
    "    del loaded_model\n",
    "#     class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb'], s['FT']]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + '/round1_train_img_part0.pkl', 'rb') as handle:\n",
    "    round1_train_img_part0 = pickle.load(handle)\n",
    "with open(path + '/round1_train_img_part1.pkl', 'rb') as handle:\n",
    "    round1_train_img_part1 = pickle.load(handle)\n",
    "with open(path + '/round2_train_img.pkl', 'rb') as handle:\n",
    "    round2_train_img = pickle.load(handle)\n",
    "# with open(path + '/round2B_train_img.pkl', 'rb') as handle:\n",
    "#     round2B_train_img = pickle.load(handle)\n",
    "with open(path + '/round2_test_img.pkl', 'rb') as handle:\n",
    "        test_data = pickle.load(handle)\n",
    "train_data = pd.concat([round1_train_img_part0, round1_train_img_part1, \n",
    "                        round2_train_img, \n",
    "#                         round2B_train_img\n",
    "                       ], axis = 0, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05108_TF14_DensetNetProcess/train_data_img_flat_20181015_113824.pickle', 'rb') as handle:\n",
    "    train_img_flat = pickle.load(handle)\n",
    "with open(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05108_TF14_DensetNetProcess/test_data_img_flat_20181015_113824.pickle', 'rb') as handle:\n",
    "    test_img_flat = pickle.load(handle)\n",
    "round2_class_id = ['ZJL' + str(i) for i in range(296, 501)]\n",
    "round2_train_class_id = round2_train_img.class_id.unique()\n",
    "del round1_train_img_part0, round1_train_img_part1, round2_train_img\n",
    "gc.collect()\n",
    "train_data = train_data.merge(class_id_emb_attr, how = 'left', on = 'class_id')\n",
    "train_data['target'] = list(train_img_flat)\n",
    "test_data['target'] = list(test_img_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del loaded_model\n",
    "loaded_model = FT_wrapper.load(path + '/documents_utf8_filtered_20pageviews_rmurl_1e5_5Epoch/documents_utf8_filtered_20pageviews_rmurl_1e5_5Epoch.wv')\n",
    "class_id_emb_attr['FT'] = class_id_emb_attr['class_name'].apply(lambda c: loaded_model[c])\n",
    "del loaded_model\n",
    "\n",
    "class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb'][:300], s['FT']]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_class_emb(class_emb_path):\n",
    "    class_emb = pd.read_csv(class_emb_path, index_col = 0, sep = ' ', header = None)\n",
    "    class_emb.index.name = 'class_name'\n",
    "    class_emb = class_emb.apply(lambda s: np.array([float(x) for x in s])[:300], axis = 1)\n",
    "    return class_emb\n",
    "\n",
    "glove_emb = read_class_emb(path + '/semifinal_image_phase2/class_wordembeddings.txt')\n",
    "# fasttext_emb =  read_class_emb(path + '/External/class_wordembeddings_fasttext')\n",
    "\n",
    "class_id_to_name = pd.read_csv(path + '/semifinal_image_phase2/label_list.txt', \n",
    "                            index_col = 'class_name', sep = '\\t', header = None, names = ['class_id', 'class_name'])\n",
    "\n",
    "attr_list = pd.read_csv(path + '/semifinal_image_phase2/attribute_list.txt', index_col = 0, sep = '\\t', header = None)\n",
    "\n",
    "attributes_per_class = pd.read_csv(path + '/semifinal_image_phase2/attributes_per_class.txt', \n",
    "                                index_col = 0, sep = '\\t', header = None)\n",
    "attributes_per_class.index.name = 'class_id'\n",
    "attributes_per_class = attributes_per_class.apply(lambda s: np.array([float(x) for x in s]), axis = 1)\n",
    "\n",
    "round2B_class_id_emb_attr = class_id_to_name.copy()\n",
    "round2B_class_id_emb_attr['emb'] = glove_emb\n",
    "# class_id_emb_attr['emb_fasttext'] = fasttext_emb\n",
    "# class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb_glove'], s['emb_fasttext']]), axis = 1)\n",
    "round2B_class_id_emb_attr.reset_index(inplace = True)\n",
    "round2B_class_id_emb_attr.set_index('class_id', inplace = True)\n",
    "round2B_class_id_emb_attr['attr'] = attributes_per_class\n",
    "round2B_class_id_emb_attr.reset_index(inplace = True)\n",
    "# print ('Load class_id_emb_attr Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "round2_class_id = ['ZJL' + str(i) for i in range(296, 501)]\n",
    "round2B_class_id_emb_attr = pd.concat([class_id_emb_attr[~class_id_emb_attr.class_id.isin(round2_class_id)], round2B_class_id_emb_attr])\n",
    "with open(path + 'round2B_class_id_emb_attr.pkl', 'wb') as handle:\n",
    "    pickle.dump(round2B_class_id_emb_attr, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31979"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(round2B_train_img.img_id) - set(round2_train_img.img_id))\n",
    "# round2B_train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 83/38221 [00:00<00:46, 824.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load setA_train_data ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38221/38221 [00:39<00:00, 973.13it/s]\n",
      "  0%|          | 104/49028 [00:00<00:47, 1039.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load setB_train_data ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49028/49028 [00:48<00:00, 1003.10it/s]\n",
      "100%|██████████| 31896/31896 [04:28<00:00, 118.90it/s]\n",
      "100%|██████████| 31979/31979 [01:54<00:00, 164.07it/s]\n",
      "  0%|          | 20/8024 [00:00<00:42, 190.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test_data ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8024/8024 [00:59<00:00, 135.04it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_image_data(img_id_path, imag_path, cols, debug):\n",
    "    img_data = pd.read_csv(img_id_path, sep = '\\t', header = None, names = cols)\n",
    "    if debug:\n",
    "        img_data = img_data[:2000]\n",
    "    img_data['img'] = img_data['img_id'].progress_apply(lambda id: \n",
    "                            image.img_to_array(image.load_img(imag_path + id, target_size = (72, 72, 3))))\n",
    "    return img_data\n",
    "\n",
    "print ('Load setA_train_data ----')\n",
    "setA_train_data = read_image_data(img_id_path = path + '/DatasetA/train.txt', imag_path = path + '/DatasetA/train/', \n",
    "            cols = ['img_id', 'class_id'], debug = False)\n",
    "print ('Load setB_train_data ----')\n",
    "setB_train_data = read_image_data(img_id_path = path + '/DatasetB/train.txt', imag_path = path + '/DatasetB/train/', \n",
    "            cols = ['img_id', 'class_id'], debug = False)\n",
    "                                  \n",
    "round2A_train_data = read_image_data(img_id_path = path + '/round2_DatasetA_20180927/train.txt', \n",
    "                                  imag_path = path + '/round2_DatasetA_20180927/train/', \n",
    "            cols = ['img_id', 'class_id'], debug = False)\n",
    "\n",
    "round2B_train_data = read_image_data(img_id_path = path + '/semifinal_image_phase2/train.txt', \n",
    "                                  imag_path = path + '/semifinal_image_phase2/train/', \n",
    "            cols = ['img_id', 'class_id'], debug = False)\n",
    "# print ('Load setB_train_data ----')\n",
    "# setB_train_data = read_image_data(img_id_path = path + '/DatasetB/train.txt', imag_path = path + '/DatasetB/train/', \n",
    "#             cols = ['img_id', 'class_id'], debug = FLAGS.debug)\n",
    "# train_data = setA_train_data.append(setB_train_data)\n",
    "# del setA_train_data, setB_train_data\n",
    "# train_data = train_data.merge(class_id_emb_attr, how = 'left', on = 'class_id')\n",
    "\n",
    "print ('Load test_data ----')\n",
    "test_data = read_image_data(img_id_path = path + '/semifinal_image_phase2/image.txt', \n",
    "                            imag_path = path + '/semifinal_image_phase2/test/', \n",
    "            cols = ['img_id'], debug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'pix72/round1A_train_img.pkl', 'wb') as handle:\n",
    "    pickle.dump(setA_train_data, handle)\n",
    "with open(path + 'pix72/round1B_train_img.pkl', 'wb') as handle:\n",
    "    pickle.dump(setB_train_data, handle)\n",
    "with open(path + 'pix72/round2A_train_img.pkl', 'wb') as handle:\n",
    "    pickle.dump(round2A_train_data, handle)\n",
    "with open(path + 'pix72/round2B_train_data.pkl', 'wb') as handle:\n",
    "    pickle.dump(round2B_train_data, handle)\n",
    "with open(path + 'pix72/round2B_test_data.pkl', 'wb') as handle:\n",
    "    pickle.dump(test_data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text =  pd.read_csv(path + '/External/class_wordembeddings_glove', \n",
    "                        index_col = 0, sep = ' ', header = None)\n",
    "fast_text.index.name = 'class_name'\n",
    "fast_text_df = pd.DataFrame(index = fast_text.index)\n",
    "fast_text_df['emb_glove_crawl'] = fast_text.apply(lambda s: np.array([float(x) for x in s])[:300], axis = 1)\n",
    "\n",
    "train_data = train_data.merge(fast_text_df, how = 'left', on = 'class_name')\n",
    "\n",
    "# train_data['emb'] = train_data.apply(lambda s: np.hstack([s['emb'], s['emb_glove_crawl']]), axis = 1)\n",
    "\n",
    "class_id_emb_attr = class_id_emb_attr.merge(fast_text_df, how = 'left', on = 'class_name')\n",
    "class_id_emb_attr['emb'] = class_id_emb_attr.apply(lambda s: np.hstack([s['emb'], s['emb_glove_crawl']]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'round2_class_id_emb_attr_add_golve_crawl.pkl', 'wb') as handle:\n",
    "    pickle.dump(class_id_emb_attr, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, scores = None, cat_max = None, flags = None, model_type = None):\n",
    "        self.batch_size = 128 #flags.densenet_batch_size\n",
    "        self.epochs = 200 #flags.densenet_epochs\n",
    "        self.patience = 30 #flags.densenet_patience\n",
    "        self.scores = scores\n",
    "        self.cat_max = cat_max\n",
    "        self.model_type = model_type\n",
    "        self.aug_data = True #flags.aug_data\n",
    "        self.lr = 1e-3 #flags.lr\n",
    "        self.verbose = 2 #flags.train_verbose\n",
    "        self.OneHotEncoder = sklearn.preprocessing.OneHotEncoder()\n",
    "        self.model = self.small_densenet(\n",
    "                blocks = [6, 12, 24, 16], #[int(b.strip()) for b in flags.blocks.strip().split(',')], \n",
    "                weight_decay = 1e-4, #flags.weight_decay, \n",
    "                kernel_initializer = 'he_normal', #flags.kernel_initializer,\n",
    "                init_filters = 128, #flags.init_filters,\n",
    "                reduction = 0.5, #flags.reduction,\n",
    "                growth_rate = 32, #flags.growth_rate,\n",
    "                init_stride = 1 #flags.init_stride\n",
    "                )\n",
    "\n",
    "    def dense_block(self, x, blocks, name, \n",
    "            weight_decay = 1e-4, \n",
    "            kernel_initializer = 'he_normal',\n",
    "            growth_rate = None):\n",
    "        \"\"\"A dense block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            blocks: integer, the number of building blocks.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            output tensor for the block.\n",
    "        \"\"\"\n",
    "        for i in range(blocks):\n",
    "            x = self.conv_block(x, growth_rate, name=name + '_block' + str(i + 1), \n",
    "                weight_decay = weight_decay,\n",
    "                kernel_initializer = kernel_initializer)\n",
    "        return x\n",
    "\n",
    "    def transition_block(self, x, reduction, name, weight_decay = 1e-4, kernel_initializer = 'he_normal'):\n",
    "        \"\"\"A transition block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            reduction: float, compression rate at transition layers.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            output tensor for the block.\n",
    "        \"\"\"\n",
    "        bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                    name=name + '_bn')(x)\n",
    "        x = layers.Activation('relu', name=name + '_relu')(x)\n",
    "        x = layers.Conv2D(int(K.int_shape(x)[bn_axis] * reduction), 1,\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_conv')(x)\n",
    "        x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "        return x\n",
    "\n",
    "    def conv_block(self, x, growth_rate, name, weight_decay = 1e-4, kernel_initializer = 'he_normal'):\n",
    "        \"\"\"A building block for a dense block.\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            growth_rate: float, growth rate at dense layers.\n",
    "            name: string, block label.\n",
    "        # Returns\n",
    "            Output tensor for the block.\n",
    "        \"\"\"\n",
    "        bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "        x1 = layers.BatchNormalization(axis=bn_axis,\n",
    "                                    epsilon=1.001e-5,\n",
    "                                    name=name + '_0_bn')(x)\n",
    "        x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n",
    "        x1 = layers.Conv2D(4 * growth_rate, 1,\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_1_conv')(x1)\n",
    "        x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                    name=name + '_1_bn')(x1)\n",
    "        x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n",
    "        x1 = layers.Conv2D(growth_rate, 3,\n",
    "                        padding='same',\n",
    "                        use_bias=False,\n",
    "                        kernel_initializer = kernel_initializer,\n",
    "                        kernel_regularizer = l2(weight_decay),\n",
    "                        name=name + '_2_conv')(x1)\n",
    "        x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n",
    "        return x\n",
    "\n",
    "    def small_densenet(self, img_input_shape = (64, 64, 3), \n",
    "        blocks = [6, 12, 24, 16], \n",
    "        weight_decay = 1e-4, \n",
    "        kernel_initializer = 'he_normal',\n",
    "        init_filters = None,\n",
    "        reduction = None,\n",
    "        growth_rate = None,\n",
    "        init_stride = None\n",
    "        ):\n",
    "        img_input = layers.Input(shape = (img_input_shape))\n",
    "\n",
    "        x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "        x = layers.Conv2D(init_filters, 3, strides=init_stride, use_bias=False, \n",
    "            kernel_initializer = kernel_initializer, \n",
    "            kernel_regularizer = l2(weight_decay),\n",
    "            name='conv1/conv')(x)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=3, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "        x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "        x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "        x = layers.AveragePooling2D(3, strides=2, name='pool1')(x)\n",
    "        \n",
    "        for i, block in enumerate(blocks):\n",
    "            scope_num_str = str(i + 2)\n",
    "            x = self.dense_block(x, block, name='conv' + scope_num_str, \n",
    "                                 growth_rate = growth_rate,\n",
    "                                 weight_decay = weight_decay, \n",
    "                                 kernel_initializer = kernel_initializer)\n",
    "            if i != len(blocks) - 1:\n",
    "                x = self.transition_block(x, reduction, name='pool' + scope_num_str, \n",
    "                                          weight_decay = weight_decay, kernel_initializer = kernel_initializer)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=3, epsilon=1.001e-5, name='bn')(x)\n",
    "        x = layers.Activation('relu', name='relu')(x)\n",
    "\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = layers.Dense(self.cat_max, activation='softmax',\n",
    "            kernel_initializer = kernel_initializer, \n",
    "            name='fc')(x)\n",
    "        \n",
    "        model = Model(img_input, x)\n",
    "        model.compile(optimizer = Adam(lr=self.lr), loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def DNN_DataSet(self, df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return preprocess_img(df['img'])\n",
    "\n",
    "    def train(self, train_part_df, train_part_label, validate_part_df, validate_part_label):\n",
    "        \"\"\"\n",
    "        Keras Training\n",
    "        \"\"\"\n",
    "        print(\"-----DNN training-----\")\n",
    "\n",
    "        DNN_Train_Data = self.DNN_DataSet(train_part_df)\n",
    "        DNN_validate_Data = self.DNN_DataSet(validate_part_df)\n",
    "\n",
    "        callbacks = [\n",
    "                EarlyStopping(monitor='val_categorical_accuracy', patience=self.patience, verbose=0),\n",
    "                ]\n",
    "        if self.aug_data:\n",
    "            datagen = preprocessing.image.ImageDataGenerator(\n",
    "                    rotation_range=45,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "\n",
    "            datagen.fit(DNN_Train_Data)\n",
    "\n",
    "            h = self.model.fit_generator(datagen.flow(DNN_Train_Data, train_part_label, batch_size=self.batch_size), \n",
    "                    validation_data=(DNN_validate_Data, validate_part_label), steps_per_epoch = DNN_Train_Data.shape[0]//self.batch_size,\n",
    "                    epochs=self.epochs, shuffle=True, verbose = self.verbose, workers=1, use_multiprocessing=False, \n",
    "                    callbacks=callbacks)\n",
    "        else:\n",
    "            h = self.model.fit(DNN_Train_Data, train_part_label, batch_size=self.batch_size, epochs=self.epochs,\n",
    "                        shuffle=True, verbose=self.verbose,\n",
    "                        validation_data=(DNN_validate_Data, validate_part_label)\n",
    "                        , callbacks=callbacks\n",
    "                        )\n",
    "        self.scores.append(pd.DataFrame(h.history))\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, test_part, batch_size = 1024, verbose=2):\n",
    "        \"\"\"\n",
    "        Keras Training\n",
    "        \"\"\"\n",
    "        print(\"-----DNN Test-----\")\n",
    "        pred = self.model.predict(self.DNN_DataSet(test_part), verbose=verbose)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145/119145 [==============================] - 12271s \n",
      "7817/7817 [==============================] - 817s   \n"
     ]
    }
   ],
   "source": [
    "img_model = DenseNet(scores = None, \n",
    "                     cat_max = 205, #flags.cat_max, \n",
    "                     flags = None, \n",
    "                     model_type = 'DenseNet').model\n",
    "# model_file_name = glob.glob(model_path + '/imgmodel_*.h5')[0]\n",
    "# print ('Model file name: ', model_file_name)\n",
    "# img_model.load_weights(model_file_name)\n",
    "img_model.load_weights('../../Data/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/model_0_2018_09_24_03_07_15.h5')\n",
    "# img_model_flat = Model(input = img_model.input, output = img_model.get_layer(name = 'avg_pool').output)\n",
    "train_data['target'] = list(model_eval(img_model, 'DenseNet', train_data))\n",
    "test_data['target'] = list(model_eval(img_model, 'DenseNet', test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 7],\n",
       "       [2, 8, 6],\n",
       "       [7, 6, 4]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(1, 10, (3, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-724ce3e98dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "np.random.choice(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42025"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "205 * 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def extract_array_from_series(s):\n",
    "    return np.asarray(list(s))\n",
    "\n",
    "def create_dem_data(df, only_emb = False, emb_len = 1200):\n",
    "    if only_emb:\n",
    "        emb = extract_array_from_series(df['emb'])[:, -300:]\n",
    "        attr = np.zeros((emb.shape[0], 50))\n",
    "        return [attr, emb]\n",
    "    else:\n",
    "        return [extract_array_from_series(df['attr'])[:, :50], extract_array_from_series(df['emb'])[:, -100:]]\n",
    "\n",
    "def create_gcn_data(df, class_to_id):\n",
    "    return np.array([class_to_id[c] for c in df['class_id'].values]).astype('int32')\n",
    "\n",
    "def create_qfsl_data(df, class_to_id, categories = 205):\n",
    "    OneHotEncoder = sklearn.preprocessing.OneHotEncoder(n_values = categories )\n",
    "    train_target = df['class_id'].apply(lambda c: class_to_id[c]).values\n",
    "    train_target = OneHotEncoder.fit_transform(np.reshape(train_target, (-1, 1))).toarray()\n",
    "    return [extract_array_from_series(df['target']), train_target]\n",
    "\n",
    "def neg_aug_data(pos_data, train_class_id, class_id_emb_attr = None, c2c_neg_cnt = None, only_emb = False):\n",
    "    if c2c_neg_cnt is None:\n",
    "        pos_len = pos_data[0].shape[0]\n",
    "        ind_array = np.array(range(pos_len))\n",
    "    #     rs = np.random.RandomState(seed=420)\n",
    "    #     perm_ind_array = rs.permutation(rs.permutation(rs.permutation(rs.permutation(ind_array))))\n",
    "        perm_ind_array = np.random.permutation(ind_array)\n",
    "        perm_label = np.zeros(pos_len)\n",
    "        perm_label[train_class_id == train_class_id[perm_ind_array]] = 1\n",
    "        perm_img_feature_map = pos_data[0][perm_ind_array] \n",
    "\n",
    "        neg_data = [perm_img_feature_map] + pos_data[1:3] + [perm_label]\n",
    "    else:\n",
    "        train_class_id_uniq = np.unique(train_class_id)\n",
    "        attr_embs = create_dem_data(class_id_emb_attr, only_emb)\n",
    "        neg_attrs = []\n",
    "        neg_embs = []\n",
    "        neg_imgs = []\n",
    "        img_origin_ind = np.array(range(train_class_id.shape[0]))\n",
    "        for i, class_id in enumerate(list(class_id_emb_attr.class_id)):\n",
    "            per_class_attrs,  per_class_embs = attr_embs[0][i], attr_embs[1][i]\n",
    "            per_class_neg_imgs = []\n",
    "            for have_img_clas_id in train_class_id_uniq:\n",
    "                if class_id == have_img_clas_id:\n",
    "                    continue\n",
    "                imgs_ind = img_origin_ind[train_class_id == have_img_clas_id]\n",
    "                per_class_neg_imgs.extend(list(pos_data[0][np.random.choice(imgs_ind, c2c_neg_cnt)]))\n",
    "            per_class_neg_len = len(per_class_neg_imgs)\n",
    "#             print ('Class_id, neg', class_id, per_class_neg_len)\n",
    "            neg_attrs.extend([per_class_attrs] * per_class_neg_len)\n",
    "            neg_embs.extend([per_class_embs] * per_class_neg_len)\n",
    "            neg_imgs.extend(per_class_neg_imgs)\n",
    "        neg_data = [np.array(neg_imgs), np.array(neg_attrs), np.array(neg_embs), np.zeros(len(neg_imgs))]\n",
    "    return neg_data\n",
    "        \n",
    "def create_dem_bc_data(df, neg_aug = 0, only_emb = False, class_id_emb_attr = None, c2c_neg_cnt = None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    train_data = [extract_array_from_series(df['target'])] + create_dem_data(df, only_emb)\n",
    "    train_len = train_data[0].shape[0]\n",
    "    train_data = train_data + [np.ones(train_len)]\n",
    "    merge_data = train_data\n",
    "    if neg_aug > 0:\n",
    "        train_class_id = extract_array_from_series(df['class_id'])\n",
    "        for i in range(neg_aug):\n",
    "            neg_data = neg_aug_data(train_data, train_class_id, \n",
    "                                    class_id_emb_attr = class_id_emb_attr, \n",
    "                                    c2c_neg_cnt = c2c_neg_cnt,\n",
    "                                    only_emb = only_emb)\n",
    "            merge_data = [np.r_[merge_data[i], neg_data[i]] for i in range(len(merge_data))]\n",
    "        print ('DEM BC Data Train Len, Pos, Neg:', train_len, np.sum(merge_data[-1]), np.sum(merge_data[-1] == 0))\n",
    "        return merge_data\n",
    "    else:\n",
    "        return train_data\n",
    "            \n",
    "def preprocess_numpy_input(x, data_format = 'channels_last', mode = 'torch', **kwargs):\n",
    "    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n",
    "\n",
    "    # Arguments\n",
    "        x: Input array, 3D or 4D.\n",
    "        data_format: Data format of the image array.\n",
    "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
    "            - caffe: will convert the images from RGB to BGR,\n",
    "                then will zero-center each color channel with\n",
    "                respect to the ImageNet dataset,\n",
    "                without scaling.\n",
    "            - tf: will scale pixels between -1 and 1,\n",
    "                sample-wise.\n",
    "            - torch: will scale pixels between 0 and 1 and then\n",
    "                will normalize each channel with respect to the\n",
    "                ImageNet dataset.\n",
    "\n",
    "    # Returns\n",
    "        Preprocessed Numpy array.\n",
    "    \"\"\"\n",
    "    if not issubclass(x.dtype.type, np.floating):\n",
    "        x = x.astype(K.floatx(), copy=False)\n",
    "\n",
    "    if mode == 'tf':\n",
    "        x /= 127.5\n",
    "        x -= 1.\n",
    "        return x\n",
    "\n",
    "    if mode == 'torch':\n",
    "        x /= 255.\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "    else:\n",
    "        if data_format == 'channels_first':\n",
    "            # 'RGB'->'BGR'\n",
    "            if x.ndim == 3:\n",
    "                x = x[::-1, ...]\n",
    "            else:\n",
    "                x = x[:, ::-1, ...]\n",
    "        else:\n",
    "            # 'RGB'->'BGR'\n",
    "            x = x[..., ::-1]\n",
    "        mean = [103.939, 116.779, 123.68]\n",
    "        std = None\n",
    "\n",
    "    # Zero-center by mean pixel\n",
    "    if data_format == 'channels_first':\n",
    "        if x.ndim == 3:\n",
    "            x[0, :, :] -= mean[0]\n",
    "            x[1, :, :] -= mean[1]\n",
    "            x[2, :, :] -= mean[2]\n",
    "            if std is not None:\n",
    "                x[0, :, :] /= std[0]\n",
    "                x[1, :, :] /= std[1]\n",
    "                x[2, :, :] /= std[2]\n",
    "        else:\n",
    "            x[:, 0, :, :] -= mean[0]\n",
    "            x[:, 1, :, :] -= mean[1]\n",
    "            x[:, 2, :, :] -= mean[2]\n",
    "            if std is not None:\n",
    "                x[:, 0, :, :] /= std[0]\n",
    "                x[:, 1, :, :] /= std[1]\n",
    "                x[:, 2, :, :] /= std[2]\n",
    "    else:\n",
    "        x[..., 0] -= mean[0]\n",
    "        x[..., 1] -= mean[1]\n",
    "        x[..., 2] -= mean[2]\n",
    "        if std is not None:\n",
    "            x[..., 0] /= std[0]\n",
    "            x[..., 1] /= std[1]\n",
    "            x[..., 2] /= std[2]\n",
    "    return x\n",
    "\n",
    "def preprocess_img(img_series):\n",
    "    return preprocess_numpy_input(extract_array_from_series(img_series))\n",
    "\n",
    "def multi_labels_cross_entropy(y_true, y_preds, eps = 1e-6):\n",
    "#     multi_labels_loss = [sklearn.metrics.log_loss]\n",
    "#     y_preds_clip = max(eps, min(1 - eps, y_preds))\n",
    "    y_preds_clip = np.clip(y_preds, eps, 1- eps)\n",
    "    multi_loss = -(y_true * np.log(y_preds_clip) + (1 - y_true) * np.log(1 - y_preds_clip))\n",
    "    return np.mean(multi_loss, axis = -1)\n",
    "\n",
    "def find_nearest_class(class_id_emb_attr, eval_df, cand_feature_map = None, img_feature_map = None,\n",
    "                      model_type = None, attr_preds = None, zs_model = None, dis_arr = None):\n",
    "    nearest_class_id = ['ZJL'] * img_feature_map.shape[0]\n",
    "    for i in range(img_feature_map.shape[0]):\n",
    "        if model_type == 'I2A':\n",
    "            dis = multi_labels_cross_entropy(extract_array_from_series(class_id_emb_attr['attr'])[:, :50],\n",
    "                                            attr_preds[i])\n",
    "        elif model_type == 'DEM_BC':\n",
    "            img = img_feature_map[i]\n",
    "            pred_data = cand_feature_map * img\n",
    "            dis = 1 - zs_model.predict(pred_data)\n",
    "        elif model_type == 'lgb':\n",
    "            img = img_feature_map[i]\n",
    "            pred_data = cand_feature_map * img\n",
    "            dis = 1 - zs_model.predict(pred_data, num_iteration = -1)\n",
    "        elif model_type == 'QFSL':\n",
    "            dis = 1 - dis_arr[i]\n",
    "        else:\n",
    "            img = img_feature_map[i]\n",
    "            dis = np.linalg.norm(img - cand_feature_map, axis = 1)\n",
    "        min_ind = np.where(dis == np.amin(dis))[0]\n",
    "        nearest_class_id[i] = class_id_emb_attr.iloc[min_ind[0]]['class_id']\n",
    "    return np.asarray(nearest_class_id)\n",
    "        \n",
    "def calc_accuracy(eval_df, eval_class, preds):\n",
    "    eval_mask = eval_df.class_id.isin(eval_class)\n",
    "    eval_num = np.sum(eval_mask)\n",
    "    right_num = np.sum(preds[eval_mask] == eval_df.class_id[eval_mask])\n",
    "    return right_num / np.sum(eval_mask), right_num, eval_num\n",
    "    \n",
    "def calc_detailed_accuracy(eval_df, preds, class_id_dict):\n",
    "    print (\"\\n\")\n",
    "    for class_set_name in sorted(class_id_dict):\n",
    "        class_set = class_id_dict[class_set_name]\n",
    "        re = calc_accuracy(eval_df, class_set, preds)\n",
    "        print(\"%s: \\t%.6f\\t%.0f\\t%.0f\" % ((class_set_name,) + re))\n",
    "#     print (\"\\n\")\n",
    "\n",
    "def multi_preds_vote(preds):\n",
    "    vote_preds = []\n",
    "    for single_img_vote in preds:\n",
    "        uniq_val, counts = np.unique(single_img_vote, return_counts = True)\n",
    "        vote_preds.append(uniq_val[np.argmax(counts)])\n",
    "    vote_preds = np.asarray(vote_preds)\n",
    "    return vote_preds\n",
    "    \n",
    "def multi_models_vote(models, eval_df = None, cand_class_id_emb_attr = None, img_feature_map = None, \n",
    "                      class_id_dict = None):\n",
    "    print ('cand shape: ', cand_class_id_emb_attr.shape[0])\n",
    "    preds = models_eval(models, eval_df, cand_class_id_emb_attr, img_feature_map, \n",
    "                class_id_dict)\n",
    "    preds = np.asarray(preds).T\n",
    "    vote_preds = multi_preds_vote(preds)\n",
    "    # print (vote_preds)\n",
    "    print ('Multi model votes results:')\n",
    "    if 'class_id' in eval_df.columns: \n",
    "        calc_detailed_accuracy(eval_df, vote_preds, class_id_dict)\n",
    "    return vote_preds\n",
    "\n",
    "def model_eval(model, model_type, eval_df, cand_class_id_emb_attr = None, img_feature_map = None, \n",
    "                class_id_dict = None, class_to_id = None, TTA = None, img_model = None, only_emb = None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if model_type == 'DenseNet':\n",
    "        flat_model = Model(inputs = model.inputs, outputs = model.get_layer(name = 'avg_pool').output)\n",
    "        pred = flat_model.predict(preprocess_img(eval_df['img']), verbose = 1)\n",
    "    elif model_type == 'DEM' or model_type == 'AE':\n",
    "        zs_model = Model(inputs = model.inputs[:2], outputs = model.outputs[0])\n",
    "        cand_feature_map = zs_model.predict(create_dem_data(cand_class_id_emb_attr), verbose = 2)\n",
    "        if TTA is not None:\n",
    "            batch_size = 32\n",
    "            datagen = MixedImageDataGenerator(\n",
    "                    rotation_range=20,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "            img_feature_map = img_model.predict_generator(\n",
    "                datagen.flow((preprocess_img(eval_df['img'])), None, shuffle = False, batch_size = batch_size), \n",
    "                steps = np.ceil(eval_df.shape[0] / batch_size) * TTA, verbose = 1)\n",
    "            pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map, img_feature_map)\n",
    "            pred = np.reshape(pred, (TTA, eval_df.shape[0])).T\n",
    "            pred = multi_preds_vote(pred)\n",
    "        else:\n",
    "            pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map, img_feature_map)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'DEM_BC':\n",
    "        zs_model = Model(inputs = model.inputs[1:3], outputs = model.outputs[0])\n",
    "        cand_feature_map = zs_model.predict(create_dem_data(cand_class_id_emb_attr, only_emb = only_emb), verbose = 1)\n",
    "        zs_model = Model(inputs = model.get_layer('attr_x_img_model').inputs, \n",
    "                         outputs = model.get_layer('attr_x_img_model').outputs)\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map = cand_feature_map, img_feature_map = img_feature_map,\n",
    "                                zs_model = zs_model, model_type = model_type)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'GCN':\n",
    "        zs_model = Model(inputs = model.inputs[2:], outputs = model.outputs[0])\n",
    "        cand_class_to_id = [class_to_id[c] for c in cand_class_id_emb_attr.class_id.values]\n",
    "        cand_feature_map = zs_model.predict(None, steps = 1)[cand_class_to_id]\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map, img_feature_map)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'QFSL':\n",
    "        cand_class_to_id = [class_to_id[c] for c in cand_class_id_emb_attr.class_id.values]\n",
    "        zs_model = Model(inputs = [model.inputs[0]] + model.inputs[2:], outputs = model.outputs[0])\n",
    "        dis_arr = zs_model.predict(img_feature_map, verbose = 2)[:, cand_class_to_id]\n",
    "#         print (dis_arr[:2])\n",
    "#         print (dis_arr[:2, cand_class_to_id])\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, model_type = model_type, dis_arr = dis_arr,\n",
    "                                 img_feature_map = img_feature_map)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'I2A':\n",
    "        zs_model = Model(inputs = model.inputs[-1], outputs = model.outputs[0])\n",
    "        attr_preds = zs_model.predict(extract_array_from_series(img_feature_map), verbose = 2)\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, None, img_feature_map, \n",
    "                                  model_type, attr_preds)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    elif model_type == 'DEM_AUG':\n",
    "        img_model = Model(inputs = model.inputs[0], outputs = model.outputs[-1])\n",
    "        img_feature_map = img_model.predict(preprocess_img(eval_df['img']), verbose = 2)\n",
    "        zs_model = Model(inputs = model.inputs[1:], outputs = model.outputs[0])\n",
    "        cand_feature_map = zs_model.predict(create_dem_data(cand_class_id_emb_attr), verbose = 2)\n",
    "        pred = find_nearest_class(cand_class_id_emb_attr, eval_df, cand_feature_map, img_feature_map)\n",
    "        if 'class_id' in eval_df.columns:\n",
    "            calc_detailed_accuracy(eval_df, pred, class_id_dict)\n",
    "    return pred\n",
    "\n",
    "def models_eval(models, eval_df, cand_class_id_emb_attr = None, img_feature_map = None, \n",
    "                class_id_dict = None, class_to_id = None, img_model = None):\n",
    "    preds = []\n",
    "    for (model, model_type) in models:\n",
    "        pred = model_eval(model, model_type, eval_df = eval_df, cand_class_id_emb_attr = cand_class_id_emb_attr, \n",
    "            img_feature_map = img_feature_map, class_id_dict = class_id_dict, class_to_id = class_to_id,\n",
    "            img_model = img_model)\n",
    "        preds.append(pred)\n",
    "    return preds\n",
    "\n",
    "class MixedImageDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MixedImageDataGenerator, self).__init__(**kwargs)\n",
    "        \n",
    "    def flow(self,\n",
    "           x,\n",
    "           y=None,\n",
    "           batch_size=32,\n",
    "           shuffle=True,\n",
    "           seed=None,\n",
    "           save_to_dir=None,\n",
    "           save_prefix='',\n",
    "           save_format='png'):\n",
    "        return MixedNumpyArrayIterator(\n",
    "        x,\n",
    "        y,\n",
    "        self,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        seed=seed,\n",
    "        data_format=self.data_format,\n",
    "        save_to_dir=save_to_dir,\n",
    "        save_prefix=save_prefix,\n",
    "        save_format=save_format)\n",
    "\n",
    "\n",
    "class MixedNumpyArrayIterator(NumpyArrayIterator):\n",
    "    \"\"\"Iterator yielding data from a Numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               x,\n",
    "               y,\n",
    "               image_data_generator,\n",
    "               **kwargs):\n",
    "        self.x_misc = None\n",
    "        if (type(x) is list) or (type(x) is tuple):\n",
    "            super(MixedNumpyArrayIterator, self).__init__(x[0],\n",
    "                   y,\n",
    "                   image_data_generator,\n",
    "                   **kwargs)\n",
    "            self.x_misc = [np.asarray(xx) for xx in x[1]]\n",
    "        else:\n",
    "            super(MixedNumpyArrayIterator, self).__init__(x,\n",
    "               y,\n",
    "               image_data_generator,\n",
    "               **kwargs)\n",
    "            \n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "\n",
    "        Returns:\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(\n",
    "              self.index_generator)\n",
    "#         print (index_array)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        batch_x = np.zeros(\n",
    "            tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())\n",
    "        for i, j in enumerate(index_array):\n",
    "            x = self.x[j]\n",
    "#             x_bak = x\n",
    "            x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "#             print (np.all(x_bak == x))\n",
    "            batch_x[i] = x\n",
    "        if self.x_misc is None:\n",
    "            batch_x = [batch_x]\n",
    "        else:\n",
    "            batch_x_miscs = [xx[index_array] for xx in self.x_misc]\n",
    "            batch_x = [batch_x] + batch_x_miscs\n",
    "        return (batch_x, None, None)\n",
    "    \n",
    "#     def next(self):\n",
    "#         \"\"\"For python 2.x.\n",
    "\n",
    "#         Returns:\n",
    "#             The next batch.\n",
    "#         \"\"\"\n",
    "#         with self.lock:\n",
    "#             index_array, current_index, current_batch_size = next(\n",
    "#               self.index_generator)\n",
    "# #         print (index_array)\n",
    "#         # The transformation of images is not under thread lock\n",
    "#         # so it can be done in parallel\n",
    "#         batch_x = np.zeros(\n",
    "#             tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())\n",
    "#         for i, j in enumerate(index_array):\n",
    "#             x = self.x[j]\n",
    "# #             x_bak = x\n",
    "#             x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n",
    "#             x = self.image_data_generator.standardize(x)\n",
    "# #             print (np.all(x_bak == x))\n",
    "#             batch_x[i] = x\n",
    "#         if self.x_misc is None:\n",
    "#             batch_x = [batch_x]\n",
    "#         else:\n",
    "#             batch_x_miscs = [xx[index_array] for xx in self.x_misc]\n",
    "#             batch_x = [batch_x] + batch_x_miscs\n",
    "#         return (batch_x, None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over all training size:\n",
      "(31896, 8)\n",
      "Fold:  0\n",
      "Seen unseen Classes:  144 16\n",
      "Seen round1, round2:  0 144\n",
      "Unseen round1, round2:  0 16\n",
      "WARNING:tensorflow:Output \"activation_9\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"activation_9\" during training.\n",
      "WARNING:tensorflow:Output \"attr_x_img_model\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"attr_x_img_model\" during training.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "wv (InputLayer)                  (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 300)           0           wv[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 300)           1200        dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 2064)          621264      batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 2064)          0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 2064)          0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 2064)          8256        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1548)          3196620     batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 1548)          0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 1548)          0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 1548)          6192        dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1290)          1998210     batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 1290)          0           dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 1290)          0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 1290)          5160        dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1032)          1332312     batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 1032)          0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "img (InputLayer)                 (None, 1032)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "attr_x_img (Lambda)              (None, 1032)          0           activation_9[0][0]               \n",
      "                                                                   img[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "attr_x_img_model (Model)         (None, 1)             5161        attr_x_img[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 7,174,375\n",
      "Trainable params: 7,161,907\n",
      "Non-trainable params: 12,468\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "-----DNN training-----\n",
      "DEM BC Data Train Len, Pos, Neg: 28730 29108.0 57082\n",
      "Train on 86190 samples, validate on 3166 samples\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s] - ETA: 0s - loss: 2.2791\n",
      "\n",
      "\n",
      "Unseen_class: \t0.271636\t860\t3166\n",
      "Unseen_round2_id: \t0.271636\t860\t3166\n",
      "86190/86190 [==============================] - 81s - loss: 2.2790 - val_loss: 2.6640\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s] - ETA: 0s - loss: 1.9854\n",
      "\n",
      "\n",
      "Unseen_class: \t0.297220\t941\t3166\n",
      "Unseen_round2_id: \t0.297220\t941\t3166\n",
      "86190/86190 [==============================] - 77s - loss: 1.9853 - val_loss: 2.5228\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s] - ETA: 0s - loss: 1.7922\n",
      "\n",
      "\n",
      "Unseen_class: \t0.329754\t1044\t3166\n",
      "Unseen_round2_id: \t0.329754\t1044\t3166\n",
      "86190/86190 [==============================] - 75s - loss: 1.7921 - val_loss: 2.3737\n",
      "Epoch 4/10\n",
      "79168/86190 [==========================>...] - ETA: 5s - loss: 1.6125"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2a4b51b53719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    657\u001b[0m        \u001b[0mround1_class_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround1_class_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m        \u001b[0mround2_class_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround2_class_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m        img_model = img_flat_model)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-2a4b51b53719>\u001b[0m in \u001b[0;36mtrain_zs_model\u001b[0;34m(train_data, class_id_emb_attr, flags, img_flat_len, round1_class_id, round2_class_id, img_model)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_fold\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mzs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mzs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_part_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_part_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2a4b51b53719>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_part_df, validate_part_df)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             h = self.model.fit(DNN_Train_Data,  validation_data = (DNN_validate_Data, None),\n\u001b[0;32m--> 522\u001b[0;31m                         epochs=self.epochs, batch_size = self.batch_size, shuffle=True, verbose = self.verbose, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1193\u001b[0m           \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m         **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class AccuracyEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_interval = 1000000, verbose = 2, \\\n",
    "            scores = [], cand_class_id_emb_attr = None, eval_df = None, threshold = None, \\\n",
    "                 seen_class = None, unseen_class = None, gamma = None, model_type = None, \n",
    "                 class_id_dict = None, class_to_id = None, TTA = None, img_model = None,\n",
    "                only_emb = None):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        # print (validation_data)\n",
    "#         self.X_val, _, \n",
    "        self.y_val = validation_data[-1]\n",
    "        if model_type == 'DEM_BC':\n",
    "            self.y_val = validation_data[0]\n",
    "        elif model_type == 'QFSL':\n",
    "            self.y_val = validation_data[0]\n",
    "        self.verbose = verbose\n",
    "        self.scores = scores\n",
    "        self.cand_class_id_emb_attr = cand_class_id_emb_attr\n",
    "        self.eval_df = eval_df\n",
    "        self.seen_class = seen_class\n",
    "        self.unseen_class = unseen_class\n",
    "        self.model_type = model_type\n",
    "        self.class_id_dict = class_id_dict\n",
    "        self.class_to_id = class_to_id\n",
    "        self.TTA = TTA\n",
    "        self.img_model = img_model\n",
    "        self.only_emb = only_emb\n",
    "#         self.class_id_dict['All'] = self.eval_df.class_id.unique()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            model_eval(self.model, self.model_type, self.eval_df, self.cand_class_id_emb_attr, \n",
    "#                 seen_class = self.seen_class, \n",
    "#                 unseen_class = self.unseen_class, \n",
    "                img_feature_map = self.y_val,\n",
    "                class_id_dict = self.class_id_dict,\n",
    "                class_to_id = self.class_to_id,\n",
    "                TTA = self.TTA,\n",
    "                img_model = self.img_model,\n",
    "                      only_emb = self.only_emb)\n",
    "\n",
    "class DEM:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, scores = None, flags = None, model_type = None, seen_class = None, \n",
    "            unseen_class = None, class_id_emb_attr = None, img_flat_len = None, \n",
    "                    unseen_round1_id = None,\n",
    "                    unseen_round2_id = None,\n",
    "                    img_model = None,\n",
    "                    only_emb = False,\n",
    "                    c2c_neg_cnt = None):\n",
    "        self.batch_size = 64 #flags.dem_batch_size\n",
    "        self.epochs = 10 #flags.dem_epochs\n",
    "        self.patience = 100 #flags.dem_patience\n",
    "        self.scores = scores\n",
    "        self.model_type = model_type\n",
    "        self.verbose = 1 #flags.train_verbose\n",
    "        self.seen_class = seen_class\n",
    "        self.unseen_class = unseen_class\n",
    "        self.cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)]\n",
    "        self.class_id_emb_attr = class_id_emb_attr\n",
    "        class_ids = class_id_emb_attr.class_id.values\n",
    "        self.class_to_id = dict([(c, i) for i, c in enumerate(class_ids)])\n",
    "        self.img_flat_len = img_flat_len\n",
    "        self.TTA = None #flags.TTA\n",
    "        self.img_model = img_model\n",
    "        self.only_emb = only_emb\n",
    "        self.c2c_neg_cnt = c2c_neg_cnt\n",
    "        if model_type == 'DEM':\n",
    "            self.model = self.create_dem(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'GCN':\n",
    "            self.model = self.create_gcn(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'I2A':\n",
    "            self.model = self.create_img2attr(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'AE':\n",
    "            self.model = self.create_ae(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'DEM_AUG':\n",
    "            self.model = self.create_dem_aug(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'DEM_BC':\n",
    "            self.model = self.create_dem_bc(img_flat_len = img_flat_len)\n",
    "        elif model_type == 'QFSL':\n",
    "            self.model = self.create_qfsl(img_flat_len = img_flat_len)\n",
    "        self.class_id_dict = {\n",
    "#                              'seen_class': seen_class,\n",
    "                             'Unseen_class': unseen_class,\n",
    "#                              'Unseen_round1_id': unseen_round1_id,\n",
    "                             'Unseen_round2_id': unseen_round2_id,}\n",
    "\n",
    "    def create_dem(self, kernel_initializer = 'he_normal', img_flat_len = 1024):\n",
    "        attr_input = layers.Input(shape = (50,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (1200,), name = 'wv')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "        \n",
    "        attr_dense = layers.Dense(1200, use_bias = True, kernel_initializer=kernel_initializer, \n",
    "                        kernel_regularizer = l2(1e-4), name = 'attr_dense')(attr_input)\n",
    "        attr_word_emb = layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "                                                                            int(img_flat_len * 2),\n",
    "                                                                            int(img_flat_len * 1.5), \n",
    "                                                                            int(img_flat_len * 1.25), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "                                                activation = 'relu')\n",
    "\n",
    "        mse_loss = K.mean(mean_squared_error(imag_classifier, attr_word_emb_dense))\n",
    "        \n",
    "        model = Model([attr_input, word_emb, imag_classifier], outputs = attr_word_emb_dense) #, vgg_output])\n",
    "        model.add_loss(mse_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "        return model\n",
    "\n",
    "    def create_dem_bc(self, kernel_initializer = 'he_normal', img_flat_len = 1024):\n",
    "        attr_input = layers.Input(shape = (50,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (300,), name = 'wv')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "        label = layers.Input(shape = (1,), name = 'label')\n",
    "        \n",
    "        attr_dense = layers.Dense(100, use_bias = True, kernel_initializer=kernel_initializer, \n",
    "                        kernel_regularizer = l2(1e-4), name = 'attr_dense')(attr_input)\n",
    "        if self.only_emb:\n",
    "            attr_word_emb = word_emb\n",
    "        else:\n",
    "            attr_word_emb = layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "#                                                                             int(img_flat_len * 4),\n",
    "                                                                            int(img_flat_len * 2),\n",
    "                                                                            int(img_flat_len * 1.5), \n",
    "                                                                            int(img_flat_len * 1.25), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "                                                                            int(img_flat_len)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "#         attr_word_emb_dense = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "#                                                 activation = 'relu')\n",
    "        \n",
    "        attr_x_img = layers.Lambda(lambda x: x[0] * x[1], name = 'attr_x_img')([attr_word_emb_dense, imag_classifier])\n",
    "#         attr_x_img = layers.Concatenate(name = 'attr_x_img')([attr_word_emb_dense, imag_classifier])\n",
    "    \n",
    "        attr_img_input = layers.Input(shape = (img_flat_len,), name = 'attr_img_input')\n",
    "#         attr_img_input = layers.Input(shape = (img_flat_len * 2,), name = 'attr_img_input')\n",
    "        proba = self.full_connect_layer(attr_img_input, hidden_dim = [1], activation = 'sigmoid')\n",
    "        attr_img_model = Model(inputs = attr_img_input, outputs = proba, name = 'attr_x_img_model')\n",
    "        \n",
    "        out = attr_img_model([attr_x_img])\n",
    "        \n",
    "        bc_loss = K.mean(binary_crossentropy(label, out))\n",
    "        model = Model([imag_classifier, attr_input, word_emb, label], outputs = [attr_word_emb_dense, out])\n",
    "        model.add_loss(bc_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "        return model\n",
    "    \n",
    "    def create_dem_aug(self, kernel_initializer = 'he_normal', img_flat_len = 1024):\n",
    "        attr_input = layers.Input(shape = (50,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (300,), name = 'wv')\n",
    "        img_input = layers.Input(shape = (64, 64, 3))\n",
    "#         imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "        img_model = DenseNet(scores = None, \n",
    "                     cat_max = 365, #flags.cat_max, \n",
    "                     flags = None, \n",
    "                     model_type = 'DenseNet').model\n",
    "#         print ('Load DenseNet Weights---')\n",
    "        img_model.load_weights(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05108_TF14_DensetNetProcess/imgmodel_20181013_092715.h5')\n",
    "        img_flat_model = Model(inputs = img_model.inputs, outputs = img_model.get_layer(name = 'avg_pool').output)\n",
    "        img_flat_model.trainable = False\n",
    "        imag_classifier = img_flat_model(img_input)\n",
    "        \n",
    "        attr_dense = layers.Dense(1200, use_bias = True, kernel_initializer=kernel_initializer, \n",
    "                        kernel_regularizer = l2(1e-4), name = 'attr_dense')(attr_input)\n",
    "        attr_word_emb = layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "                                                                            int(img_flat_len * 2),\n",
    "#                                                                             int(img_flat_len * 1.5), \n",
    "#                                                                             int(img_flat_len * 1.25), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "                                                activation = 'relu')\n",
    "\n",
    "        mse_loss = K.mean(mean_squared_error(imag_classifier, attr_word_emb_dense))\n",
    "        \n",
    "        model = Model([img_input, attr_input, word_emb], outputs = [attr_word_emb_dense, imag_classifier]) #, vgg_output])\n",
    "        model.add_loss(mse_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "        return model\n",
    "    \n",
    "    def create_img2attr(self, kernel_initializer = 'he_normal', img_flat_len = 1024):\n",
    "        attr_input = layers.Input(shape = (50,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (600,), name = 'wv')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "        attr_dense = layers.Dense(600, use_bias = True, kernel_initializer=kernel_initializer, \n",
    "                        kernel_regularizer = l2(1e-4), name = 'attr_dense')(attr_input)\n",
    "        attr_word_emb = layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        out_size = 50\n",
    "        \n",
    "        attr_preds = self.full_connect_layer(imag_classifier, hidden_dim = [\n",
    "                                                                            int(out_size * 20),\n",
    "                                                                            int(out_size * 15), \n",
    "#                                                                             int(out_size * 7), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "        attr_preds = self.full_connect_layer(attr_preds, hidden_dim = [out_size], activation = 'sigmoid')\n",
    "        log_loss = K.mean(binary_crossentropy(attr_input, attr_preds))\n",
    "        \n",
    "        model = Model([attr_input, word_emb, imag_classifier], outputs = [attr_preds]) #, vgg_output])\n",
    "        model.add_loss(log_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-5), loss=None)\n",
    "        return model\n",
    "    \n",
    "    def create_ae(self, kernel_initializer = 'he_normal', img_flat_len = 1024):\n",
    "        gamma = 0.5\n",
    "        attr_input = layers.Input(shape = (50,), name = 'attr')\n",
    "        word_emb = layers.Input(shape = (600,), name = 'wv')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "        attr_dense = layers.Dense(900, use_bias = True, kernel_initializer=kernel_initializer, \n",
    "                        kernel_regularizer = l2(1e-4), name = 'attr_dense')(attr_input)\n",
    "#         attr_dense = self.full_connect_layer(attr_dense, hidden_dim = [int(img_flat_len * 1.5), \n",
    "#                                                                             int(img_flat_len * 1.25), \n",
    "# #                                                                             int(img_flat_len * 1.125),\n",
    "# #                                                                               int(img_flat_len * 0.5)\n",
    "#                                                                             ], \\\n",
    "#                                                 activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "        attr_word_emb = layers.Concatenate(name = 'attr_word_emb')([word_emb, attr_dense])\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "                                                                            int(img_flat_len * 2),\n",
    "                                                                            int(img_flat_len * 1.5), \n",
    "                                                                            int(img_flat_len * 1.25), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "                                                activation = 'relu')\n",
    "\n",
    "        mse_loss = K.mean(mean_squared_error(imag_classifier, attr_word_emb_dense))\n",
    "        \n",
    "        out_size = 50\n",
    "        attr_preds = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [\n",
    "                                                                            int(out_size * 20),\n",
    "                                                                            int(out_size * 15), \n",
    "                                                                            int(out_size * 7), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "        attr_preds = self.full_connect_layer(attr_preds, hidden_dim = [out_size], activation = 'sigmoid')\n",
    "        log_loss = K.mean(binary_crossentropy(attr_input, attr_preds))\n",
    "        \n",
    "        loss = (1 - gamma) * mse_loss + gamma * log_loss\n",
    "        \n",
    "        model = Model([attr_input, word_emb, imag_classifier], outputs = [attr_word_emb_dense, attr_preds])\n",
    "        model.add_loss(loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "        return model\n",
    "    \n",
    "    def create_gcn(self, img_flat_len = 1024):\n",
    "        adj_graph = 1 - sklearn.metrics.pairwise.pairwise_distances(\n",
    "            np.array(list(self.class_id_emb_attr['emb']))[:, :300], metric = 'cosine')\n",
    "        attr_input = layers.Input(tensor=\n",
    "                            tf.constant(np.array(list(self.class_id_emb_attr['attr']), \n",
    "                                                 dtype = 'float32')))\n",
    "        all_word_emb = layers.Input(tensor=\n",
    "                        tf.constant(extract_array_from_series(self.class_id_emb_attr['emb']), \n",
    "                                    dtype = 'float32')) #Input(shape = (230, 300,), name = 'wv')\n",
    "        class_index = layers.Input(shape = (1, ), name = 'class_index', dtype = 'int32')\n",
    "        adj_graphs = layers.Input(tensor=tf.constant(adj_graph, dtype = 'float32')) #Input(shape = (230, 230,), name = 'adj_graph')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "        attr_dense = layers.Dense(600, use_bias = False, kernel_initializer='he_normal', \n",
    "                        kernel_regularizer = l2(1e-4))(attr_input)\n",
    "        attr_word_emb = layers.Concatenate()([all_word_emb, attr_dense])\n",
    "        \n",
    "        all_classifier = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "                                                                        int(img_flat_len * 2),\n",
    "#                                                                         int(img_flat_len * 1.5), \n",
    "#                                                                         int(img_flat_len * 1.25 ),\n",
    "#                                                                         img_flat_len\n",
    "                                                                            ], \n",
    "                                    activation = 'relu', adj_graphs = adj_graphs, drop_out_ratio = 0.2)\n",
    "        all_classifier = self.full_connect_layer(all_classifier, hidden_dim = [img_flat_len], \n",
    "                                    activation = 'relu', adj_graphs = adj_graphs)\n",
    "        x = tf.gather_nd(all_classifier, class_index)\n",
    "\n",
    "        mse_loss = K.mean(mean_squared_error(imag_classifier, x))\n",
    "\n",
    "        model = Model([class_index, imag_classifier, attr_input, all_word_emb, adj_graphs], \n",
    "                      outputs = [all_classifier]) #, vgg_output])\n",
    "        model.add_loss(mse_loss)\n",
    "        model.compile(optimizer=Adam(lr=5e-4), loss=None)\n",
    "    #     model.summary()\n",
    "        return model\n",
    "\n",
    "#     def create_qfsl(self, img_flat_len = 1024):\n",
    "# #         adj_graph = 1 - sklearn.metrics.pairwise.pairwise_distances(\n",
    "# #             np.array(list(self.class_id_emb_attr['emb']))[:, :300], metric = 'cosine')\n",
    "#         class_num = self.class_id_emb_attr.shape[0]\n",
    "#         print ('Class name in model: ', class_num)\n",
    "#         attr_input = layers.Input(tensor=\n",
    "#                             tf.constant(np.array(list(self.class_id_emb_attr['attr']), \n",
    "#                                                  dtype = 'float32')), name = 'attr')\n",
    "#         all_word_emb = layers.Input(tensor=\n",
    "#                         tf.constant(extract_array_from_series(self.class_id_emb_attr['emb']), \n",
    "#                                     dtype = 'float32'), name = 'wv') #Input(shape = (230, 300,), name = 'wv')\n",
    "#         classes = layers.Input(shape = (class_num, ), name = 'classes')\n",
    "#         imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "# #         attr_dense = layers.Dense(1200, use_bias = False, kernel_initializer='he_normal', \n",
    "# #                         kernel_regularizer = l2(1e-4))(attr_input)\n",
    "# #         attr_word_emb = layers.Concatenate()([all_word_emb, attr_dense])\n",
    "#         attr_word_emb = np.c_[extract_array_from_series(self.class_id_emb_attr['emb']), \n",
    "#                               extract_array_from_series(self.class_id_emb_attr['attr'])]\n",
    "#         attr_word_emb_size = 1250\n",
    "        \n",
    "#         attr_emb_from_img = self.full_connect_layer(imag_classifier, hidden_dim = [\n",
    "#                                                                         int(attr_word_emb_size * 2),\n",
    "# #                                                                         int(attr_word_emb_size * 1.5), \n",
    "# #                                                                         int(attr_word_emb_size * 1.25 ),\n",
    "#                                                                         attr_word_emb_size\n",
    "#                                                                             ], \n",
    "#                                     activation = 'relu')\n",
    "        \n",
    "#         attr_emb_from_img = layers.Reshape((attr_word_emb_size, 1))(attr_emb_from_img)\n",
    "#         scoring_sub = layers.Conv1D(filters = class_num, \n",
    "#                                     kernel_size = 1, \n",
    "#                                     use_bias = False,\n",
    "#                                     weights = attr_word_emb,\n",
    "#                                     trainable = False)(attr_emb_from_img)\n",
    "# #         scoring_sub = layers.Lambda(lambda x: K.dot(x[0], K.transpose(x[1])), \n",
    "# #                              name = 'scoring_sub')([attr_emb_from_img, attr_word_emb])\n",
    "#         scoring_sub = layers.Flatten()(scoring_sub)\n",
    "#         out = self.full_connect_layer(scoring_sub, hidden_dim = [class_num], \n",
    "#                                     activation = 'softmax')\n",
    "\n",
    "#         log_loss = K.mean(K.categorical_crossentropy(classes, out))\n",
    "\n",
    "#         model = Model([imag_classifier, classes, attr_input, all_word_emb], outputs = [out])\n",
    "#         model.add_loss(log_loss)\n",
    "#         model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "#     #     model.summary()\n",
    "#         return model\n",
    "    \n",
    "    def create_qfsl(self, img_flat_len = 1024):\n",
    "        class_num = self.class_id_emb_attr.shape[0]\n",
    "        print ('Class name in model: ', class_num)\n",
    "        unseen_mask = np.ones(class_num)\n",
    "        unseen_mask[[self.class_to_id[c] for c in self.unseen_class]] = 0\n",
    "        attr_input = layers.Input(tensor=\n",
    "                            tf.constant(np.array(list(self.class_id_emb_attr['attr']), \n",
    "                                                 dtype = 'float32')), name = 'attr')\n",
    "        all_word_emb = layers.Input(tensor=\n",
    "                        tf.constant(extract_array_from_series(self.class_id_emb_attr['emb']), \n",
    "                                    dtype = 'float32'), name = 'wv') #Input(shape = (230, 300,), name = 'wv')\n",
    "        classes = layers.Input(shape = (class_num, ), name = 'classes')\n",
    "        imag_classifier = layers.Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "        attr_dense = layers.Dense(1200, use_bias = False, kernel_initializer='he_normal', \n",
    "                        kernel_regularizer = l2(1e-4))(attr_input)\n",
    "        attr_word_emb = layers.Concatenate()([all_word_emb, attr_dense])\n",
    "#         attr_word_emb_size = 2400\n",
    "        \n",
    "        attr_word_emb_dense = self.full_connect_layer(attr_word_emb, hidden_dim = [\n",
    "                                                                            int(img_flat_len * 2),\n",
    "                                                                            int(img_flat_len * 1.5), \n",
    "                                                                            int(img_flat_len * 1.25), \n",
    "#                                                                             int(img_flat_len * 1.125),\n",
    "#                                                                             int(img_flat_len * 1.0625)\n",
    "                                                                            ], \\\n",
    "                                                activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "        img_from_attr_emb = self.full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "                                                activation = 'relu')\n",
    "        \n",
    "#         imag_classifier = layers.Reahpe((img_flat_len, 1))(imag_classifier)\n",
    "#         scoring_sub = layers.Conv1D(filters = class_num, \n",
    "#                                     kernel_size = 1, \n",
    "#                                     use_bias = False,\n",
    "#                                     weights = )(imag_classifier)\n",
    "        scoring_sub = layers.Lambda(lambda x: K.reshape(tf.tile(x[0], [1, class_num]), [-1, class_num, img_flat_len]) *  x[1],\n",
    "                    name = 'scoring_sub')([imag_classifier, img_from_attr_emb])\n",
    "        out = layers.Dense(1, activation=\"sigmoid\")(scoring_sub)\n",
    "        out = layers.Flatten()(out)\n",
    "        out_mask = layers.Lambda(lambda x: x * unseen_mask)(out)\n",
    "#         scoring_sub = layers.GlobalAveragePooling1D()(scoring_sub)\n",
    "#         scoring_sub = layers.Flatten()(scoring_sub)\n",
    "#         out = self.full_connect_layer(scoring_sub, hidden_dim = [class_num], \n",
    "#                                     activation = 'softmax')\n",
    "\n",
    "        log_loss = K.mean(K.mean(K.binary_crossentropy(classes, out_mask)))\n",
    "\n",
    "        model = Model([imag_classifier, classes, attr_input, all_word_emb], outputs = [out, out_mask])\n",
    "        model.add_loss(log_loss)\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss=None)\n",
    "    #     model.summary()\n",
    "        return model\n",
    "    \n",
    "    def full_connect_layer(self, input, hidden_dim, activation, resnet = False, adj_graphs = None, \n",
    "                        drop_out_ratio = None, kernel_initializer = 'he_normal'):\n",
    "        full_connect = input\n",
    "        for i, hn in enumerate(hidden_dim):\n",
    "            fc_in = full_connect\n",
    "            if drop_out_ratio is not None:\n",
    "                full_connect = layers.Dropout(drop_out_ratio)(full_connect)\n",
    "            full_connect = layers.BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "            full_connect = layers.Dense(hn, kernel_initializer=kernel_initializer, kernel_regularizer = l2(1e-4), \n",
    "                    activation = None)(full_connect)\n",
    "            if adj_graphs is not None:\n",
    "                full_connect = layers.Lambda(lambda x: K.dot(x[1], x[0]))([full_connect, adj_graphs])\n",
    "            full_connect = layers.Activation(activation)(full_connect)\n",
    "            if resnet:\n",
    "                full_connect = layers.Concatenate()([fc_in, full_connect])\n",
    "        return full_connect\n",
    "\n",
    "    def DNN_DataSet(self, df, neg_aug = 0):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if self.model_type == 'DEM' or self.model_type == 'I2A' or self.model_type == 'AE':\n",
    "#             return create_dem_data(df) + [extract_array_from_series(df['target'])]\n",
    "            return create_dem_data(df) + [sklearn.preprocessing.normalize(extract_array_from_series(df['target']))]\n",
    "        elif self.model_type == 'DEM_AUG':\n",
    "            return [preprocess_img(df['img'])] + create_dem_data(df)\n",
    "        elif self.model_type == 'GCN':\n",
    "            return [create_gcn_data(df, self.class_to_id), \n",
    "                    sklearn.preprocessing.normalize(extract_array_from_series(df['target']))]\n",
    "        elif self.model_type == 'DEM_BC':\n",
    "            return create_dem_bc_data(df, neg_aug, self.only_emb, \n",
    "                class_id_emb_attr = self.class_id_emb_attr[self.class_id_emb_attr.class_id.isin(self.seen_class)],\n",
    "                c2c_neg_cnt = self.c2c_neg_cnt)\n",
    "        elif self.model_type == 'QFSL':\n",
    "            return create_qfsl_data(df, self.class_to_id)\n",
    "\n",
    "    def lgbm_train(self, train_part, train_part_label, valide_part, valide_part_label, fold_seed = None,\n",
    "        fold = 5, train_weight = None, valide_weight = None, flags = None):\n",
    "        \"\"\"\n",
    "        LGBM Training\n",
    "        \"\"\"\n",
    "        print(\"-----LGBM training-----\")\n",
    "\n",
    "        d_train = lgb.Dataset(train_part, train_part_label)\n",
    "        d_valide = lgb.Dataset(valide_part, valide_part_label)\n",
    "        params = {\n",
    "                'task': 'train',\n",
    "                'boosting_type': 'gbdt', #'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': ['auc', 'binary_logloss'],\n",
    "                'num_leaves': 7, #60, #40, # 60,\n",
    "#                 'min_sum_hessian_in_leaf': 10,\n",
    "                'max_depth': 3,#12, #6, # 10,\n",
    "                'learning_rate': 1, # 0.025,\n",
    "               # 'feature_fraction': 0.5,#0.35, # 0.6\n",
    "                'verbose': 0,\n",
    "                'num_boost_round': 800, #361,\n",
    "#                 'feature_fraction_seed': fold_seed,\n",
    "                #'drop_rate': 0.05,\n",
    "                # 'bagging_fraction': 0.8,\n",
    "                # 'bagging_freq': 20,\n",
    "                # 'bagging_seed': fold_seed,\n",
    "                 'early_stopping_round': 1500,\n",
    "                # 'random_state': 10\n",
    "                # 'verbose_eval': 20\n",
    "                #'min_data_in_leaf': 665\n",
    "            }\n",
    "#         params.update(config.all_params)\n",
    "        print (\"lightgbm params: {0}\\n\".format(params))\n",
    "\n",
    "        bst = lgb.train(\n",
    "                        params ,\n",
    "                        d_train,\n",
    "                        verbose_eval = 200,\n",
    "                        valid_sets = [d_train, d_valide],\n",
    "                        # feature_name= keras_train.DENSE_FEATURE_LIST,\n",
    "                        #feval = gini_lgbm\n",
    "                        #num_boost_round = 1\n",
    "                        )\n",
    "        return bst\n",
    "\n",
    "    def train(self, train_part_df, validate_part_df):\n",
    "        \"\"\"\n",
    "        Keras Training\n",
    "        \"\"\"\n",
    "        print(\"-----DNN training-----\")\n",
    "\n",
    "        DNN_Train_Data = self.DNN_DataSet(train_part_df, neg_aug = 2)\n",
    "        DNN_validate_Data = self.DNN_DataSet(validate_part_df)\n",
    "        \n",
    "        callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=self.patience, verbose=0),\n",
    "        AccuracyEvaluation(validation_data=DNN_validate_Data, interval=1,\n",
    "                            cand_class_id_emb_attr = self.cand_class_id_emb_attr,\n",
    "                            eval_df = validate_part_df,\n",
    "                            model_type = self.model_type,\n",
    "                            class_id_dict = self.class_id_dict,\n",
    "                            class_to_id = self.class_to_id,\n",
    "                            TTA = self.TTA,\n",
    "                            img_model = self.img_model,\n",
    "                          only_emb = self.only_emb)\n",
    "        ]\n",
    "        if self.model_type == 'DEM_AUG':\n",
    "            datagen = MixedImageDataGenerator(\n",
    "                    rotation_range=20,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "            datagen.fit(DNN_Train_Data[0])\n",
    "#             print (DNN_Train_Data[0])\n",
    "            h = self.model.fit_generator(\n",
    "                    datagen.flow((DNN_Train_Data[0], DNN_Train_Data[1:]), None, batch_size=self.batch_size), \n",
    "                    validation_data=(DNN_validate_Data, None), steps_per_epoch = DNN_Train_Data[0].shape[0]//self.batch_size,\n",
    "                    epochs=self.epochs, shuffle=True, verbose = self.verbose, workers=1, use_multiprocessing=False, \n",
    "                    callbacks=callbacks)\n",
    "#         elif self.model_type == 'DEM_BC':\n",
    "#             h = self.model.fit(DNN_Train_Data[0],  DNN_Train_Data[1], validation_data = DNN_validate_Data,\n",
    "#                         epochs=self.epochs, batch_size = self.batch_size, shuffle=True, verbose = self.verbose, callbacks=callbacks)\n",
    "        else:\n",
    "            h = self.model.fit(DNN_Train_Data,  validation_data = (DNN_validate_Data, None),\n",
    "                        epochs=self.epochs, batch_size = self.batch_size, shuffle=True, verbose = self.verbose, callbacks=callbacks)\n",
    "        self.scores.append(pd.DataFrame(h.history))\n",
    "        \n",
    "#         zs_model = Model(inputs = self.model.inputs[1:3], outputs = self.model.outputs[0])\n",
    "#         train_attr_x_img = zs_model.predict(DNN_Train_Data[1:3], verbose = 1)\n",
    "#         train_label = DNN_Train_Data[-1].flatten()\n",
    "#         validate_attr_x_img = zs_model.predict(DNN_validate_Data[1:3], verbose = 1)\n",
    "#         validate_label = DNN_validate_Data[-1].flatten()\n",
    "# #         print (train_label)\n",
    "# #         print (validate_label)\n",
    "#         bst = self.lgbm_train(train_attr_x_img, train_label, validate_attr_x_img, validate_label)\n",
    "        \n",
    "#         cand_feature_map = zs_model.predict(create_dem_data(self.cand_class_id_emb_attr, only_emb = self.only_emb), \n",
    "#                                             verbose = 1)\n",
    "        \n",
    "#         attr_x_img_model = Model(inputs = self.model.get_layer('attr_x_img_model').inputs, \n",
    "#                          outputs = self.model.get_layer('attr_x_img_model').outputs)\n",
    "#         pred = find_nearest_class(self.cand_class_id_emb_attr, \n",
    "#                                   validate_part_df, \n",
    "#                                   cand_feature_map = cand_feature_map, \n",
    "#                                 img_feature_map = DNN_validate_Data[0],\n",
    "#                                 zs_model = bst, model_type = 'lgb')\n",
    "#         calc_detailed_accuracy(validate_part_df, pred, self.class_id_dict)\n",
    "        \n",
    "        return self.model\n",
    "\n",
    "    def predict(self, test_part, batch_size = 1024, verbose=2):\n",
    "        \"\"\"\n",
    "        Keras Training\n",
    "        \"\"\"\n",
    "        print(\"-----DNN Test-----\")\n",
    "        pred = self.model.predict(self.DNN_DataSet(test_part), verbose=verbose)\n",
    "        if self.model_type == 'r':\n",
    "            pred = pred[:, -1]\n",
    "        return pred\n",
    "\n",
    "def train_zs_model(train_data, class_id_emb_attr, flags, img_flat_len,\n",
    "                   round1_class_id = None,\n",
    "                   round2_class_id = None,\n",
    "                   img_model = None):\n",
    "    print(\"Over all training size:\")\n",
    "    print(train_data.shape)\n",
    "\n",
    "    fold = 10 #flags.dem_nfold\n",
    "    ensemble_nfold = 10 #flags.dem_ensemble_nfold\n",
    "    kf = KFold(n_splits=fold, shuffle=True, random_state = 100)\n",
    "    num_fold = 0\n",
    "    models = []\n",
    "    model_type = 'DEM_BC'\n",
    "    scores = []\n",
    "    classes = train_data.class_id.unique()\n",
    "    model_file_names_0 = glob.glob(path + '../submit/image_05108_10fold_zs_DEMBC_02161/zsmodel_*.h5')\n",
    "    model_file_names_1 = glob.glob(path + '../submit/image_05108_10fold_zs_DEMBC_negaug5_/zsmodel_*.h5')\n",
    "    model_file_names_2 = glob.glob(path + '../submit/image_05108_10fold_zs_DEMBC_negaug2_/zsmodel_*.h5')\n",
    "    model_file_names = [model_file_names_0, model_file_names_1, model_file_names_2]\n",
    "    \n",
    "    for train_index, test_index in kf.split(classes):\n",
    "        print ('Fold: ', num_fold)\n",
    "        seen_class = classes[train_index]\n",
    "        unseen_class = classes[test_index]\n",
    "        \n",
    "        train_part_df = train_data[train_data.class_id.isin(seen_class)]\n",
    "        validate_part_df = train_data[train_data.class_id.isin(unseen_class)]\n",
    "\n",
    "        seen_round1_id = np.intersect1d(seen_class, round1_class_id)\n",
    "        seen_round2_id = np.intersect1d(seen_class, round2_class_id)\n",
    "        unseen_round1_id = np.intersect1d(unseen_class, round1_class_id)\n",
    "        unseen_round2_id = np.intersect1d(unseen_class, round2_class_id)\n",
    "        print ('Seen unseen Classes: ', seen_class.shape[0], unseen_class.shape[0])\n",
    "        print ('Seen round1, round2: ', seen_round1_id.shape[0], seen_round2_id.shape[0])\n",
    "        print ('Unseen round1, round2: ', unseen_round1_id.shape[0], unseen_round2_id.shape[0])\n",
    "\n",
    "        zs_model = DEM(scores = scores, flags = flags, model_type = model_type, \n",
    "                    seen_class = seen_class, img_flat_len = img_flat_len, \n",
    "                    unseen_class = unseen_class,\n",
    "                    class_id_emb_attr = class_id_emb_attr,\n",
    "                    unseen_round1_id = unseen_round1_id,\n",
    "                    unseen_round2_id = unseen_round2_id,\n",
    "                    img_model = img_model,\n",
    "                    only_emb = True,\n",
    "                      c2c_neg_cnt = None)\n",
    "        \n",
    "        if num_fold == 0:\n",
    "            print (zs_model.model.summary())\n",
    "        zs_model.train(train_part_df, validate_part_df)\n",
    "        models.append((zs_model.model, model_type))\n",
    "        \n",
    "#         for model_files in model_file_names:\n",
    "#             zs_model = DEM(scores = scores, flags = flags, model_type = model_type, \n",
    "#                         seen_class = seen_class, img_flat_len = img_flat_len, \n",
    "#                         unseen_class = unseen_class,\n",
    "#                         class_id_emb_attr = class_id_emb_attr,\n",
    "#                         unseen_round1_id = unseen_round1_id,\n",
    "#                         unseen_round2_id = unseen_round2_id,\n",
    "#                         img_model = img_model)\n",
    "#             print ('model file name: ', model_files[num_fold])\n",
    "#             zs_model.model.load_weights(model_files[num_fold])\n",
    "#             zs_model.model.trainable = False\n",
    "# #             model_eval(zs_model.model, model_type, validate_part_df, \n",
    "# #                        cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \n",
    "# #                     img_feature_map = extract_array_from_series(validate_part_df['target']),\n",
    "# #                     class_id_dict = {\n",
    "# #     #                              'seen_class': seen_class,\n",
    "# #                                  'Unseen_class': unseen_class,\n",
    "# #     #                              'Unseen_round1_id': unseen_round1_id,\n",
    "# #                                  'Unseen_round2_id': unseen_round2_id,},\n",
    "# #                     class_to_id = dict([(c, i) for i, c in enumerate(class_id_emb_attr.class_id.values)]))\n",
    "#             models.append((zs_model.model, model_type))\n",
    "#         print ('Multi models votes-------')\n",
    "#         multi_models_vote(models = models[-3:], \n",
    "#                       eval_df = validate_part_df,\n",
    "#                     cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)],\n",
    "#                     img_feature_map = extract_array_from_series(validate_part_df['target']), \n",
    "#                     class_id_dict = {\n",
    "#                          'Unseen_class': unseen_class,\n",
    "#                          'Unseen_round2_id': unseen_round2_id,})\n",
    "        \n",
    "        num_fold += 1\n",
    "        if num_fold == ensemble_nfold:\n",
    "            break\n",
    "    return models\n",
    "\n",
    "# img_model = DenseNet(scores = None, \n",
    "#              cat_max = 365, #flags.cat_max, \n",
    "#              flags = None, \n",
    "#              model_type = 'DenseNet').model\n",
    "# img_model.load_weights(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05108_TF14_DensetNetProcess/imgmodel_20181013_092715.h5')\n",
    "# img_flat_model = Model(inputs = img_model.inputs, outputs = img_model.get_layer(name = 'avg_pool').output)\n",
    "img_flat_model = None\n",
    "\n",
    "round1_class_id = list(set(train_data.class_id.unique()) - set(round2_class_id))\n",
    "zs_models = train_zs_model(train_data[train_data.class_id.isin(round2_class_id)], \n",
    "       class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(round2_class_id)], \n",
    "       flags = None, \n",
    "       img_flat_len = 1032,                     \n",
    "       round1_class_id = round1_class_id,\n",
    "       round2_class_id = round2_class_id,\n",
    "       img_model = img_flat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(round2_class_id)]\n",
    "cand_class_id_emb_attr = cand_class_id_emb_attr[~cand_class_id_emb_attr.class_id.isin(train_data.class_id.unique())]\n",
    "vote_preds = multi_models_vote(models = zs_models[-3:], \n",
    "                      eval_df = test_data,\n",
    "                    cand_class_id_emb_attr = cand_class_id_emb_attr,\n",
    "                    img_feature_map = extract_array_from_series(test_data['target']))\n",
    "sub = pd.DataFrame(vote_preds, index = test_data['img_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_label = time.strftime('%Y%m%d_%H%M%S')\n",
    "sub.to_csv(path + \"../submit/submit_\"+ time_label + \".txt\", header = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 11915\n",
      "class size  365\n",
      "\n",
      "Initializing search.\n",
      "Initialization finished.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 0               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "Saving model.\n",
      "+--------------------------------------------------------------------------+\n",
      "|        Model ID        |          Loss          |      Metric Value      |\n",
      "+--------------------------------------------------------------------------+\n",
      "|           0            |    70.7620168685913    |  0.009264853977844914  |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 1               |\n",
      "+----------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fd/study/TC/ZJC/sub/code/autokeras/bayesian.py:151: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+--------------------------------------------------------------------------+\n",
      "|    Father Model ID     |                 Added Operation                 |\n",
      "+--------------------------------------------------------------------------+\n",
      "|           0            |           ('to_add_skip_model', 1, 5)           |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "Saving model.\n",
      "+--------------------------------------------------------------------------+\n",
      "|        Model ID        |          Loss          |      Metric Value      |\n",
      "+--------------------------------------------------------------------------+\n",
      "|           1            |   58.29625339508057    |  0.007452165156092649  |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 2               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "+--------------------------------------------------------------------------+\n",
      "|    Father Model ID     |                 Added Operation                 |\n",
      "+--------------------------------------------------------------------------+\n",
      "|                        |          ('to_conv_deeper_model', 9, 3)         |\n",
      "|                        |          ('to_conv_deeper_model', 1, 3)         |\n",
      "|                        |           ('to_add_skip_model', 5, 9)           |\n",
      "|                        |          ('to_concat_skip_model', 5, 9)         |\n",
      "|           0            |            ('to_wider_model', 14, 64)           |\n",
      "|                        |            ('to_wider_model', 9, 64)            |\n",
      "|                        |            ('to_wider_model', 9, 128)           |\n",
      "|                        |          ('to_conv_deeper_model', 1, 3)         |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "Saving model.\n",
      "+--------------------------------------------------------------------------+\n",
      "|        Model ID        |          Loss          |      Metric Value      |\n",
      "+--------------------------------------------------------------------------+\n",
      "|           2            |   104.62083415985107   |  0.007250755287009064  |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 3               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "+--------------------------------------------------------------------------+\n",
      "|    Father Model ID     |                 Added Operation                 |\n",
      "+--------------------------------------------------------------------------+\n",
      "|                        |          ('to_conv_deeper_model', 9, 3)         |\n",
      "|                        |         ('to_conv_deeper_model', 18, 3)         |\n",
      "|                        |           ('to_add_skip_model', 5, 18)          |\n",
      "|                        |            ('to_wider_model', 14, 64)           |\n",
      "|                        |          ('to_concat_skip_model', 5, 9)         |\n",
      "|                        |           ('to_add_skip_model', 1, 18)          |\n",
      "|                        |         ('to_concat_skip_model', 1, 18)         |\n",
      "|           0            |           ('to_add_skip_model', 9, 18)          |\n",
      "|                        |          ('to_concat_skip_model', 1, 5)         |\n",
      "|                        |         ('to_concat_skip_model', 5, 18)         |\n",
      "|                        |          ('to_concat_skip_model', 1, 9)         |\n",
      "|                        |         ('to_concat_skip_model', 9, 18)         |\n",
      "|                        |           ('to_add_skip_model', 1, 9)           |\n",
      "|                        |          ('to_conv_deeper_model', 9, 3)         |\n",
      "|                        |           ('to_add_skip_model', 1, 5)           |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "Saving model.\n",
      "+--------------------------------------------------------------------------+\n",
      "|        Model ID        |          Loss          |      Metric Value      |\n",
      "+--------------------------------------------------------------------------+\n",
      "|           3            |   125.46946926116944   |  0.00825780463242699   |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 4               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "+--------------------------------------------------------------------------+\n",
      "|    Father Model ID     |                 Added Operation                 |\n",
      "+--------------------------------------------------------------------------+\n",
      "|                        |          ('to_conv_deeper_model', 5, 3)         |\n",
      "|                        |         ('to_conv_deeper_model', 18, 3)         |\n",
      "|                        |            ('to_wider_model', 1, 64)            |\n",
      "|                        |           ('to_add_skip_model', 1, 21)          |\n",
      "|                        |          ('to_add_skip_model', 18, 21)          |\n",
      "|           0            |            ('to_wider_model', 1, 128)           |\n",
      "|                        |         ('to_concat_skip_model', 1, 21)         |\n",
      "|                        |          ('to_conv_deeper_model', 1, 3)         |\n",
      "|                        |           ('to_add_skip_model', 1, 5)           |\n",
      "|                        |            ('to_wider_model', 14, 64)           |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "Saving model.\n",
      "+--------------------------------------------------------------------------+\n",
      "|        Model ID        |          Loss          |      Metric Value      |\n",
      "+--------------------------------------------------------------------------+\n",
      "|           4            |   135.45114707946777   |  0.007653575025176234  |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 5               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "Current model size is too big. Discontinuing training this model to search for other models.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 5               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "Current model size is too big. Discontinuing training this model to search for other models.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 5               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "Current model size is too big. Discontinuing training this model to search for other models.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 5               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "Current model size is too big. Discontinuing training this model to search for other models.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 5               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "Current model size is too big. Discontinuing training this model to search for other models.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 5               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "Current model size is too big. Discontinuing training this model to search for other models.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 5               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "Current model size is too big. Discontinuing training this model to search for other models.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 5               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "Current model size is too big. Discontinuing training this model to search for other models.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 5               |\n",
      "+----------------------------------------------+\n",
      "\n",
      "Current model size is too big. Discontinuing training this model to search for other models.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 5               |\n",
      "+----------------------------------------------+\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ad54327e5733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_part_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcategory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# y_test = test_part_data['class_id'].apply(lambda id: category_dict[id]).values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# results = clf.predict(x_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/study/TC/ZJC/sub/code/autokeras/image_supervised.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, x_test, y_test, time_limit)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mtime_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_output_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/study/TC/ZJC/sub/code/autokeras/cnn_module.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_output_node, input_shape, train_data, test_data, time_limit)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mtime_remain\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0m_run_searcher_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_remain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_searcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_MODEL_NUM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/study/TC/ZJC/sub/code/autokeras/cnn_module.py\u001b[0m in \u001b[0;36m_run_searcher_once\u001b[0;34m(train_data, test_data, path, timeout)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msearcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'searcher'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0msearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/study/TC/ZJC/sub/code/autokeras/search.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, train_data, test_data, timeout)\u001b[0m\n\u001b[1;32m    192\u001b[0m                     new_graph, new_father_id = self.bo.optimize_acq(self.search_tree.adj_list.keys(),\n\u001b[1;32m    193\u001b[0m                                                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                                                                     remaining_time)\n\u001b[0m\u001b[1;32m    195\u001b[0m                 \u001b[0mnew_model_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/study/TC/ZJC/sub/code/autokeras/bayesian.py\u001b[0m in \u001b[0;36moptimize_acq\u001b[0;34m(self, model_ids, descriptors, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_exp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0map\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mtemp_graph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcontain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/study/TC/ZJC/sub/code/autokeras/net_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mtemp_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mtemp_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_deeper_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mtemp_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_wider_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/study/TC/ZJC/sub/code/autokeras/net_transformer.py\u001b[0m in \u001b[0;36mto_deeper_graph\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Conv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_conv_deeper_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense_deeper_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/study/TC/ZJC/sub/code/autokeras/graph.py\u001b[0m in \u001b[0;36mto_conv_deeper_model\u001b[0;34m(self, target_id, kernel_size)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'to_conv_deeper_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mnew_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeeper_conv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0moutput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_block_end_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/study/TC/ZJC/sub/code/autokeras/layer_transformer.py\u001b[0m in \u001b[0;36mdeeper_conv_block\u001b[0;34m(conv_layer, kernel_size, weighted)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfilter_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mn_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_filters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilter_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# del test_data\n",
    "import autokeras as ak\n",
    "\n",
    "clf = ak.ImageClassifier(verbose = True)\n",
    "fold = 10 #flags.dem_nfold\n",
    "ensemble_nfold = 10 #flags.dem_ensemble_nfold\n",
    "kf = KFold(n_splits=fold, shuffle=True, random_state = 100)\n",
    "for train_index, test_index in kf.split(train_data):\n",
    "    train_part_data = train_data.iloc[test_index]\n",
    "#     test_part_data = train_data.iloc[test_index]\n",
    "#     del train_data\n",
    "    break\n",
    "print ('train size', train_part_data.shape[0])\n",
    "x_train = preprocess_img(train_part_data['img'])\n",
    "# x_test = preprocess_img(test_part_data['img'])\n",
    "\n",
    "category = train_part_data['class_id'].unique()\n",
    "print ('class size ', category.shape[0])\n",
    "category_dict = dict((category[i], i) for i in range(category.shape[0]))\n",
    "y_train = train_part_data['class_id'].apply(lambda id: category_dict[id]).values\n",
    "# y_test = test_part_data['class_id'].apply(lambda id: category_dict[id]).values\n",
    "clf.fit(x_train, y_train)\n",
    "# results = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((2, 2)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Re</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.386247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.414385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.394172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.399457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.402835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.404664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.389624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.396466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.372984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.384961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.356423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.361039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.349638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.337431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.351447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.341436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.336275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.333961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.316138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Re\n",
       "Epoch          \n",
       "1      0.386247\n",
       "2      0.414385\n",
       "3      0.396310\n",
       "4      0.394172\n",
       "5      0.399457\n",
       "6      0.402835\n",
       "7      0.404664\n",
       "8      0.389624\n",
       "9      0.396466\n",
       "10     0.372984\n",
       "11     0.384961\n",
       "12     0.356423\n",
       "13     0.361039\n",
       "14     0.349638\n",
       "15     0.337431\n",
       "16     0.351447\n",
       "17     0.341436\n",
       "18     0.336275\n",
       "19     0.333961\n",
       "20     0.316138"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEWCAYAAACKSkfIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XdYVMf6wPHv0DsqzYICNhAFEbB3TSyxxmiMGmNictM01cSY3PuL5qaYYkxuejMxRWNijaLGWLBXsKCiFBVRVARUpJdlfn8cRJC2dGTn8zw82T17zpx3wbx7ds7MO0JKiaIoimIYjOo6AEVRFKX2qKSvKIpiQFTSVxRFMSAq6SuKohgQlfQVRVEMiEr6iqIoBkQlfUVRFAOikr6iKIoBUUlfURTFgKikrxgUIUSMEOJVIUSYECJNCLFICOEihNgohEgRQmwRQjTO37eHEGKvEOKGEOKYEGJAoXYeE0Kcyj/mrBDiqUKvDRBCXBRCzBJCXBVCXBZCPFYHb1dRilFJXzFEDwD3Au2BUcBG4A3ACe3/ieeFEC2A9cA7QBPgFWClEMIpv42rwEjADngM+EQI4V/oHE0Be6AF8Djw5a0PE0WpSyrpK4bocyllvJQyDtgFHJBSHpFSZgKrgS7Aw8AGKeUGKWWelHIzEALcByClXC+lPCM1O4B/gL6FzpED/FdKmSOl3ACkAp619xYVpWQq6SuGKL7Q44wSntsAbsCE/K6dG0KIG0AfoBmAEGK4EGK/EOJa/mv3AY6F2kmSUuYWep6e366i1CmTug5AUeqpC8CvUsp/3fmCEMIcWAk8AvwlpcwRQqwBRC3HqCgVpq70FaVkvwGjhBBDhRDGQgiL/Bu0roAZYA4kALlCiOHAkLoMVlH0pZK+opRASnkBGIN2gzcB7cr/VcBISpkCPA/8CVwHJgNr6yhURakQoRZRURRFMRzqSl9RFMWAqKSvKIpiQFTSVxRFMSAq6SuKohiQejdO39HRUbq7u9d1GKVKS0vD2tq6rsMolYqvalR8VaPiq5qqxBcaGpoopXQqd0cpZb36CQgIkPVZcHBwXYdQJhVf1aj4qkbFVzVViQ8IkXrkWNW9oyiKYkBU0lcURTEgKukriqIYkHp3I1dRlPonJyeHixcvkpmZWeZ+9vb2nDp1qpaiqriGEJ+FhQWurq6YmppW6hwq6SuKUq6LFy9ia2uLu7s7QpReTDQlJQVbW9tajKxi7vb4pJQkJSVx8eJFPDw8KnUO1b2jKEq5MjMzcXBwKDPhKzVPCIGDg0O537jKopK+oih6UQm/fqjq30El/Xy6PMnSA7GkZeWWv7OiKMpdSiX9fDsir/LG6uN8v+tsXYeiKAZFCMGsWbMKni9YsIB58+bV6Dnd3d154IEHCp6vWLGCRx99tEbPWV+opJ9ve0QCAL/tP09mjq6Oo1EUw2Fubs6qVatITEys1fOGhoYSHh5eq+esD1TSz7cjMgEXO3MSU7NZd+xSXYejKAbDxMSEJ598kk8++aTYazExMQwaNAhfX18GDx5MbGwsAI8++ijPP/88vXr1onXr1qxYsaLgmI8++oiuXbvi6+vL3LlzSz3vrFmzePfdd4ttv3btGmPHjsXX15cePXoQFhYGwLx585g+fToDBgygdevWfPbZZwXH/Pbbb3Tr1g0/Pz+eeuopdLr6e+Gokj4Qk5jG+aR0nh3QFk8XWxbtPodUK4opSq2ZMWMGS5YsITk5ucj25557jmnTphEWFsaUKVN4/vnnC167fPkyu3fvJigoiDlz5gDwzz//EBUVxcGDBzl69CihoaHs3LmzxHM++OCDHD58mOjo6CLb586dS5cuXQgLC+O9997jkUceKXjt9OnTbNq0iYMHD/LWW2+Rk5PDqVOn+OOPP9izZw9Hjx7F2NiYJUuWVNevptqppA9sj7gKwEBPZ6b3cef0lRT2nUmq46gUxXDY2dnxyCOPFLl6Bti3bx+TJ08GYOrUqezevbvgtbFjx2JkZIS3tzfx8fGAlvT/+ecfunTpgr+/P6dPnyYqKqrEcxobG/Pqq68yf/78Itt3797N1KlTARg0aBBJSUncvHkTgBEjRmBubo6joyPOzs7Ex8ezdetWQkND6dq1K35+fmzdupWzZ+vvvUE1OQuta8fD0ZpWDlY427Xgg78jWLT7HL3aOtZ1aIpiMF588UX8/f157LHH9Nrf3Ny84PGtb+ZSSl5//XWeeuopvdqYOnUq8+fPp1OnThU+p7GxMbm5uUgpmTZtWrEPj/rK4K/0M3N07DubRP/2WhlqC1NjHu7eiq2nr3IuMa2Oo1MUw9GkSRMefPBBFi1aVLCtV69eLFu2DIAlS5bQt2/fMtsYOnQoP/74I6mpqQDExcVx9ar2TX7w4MFculT0fp2pqSkvvfRSkfsJffv2Leie2b59O46OjtjZ2ZV6zsGDB7NixYqC81y7do3z58/r+7ZrncEn/YPnrpGZk0d/z9trDzzc0w0zYyN+2nOuDiO7i0gJJ9fAN33gVFBdR6PcxWbNmlVkFM/nn3/OTz/9hK+vL7/++iv/+9//yjx+yJAhTJ48mZ49e+Lj48P48eNJSUkhLy+P6OhoGjduXOyYxx9/nNzc2/Nz5s2bR2hoKL6+vsyZM4eff/65zHN6e3vzzjvvMGTIEHx9fbn33nu5fPlyBd957TH47p3tEQmYmRjRw8OhYJuzrQWjOjdnechFZt3rib1V5QobGYRrZ2HDqxC9BYxMYc2z0MwXGrWq68iUu8Stq3IAFxcX0tPTC567ubmxbdu2YscsXry41DZeeOEFXnjhhSKvnzhxggceeABLS0tAGxV0i7m5eZFvAE2aNGHNmjXFznnn3IETJ04UPJ44cSITJ04s4d3VPwZ/pb8j8io9WjtgaWZcZPvjfTzIyNGx7FBsHUVWz+VmwY4P4aueEHsAhn0Az+4HqYNVT0Fe/R2yphieTp06sXDhwroOo14w6KR/4Vo6ZxLSCvrzC/NubkfP1g78vDeGXF1eHURXj53dDl/3guB3wXM4zDwEPZ4Gx7Zw3wKI3Qu71P9gilIfGXTS3xGpzcItKekDTO/jwaXkTDaeuFKbYdVfKfGw4nH4ZYx2Jf/wKpiwGOya3d6n80PQaTxsnw8XDtVZqIqilMzgk75rY0vaOJW8+vxgL2fcHaxYtNvAb+jm6eDAd/BFIJxaC/3naF05bQcX31cIGLkQ7FrAysch82btx6soSqkMNuln5+axNzqR/u2dSi1VamQkeKy3B0cv3OBw7PVajrCeiDsM3w+Cja9CiwAt2Q98HUwtSj/Gwh4e+B6SL2g3eRVFqTcMNumHnL9GWraOAZ7OZe43PsAVWwsTw7vaz7gB62dpCT/lCoz/EaauBoc2+h3fqgf0mw1hyyBsec3GqiiK3gx2yOaOiARMjQU92ziUuZ+1uQmTurVi0e5zxN3IqKXo6pCUcHw5bPo3pCdC96dg4Bva1XtF9XsVzgbD+pehZVdo7F7t4SqKUjEGe6W/IzKBru5NsDEv/3NvWi93AH7eG1OzQdW1hEj4ZTSs+hfYu8K/gmH4B5VL+ADGJjDuO+3xqidBpxaoUSovIyOD/v37o9PpiImJwdLSEj8/P7y9vXnkkUfIycmp6xD19sorr5Q4/6A2GGTSv5KcyekrKaWO2rlTi0aWDOvUlN8PxpKZ20Cqb+ZkwIWDsP9rWPkEfNYFvuwKl47BiI/hiS3Q3K/q52nsDiMWwoUDsPOjqrenGKwff/yRcePGYWyszalp06YNR48e5fjx41y8eJE///yzjiPU33PPPcf7779fJ+c2yO6dHZFajYzCpRfK83gfD9aHXWZ3nBHDaiqwmpKng8RIiAu9/RN/EvLyr7ztWkALf/B/BPymgE3Z9zkqzHeCNmN354fY+b0HDKje9pVa9da6k4RfKnlUlk6nK0jKFeHd3I65ozqWuc+SJUtYunRpse3GxsZ069aNuLi4ghjmzJnD9u3bycrKYsaMGeUWYLOxseGZZ55hw4YNNGvWjPfee4/Zs2cTGxvLp59+yujRo0ttNzU1lTFjxnD9+nVycnJ45513GDNmDDExMQwfPpw+ffqwd+9eWrRowV9//YWlpSVubm4kJSVx5coVmjZtWuHfV1UY5JX+jsgEmtpZ4Olie3vj9fPwsRec31viMf6tGuPXshGbz+eQl1ePr/alhOSLEP4XbH4TFo+E91vBVz3grxlwfAVYNILeL8BDS+Hl0/ByOEz8Dfq8VKGEn5GtY//ZJL4Mjuaxnw7S472tbA6PL3nn+z6CRq3wDl8Imckl76MopcjOzubs2bO4u7sXey0zM5MDBw4wbJh2ObZo0SLs7e05dOgQhw4d4vvvv+fcubIHYqSlpTFo0CBOnjyJra0t//nPf9i8eTOrV6/mzTffLLNdCwsLVq9ezeHDhwkODmbWrFkFVT+joqKYMWMGJ0+epFGjRqxcubLgnP7+/uzZs6eafkP6M7gr/VxdHruiErmvU7OiQzVProKUy7BzAUxdVeKxj/fx4Lnfj7D19FXu9XappYj1lJMBQS/T89RG2JE/vNTIFJr6QOdJ2nDLFgHg0BaMKvdZf/VmJiHnrxMSc53Q89c4eekmufkfgLfmOryzPpwBnk6YGt9xDgs7GPcD5ouGQNDL8MAP2ph+5a5T1hV5SkoKtra2pb5eWYmJiTRq1KjItjNnzuDn58e5c+cYMWIEvr6+gFZTPywsrGA1reTkZKKiovDw8Ci1fTMzs4IPDR8fH8zNzTE1NcXHx6egTk9p7bq6uvLGG2+wc+dOjIyMiIuLK6jv7+HhgZ+f1k0aEBBQpOaPs7NzsaqftcHgkv6RCzdIycxlwJ1dO6eCAAFntkJ8OLh4Fzt2eKemNLEQ/Lj7XP1L+mF/wrGlJDv1xjlwrJbgm3YCE/Pyjy2BLk8SGZ9CyPnrhMZcIzT2OheuaaOXzE2M6OzaiH/1a02gW2P8WzWmsbUZ207HM31xCH+GXGBKd7fijbbsSoz7JDxOLIF292qzdxVFD5aWlmRmZhbZdqtPPzExkd69e7N27VpGjx6NlJLPP/+coUOH6t2+qalpwUWgkZFRQd18IyOjggqcpbW7ePFiEhISCA0NxdTUFHd394JY76y/n5FxewRgZmZmQQG42mRwSX97xFWMjUTRBVJuXoK4EOg5Ew4tgv1fwZgvih1rYmzEPW4m/BmRxMlLyXRsXslRLdVNSjj4Hbh0ItzrVZy7D6xwE3l5kkMx1zhw7hoh569z5Px1UrK0f+yONuYEujVmWk93Atwa07G5PWYmxb8tDPR0JtCtMf/bEsW4Lq7FitgBnHd7AI+8c7D+FWjZDZq0rvj7VQxO48aN0el0ZGZmYmFRdGKgo6Mj77//PvPnz2f06NEMHTqUr7/+mkGDBmFqakpkZCQtWrTA2tqagIAAIiMjKxVDae0mJyfj7OyMqakpwcHBetfSj4yMZMKECZWKpSoMLunviEwgoFVj7C0LlUs+vV77b5epWjfJkd9g8Jsl9m/3dzVl3dk8ftwdw8cPdq6lqMtxfg/En4BRn0FKxbpMUjJzWBl6kV/2nedsYhpCQHtnW0b5NSfQrTEBbo1p1cSq1FnLhQkheG24FxO+2cfP+2J4un8JE7mEsTaM8+vesPJfMP1vMFalq5XyDRkyhN27d3PPPfcUe23s2LHMmzePXbt28cQTTxATE4O/vz9SSpycnFizZg2JiYlVWvu6tHanTJnCqFGj8PHxITAwEC8vr3LbysnJITo6msDAwErHU2lSynr1ExAQIGvK1ZuZ0u21IPnFtqiiL/w8WsrP/KXMy5MyIUrKufZSbnuvxDaCg4Pl/605Ltu9sUHG38yosVgrZNnDUr7vJmVWmgwODtbrkKj4FPl/a45L7//bKN1eC5Jjv9wtVx2+IG+kZ1c5nEd/PCB9520qsa2C+I6vlHKunZRb367y+aqTvr+/ulJX8YWHh+u1382bN2sshtDQUPnwww9X+vh169bJDz74oBojqrxVq1bJ//znP8W26/v7K+nvAYRIPXKsQY3e2VlSVc2M6xCzG7xGajcWHdtq5YIPfa9d9Zfgsd4e5OTl8dv+elBr/8YFOB2kDbc0sypzV12eZHN4PA//cIB7Fu5g2cELDO3UlLUze7P62d7c38W16DegSnp1qBfJGTl8t/NM6Tt1GqcND931McTU/ggG5e7j7+/PwIED0ekqt1bDyJEjeeaZZ6o5qsrJzc1l1qxZdXJuvZK+EGKYECJCCBEthJhTxn4PCCGkECKw0LbX84+LEELof2elBuyITMDRxhzvZoXWu4zcpI1X7zDq9raeMyA9CcL+KLEdD0drBns5s2T/eTJz6nixkJD89US7PlHqLjfSs/l2xxn6fxTMv34J4UxCKq8O9WTf64NY+KAfvq6NSj22Mryb2zG6c3N+3B3D1ZTM0ncc/oE2eWvVk9qHr6KUY/r06ZWaB1DfTJgwodhopNpSbtIXQhgDXwLDAW9gkhCi2NAWIYQt8AJwoNA2b+AhoCMwDPgqv71ap8uT7IxKoF97R4yMCvVPn1oHts2guf/tbW69oVln2PcV5JW8gMr0Ph4kpWXz19G4Go68DDkZEPozeN5X4vKE4Zdu8tqKMLq/t5X5G0/TopElX0/xZ9fsgcwY2BYHm8qN7NHHy/e2J0eXxxfbokvfydxWG7qZegWCXtJuSCuKUqP0udLvBkRLKc9KKbOBZcCYEvZ7G/gAKHxpNwZYJqXMklKeA6Lz26t1YRdvcCM9p2hVzex0iN4KXiOKjl0XQhvJkxihDeEsQc/WDng1tWXR7nNVujlUJcdXQMY1rShavtw8SVDYJR78Zh/3fbaLtccuMc7flb9f7MsfT/VkuE8zTO4cQ18D3B2tmdi1JUsPxBKblF76ji0CYOC/4eRqOFp8tqWiKNVLn9E7LYALhZ5fBLoX3kEI4Q+0lFKuF0K8esex++84tsWdJxBCPAk8CdrCyNu3b9cr+IpYHZWNAIziI9i+XRuy5Ziwn065GRzLasn1O84p8prQw8yB9PX/5Zjf7X7u1NTUgvh6O+aw6EQ2X63cRkfHWv4CIyUBoR8jrN0IidGRfTaYTTE5bDmfTXL2EZwsBQ95mtHX1QRr0ySunE7iyunaDTHQMo/lSF77bSdPddaG2RX+/d1+L53p3KgTduteJuSyJMPKtXYDLaTE+OqRuorP3t6elJSUcvfT6XR67VdXGkp8mZmZlf53UOUhm0III2Ah8Ghl25BSfgd8BxAYGCgHDBhQ1bCK+fTkHvxawcghvW9vXL0MLBrRecyMkocNmj2P+Za5DPBy0Ga2Atu3b+dWfD1zdfz1fjAhKbbMGF/LX2DO74Md52Dkp9g6debV5WGcTcyhk6MJn4zsQv/2zhgb1f2M1wh5mm93nuHNB/3p0MyuyO+vCH8v+LYv3aM+gsc3V3/9Hz2VGl89UVfxnTp1Sq+ZtjU1I7e6NJT4LCws6NKlS6XOoc/3/DigZaHnrvnbbrEFOgHbhRAxQA9gbf7N3PKOrRXX0rI5dvFG0VE7uhyI2Ajth5U+TjxgGphaa337JTA3MWZqDzeCIxKIvppaA5GX4cA3SAt73o/zZfw3+8jKzWPJE915JdCCQV4u9SLhAzzTvw225iYs2BRR9o72LWDycki9CkvGQ1b9vRpT6sbdUlr50UcfLSjV8MQTTxAeHl6pdoKCggrq/lQnfZL+IaCdEMJDCGGGdmN27a0XpZTJUkpHKaW7lNIdrTtntJQyJH+/h4QQ5kIID6AdcLDa30U5dkUlIOUdQzXP74HMG9BhZOkHWjaGLg9ri4qklLw4+pQerTAzMWLx3lpcWSs5DnlqHX/oBvLNvis83N2NTS/1o3fhWcb1hL2VKU/1b8PW01cJiblW9s6uAfDgL3DlBPwxFXKzaydI5a5wN5ZW/uGHH/D2Ll7SRR8jRoxg3bp1pKeXcU+sEsrt3pFS5gohZgKbAGPgRynlSSHEf9EmA6wt49iTQog/gXAgF5ghpaz1MY47IhNobGVadGjiqSAwsYQ2JSzuXViPp7USBwe/h8H/V+xlRxtzxvo1Z2VoHK8M8aSRlVk1R19UenYuob+/T++8PFYZD2Ppv7rTq039S/aFPdbbncV7Y/jw7wie8Sznpne7e7USGGue0aqC3v9tpQvEKTVk4xy4crzElyx1udriORXV1AeGl11fvr6WVpZS8txzz7F582ZatmyJmdntHDBgwAAWLFhAYGAgzzzzDIcOHSIjI4Px48fz1ltvAeDu7s60adNYt24dWVlZrFy5Ei8vL4QQDBgwgKCgIB588MGK/kZLpdf/TVLKDVLK9lLKNlLKd/O3vVlSwpdSDsi/yr/1/N384zyllBurLXI95eVJdkYm0Led0+0uj7w8rfRC28HlTmiiSWvt20DIIshOK3GX6X08yMjRsfRgzU7WOnA2iTGfbsX78moiGvXhp5cm1PuED2BlZsLzg9pyMOYaxxP1+Mz3mwyD58LxP2FL9X+9Ve4+9bm08urVq4mIiCA8PJxffvmFvXtLLs/+7rvvEhISQlhYGDt27CAsLKzgNUdHRw4fPszjjz/OggULCrYHBgaya9euiv66ytTga++EX75JYmp20aqal45AyiXw0jOh9Jypjec/9jvQttjLXk3t6NPWkV/2nueJPq1LLEZWFenZuXz4dwSL98bwpN1+HEQKDmNeAT2WeqwvJnZtxfe7zrE8MpOZebLoXImS9HlJK3W993OwaQq9Zpa5e16e5J/wK/Rq64idharlU6PKuCLPMMDSyjt37mTSpEkYGxvTvHlzBg0aVOI5/vzzT7777jtyc3O5fPky4eHhBTGPGzcOAD8/PzZs2FBwTE2UX27w35u3R2irZPVtVyjpn16nFf5qr+cE4ZbdtfHk+74CWfJkrcf7eHDlZiY952/lud+P8OehC9WykPq+M0kM+3QXi/fG8GhPN+Y02QFOXuDRv8pt1yYzEyNmDWnPhZQ8go5fLv8AIWDY++A9Bv75tzYnoRSZOTqe+/0IT/92mE83R1Vj1Ep9UVZp5TNnzhAaGsratVrHg8wvgXz06FGOHj3KuXPnGDJkSJntV6S0ckXaveXcuXMsWLCArVu3EhYWxogRI4q8n1vnMzY2Ljgf1Ez55Qaf9HdEJtCphR1OtoVmn54KAvc+YNVEv0aE0EozXDuDQ1JIibsM8HTi6yn+9G/vxP6zScxeGUbv97cxaMF23vzrBP+cvMLNTP1HF6Rl5fLmXyeY9P1+hIA/nuzBvC5pGF05Bt2evCsXIBnl25yWtkZ8/E8EObqSPzyLMDKG+78Dtz6w+mk4E1xsl8TULCZ9v58NJy7T3N6CDccv1++VzZRKKVxa+U6FSyvD7RLIt0bzREZGkpamdc0GBARUOobS2u3Xrx9//PEHOp2Oy5cvExxc/N/pzZs3sba2xt7envj4eDZu1K+nOzIykk6dOlU65pLcPf0DlZCckcPh2Bs8U7jEb0IEJEUVmcWqlw5jwL4lLS/8Bcwu9rIQguE+zRju0wwpJZHxqeyKSmBPdCLLQ7TSxcZGgs6u9vRp50Tfdo74tWxUfIUpYG90IrNXhhF3I4PpvT14dainVpt+xatgbg++Eyv4m6gfjIwED7Qz5dPD6aUvtHInUwt4aAn8dB/88TA8tkErkQFEX03hscWHSEjJ4usp/mTl5vHCsqOExl6nq7ueH+jKXaO+lla+//772bZtG97e3rRq1YqePXsWO7Zz58506dIFLy8vWrZsSe/evUs4Q3HBwcEFH2bVRp9SnLX5U52lldeHXZJurwXJg+eSbm/c8ZFW0jc5ruIN7vlcOzbucIUOy8rRyX1nEuVHf5+WY77YLT3mBEm314Kk9/9tlNN/Oih/3H1WRsXflCmZOfLfq8Ok22tBcsBHwUXjTr4k5VtNpPz7jTLPVd9LA2/btk0+8NUe2fWdzTI9K1f/A5PjpFzYUcoP20qZdFbuiU6QPnP/lgFv/yOPxF6XUkqZkpkj2/97g3xzzfFKx1fff3+qtHLDKK1cmsK/vytXrshBgwaVuF9VSis36Cv9HREJ2FqY0KVloRtAp4O0/nm75hVv0H8quVvfwWTfV/DA93ofZmZiRI/WDvRo7cArQz1JTs9h39lEdkUlsic6ka2ntfsOpsaC3DzJE308mDXEs+jKUyE/Qp6uzGqadwO9FlopiV1zeHgl/DiUlB9G8+KNN3BxbM6Pj3alZRNtBJaNuQmDvJzZcOIKb47qWG8mqCnVo3Bp5cpU2hw5ciT9+98998JiY2P5+OOPq73dBpv0pZTsiEygbzvH2wXGki9qI3cGz61coxb2XG52Ly1ProJ75mmzSCvB3sqUYZ2aMaxTMwAuXEtnd3QiJy8lc3+XFgS43dE1kZsFoT9pN56blD4C4W7R1b0JAz2d+Co4mkldW2Fvpd9oG+nYnt/bfsT9Yc/yu/UnOD6+CXv7okNuR/g2Y+OJKxw4l3RXDGe9m0gp9VpBrSZNnz69Ts9fm7p27VridlnFAo8N9kZuRHwKV25mMqB9oRout5ZFLFw7v4LiWozURvAc/LaKEd7WsokVk7q14p2xPsUTPmgVKNMSKn4foh57dagXNzNz+bashVYKyczR8cKyo7xxyIo/3P5L69wo7Nc9oZXTKGSQlzOWpsasD9NjhJCiNwsLC5KSkuquoqwCaAk/KSmp2DrBFdFgr/S3R2irZPUrXHrh1Dpw9ATHdpVuN9PSRRtGGLIY+s0Gc5sqRloOKeHAN+DYHlpXfMHz+urWQis/7Ynh0V7uONuV/o/4Wlo2T/4SQsj568we5sm0/vchDlvBuudh7XMw9uuC0UxWZiYM7uDM3yeu8NbojrVSRtoQuLq6cvHiRRISEsrcr6SFy+uThhCfhYUFrq6Vr0TbYJP+jogEvJra0tQ+/xeYfg3O74U+L1a98Z4z8+u/L6n5q++LIVqX1H0L7sphmmV5+d72bDh+mc+3RfP22JKHpZ1NSGX64kNcSs7ki8ldGOmbfy8mYBqkxkPwu2DbVOtuyzfStzlBYZfZdzap6PwMpdJMTU3LnNx0y/bt2ytd/bE2qPgaaPdOalYuIeev0b/wLNyIjSB12lq4VeUaqE3Y2v/vHakOAAAgAElEQVSVdnO1Jh38FsztoPOkmj1PHbi10MrvB0teaOXA2STGfb2Xm5m5/P6vHrcT/i39XoXA6bD7E9j/TcHmAZ5OWJsZE3RMdfEoyp0aZNLfG51Ijk4Wrap5OgjsXKF5NX2K9pwB12MgYkO5u1ZayhU4uUZbQLymu5HqyPOD22FiLFi4uWjp5dVHLvLwogM4WJux5tneBLg1Ln6wENo3IK+R8PccOLEKAAtTY+71duHvk1fIztVjEpiiGJAGmfR3RCZgbWZM4K2botlpcGabtixidXWReI2ERm6w94vqaa8kIT9pi7Z3+1fNnaOOudhZ8GgvD/46dolTl28ipeTTLZG89McxAt2asOqZ3rRyKKMonpGxts5uqx6w+im4cAjQuniSM3LYcyaxlt6JotwdGlzSl1KyPSKBXm0dbxc+i94CuZll186vKCNj6PEsXNiv9btXt9xsbWx+u3vBQc+x7HepWwutvL/xNLP+PManW6IYH+DKz9O76Tec09QSJv0OFvZaVw/Qt70jthYmqotHUe7Q4JL+mYQ04m5kFK2qeSoILJtAq17Ve7IuU7SyCPu+rN52AcLXQNpV6NZwhmmW5tZCKzsiE1h1JI5XhrTno/G+FatWatlYK8kc+TfcvIy5iTFDOzbln/ArZOXW+hIOilJvNbikf6uqZr9bozZysyFyE3gOr9ziDmUxt9VGkYT/BTequZb+gW/BoS20KblMa0PzWG937vNpyueTujBzULvKTQLyn6bdrD/6GwAjfZuRkpnLzkjVxaMotzS4pL8jMoE2TtYFU/OJ2QVZydUzaqck3Z/S7hMcqL7JWlwMhbgQrZqmgawaZWVmwldTAhjVuRLlMW5xaAPufeHwL5CXR++2jjSyMiUorHrrkSvK3axBZZSMbB0Hzl1jgGfhWbhB2uLmbWpoYpO9K3S8H0J/hsyb1dPmwW/BzLZBDtOscQGPat+6zgZjamzEsI5N2RIeT2aO6uJRFGhgSX//2SSyc/NuD9XMy4PTG7RlEU2rdyGCIno8C9kpcOTXqreVelUbeug3GSzsqt6eoekwSrt/E7oY0EbxpGXrCrr9FMXQNaikvyMyAQtTI7p55A/VjAuB1CtVqrWjlxb+4NZbmyCkyy1//7KELoa8HK1rR6k4E3PtAzNiA6RepUfrJjhYm7FO1eJRFKCBJf3tEVfp2doBC9P8squn1oGRCbTTb0mzKuk5A5Jj4QN3WDQUgl6GQ4vgwkHIStGvjdxs7Zi294Bj8bV4FT35P6LNbzi6BBNjI4b7NGXbqaukZ1fxA1lRGoAGU3snJjGNmKR0Hu3lrm2QUuvP9+gHlo3KPLZaeN4H43+E8/sg/gQcXw4hi26/3tgdXDrl/3TUfhp7FL1Re2qt9s2k2+c1H29D5uSpDc89/Av0fpERPs35bX8sW09drdqNYkVpABpM0pfA+ABXBnrl38S9egqundWKo9UGIaDTA9oPaB86yRcg/iRcOaF9EMSf1Lodbi2ubmoNLt75HwKd4Mhv0KS1dqWvVE3ANG2Gbswuunn0xcnWnKCwSyrpKwavwSR9D0drFkzofHvD6fWA0Eov1AUhoFEr7cdz+O3t2emQcEr7ALj1c3JNwY1Hhn1gMMM0a5T3GNg4G0IXY+zRjxE+zVh6MJbUrFxszGvmn31kfAqujS2xMmsw/1spDVDD/dd5eh24dtXK7tYnZlbaco0tAm5vkxJuXtIKuLXqUWehNSimluD7kLbiWFoSI32bsXhvDFvC4xnbpXIrnpXlcOx1xn+9l2cHtOWVoZ7V3r6iVJeGeUl5IxYuH6veWjs1SQht6UX33lpNH6V6BEwDXTYc+x3/Vo1pZm9RIxO1MnN0vLr8GHkStp1WQ0OV+q1hJv1byyLW1Cxc5e7g0lH7tnf4Z4wE3OfTjB2RCSRn5JR/bAV8siWSMwlp9GvvRPjlmySkZFVr+4pSnRpm0j8VBM7eDb46paKHgEchMRJi9zHStxk5Osk/J69UW/NHYq/z/c6zTOrWktn53Tq7ospeUlBR6lLDS/ppiRC7V13lK5qO92srj4X+jF/LRrg2tmT98eqZqJWZo+PVFWE0tbPgjfs64N3MDkcbM3ZEqqSv1F8NL+lHbNSGRN4t/flKzTKzBp8JEL4GkXmDEb7N2B2VyPW07Co3/b+tUURfTWX+A77YWphilHWDfm2bsCsqkbw8WQ3BK0r1a3hJ/3QQ2LeCpr51HYlSXwRM0xbRCfuTkT7Nyc2TbKpiF8+xCzf4dscZJga21Go9JUTAwo48wRqupWVz4lJyNQWvKNVLr6QvhBgmhIgQQkQLIeaU8PrTQojjQoijQojdQgjv/O2mQoif8187JYR4vbrfQBFZKXAmWLvKr65lEZW7X7PO0MwPQn+mU3Nb3BysCKpCLZ7MHB2vLD+Gi50F/x7ZQSufsfIJyEnDM24Vgjx2qi4epZ4qN+kLIYyBL4HhgDcw6VZSL2SplNJHSukHfAgszN8+ATCXUvoAAcBTQgj3aoq9uOgtoMtS/flKcQGPwtWTiLhQRvo2Y++ZRBJTKzfK5rOtUURdTWX+OB/sLExh+3y4EgY+D2KccpHJTjGqX1+pt/S50u8GREspz0ops4FlwJjCO0gpCxeSt0arikD+f62FECaAJZANVFPR+RKcCgIrRzXBSSnOZ7xW9uLwYkb6NidPwsYTFe/iOXbhBt/sOMODga7aug3n92rr8naZCqM/A3N7ppjv4nDsDW5mVu/QUEWpDkLKsm84CSHGA8OklE/kP58KdJdSzrxjvxnAy4AZMEhKGSWEMAV+BQYDVsBLUsrvSjjHk8CTAC4uLgHLli2r+BvJy6H3nkdIcOpFhNdzFT5eX6mpqdjY2NRY+1Wl4itd+4gvcInfyZ6eP/HafoG9uWBOt6LrLJQVX06eZN7eDNJz4J0+ltiJDLoeegEpjAgJ/ASdiRXtIr/B5fJW/DO+ZFqXJgS4VO+kd/X3rZqGHN/AgQNDpZSB5e4opSzzBxgP/FDo+VTgizL2nwz8nP+4N7AEMAWcgQigdVnnCwgIkJVydoeUc+2kjPi7csfrKTg4uEbbryoVXxkuhGj/Rg7+ID/+J0K6zwmS8ckZRXYpK76P/j4t3V4LkttOxWsbVj0t5bxGUsYeuL3TRe0c896cJeesDKv2t6D+vlXTkOMDQmQ5+VxKqVf3ThzQstBz1/xtpVkGjM1/PBn4W0qZI6W8CuwByv8kqgz3vjDjILQeUCPNKw1AC39w8YHDPzPKtxlSwgY9x+wfv5jM1zvO3K7kenINHFsKfV+Blt1u79jcH5w68IjFLnZGJty6EFKUekOfpH8IaCeE8BBCmAEPAWsL7yCEaFfo6QggKv9xLDAofx9roAdwuqpBl0gIrY66iXmNNK80AEJowzcvH6OdLhpPF1u9RvFk5WqjdRxtzPi/kd5w8zIEvagl+P6zi5+jyxQ8sk5jmRzFmYS0GnozilI55SZ9KWUuMBPYBJwC/pRSnhRC/FcIMTp/t5lCiJNCiKNo/frT8rd/CdgIIU6ifXj8JKUMq/Z3oSj68pkAJpYQ+jMjfZsRcv46l25klHnIF9uiiYhPYf44H+zNjWHNM5CbBeO+B2PT4gf4TkQKYyYY71BDN5V6R69x+lLKDVLK9lLKNlLKd/O3vSmlXJv/+AUpZUcppZ+UcqCU8mT+9lQp5YT817yllB/V3FtRFD1YNtJKMxxfzkgvbeH5srp4TsQl89X2Mzzg78ogLxc4+B2cDYYh75S+pKWNM6L9MCaY7mFPpFqbV6lfGt6MXEUpT8CjkJ2KR/wmvJvZldrFk52bxyvLj+FgbcabI73h6mnYMhfaDYXA6WWfo8sUmsgbmJ3bRmaOrvrfg6JUkkr6iuFp2Q2cvCB0MSM7N+PohRtcuJZebLcvgqM5fSW/W8dMwqonwMwGxnxR/ozvdkPINndgDNs5FHOtht6IolScSvqK4RFCu9qPC+X+ZjcAilXePBGXzFfB0Yzzb8HgDi4Q/C5cOQ6jPwcb5/LPYWyK6DyRwUaHOXQiogbehKJUjkr6imHynQjG5jQ78wedXe2LrKh1q1unibUZc0d2hJg9sOd/4D8NvO7T+xSmAVMxFTqsIlbVxDtQlEpRSV8xTFZNtMXTj/3BmI6NORF3k5hEbXjll/ndOu/d74O9UTqsfgqaeMDQ9yp2Dhdvrtp2pH/6P1y6Xrz7SFHqgkr6iuEKmAZZyYw1DwG0Lp7zN3V8GRzN/V1acI+3C2yYrS1af/93YF7x6fHSbwodjC5wInRHdUevKJWikr5iuNx6g0Nbmpxain+rRvx1NI4fjmfTyMqMuaO84cQqCFsG/V6Fll0rdQrnnpPJwhTz4xWvJ6UoNUElfcVwCaH101/Yz8OtM4iMT+VCSh7v3d+JRrmJEPQStAiAfq9U/hRWjTll348uyZvJzVJdPErdU0lfMWx+k8HIlKHZmzAxEvRoZsyQDs7arFtddumzbisgs9Mk7Egjdu+KagpaUSpPJX3FsFk7QoeRWJ9azsYZXXncxxwOfgtnt2s3bh3aVPkUXj1Hckk6YHRsSdXjVZQqUklfUfynQcZ12iVtp1F6LGyeC+2HaWP5q0EjG0t2W99LqxsHILmsArWKUvNU0lcUj/7Q2B0O/UCHU5+AhR2M1mPWbQWkek3ECElGyG/V1qaiVIZK+opiZAT+j8CF/dikndMSvo1TtZ7Cz68LB/K80B3+DVSNfaUOqaSvKAB+D4OZDXHNh4PnsGpvvrNrI4KMBmGTFgux+6q9fUXRl0r6igJg6wIvHieq3VM10ryxkSCt7UjSsEAeUV08St1RSV9RbrFqUq39+Hfq4dmKoNweyBOrISu1xs6jKGVRSV9Raknf9o4s1/XDKDcdwv+q63AUA6WSvqLUkmb2lqQ4BXLZpAUcVWP2lbqhkr6i1KJ+nk78ntUHzu+BpDN1HY5igFTSV5Ra1L+9M3/m9EEKIzi6tK7DUQyQSvqKUosC3Rtzw9SJaNtucOx3yFPr5yq1SyV9RalFFqbG9GjtwNKsvnAzTqvxoyi1SCV9Rall/ds7sTS5IzrzRuqGrlLrVNJXlFrWr70TWZgR5TIcTgVBxvW6DkkxICrpK0ota+1ojWtjS5br+oEuC46rOvtK7VFJX1FqmRCCfu2d+ONiE/KcO6ouHqVWqaSvKHWgf3snUrN0xLa6Hy4dgfjwug5JMRAq6StKHejVxgETI8E62QeMTNTVvlJrVNJXlDpga2GKf6vG/H0uFzyHw7FloMup67AUA6CSvqLUkf6eTpy8dJNkz4mQngiRm+o6JMUAqKSvKHWkXzttda5gnQ/YuKguHqVWqKSvKHWkY3M7HKzN2B51HXwnalf6qVcr3d61tGx0eWopRqVseiV9IcQwIUSEECJaCDGnhNefFkIcF0IcFULsFkJ4F3rNVwixTwhxMn8fi+p8A4pytzIyEvRt58iuqETyOk8BqYN1L0BKfIXaSc7I4b/rwun27hZmrwiroWiVhqLcpC+EMAa+BIYD3sCkwkk931IppY+U0g/4EFiYf6wJ8BvwtJSyIzAAUHerFCVfv/ZOJKVlczKnGdwzD6K3wBdd4eD35RZj0+VJlh6IZeCC7fy09xwdm9ux8vBF1oddrpXYlbuTPlf63YBoKeVZKWU2sAwYU3gHKeXNQk+tgVvfMYcAYVLKY/n7JUkpVVlBRcnXN79ff2dUAvR5CZ7ZB839YMMrsOheuHysxOMOnE1i1Oe7eWP1cdo62bBuZh9WPNOLzq72vLH6OFeSM2vzbSh3ESFl2X2AQojxwDAp5RP5z6cC3aWUM+/YbwbwMmAGDJJSRgkhXgQCAGfACVgmpfywhHM8CTwJ4OLiErBs2bIqv7Gakpqaio2NTV2HUSoVX9XURXxz92ZgbgxvdLfUNkiJ89WdtI1ehGlOCnEtRnDOYzI6EytiE1MJumjCwSs6mlgIHvI0o2tTY0T+2r5X0vJ4c28G7RoZMSvQAqMaXPO3JOrvWzVViW/gwIGhUsrAcneUUpb5A4wHfij0fCrwRRn7TwZ+zn/8CnAOcASsgH3A4LLOFxAQIOuz4ODgug6hTCq+qqmL+D7YeEq2eX29vJmRXfSF9GtSrntJyrn2Mu8jT7lu6Vey7evrpOd/NshPNkfI9KzcEtv7dV+MdHstSP64+2wtRF+U+vtWTVXiA0JkOflcSqlX904c0LLQc9f8baVZBozNf3wR2CmlTJRSpgMbAH89zqkoBqNfeydy8yR7zyQVfcGyMXLEx+zq/ztRaRaMjJjDH1Yfsf0JD168pz2WZsYltjeleysGeTnz/sbTRMWn1MI7UO4m+iT9Q0A7IYSHEMIMeAhYW3gHIUS7Qk9HAFH5jzcBPkIIq/ybuv0BVWREUQrxb9UYG3MTdkQmFNl+Ii6Zid/uZ+qmPF62/5TzXf8PX3mapr/2h50LIDe7xPaEELz/gA/W5ia8+MdRsnPzauNtKHcJk/J2kFLmCiFmoiVwY+BHKeVJIcR/0b5OrAVmCiHuQRuZcx2Yln/sdSHEQrQPDglskFKur6H3oih3JTMTI3q2cWBnZAJSSpLSsvn4nwiWHbpAYysz5o/z4cHAlhgbDWCfsTs9k/+CbW9D2J8wciG49ynWprOtBfPH+fDUr6F8uiWS2cO8av+NKfVSuUkfQEq5Aa1rpvC2Nws9fqGMY39DG7apKEop+rV3YnN4PO9vPM3Sg7FkZOuY3tuD5we3w97StGC/LAtHGPYrRP4DG2bB4hHQeTIMeRusHYu0ObRjUx4MdOWbHWcY6OVMV/cmtf22lHpIzchVlHqgf/7QzW93ntUKsb3Yj/8b6V0k4RfRfgg8ewD6zoLjy+HzAAj9GfKKduW8Oaojro2teOmPo6Rkqikyikr6ilIvtHKwYt4ob358NJDFj3WlrbMew/bMrGDwm/D0bnD2hnXPw5qniyR+G3MTPpnYmUs3MvjvOnU7TVFJX1HqjUd7ezDIy6VgzL3enL3gsQ0w4A0I+wP+fg0Kzb8JcGvCswPasjz0In+fULN1DZ1K+orSEAgB/WdDr+fg4HewfX6Rl1+4px0+Lex5fdVxrt5Us3UNmUr6itJQCAH3vg1dpsKOD2DfVwUvmRob8cnEzqRn65i9MuzWRErFAKmkrygNiRAw6n/gPQY2vQ5Hbtfob+tsyxv3dWB7RAK/HYitwyCVuqSSvqI0NEbGMO57aD0Q1s6EU+sKXnqkpxv92jvx7vpwziSk1mGQSl1RSV9RGiITc5j4G7QIgBXT4ex2QJut+9F4XyxMjXnpj6Pk6OrJbN28PFg2BUJ+qutIGjyV9BWloTK3gSnLwaEd/D4ZLoYA4GJnwfz7fQi7mMznW6PKaaSWRP0Dp4Ng2zuQk1HX0TRoKukrSkNm2RimrgIbJ1gyHuK1sfrDfZoxzr8FXwRHE3r+eh0HCez+BMxstQXij/1e19E0aCrpK0pDZ9sUHvkLjM3h1/vhegwA80Z3pJm9JS//eZS0rNy6iy92P1zYz3L7aSTYdYS9X5S7aphSeSrpK4ohaOwOj6wBXRb8MgZSrmBnYconE/2IvZbOO+vrcLbu7k/JMm3Emxf8mZc0GK6dgYgN5R+nVIpK+opiKJw7wJQVkJoAv46D9Gt082jCU/3a8PvBC2wOr9iC7NXi6imI3Mhi3VA6tGpKrPNgLkpnMnd8UvuxGAiV9BXFkLgGwqSlkBQFSx+E7DRevrc93s3smLMyjISUrNqNZ8//yDay4Ov0Qcwd1ZGvpnbjN6ORWFwJJf3MntqNxUCopK8ohqb1ABj/I8SFwrIpmJHDpw/5kZKVy3/WHK+92bo3LiCPL2dp7kAGdfGic8tGtGxiRb8HX+K6tCFy1btq5nANUElfUQxRh1Ew+nM4Gwwrn6C9kxUv39ueTSfj2XD8Su3EsP8r8vIkP8sRvDrMs2Bzrw6tOOsxCd/Uvfy+cWvtxGJAVNJXFEPV5WEY+h6cWgvrXuCJ3u74tLBn7toTXE8reSnGapN+DV3IYtboejKmf3ea2VsWedl//GxyjUwR+74otoykUjUq6SuKIes5A/rNhiO/YrJtLh8+4MON9Bz+G1Szo3nyDnyHcW46K80f4Ml+rYu9LmycEX6TecB4N/OWBhOblF6j8RgSlfQVxdANfAO6/gv2fk6H2N95dkAbVh+JI/j01Zo5X3Y6Ofu+YYuuCxNGDMHKrORVW037PI8puUxiI0/+GkJ6dh3OJWhAVNJXFEMnBAz/ENoPh81vMtMnh3bONryx+niNLLGYHfIz5tnX2dJkEmM6tyh9R4c2CK8RPGa2lQvxCcxZWYs3mRswlfQVRQEjI+3GrrkNZmuf5cNxHYi/mcn8jaer9zy6HDJ2/I+QvPaMv38CRkblrBLW+wVMs5P5xjuctccusWj3ueqNxwCppK8oisbGSavFf/kYXc79wPTeHiw9EMu+M0nVdorrh/7APusyoa6PEOjepPwDWnaDlj3ok/Qn93k7MX/jafZGJ1ZbPIZIJX1FUW7rMAp8H4KdC3ilUxpuDlbMWRVGRnY11MKRkvTghURJV0aMf0z/43o/j7gRy0KfGDwcrZn5+xHibqhKnJWlkr6iKEUN/wBsm2Kx7hk+HN2e80npLNwcUeVmz+xdTYusM0S1nY5rExv9D2w/HBzaYXHwC7592J+c3Dye/jWUzBxVlK0yVNJXFKUoy0Yw5ktIiqL72c+Z3L0Vi3af4+iFG5VuUkpJxvaFxONAvweeqdjBRkbQayZcPkab1MMsnOjH8bhk/r36hLqxWwkq6SuKUlybgdowzgNf8x/vBFzsLJi94hhZuZW7ut69fSOdco5zqcN0bKysKt6A70Ng7QR7P+debxdeGNyOlYcv8uv+85WKx5CppK8oSsnufQuatMFqw/N8MNKdyPhUvgw+U+FmMnN05O36lBRhg++YFyoXi6kFdHsKojdDfDgvDG7HYC9n/rsunIPnrlWuTQOlkr6iKCUzs4b7v4WbcfQ7s5D7u7Tgq+BoTl2+WaFmVmzaRl/dQZI7PYaxhW3l4+n6OJhawd7PMTISLJzoR8smVjy7JJQryZmVb9fAqKSvKErpWnaFPi/B0d942yuWRlamzF4RRq6eC6pfvZmJ5aEvyTUyw3XYi1WLxaoJdJkKx5fDzUvYW5ry3dQAMrJ1PP1baKW7ngyNSvqKopSt/xxw8cHmn5eZP7Q5x+OS+UHPSVLfBe1iFDvJ7DQJrB2rHkvPZ0HqYP/XALRzsWXBhM4cvXCDeWtPVr19A6CSvqIoZTMxg/u/gYwb3HP2fYZ6O/PJ5kjOJqSWediJuGRcwn/CRIDdoJeqJ5bG7uA9FkIXQ6bWzTTcpxnPDtBW//p0S6Te30IMlV5JXwgxTAgRIYSIFkLMKeH1p4UQx4UQR4UQu4UQ3ne83koIkSqEeKW6AlcUpRY17QSD/o04tZYPPSMwNzHitZVh5OWVPGRSSsnHaw8w2WQrOu+xWrKuLr2fh6ybWuLPN2uIJ6M6N+fTLVHc/9Vewi9V7L6DISk36QshjIEvgeGANzDpzqQOLJVS+kgp/YAPgYV3vL4Q2FgN8SqKUld6PQ8tu2O/7Q3eG9yEQzHX+e1AyUMmN528QoeLy7EmE9N+1XSVf0vzLuDeV+viydXq/hsbCT57yI8vJnfh0o0MRn+xm4//iVD9/CXQ50q/GxAtpTwrpcwGlgFjCu8gpSz8sWoNFHz8CyHGAucA1eGmKHczI2MY+zXk5TDi3Lv0a+fIBxtPc/F60Vr3Wbk6Fqw/xpNmm8hrMxia+lR/LL1fgJRLcGJlwSYhBCN9m7Pl5f6M7tycz7dFM+Kz3YSeV0M6CxPlzWgTQowHhkkpn8h/PhXoLqWcecd+M4CXATNgkJQySghhA2wG7gVeAVKllAtKOMeTwJMALi4uAcuWLavyG6spqamp2NhUYAp5LVPxVY2Kr3zN4zbSPuobDrs/yeSoAbRtZMysQHOEEKSmprIzwQyz6A28Y/oTR/zeJblRp+oPQkoCQ7Qx/yGB/9PKQ98hLCGXn09mcy1Tco+bCQ+0MyM3M63Of39lqcrfd+DAgaFSysByd5RSlvkDjAd+KPR8KvBFGftPBn7Of7wAeDD/8TzglfLOFxAQIOuz4ODgug6hTCq+qlHx6SEvT8pfxkr5TlO5avMO6fZakPzzUKyUUsq//t4mfd9cL+Pf9pTyu0HavjXlyBIp59pJGbm51F1SMnPkm2uOS7fXgmSv+Vvl58tL37c+qMrfFwiR5eRXKaVe3TtxQMtCz13zt5VmGTA2/3F34EMhRAzwIvCGEGJmaQcqinIXEAJGfwHGpoyNeZvubva8HRTO1ZuZrIrOpr9uH865l6HPiyVegVebTuPBtjns/V+pu9iYm/DWmE4sf7on5qZGLAjJ4pXlx7iRXsNrANdj+iT9Q0A7IYSHEMIMeAhYW3gHIUS7Qk9HAFEAUsq+Ukp3KaU78CnwnpTyi2qJXFGUumPfAu5bgLh4kK88dpOVm8czSw6z40IOr9tuBId24DmiZmMwMYMeT8O5nXDpaJm7dnVvwobn+zKytSmrj8Rxz8KdbDx+uWbjq6fKTfpSylxgJrAJOAX8KaU8KYT4rxBidP5uM4UQJ4UQR9H69afVWMSKotQPPhOgw2gcDi7g7Z4Qev4695gep1lGlHaj1agWpgEFPApmtrD3s3J3tTA1Znx7M9bO7I2LnTnPLDnMU7+GcPWmYZVw0OuvIqXcIKVsL6VsI6V8N3/bm1LKtfmPX5BSdpRS+kkpB0opi43UkVLOkyXcxFUU5S4lBIz8BCwbM+H82zzUxZn/2K4H22bg+2DtxGBhDwHT4OQauK5fxc2Oze35a0ZvXhvmRXBEAvcs3MGfhy4YTJlmNSNXUZTKs3aE0Z8hrp7k/bxPcEs/Dj2eBRPz2ouhxzPaB9D+r/Q+xMTYiGcGtOHvF/ri1dSO2SvDmLroIJqb4GoAAA/cSURBVMcu3Ch1wllDoZK+oihV4zkcujwMEevJNbbWulxqk72rdlP38C+QXrEx+a2dbFj2ZA/eHtuJoxduMObLPXSfv5VXlx9jw/HL3MzMqaGg645JXQegKEoDMHQ+xJ8kxtKfthZ2tX/+Xs9B2DI49AP0n12hQ42MBFN7uDHSpxnBEVfZdvoqm05eYXnoRUyMBIHujRno6cwgL2faOtsganJEUi1QSV9RlKqzsIMnt3Nx+3ba1sX5m3bSRgvt+Qz8p4GtS4WbaGxtxjh/V8b5u5Kry+Nw7A2C/7+9O4+SqjzzOP596AWwQdlR1gYEsRkyCoioqIDKFkQDRhYXBDc05sTJuBAXdCYajzrmGJWMI6ghbuCoOBpRQEEDjqCCgCBgs86IbIJKUGTpfuaPe/tM2VR1F1TXrU7X73NOnbr13rfu+9Tbl4dbb9373jXbmbd6O/e9uZr73lxNywZ16de5GX07N+W09k2om5+Thg+TXkr6IlIz9P8tTDoV5t0DQx9NaVO5ObXo2a4RPds14taBnfnym728u2YHc1dv56XFwW0aa+fW4rQOjel7QjP6ntCMNo2P4DaQGaCkLyI1Q+MOcOq18MGk4P6+x/2kyjbdokFdRp/ahtGntmHfwRI+3LCLuau38+6aHdz12kruYiUdmhbwm0Encm7R4X/LiJJ+yBWRmuOsm6FuQ3jrN5CmUzBr5+ZwZsem3HV+F+bd1Id5N/Vh4pAiSh3ueHUFB6r5fP5K+iJSc9RtAP1uh00LYPVfImmyXZMCxvVux51DTmTr7h94Y3n1vtJXSV9EapZuV0DTE2H2nXBwX2TN9unUjPZNC5iyYH21vtBLSV9EapacXBhwL3y9ARb9R2TN1qplXNW7PSs272bRhuo7h7+SvojUPMefAx0HwF8fhD07Imt2WLeWNCrIZ8r89ZG1ebiU9EWkZup/Dxz4Hubdm/623OG9B6mz6mUu7dWWt1dtr/TG8ZmipC8iNVPTTsGpm0umwtYV6W1r/kPB9QGvXM3V+XPIz6nFkws2pLfNI6SkLyI119m3BDNxzrotbadwsvJVmPtb+Ifh0HkI9efdxkOt5/Pyki/Y9V31u1mLkr6I1FxHNYI+t8GG9+Dzt6p++5uXwIzx0KonXPBH+PmfoOhCzt86iXGlM3h+UXLTPUdJSV9EarYeY6FJJ5h1O1ZahbNmfrsZXhgFBU1h5HOQVwdy8mD4k9D1Ym7Jm07eggfZd+Bg1bVZBZT0RaRmy8mDAb+DXetouXlm1Wxz3x54YQTs/w5GT4d6zWLay4WfPc7W9sO5tnQ666dPSN/Q0hFQ0heRmq/jeXD8uRRunA7f7UxtW6Wl8Mo1sG0lXPQUNC86tE6tHJpfOpmZeQM4ce1kfPad1SbxK+mLSHbofy85JXvh3d+ltp137oY1bwT3EOjUP2E1q5XDnv4PMvXgedgHj8Jb1eOIX0lfRLJDs85sbjkIPn4atq86sm188iy8/wfocWUwo2clLji5FY/Wvpa36g+HRY/DG78OvilkkJK+iGSNjYUjoXa9IzuFc+MCeP1GaN8HBt0f3Je3ErVzcxhzeiHjdwxj18nXw8dPweu/hNKSI4q/Kijpi0jWOJh3NJw9AdbNheI5yb9x5zqYfik0agc/nxr8OJykS3q1pU5eDvfvHwln3xp8W3j1OijJzFk9Svoikl1OuQoaHx8c7ZckcQrn3q/h+RGABWfq1G1wWM01KshneLdWzFj2JTt6/DP0vQOWT4cZ1yTXfhVT0heR7JKbD/3vhZ3F8NGTFdctOQAvjoGvN8KIZ6FR+yNqclzvduw/WMqzCzfB2TfDuf8CK16Gl8bCwWiv2lXSF5Hs02kAtO8L794H3yeYBtkdZt4cXM17/h+g8Iwjbq5D03qc07kZzyzcxA8HSqD3jcHZP6tehxcvj3TefyV9Eck+ZsEFW/t2w3v3x6+z6HFY/DT0/ic4+ZKUm7zqzPbs+m4/Mz7ZHBScdj0M/jf4/E2YNhoO7E25jWQo6YtIdmpeBN3HwoeTYceaH6/7fFYw5t95CPSbWCXN9WrfiC4tjubJBRsoLQ3PHOp5NZz/CKx9B54fQa2S9B/xK+mLSPbqexvk14PZd/x/2baV8NI4OLYrDHsCalVNmjQzrjqzHWu37+G9z2Nu7NJ9DFz4R9g4n6LPHqqStiqipC8i2augSfDDavFsKH4b9mwPztSpXR9GTYP8gipt7qddW3Ds0XWYsqDcnbVOGg3DJrOp7UVV2l48Svoikt16XhuclTPrtmBs/buvYNQLcHSLKm8qP7cWY04v5P21O/nsy90/Xtn1Iv52dKcqb7M8JX0RyW65+cGtFb9aA198FAzptDg5bc2N7tmGo/JzDj3aj0hSSd/MBprZGjNba2YT4qwfb2afmtlSM1tgZkVh+Xlmtjhct9jM+lX1BxARSdkJg6HX9TDkYSgamtamjjkqj4t7tOb1ZV+ybfcPaW0rnkqTvpnlAJOAQUARMKosqcd43t27uvtJwAPA78Pyr4Dz3b0rMAZ4psoiFxGpKmYw8L7ghisRGHtGIQdLnT9/sDGS9mIlc6TfE1jr7uvdfT8wDbggtoK7xw5OFQAeln/i7l+G5SuBumZWO/WwRUT+frVtXMCAomN5duH/8P3+aOfgMa9kpjkzuwgY6O5Xha8vA0519xvK1fsF8GsgH+jn7sVxtjPe3c+N08Y1wDUAzZs37z5t2rQj/0RptmfPHurVq5fpMBJSfKlRfKlRfMkr/rqEexf9wGVF+ZzTJpjALZX4+vbtu9jde1Ra0d0rfAAXAVNiXl8GPFZB/dHA1HJlXYB1QIfK2uvevbtXZ/Pmzct0CBVSfKlRfKlRfMkrLS31oY8t8LMfmOslJaXunlp8wMdeSX5196SGdzYDrWNetwrLEpkGXFj2wsxaATOAy919XRLtiYjUeGbG1We2Y+PO73l71bbI2k0m6X8EdDSzdmaWD4wEXoutYGYdY17+FCgOyxsAbwAT3P39qglZRKRmGNjlWFo2qMuUBRsia7PSpO/uB4EbgFnAKuBFd19pZv9qZmXnNt1gZivNbCnBuP6YsnLgeGBieDrnUjNrVr4NEZFslJtTi7FnFPLhhl0s/+KbaNpMppK7zwRmliubGLP8qwTvuwe4J5UARURqshGntObht4uZMn8Dw45Lf3u6IldEJIPq18lj5CmteePTLezcm/6bpivpi4hk2BVnFAIwZ1P6z9lX0hcRybBWDY/isl5taVzH0t6Wkr6ISDVw99AunFeYl/Z2lPRFRLKIkr6ISBZR0hcRySJK+iIiWURJX0Qkiyjpi4hkESV9EZEsoqQvIpJFKr1zVtTMbAewKdNxVKAJwb1/qyvFlxrFlxrFl5pU4mvr7k0rq1Ttkn51Z2YfezK3JMsQxZcaxZcaxZeaKOLT8I6ISBZR0hcRySJK+ofviUwHUAnFlxrFlxrFl5q0x6cxfRGRLKIjfRGRLKKkLyKSRZT0yzGz1mY2z8w+M7OVZnbITd/NrI+ZfWtmS8PHxHjbSmOMG83s07Dtj+OsNzN7xMzWmtlyM+sWYWwnxPTLUjPbbWY3lqsTef+Z2VNmtt3MVsSUNTKzOWZWHD43TPDeMWGdYjMbE2F8D5rZ6vBvOMPMGiR4b4X7Qxrju9vMNsf8HQcneO9AM1sT7o8TIoxvekxsG81saYL3RtF/cfNKRvZBd9cj5gEcB3QLl+sDnwNF5er0Af6SwRg3Ak0qWD8YeBMwoBewKENx5gBbCS4ayWj/AWcB3YAVMWUPABPC5QnA/XHe1whYHz43DJcbRhRffyA3XL4/XnzJ7A9pjO9u4KYk9oF1QHsgH1hW/t9TuuIrt/4hYGIG+y9uXsnEPqgj/XLcfYu7LwmX/wasAlpmNqrDdgHwZw8sBBqY2XEZiOMcYJ27Z/wKa3f/K7CrXPEFwNRweSpwYZy3DgDmuPsud/8amAMMjCI+d5/t7mV3yl4ItKrqdpOVoP+S0RNY6+7r3X0/MI2g36tURfGZmQEXAy9UdbvJqiCvRL4PKulXwMwKgZOBRXFWn2Zmy8zsTTPrEmlg4MBsM1tsZtfEWd8S+N+Y11+Qmf+4RpL4H1om+69Mc3ffEi5vBZrHqVNd+nIcwbe3eCrbH9LphnD46akEQxPVof/OBLa5e3GC9ZH2X7m8Evk+qKSfgJnVA14GbnT33eVWLyEYsvhH4FHg1YjD6+3u3YBBwC/M7KyI26+UmeUDQ4H/jLM60/13CA++R1fL85fN7HbgIPBcgiqZ2h/+HegAnARsIRhCqY5GUfFRfmT9V1FeiWofVNKPw8zyCP4wz7n7K+XXu/tud98TLs8E8sysSVTxufvm8Hk7MIPgK3SszUDrmNetwrIoDQKWuPu28isy3X8xtpUNe4XP2+PUyWhfmtkVwBDgkjApHCKJ/SEt3H2bu5e4eykwOUG7me6/XGAYMD1Rnaj6L0FeiXwfVNIvJxz/exJY5e6/T1Dn2LAeZtaToB93RhRfgZnVL1sm+LFvRblqrwGXh2fx9AK+jfkKGZWER1eZ7L9yXgPKzoQYA/xXnDqzgP5m1jAcvugflqWdmQ0EbgGGuvv3Ceoksz+kK77Y34l+lqDdj4COZtYu/PY3kqDfo3IusNrdv4i3Mqr+qyCvRL8PpvMX67/HB9Cb4CvWcmBp+BgMjAfGh3VuAFYSnImwEDg9wvjah+0uC2O4PSyPjc+ASQRnTXwK9Ii4DwsIkvgxMWUZ7T+C/4C2AAcIxkSvBBoD7wDFwNtAo7BuD2BKzHvHAWvDx9gI41tLMJZbth8+HtZtAcysaH+IKL5nwv1rOUHyOq58fOHrwQRnq6yLMr6w/E9l+11M3Uz0X6K8Evk+qGkYRESyiIZ3RESyiJK+iEgWUdIXEckiSvoiIllESV9EJIso6UtWMrMS+/FsoFU2+6OZFcbO9ihSneRmOgCRDNnr7idlOgiRqOlIXyRGOLf6A+H86h+a2fFheaGZzQ0nF3vHzNqE5c0tmOt+Wfg4PdxUjplNDudOn21mdTP2oURiKOlLtqpbbnhnRMy6b929K/AY8HBY9igw1d1/QjDx2SNh+SPAex5MHteN4KpOgI7AJHfvAnwDDE/z5xFJiq7IlaxkZnvcvV6c8o1AP3dfH06QtdXdG5vZVwTTDBwIy7e4exMz2wG0cvd9MdsoJJj/vGP4+lYgz93vSf8nE6mYjvRFDuUJlg/HvpjlEvT7mVQTSvoihxoR8/xBuPzfBDNEAlwCzA+X3wGuAzCzHDM7JqogRY6Ejj4kW9W1H98o+y13Lztts6GZLSc4Wh8Vlv0SeNrMbgZ2AGPD8l8BT5jZlQRH9NcRzPYoUi1pTF8kRjim38Pdv8p0LCLpoOEdEZEsoiN9EZEsoiN9EZEsoqQvIpJFlPRFRLKIkr6ISBZR0hcRySL/B+WGtkFRqd6CAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEWCAYAAACKSkfIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl43Gd16PHvOzPaV2vfJduSFymJlzjOQhIcQkLYsrSBJKUhQG7Dllt6+5QC7S0FntKnwKXcC6SFAClpAlmAQAIE7GxK4pDNdmzHsmRLXmRLlkbWPto1M+/9Y+Znj8cz0uzr+TyPH49mfpKOxuOjd87v/M6rtNYIIYRID6Z4ByCEECJ2JOkLIUQakaQvhBBpRJK+EEKkEUn6QgiRRiTpCyFEGpGkL0QEKKW+opR6ON5xCLEcSfpCLEMSukglkvSFECKNSNIXwoNS6gtKqX6llE0pdUgp9X7gH4DblFJTSql97uNWKqVedB/3DFAW18CFCJAl3gEIkSiUUmuBe4FLtNanlFJNgBn4V6BZa/2XHof/HHgVuB64FPg98GRMAxYiBJL0hTjLAWQBrUqp01rr4wBKqXMOUko1AJcA79ZazwMvKaV+G+NYhQiJlHeEcNNa9wB/A3wFGFJKPaqUqvFxaA0wprWe9rivNwYhChE2SfpCeNBa/1xrfSXQCGjgG+6/PQ0AK5RSeR73NcQoRCHCIklfCDel1Fql1LuUUlnAHDALOAEr0KSUMgForXuBXcBXlVKZSqkrgQ/GK24hgiFJX4izsoB/A4aBQaAC+BLwC/fjI0qpPe7bf4HrBO4o8M/Af8c2VCFCo2QTFSGESB+y0hdCiDQiSV8IIdKIJH0hhEgjkvSFECKNJNwVuWVlZbqpqSneYfg1PT1NXl7e8gfGicQXHokvPBJfeMKJb/fu3cNa6/JlD9RaJ9Sfiy++WCeyF154Id4hLEniC4/EFx6JLzzhxAfs0gHkWCnvCCFEGpGkL4QQaUSSvhBCpJGEO5Hry+LiIn19fczNzcU7FIqKiujs7Azqc7Kzs6mrqyMjIyNKUQkhRGCSIun39fVRUFBAU1PTebPNY81ms1FQUBDw8VprRkZG6OvrY+XKlVGMTAghlpcU5Z25uTlKS0vjnvBDoZSitLQ0Id6lCCFEQElfKXWDe7/QHqXUF308nqWUesz9+OvubeZQSn1EKbXX449TKbUxlECTMeEbkjl2IURqWTbpK6XMwH3Ae4FW4A6lVKvXYXfj2kmoGfgOro0n0Fr/TGu9UWu9EbgTOKa13hvJH0AIISJhZ/cwPUNT8Q4j6gJZ6W8FerTWR7XWC8CjwE1ex9wEPOi+/UvgWnX+8vYO9+cmJbPZzMaNG7n00kv54Ac/yPj4eLxDEkJE0OcefYvvPHs43mFE3bLz9JVStwI3aK3/h/vjO4FLtdb3ehxzwH1Mn/vjI+5jhj2OOQLcpLU+4ON73APcA1BZWXnxo4+e+7uhqKiI5ubm0H7CCKmurmZgYACHw8FnPvMZmpub+fznPx/w5/f09DAxMRHFCF2mpqbIz8+P+vcJlcQXHokvPP7im7VrPv3sDI2FJr56RU4cInMJ5/m75pprdmuttyx3XEy6d5RSlwIzvhI+gNb6fuB+gC1btuht27ad83hnZ2dQHTPRUlBQgM1m4+qrr2b//v1nYvrWt77F448/zvz8PLfccgtf/epXz/vc7OxsNm3aFPUY29vb8X7+EonEF55Eju+hV49jnzjCBxI0PvD//B0atMGzLzG6YOKd73xn3M7DxeLfN5Ck3w/Ue3xc577P1zF9SikLUASMeDx+O/BIGHGe8dXfdnDw1GQkvtQZrTWF/PMH2wI61uFw8Nxzz3H33XcDsGPHDrq7u3njjTfQWnPjjTfy0ksvcfXVV0c0RiES2eyCg39+qoOtVWY+Hu9gQtA3NgOAbc7O+MwiK/Iy4xxR9ARS038TaFFKrVRKZeJK4E95HfMUcJf79q3A8+4BQLg3k/4wSVzPB5idnWXjxo00NzdjtVq57rrrAFfS37FjB5s2bWLz5s10dXXR3d0d52iFiK3uIRtODScmnfEOJSR9Y7Nnbh8fmY5jJNG37Epfa21XSt0LbAfMwANa6w6l1NdwTXV7CvgJ8JBSqgfXRtG3e3yJq4GTWuujkQg40BV5pOXk5LB3716sViu33nor9913H3/913+N1povfelLfPKTn4xLXEIkgq4BGwAD05rZBQc5meY4RxQcY6UPcGJ0hk0NK+IYTXQF1KevtX5aa71Ga71aa/11931fdid8tNZzWusPaa2btdZbPRO81rpda31ZdMKPvdzcXL773e/y7W9/G7vdznve8x4eeOABpqZcrV79/f0MDQ3FOUohYqtz0FVy1R63k0nf2Cy1xa4TuL0jM8scndySYgxDotm0aRMXXXQRjzzyCHfeeSednZ1cfvnlAOTn5/Pwww9TUVER5yiFiJ2uARtVhdkMTs5x8NQkm5Nspdw3NktzRT4Op5byjnAxVvKG3/72t2duf+5zn+Nzn/tcrEMSIiForekcnOSGtip+u/ckHRFutIiFvrEZLqorYnbRwYkUX+knxewdIUTisk7OMz6zyPrqQhoKTBw8Ff3rUSJpat7O2MwidStyaSrNpXdUkr4QQvhl1PDXVxfSUGiia9CG3ZE8XTz97s6duhU5NJbmcdo2z8yCPc5RRU/SJP3lrhxOZMkcuxDLMTp31lYV0FhoZt7u5Ohw8tTFjc6duhU5NJTkAql9Mjcpkn52djYjIyNJmTyNefrZ2dnxDkWIqOganKS2OIeinAwaC1wppSOJSjx9Z1b6uTSWpn7ST4oTuXV1dfT19XH69Ol4h8Lc3FzQCdzYOUuIVNQ5MMm6KtdIkqo8RZbFxMFTk9wS/akjEdE3NkOWxURZfiaZZtcvrROjyfNOJVhJkfQzMjISZtep9vb2mMzQESIZzNsdHDk9zXWtlQCYTYp1VQVJ1cHTNzZL3YoclFIU5WZQnJvB8RRe6SdFeUcIkZh6hqZwODXrqgrP3NdaU0THqcmkKce6kn7umY8bS3JTum1Tkr4QImTGSdz11Z5Jv5CJ2UVOTSTHFqF9YzPUrTg7TrmxNI/eFC7vSNIXQoSsa3CSLIuJptKzK+W2GtcvgI7+xD+Z69mjb2gszaV/bJYFe/K0nQZDkr4QImRdgzbWVBZgMZ9NJeurCjEpkqKu79mjb2goycWpoX981t+nJTVJ+kKIkHl27hhyMs2sLMvj4EDiJ33PHn1DY2keAL0pOoNHkr4QIiSnbfMMTy2wzqOeb2irKYr4ZkfR4NmjbzBKVSdSdByDJH0hREi6zoxfOH8r07aaQvrHZxmbXoh1WEHx7NE3lBdkkZNhTtkLtCTpCyFCYnTueLZrGlrdJ3M7E7zE49mjb1BK0VCSK+UdIYTw1Dk4SWVhFiU+9pNtqykCEv9krnePvqGxNFdW+kII4alrwOZzlQ9QkpdJdVF2ws/g8e7RNzSW5nJidAanMzkuMAuGJH0hRNAWHU56hqZY56Oeb2itLkzoDh5fPfqGhtI85u1OrLbkuMAsGJL0hRBBO3p6mgWHk/V+VvrgOpl75PQ0c4uOGEYWOF89+obGFB6xLElfCBG0Lo+NU/xprSnC4dR0DdpiFVZQfPXoG5rcvfqpOINHkr4QImidAzYyzIpV5Xl+jzkzjiFB6/q+evQNNcXZWEwqJWfwSNIXQgSta3CS5ooCMsz+U0jdihwKsy0Je5GWrx59g8VsonZFTkqOWJakL4QIWufAJOur/J/EBVe/e2tNYcK2bfrq0ffUWJon5R0hhBidXsA6Ob9k546htbqIrsFJHAnY+uivR9/QWJLL8ZHppNkXIFCS9IUQQQnkJK6hraaQuUUnx4anoh1W0Pz16BsaS3OxzdkZn1mMYVTRJ0lfCBGUpcYveGurNU7mJlaJZ6kefUOD0baZYoPXJOkLIYLSNThJWX4m5QVZyx67ujyfTIsp4ZL+Uj36hqay1ByxLElfCBGUrkH/4xe8ZZhNrK0sSLgOnqV69A3GSj/VTuZK0hdCBMzucHJo0HbexilLaasppOPUREKdEF2qR9+QnWGmsjAr5do2JekLIQJ2fGSGebvT58Yp/rTWFDI2s8hAAm2UvlSPvqfG0jxOpNgFWpL0hRABW2rjFH+MK3MTqcSzXI++obEk9UYsS9IXQgSsa8CG2aRorsgP+HPWVRWiEmyj9OV69A2NpbkM2eaZWbDHIKrYkKQvhAhY1+Akq8vzyLKYA/6cvCwLK0vzEmoGz3I9+oYGY/BaCrVtStIXKeP3+wcYmZqPdxgprXOJjVOW0lqTOLP1A+nRNxibpKdSiUeSvkgJh602PvvzPTz82ol4h5KyJmYX6R+fDWj8gre2miL6xmaZSICrWwPp0Tc0lqTeiOWAkr5S6gal1CGlVI9S6os+Hs9SSj3mfvx1pVSTx2MXKaVeVUp1KKXeVkplRy58IVy2HxgEXMlfRMch91z8QMYveDM2Su8YiH+JJ5AefUNRbgZFORkcT6ELtJZN+kopM3Af8F6gFbhDKdXqddjdwJjWuhn4DvAN9+dagIeBT2mt24BtQPx/1YuUs/2gJP1oO9O5E0J5J5E6eALp0fdk7JebKgJZ6W8FerTWR7XWC8CjwE1ex9wEPOi+/UvgWuXqhboe2K+13gegtR7RWifm3mkiafWPz3Kgf5LCbAvHhqdZsDvjHVJK6hywUZybQWXh8uMXvJXlZ1FZmJUgST+wHn1DY2leStX0LQEcUwuc9Pi4D7jU3zFaa7tSagIoBdYAWim1HSgHHtVaf9P7Gyil7gHuAaisrKS9vT3IHyN2pqamJL4wRCO+Z4673jxeU6t48ojmF39op7YgtNNV6fj8BeqNQ7NUZcOLL77o95il4qvMsvNG9yna28ejFOHypqameKt7jpIsveTPcQ7bAn1jizz7/AtYTEv39Ucivmj/+waS9MP9+lcClwAzwHNKqd1a6+c8D9Ja3w/cD7Blyxa9bdu2KIcVuvb2diS+0EUjvh/c/yotFQv81fs28uT3dlLcuJ5tF1UnTHyRFK/4nE7NwPPb+fCWerZta/N73FLx7Zo/xH++eITL3nEV2RmBt3xGUnt7O/MWC2tqM9m2bWtAnzOUf5LfHt1P80Vbzwxhi2Z80f73DWQ51A/Ue3xc577P5zHuOn4RMILrXcFLWuthrfUM8DSwOdyghTCMTS/wxrFR3tNWRXNFPiYldf1oODE6w8yCg9YQTuIa2moKcTh13P99Au3RNxibpKfKiOVAkv6bQItSaqVSKhO4HXjK65ingLvct28Fnteu6UrbgQuVUrnuXwbvBA5GJnQh4NlOK04N72mrIjvDTENJLt1DkvQjzTiJG0q7puFMB08c6/qzdh1wj76hsdSYtpkaHTzLlnfcNfp7cSVwM/CA1rpDKfU1YJfW+ingJ8BDSqkeYBTXLwa01mNKqX/H9YtDA09rrX8fpZ9FpKHtHVZqirK5wL1ZR0tlAYetibdLU7LrHLBhUtBSEXrSr1+RS0FWfDdKH5l1TfoMZqVfUZBFdoYpZaZtBlTT11o/jas043nflz1uzwEf8vO5D+Nq2xQiomYW7LzcfZo7tjacGZzVUpHPC11DLNidZFrk2sNI6RqcpKksj5zM0GvxJpNivXvMcrycnnV1dgWT9JVSNKTQ4DX5XyGS1kuHTzNvd3J9W+WZ+9ZUFmB36pS6mCYRdA3aQurP99ZaXUjngC1uG6UPn1npB17egdQasSxJXySt7R1WinMz2NpUcua+lkrX9Md4nyxMJVPzdnpHZoLaOMWftppCZhcdcfulPDzrDKpH32CMWHbG6ZdVJEnSF0lp0eHkuU4r166rxGI++zJeXW508EhdP1LCGb/gra2mCIjfydzhWR3QHH1vjaW5zNudDNmSf6CfJH2RlF47OsLknJ33eJR2wLXFXWNpHt2y0o+YSHTuGJor8skwq7jV9YdnNfUlwZV2wFXegdTYJF2SvkhKOzqs5GSYuXpN+XmPNVfkS3kngroGbBRkWagtDvzkpz+ZFhNr4rhR+vCsM6iTuAajbTMVevUl6Yuk43Rqdhwc5J1ryn1e2bmmMt+9l6uMeYqErsFJ1lUXBF0S8aetppCDpyZjvlG6bW6R6cXgT+IC1BTnYDYpWekLEQ/7+saxTs6f07XjaU1lAQ6n5vhw8q/K4k1rTVeIG6f401pdyMj0AtbJ2NbH+8cDn6PvLcNsorY4JyXaNiXpi6SzvcOKxaS4dp3vpG9cQCQlnvD1jc1im7dH5CSuoa3WdTL3YIxn6/eNBjdS2VuqjFiWpC+Szo6Dg1y2qpSi3Ayfj68qz8OkkJO5EdDl7tyJxElcg/ELpKM/tnX9YDZP8aWxNJfjw1LeESKmeoZsHD097be0A64OnqbSPGnbjIAu9762aysjl/Tzsyw0lebGvG2zb2yWTBOU5gXXo29oLMljcs7O+MxChCOLLUn6Iqls77ACcH1r1ZLHNVfkc1gGr4Wta9BGY2kueVmRncLeVlMU843S+8ZmKctRIZ+QbkyRTdIl6Yuksr1jkA31xVQVLb3V8prKAnqlgydsnYOTEbkS11trTSEnRmeYnIvd7ql94zOU5YSe8hpTZMSyJH2RNE6Nz7K/b+K8C7J8aanMx+HUHEuBGmy8zC44OD48HdHOHUNrHPbMNVb6oWpwX9TVm+SvKUn6Imk8czCw0g64Vvog4xjCcdhqw6kjM37BW6w3SrfNLTI+sxhW0s/JNFNRkCUrfeEyb3fw7R2HUuLsfqLa3jHI6vI8mivylz12VXkeZpOSDp4wGOMX1kewc8dQUZBNeUFWzE7mGj364ZR3wLWL1gmp6QuAFw+d5nvP9/CRH7/OwMRsvMNJOeMzC7zu3hYxEFkWM42ludKrH4bOARu5mWbqQ+xrX05rdexm6xs9+uGs9AEaSnOTfmy3JP0IeaVnmOwMExOzi3z0J28wNp3cbV2J5rnOIRxOHXDSB9eGKt1S3glZ1+Aka6sKMJkiM37BW1tNIT1DUzE52W706Ie70m8syWXINs/sQvI2CEjSj5CXe4a5bFUpP/roFnpHZ/jYT99ket4e77BSxvaOQaoKs7nQfTVnINZUFnB8ZFo6eEKgtaYzwuMXvLXVFGF36pj8Yu4bmyU7w0RBaC36ZzSWuTp4kvnKXEn6EXBqfJajp6e5srmMy1eX8v07NvF23zifeni3JJwImF1w8FL3aa5vqwxq1dlSWYBTw9HTyf12PB4GJ+eYmF2kNQr1fMPZjdKjX+LpG5ulbkVu2EPjGo0OniQu8UjSj4BXeoYBuLKlDIDr26r4tz+/iJe7h/nbx/bFbWu4VPFS92nmFp1BlXbANW0TZAZPKLoGjPEL0VvpN5bkkh+jjdL7xmdCHr/gKRUu0IrsZXZp6pWeYcryM8+5VP3DW+qZmFnk6093UpiTwb/eckHERtOmm+0dgxTlZLB1ZcnyB3tYWWZ08EhdP1id7s6dtVG4MMtgMinWVxfEpIOnb2yWjfXFQHjJujg3k8JsC71JvF+urPTDpLVmZ88I72guOy+p/9XVq/jMttU88sYJ/s+OQ3GKMLm5tkUc4tp1FWSYg3u5ZlnMNEkHT0i6BmzUFudQmO17qF2kuDZKn4zq3rNGj36o0zW9NZXlJfVKX5J+mA5ZbQxPzfOO5jKfj3/+PWu5Y2s9971whB+/fDTG0SW/N46NMjG7yPVBlnYMLRUF9AzJSj9YXYOTUenP99ZWU8T0giOqFzyFM0ffl4aS5B6xLEk/TDu73fV8P0lfKcW/3Hwh77uwin/5fSe/2HUyluElvR0dg2RnmHinj20RA+HaRWuauUU5oR6ouUUHR05HZ/yCt1iczA13jr63xtJc+sZmWXQ4I/L1Yk2Sfphe6RlmVXkeNUvsH2o2Kb5z20aubC7ji0+8zY6OwRhGGLgD/RPYE+iFrLVmx0ErV7eUk5N5/raIgZAOnuD1DE3hcOqojF/w1lKZj8WkolrXD3eOvrfG0jwcTs2p8eS8CFOSfhgW7E5ePzbqd5XvKcti5od3XswFtUXc+8hbvHZ0JAYRBq5nyMYHvreTH76UOCWo/X0TDEzMhVzagbMzeLplzHLAorFxij9ZFjMtUd4o3ejRD3WOvrezbZvJWeKRpB+Gt06MMbPg8FvP95aXZeGnH7uEhpJc/seDuzjQH9vt4pZizKl/8E/HWbAnxmp/e8cgZpPi3esrQv4aRgePnMwNXNfAJFkWE03uUcLR1lZTGOWVfmR69A1nRiwnaa++JP0wvNIzjEnB5atLA/6cFXmZPHT3VopyMrjrgTc4ejoxTjLu6BikINvCkG2ep98eiHc4AOw4aOXSlSUU54a+Qsu0mNwdPInxPCeDrkEba6sKMEdp/IK31upChqfmGZqci8rXj1SPvqGiIIssi0lW+uno5Z5hNtQXB93WVl2Uw0N3bwXgzp+8EfcBbYMTc+zrm+CTV69idXkeD7xyDK3je0HZkdNT9AxNBX1Bli9rKqWDJxhdUdo4xR9jzHJHlHbScq30I5f0TSZFY2lu0o5YlqQfosm5RfadHA+onu/LqvJ8fvrxrQkxoO2ZTldp54YLqvj4O1ayv2+C3b1jcYsHXKUdgOtal98wZTktlQX0SgdPQIZscwxPLcTkJK5hfRRn60e6R9/QUJK8I5Yl6YfotSMjODUB1/N9ubCuKCEGtO3oGGRlWR6ry/P5s821FOVk8JOdx+ISy9mYrFxUV7RkV1Sg1lTm49Sudw9iaWfGL8SgXdNQmJ1BQ0luVNo2I92jb3Ct9Kfj/o44FJL0Q/RKzzA5GWY2N6wI6+t4Dmj75EOxH9A2MbvIq0dGuL61EqUUuZkW/uLSBrZ3DHIyTm9fByfm2HtyPCKlHfDo4JG6/rKMjVNiWd4BV4knGiv9SPfoGxpLc5lbdDJkm4/o140FSfoherlnmEtXlZBpCf8pNAa07ewZ5vE3Y3vxVvuhIexOzfUe+85+9PJGlFL896vHYxqL4ZmDrtJOIHvhBqKpNA+LdPAEpGvARlVhNisi1N4YqLaaQo6PzGCL8Ebpke7RN5zt4Em+Eo8k/RB4jlKOlA9vqWddVQFPvNUfsa8ZiGcOWinLz2Jj/dl3LNVFObzvwmoeffMkU3EoOW3vsLLKXW6KhEyLiaayPLrlZO6yOgdtMenP92Zcmds5ENlfzJHu0TcYvfrJuIuWJP0QeI9SjpSbN9Xy1onxmO2zO2930H7oNO9eX3Fee94n3tGEbc7Or3b3xSQWw8TMIq8dHeH6tqqITiVdU5kv++UuY8HupGcouhun+NNW49ocJ9J1/Uj36BtqV+RgNqmkPJkrST8EvkYpR8JNG2tQCn6zNzar/VePjDA1bz+ntGPY1LCCTQ3F/Ncrx6I6AdHb84es2J06YqUdQ0tFAb2jM9LBs4Sjw1MsOnRMBq15qyjIoqowm1d6InuleqR79A0ZZhO1xTlJ2bYZUNJXSt2glDqklOpRSn3Rx+NZSqnH3I+/rpRqct/fpJSaVUrtdf/5QWTDj72lRimHq7ooh8tXlfKbt/pj0hXwzEEruZlmrljt+x3L3Veu5PjIDM93DUU9FsP2A1YqCrLYUFcc0a+7prIArZF+/SUYnTuxbNc0KKW4aVMNLxwaYsgWuYu0It2j76mxNJcTqVjeUUqZgfuA9wKtwB1KqVavw+4GxrTWzcB3gG94PHZEa73R/edTEYo7bvqm9JKjlMN186Zajo/MsPfkeFS+vsHp1Dxz0Mo715STneF7mNkNbVXUFGXzwCuxad+cW3Tw4uHgt0UMhLGLlszg8a9zcJJMs4mVZbEZv+Dtti31OJyaX+2OzDvdaPXoGxpKcjmeouWdrUCP1vqo1noBeBS4yeuYm4AH3bd/CVyrUnSbqIMjrvJAJE/ienrvBVVkWUz8OsondPf1jTNkm/dZ2jFYzCY+ekUTfzoyQmeUrpb09HL3MLOLjoi1anpqKjM6eGSl70/XgI3mivygN6uJlFXl+WxdWcJjb56IyDvdaPXoGxpLc5mYXWRiJrIdR9EWyHaJtYBnH2EfcKm/Y7TWdqXUBGAMpFmplHoLmAT+t9b6Ze9voJS6B7gHoLKykvb29mB+hpjaZ52nKs/E4b2vczhK32NDmeKJXb1cXXAaS5Ar3qmpqYCev18eXsCkIHO4m/b2Hr/H1S1oMs3wr798lbsvzAoqlmDje/DteXIsMH/yAO39kV8zVOTCaweP057tf7R1oM9fvEQzvn29M7SVmsP6+uHGtyF/kR8dW+AHTzzP+tLQxmkb3hpydZ4NHe2kffRwROLzZLO6vv4Tz7zEyqLwYjXE5PWntV7yD3Ar8GOPj+8Evu91zAGgzuPjI0AZkAWUuu+7GNcvhsKlvt/FF1+sE9X8okO3/MPv9D/95u2ofp9nDw7qxi/8Tj97cDDoz33hhRcCOu7ab7frO+5/NaBj//HX+3XLPz6tT9vmgo7Hm7/4ZhfseuNXt+vPPbIn7O/hz2ce3q2v/ubzSx4T6PMXL9GKb2x6Xjd+4Xf6hy/2hPV1wo1vdsGuL/jnP0bkdfBfO4/qxi/87pzXbSSfv86BCd34hd/pJ/f2R+xrhhMfsEsvk8+11gGVd/qBeo+P69z3+TxGKWUBioARrfW81nrE/ctlt/uXwZqgfislkLdOjLHgCG/0QiCuXlPOityMqJV4jrqHmV0f4Fybj79jJQt2Jz977URU4gH4ylMdjM0s8uFL6pc/OEQtlfmcGJ1hdkE6eLwZZa+WCHekBSs7w8wtm2p5+sBg2GWTaPXoGxrcvfrJdjI3kKT/JtCilFqplMoEbgee8jrmKeAu9+1bgee11lopVe4+EYxSahXQAiTOLh1BeqVnGEVwo5RDkWE28cENNTxz0MpkhK9QBFfXDsB1AdbOV5fnc83ach56rTcqYyJ+seskj755ks9sW+23kygSjA4emcFzPuNq5TVxTvoAt11Sz4LdGXbrcrR69A25mRYqCrKS7qrcZZO+1toO3AtsBzqBx7XWHUqprymlbnQf9hOgVCnVA/wtYLR1Xg3sV0rtxXWC91Na69FI/xCx8nLPMKuKTEGPUg7FzZtqmbc7+eOByG+tuOOglbZKIam1AAAgAElEQVSaQmqDGGb2iStXMjw1z+/2RXbWfufAJP/05AEuW1XC314X3TeBRgePjGM4X7fVRn6WhZqi7HiHQltNERfWFvHIG+Gd0I1Wj76nZByxHNBpeq3101rrNVrr1Vrrr7vv+7LW+in37Tmt9Ye01s1a661a66Pu+3+ltW7TrnbNzVrr30bvR4kuY5Rya1lkTtgsZ1N9MU2lufwmwiWe07Z59pwY4/rW4Dpkrmwuo6UiP6Kz9m1zi3zmZ3soyM7gu3dswhLlrpHG0jwyzErGMfhw2DpFc0V+1FbFwbrtknq6Bm28HcbuctHs0Tc0lOQl3Q5ackVugIxRym1hdhQESinFzZtqefXoSEQ3WXmu04rWLNmq6S+eT1y5ko5Tk7x+LPw3a1prvvirtzkxOsP379hERUH0V5gZ7h50Gcdwvu4h25l3Qongxo01ZGeYeDTEAYTR7tE3NJbmYp2cT6orvSXpB8gYpdxcHLun7OaNtWgNT+09FbGvueOglboVOSGNzr1lUy0rcjN4IAKz9n/6p+P8/u0BPv+etVy6KrrnSDy1VBZIr76Xkal5hqcWEqKebyjMzuD9F9bw1N5TIe0zEe0efUNjqftkbhKVeCTpB8gYpRxs33w4msry2NRQHLEunul5Ozt7hrm+NbRhZtkZZj5yaSPPdFrDGjS1u3eMr/++k3evr+Seq1aF/HVCsaaigJNj0sHjyfglmEhJH+COrfVMzdv5fQh7Nkdrjr43Y8RyrIYkRoIk/QBEY5RyoG7ZVEvXoC0iV8S+dPg0C3Zn0KUdT3de3ohZKX76p+Mhfb5tQXPvz/dQXZzNtz+0IeLjFpazpjI/oWbwOJ2abquNX+7u4+u/PxiXk8zGaIpES/oXN65gdXkej4VQ4onWHH1vxojlZFrpB3JFbtrzHKU82BW9XnVfPnBRDV/77UF+81Z/2IOwdhy0UpybwZbG0Hf7qizM5gMXVfP4rpP8r+taKAiik8np1Pxw/zwj05onPn0FRbnR74LyZvShH7bauLCuKKbfW2tN//gs+/sm2HdynH194xzonzxnz4LZRQf/cvOFMY3rsNVGQbaFysLwr7iOJKUUt1/SwNef7qTbagvqGoJo9+gbinMzKMy2JFXbpiT9AOz0GKU82BXb712Sl8m2teU8ufcUf3/DuvPm3gdq0eHkuU4r17VWhd0l84krV/Kbvad4fFcfd1+5MuDP+/4LPRwYdvD1Wy7ggtrYJlxDY2luzDp4RqcX2Nc3zr6T4+zvm2B/3zjDUwsAZJpNrK8u4M8213JRXTEb6or40hNvR3wTkUActk6xprIgYTp3PN2yuZZvbu/isTdP8r8/4D3n0b9o9+gblFI0luYlVdumJP1laK15pWc4KqOUA3Xzplqe7Rzi9aMjXBFiienNY6NMzvmenR+si+qKuaRpBT/90zE+dkVTQL+IdnYP851nD3N5jZm/2NoQdgyhyjCbWFUWnQ1VDg3aePHwEPvcK/m+MVddWSloqchn29oKNtQVsaG+mLVVBWRZzu0Eu6C2iMd3ncTp1DEre2ntKi/dcEHkh9xFQll+Fte1VvLEW/18/oa15z1n/sSiR9/QUJrLgTBaS2NNkv4yDlltDE8tRH30wlLevb6SgiwLT7zVH3LS33HQSpbFxFUR2u3rE+9Yyad/todnO63LTsUcmJjlrx99i5aKfD7W6oz7irKlMp99fZEdXX1ydIYPfO9lFh2auhU5bKgr5qOXN3JRXTEX1BaRn7X8f7X11QXMLDjoHZ2J2Xjj4akFxmYWaalIrHq+p9suaeDptwd59uAQ77+oOqDP6RubZVN96GXMYDSW5LL9wCB2hzPq15pEQuJHGGc7u931/Dgm/ewMM++9sIo/HhgMqetEa82OjkGuaiknNzMyv+eva62ktjhn2fbNRYeTe3/+FnOLDv7jIxeTZYl/CWFNZQEnR2eZWYjc/r8/fOkICkX7321j5xfexX0f2cw9V6/mslWlASV8gNZqV8krFmOsDd0JNH7Bnyuby6gtzuHRNwM7n3a2Rz82K/2m0jzsTs2p8fA2f3E6NQuO6G+eJEl/GTt7hllVnkdNECMLouHmTbVMzdt5ttMa9Od2nJrk1MRcREo7BovZxMeuaOL1Y6NLvrX9xh+62N07xr/9+UU0VyTGxT/GRUiR6uAZmpzj8V193LqljqYwVugtlfmYTYqDp2KX9M/O3EmMfxtfzCbFh7bU8XL3MCcDqJ2f7dGPbrumoaE0/E3SD/RPcOsP/sQvDi9EKiy/JOkvYcHu5PWjo3Fd5RsuW1lKdVF2SGMZdhy0YlJw7bqKiMb04Uvqyc00+91Z648HBvjxzmPcdXkjN26oiej3DofRBdIdoYu0frzzGHaHk09dvTqsr5OdYaa5PJ+DMVzpH7JOUZybQXlBYnXuePvwlnqUcg3nW87ZHv3YLNSMC7RCOZk7MbPIl588wI3f30nvyAxNhdFPyZL0l/DWiTFmFx1xrecbTCbFjRtrePHwaUam5oP63B0dg2xpLKE0P7L/sYtyMvjwlnp+u+/UefuaHh+e5vO/2M+G+mL+4f3rI/p9w9VYkkum2cThCGydOD6zwMOv9XLjhpozK75wrK8uiOlKv9tqY01FYnbueKopzuGda8p5fFcfDufSJZBY9egbKguyybKYghqx7HRqHt91knd9u52HX+vlzssaef7vtvGO2ui3MUvSX8IrPcOYVPRHKQfqlk212J2a3+0P/ArFk6MzdA3aIlra8XTXFU3YnZqHPWbtzy06+PTP9mA2K+77i00Bd1zEisVsYlV5XkRW+j/903FmFhx8eltzBCKD1ppCBifnGJ2O/tt8rTWHrTZaEri04+n2S+oZnJzjpcOnlzyub2yWnAwzJVHu0TeYTIqGktyAe/WNUs7f/3I/TWV5/PZ/XslXb7qAopzYXLciSX8JL/cMs6G+OCajlAOxrqqQ9dWFQY1l2GHMzg9ww5RgrSzL49p1Ffzstd4zQ6f++ckOOgcm+c5tG2NWVw2WawZPeCv9qXk7//XKca5rrWRtCLOMfInlydwh2zyTc/aEPonr6V3rKinLz1z2hO7JMVe7ZizfvTSWLp/0vUs537r1In7xyctpq4ntNSuS9P0wRiknQj3f0y2bath7cpxjAc762NExyNrKgjMzQqLhE+9Yycj0Ak/tO8Xju07y2K6T3HtNM9esjew5hEhaU5FP39hsSMO8DD9/vZeJ2UU+e01kVvngKu8AMSnxGL/0kmWln2kx8eeb63iuc+i8cqKnWIxU9tZQkseJ0RmfY8f9lXI+tKU+5mNIQJK+X8Yo5URL+jduqEUpAjqhOza9wJvHR6NW2jFcvrqUdVUFfO/5bv7pNwe4YnUp/yvKG6KEyziZG2oHz9yigx+9fIwrm8vYWF8csbhK87OoLMyKycncRB20tpQPX1KP3al5Yo//179xNW4sNZXlMrvo4LTt3PNt8S7l+CJJ34+d7lHKmxpic4FHoKqKsrlidSm/2du/7GYmz3UN4dTRK+0YjFn7J0dnKcrJ4P/dvinkcRGxYrQohjqO4Ze7+zhtm+cz14TXseNLa3VhTMo73VYbJXmZlEX4BH80rS7PZ2tTCY+9edLn639ybpGJ2dj16BuM/XKPu0s83qWc//OhDXEp5fgiSd+Pne5RypmWxHuKbt5YS+/IDHtOLH1V6Y6OQaoKs7kwBnNubtxQw19e1sD9H92S8O1/4PpPmmk2hTSOwe5w8oMXj7CpoZjLo7AXQGtNIT1DU1HfmOOw1UZLglw7EYzbLqnn2PC0z818+sdi26NvODNieWT6nFLORy9v4vm/28atF9fFpZTjS+JltAQQz1HKgbjhgiqyM0xLlnhmFxy81H2a69sqY3JCKzvDzL/cfGFESx3RZHTwhHIy96l9p+gbm+Xea5qj8ty2Vhdhd+qojn92zdyZSqrSjuF9F1ZTkG3xOXK5byy2PfqG2uIczCbFV5/qOKeU85Ub2+JayvFFkr4PnqOUE1FBdgbXtVbxu/2nWLA7fR6zs2eYuUVn1Es7yWxNCLtoOZ2a/2g/wrqqAt4V4YvdDLE4mTswMYdt3s6aCHUdxVJOppmbN9by9NsDTMwsnvNYrHv0DZkWE2sqC8jOMCdUKccXSfo+eI5STlS3bKphbGbRb8/yjo5BCrItXLoyMa4xSERrKvPpHw+ug2fHQSs9Q1N8JkqrfHCVCnIzzVE9mXtm/EISlnfAVeKZtzt5ct+573Zj3aPv6dG/uoyXv3BNQpVyfJGk7yURRikH4qqWckrzMn327Ducmue6hnjXuoqEPCeRKILt4NFa8x/tPTSV5vL+CwOb9hgKs0mxrqogqkm/Owk7dzxdUFvEBbWFPPLGuSd0++LQo28oys2I2EDDaJKM4CURRikHIsNs4oMbanim08rk3LlvcXf3jjE6vSClnWUYJzEDreu/3D3M/r4JPr1tddS7k1prCuk8Nblsh1aoDlttlOVnsSIOK+JIue2SBjoHJjnQf/aXYzx69JONJH0viTBKOVA3b6plwe7kj28PnnP/jo5BMs0m3rmmPE6RJYfG0jwyLaaA2zbve6GH6qJsbtlUF+XIYH11IbZ5+5kTk5F2eGgqoSdrBuLGDTVkZ5jOuUI3Hj36yUaSvpdEGaUciA11RawsyzunxKO1ZsdBK1c0lwa1f206MpsUq8vzA1rp7zo+yuvHRvmrq1bFpGTW6t4PORolHq01PVZb0pZ2DEU5Gbzvwmqe3HuKmQV73Hr0k40kfQ+JNEo5EEopbt5Yy2vHRjjlniHeP6U5MTojpZ0AranMD2jw2n+0H6EkL5Pbt9bHICrXnCWTik4HT//4LNMLjqQZv7CU2y9pYGrezu/3D8StRz/ZSNL3kEijlAN186YatIYn954CYM+QqxPluvWS9AOxprKA/vFZppbo4Ok4NcHzXUN84h1NMTtRl5NpZmVZXlRW+oeTYLesQF3StIJV5Xk89ubJuPXoJxtJ+h52Jtgo5UA0luZxceMKfv1WH1pr9lgdbGoopqIwO96hJQXjZO5SHTz/0X6EgiwLd17eFKOoXNZHaRzDmZk7CbwvbqCUUtx+ST27esdoPzQESNJfjiR9DzsTbJRyoG7eVMth6xTPdw1xfFIuyAqG0bbpr65/9PQUT789wJ2XN8b8ysrWmkL6xmaZmF1c/uAgHLbaqCzMoig3uV7n/vzZ5josJsXju07GrUc/mUjSd0vUUcqB+MCF1VhMii898TYA17dWxTmi5NFQkkuWxf8Mnh+8eIRMs4lPXLkyxpGdPZkb6dV+so5f8KcsP4vrWitZdOi49egnE0n6bruPj+HUyVXaMazIy2Tb2gqGbPNU5amE2YA8GZzt4Dm/vNM/PssTe/q5Y2tDXCZRtta4O3gieDLX6Z7p05ICpR1Pt13iOsEupZ3lSdJ32907htmkkmZgmLdbNtUCsLki8a8ITDSuDp7zV/o/eukoAPdcvSrWIQFQUZBNWX5mRFf6fWOzzC46kr5H39tVLeWsqcxnY31ijUJPRJIh3Hb3jtFaXZgUl1H78u7WCv7qqpWsMw0uf7A4R0tlAb/Zewqbx5XNw1PzPPLGCf5sc21cr9lYX10Y0Q6es7tlpdZK32xS/PFzVyf0zJtEISt9XPPR954c5+LG5F0lZFnM/OP7WynNkX/SYK3xMYPngZ3HWHA4+dQ7I79JSjBaawrptk75naYarMNDybVFYjAk4QdGMgTQNWhjdtHB5iRO+iJ0RtumcZHWxOwiD73ay/surGZVeXyTY2t1IQsOJ0dOR2a2frd1iuqi7KTrUBORI0kfV2kHSOqVvghdvbuDxyh9PPTqcWzzdj67LXIbnocq0h08hwZtKVfaEcEJKOkrpW5QSh1SSvUopb7o4/EspdRj7sdfV0o1eT3eoJSaUkr9XWTCjqzdvWNUFWZTUyQXNKUjs8nV8XR4aIp5u+aBV47zrnUVZ7pn4mllWR5ZFlNEOngcTs2R01OsTcHSjgjcsklfKWUG7gPeC7QCdyilWr0OuxsY01o3A98BvuH1+L8Dfwg/3OjY3TvGxY0rpL83ja2pLKDbauPFPjuj0wt8NgobnofCYjZFbLb+idEZ5u1OWemnuUBW+luBHq31Ua31AvAocJPXMTcBD7pv/xK4VrkzqFLqZuAY0BGZkCPLOjlH//is1PPTXEtlPgMTc/zu6CKXrizh4saSeId0RmuNq4Mn3Nn6qTRzR4QukP7EWsBzB+I+4FJ/x2it7UqpCaBUKTUHfAG4DvBb2lFK3QPcA1BZWUl7e3ug8YftzUHXoC01fJT29t5lj5+amoppfMGS+EIz7x5UN7mguap0JqFiNNsWGZ9Z5NfbXyDTHnps248sADB46C3aj0TnXW2i/vsaJL7o9+l/BfiO1npqqdKJ1vp+4H6ALVu26G3btkU5rLN2/u4gWZZe/vID1wQ0J729vZ1YxhcsiS80K0em+X972llZaOKzf/6uhCr15R8f5eHOVylqbMNs7Qz5+Xti4C1qi8e44d3XRDZAD4n672uQ+AJL+v2A5xDxOvd9vo7pU0pZgCJgBNc7gluVUt8EigGnUmpOa/39sCOPkN0nxriorkj2kk1z9Sty+dDFdayxDCdUwgdYV312HMOF5tC/zmGrLeWuxBXBCyTTvQm0KKVWKqUygduBp7yOeQq4y337VuB57XKV1rpJa90E/F/gXxMp4c8tOjjQPyH1fIHJpPjWhzbQsiKMrBol+VkWGktzwzqZa3c4OXp6Wur5Yvmkr7W2A/cC24FO4HGtdYdS6mtKqRvdh/0EVw2/B/hb4Ly2zkR0oH+CRYfm4gZJ+iKxtYY5W//4yAwLDuncEQHW9LXWTwNPe933ZY/bc8CHlvkaXwkhvqgyLsqSlb5IdK3VhfzhwCCz9tC2Auw+07kj5Z10l9aF7N29YzSV5sZlbK4QwTAuFOuzhTaD57B1CqWQsdsifZO+1po9J8ZklS+Swnr3ydwToSb9IRv1K3KTdoqsiJy0TfonRmcYnlqQeTsiKVQXZVOcm8GJydCSfrd07gi3tE36MmRNJBOlFK3VhSGt9BcdTo4NT8tJXAGkedIvyLKk3LZxInW1VhfSZ3NidwSX+I8PT7Po0LLSF0CaJ/2NDcWYZeMFkSTWVxey6ITjI9NBfZ6x/68scASkadK3zS1yyGqT0o5IKkYHT0eQY5YPWW2YpHNHuKVl0t97chytpZ4vksvq8nwsiqCvzO222mgoySU7I/GuNhaxl5ZJf3fvGErBxvrieIciRMAyLSZqC4LfUMU1c0dKO8IlbZP+2soCCmSfUJFk6gtMdA7YAj5+3u7g+MiMJH1xRtolfYdTs/fEuJR2RFJqKDAxPDXPkG0uoOOPDU/jcGpapHNHuKVd0u8esmGbt0vSF0mpodD1XzbQEo/RuSMrfWFIu6QvF2WJZFZf4E76AZ7M7bbaMJsUq8rzohmWSCJpmfTL8jNpKAltWqEQ8ZSXoagtzgm4rn/YaqOxNJcsi3TuCJe0S/p7esfY3LAi4XZHEiJQrTWFHDw1EdCxh61TrJGLsoSHtEr6w1PzHB+ZkcmaIqm1VhdydHiamQX7ksfNLTroHZmW8QviHGmV9N86MQ5IPV8kt9aaQrSGQ4NLl3iOnJ7CqZFBa+IcaZX0d/eOkWFWXFhbFO9QhAhZq3u2/nJ1/W53587aKkn64qy0Svp7esdoqymSy9FFUqtbkUNBloWDA0vX9Q9bbVhMiqZS6dwRZ6VN0l+wO9nXJxdlieSnlGJ9TeGyvfqHrVOsLMsj05I2/81FANLm1XBwYJJ5u1OSvkgJrdWFdA3acDq132O6h2Tmjjhf2iR9uShLpJLW6kJmFhz0js74fHx2wcGJ0RkZvyDOkzZJf0/vGLXFOVQWZsc7FCHCZszW91fiOXJ6Cq1l/II4X1okfa01u3pHZZUvUkZzRT4Wk/J7Mtdo55QefeEtLZL+qYk5rJPzkvRFysjOMNNcke+3bfPwkI0Ms6JROneEl7RI+lLPF6lofbX/Dp5u6xSry/PJMKfFf3ERhLR4RezpHSMnw8w6uUhFpJDW6kIGJ+cYmZo/77HDVptciSt8Soukv7t3jI31xVhk1SNSiHEy17vEMz1vp29sljWyEbrwIeWz4MyCnYMDk1LaESln/ZlxDOeWeHqGXOMXZKUvfEn5pL/v5AQOp5akL1JOSV4mVYXZ522octgqnTvCv5RP+ntOuE7ibmoojnMkQkReq49xDN1DU2RaTNK5I3xK+aS/u3eM5op8inMz4x2KEBHXWl1Iz+kp5hYdZ+47NGhjdXk+ZpNsFCTOl9JJ3+nU7DkxxsUNUtoRqam1phCHU5+p44NrX1wp7Qh/UjrpHx2eZnxmUer5ImUZJ3ONEo9tbpFTE3MyfkH4ldJJf4/7oqzNjVLPF6mpsSSX3EzzmZO53e4VvyR94U9ASV8pdYNS6pBSqkcp9UUfj2cppR5zP/66UqrJff9WpdRe9599SqlbIhv+0nb3jlGUk8GqMnmrK1KTyaTOuTK3Wzp3xDKWTfpKKTNwH/BeoBW4QynV6nXY3cCY1roZ+A7wDff9B4AtWuuNwA3AD5VSlkgFv5zdJ8bY3FCMSU5oiRTWWl1I58AkWmsOW6fIzjBRvyI33mGJBBXISn8r0KO1Pqq1XgAeBW7yOuYm4EH37V8C1yqllNZ6Rmttd9+fDfjf8SHCxmcW6Bmaknq+SHnrqwuxua/CPWy10VyRLwsd4VcgSb8WOOnxcZ/7Pp/HuJP8BFAKoJS6VCnVAbwNfMrjl0BUvXVyHIDNkvRFijPGMXScmqTbOsWaCqnnC/+iXmrRWr8OtCml1gMPKqX+oLWe8zxGKXUPcA9AZWUl7e3tYX/fJ7oXMCmYPPY27Scjt+qZmpqKSHzRIvGFJxnjm3doFPCrl/cxOGnHPD0Ut58hGZ+/RBKL+AJJ+v1AvcfHde77fB3T567ZFwEjngdorTuVUlPABcAur8fuB+4H2LJli962bVsQP4Jv93e/RmvNIje8+6qwv5an9vZ2IhFftEh84UnW+Fbve5G3RhYBOzdcvoFt6ytjHhsk7/OXKGIRXyDlnTeBFqXUSqVUJnA78JTXMU8Bd7lv3wo8r7XW7s+xACilGoF1wPGIRL4Eu8PJ3pPjclGWSBvrqwsZdo9YlnZNsZRlk767Bn8vsB3oBB7XWncopb6mlLrRfdhPgFKlVA/wt4DR1nklsE8ptRf4NfAZrfVwpH8Ib12DNmYWHFLPF2mj1X2RVm6mmdrinDhHIxJZQDV9rfXTwNNe933Z4/Yc8CEfn/cQ8FCYMQbNGLImnTsiXRgnc1ukc0csIyWvyN3dO0ZlYZaseETaWF/tKunIDH2xnJhdKBVLu3vHuLhxBUrJikekh4qCbO66vJH3XFAV71BEgku5pG+dnKNvbJaPXdEU71CEiKmv3nRBvEMQSSDlyjvGkDWp5wshxPlSLunv7h0j02KiraYo3qEIIUTCSb2kf2KMDXVFZFpS7kcTQoiwpVRmnFt0cKB/QvrzhRDCj5RK+gf6J1h0aLkSVwgh/EippL/7zE5ZkvSFEMKXlEv6TaW5lOVnxTsUIYRISCmT9LXW7DkxxmYp7QghhF8pk/RPjM4wPLUgpR0hhFhCyiT9RYeT915QxaUrS+IdihBCJKyUGcPQXFHAf/7lxfEOQwghElrKrPSFEEIsT5K+EEKkEUn6QgiRRiTpCyFEGpGkL4QQaUSSvhBCpBFJ+kIIkUYk6QshRBpRWut4x3AOpdRpoDfecSyhDBiOdxBLkPjCI/GFR+ILTzjxNWqty5c7KOGSfqJTSu3SWm+Jdxz+SHzhkfjCI/GFJxbxSXlHCCHSiCR9IYRII5L0g3d/vANYhsQXHokvPBJfeKIen9T0hRAijchKXwgh0ogkfSGESCOS9L0opeqVUi8opQ4qpTqUUp/zccw2pdSEUmqv+8+XYxzjcaXU2+7vvcvH40op9V2lVI9Sar9SanMMY1vr8bzsVUpNKqX+xuuYmD9/SqkHlFJDSqkDHveVKKWeUUp1u//2udemUuou9zHdSqm7Yhjft5RSXe5/w18rpYr9fO6Sr4coxvcVpVS/x7/j+/x87g1KqUPu1+MXYxjfYx6xHVdK7fXzubF4/nzmlbi8BrXW8sfjD1ANbHbfLgAOA61ex2wDfhfHGI8DZUs8/j7gD4ACLgNej1OcZmAQ10UjcX3+gKuBzcABj/u+CXzRffuLwDd8fF4JcNT99wr37RUxiu96wOK+/Q1f8QXyeohifF8B/i6A18ARYBWQCezz/v8Urfi8Hv828OU4Pn8+80o8XoOy0veitR7QWu9x37YBnUBtfKMK2k3Af2uX14BipVR1HOK4FjiitY77FdZa65eAUa+7bwIedN9+ELjZx6e+B3hGaz2qtR4DngFuiEV8WusdWmu7+8PXgLpIf99A+Xn+ArEV6NFaH9VaLwCP4nreI2qp+JRSCvgw8Eikv2+glsgrMX8NStJfglKqCdgEvO7j4cuVUvuUUn9QSrXFNDDQwA6l1G6l1D0+Hq8FTnp83Ed8fnHdjv//aPF8/gyVWusB9+1BoNLHMYnyXH4C17s3X5Z7PUTTve7y0wN+ShOJ8PxdBVi11t1+Ho/p8+eVV2L+GpSk74dSKh/4FfA3WutJr4f34CpZbAC+B/wmxuFdqbXeDLwX+KxS6uoYf/9lKaUygRuBX/h4ON7P33m06310QvYvK6X+EbADP/NzSLxeD/8JrAY2AgO4SiiJ6A6WXuXH7PlbKq/E6jUoSd8HpVQGrn+Yn2mtn/B+XGs9qbWect9+GshQSpXFKj6tdb/77yHg17jeQnvqB+o9Pq5z3xdL7wX2aK2t3g/E+/nzYDXKXu6/h3wcE9fnUin1MeADwEfcSeE8AbweokJrbdVaO7TWTuBHfr5vvJ8/C/BnwGP+jonV8+cnr8T8NShJ3ya33SkAAAL0SURBVIu7/vcToFNr/e9+jqlyH4dSaiuu53EkRvHlKaUKjNu4TvYd8DrsKeCj7i6ey4AJj7eQseJ3dRXP58/LU4DRCXEX8KSPY7YD1yulVrjLF9e774s6pdQNwN8DN2qtZ/wcE8jrIVrxeZ4nusXP930TaFFKrXS/+7sd1/MeK+8GurTWfb4ejNXzt0Reif1rMJpnrJPxD3AlrrdY+4G97j/vAz4FfMp9zL1AB65OhNeAK2IY3yr3993njuEf3fd7xqeA+3B1TbwNbInxc5iHK4kXedwX1+cP1y+gAWARV030bqAUeA7oBp4FStzHbgF+7PG5nwB63H8+HsP4enDVco3X4Q/cx9YATy/1eohRfA+5X1/7cSWvau/43B+/D1e3ypFYxue+/6fG687j2Hg8f/7ySsxfgzKGQQgh0oiUd4QQIo1I0hdCiDQiSV8IIdKIJH0hhEgjkvSFECKNSNIXaUkp5VDnTgON2PRHpVST57RHIRKJJd4BCBEns1rrjfEOQohYk5W+EB7cs9W/6Z6v/oZSqtl9f5NS6nn3cLHnlFIN7vsrlWvW/T73nyvcX8qslPqRe3b6DqVUTtx+KCE8SNIX6SrHq7xzm8djE1rrC4HvA//Xfd/3gAe11hfhGnz2Xff93wVe1K7hcZtxXdUJ0ALcp7VuA8aBP4/yzyNEQOSKXJGWlFJTWut8H/cfB96ltT7qHpA1qLUuVUoN4xozsOi+f0BrXaaUOg3Uaa3nPb5GE6755y3uj78AZGit/yX6P5kQS5OVvhDn035uB2Pe47YDOX8mEoQkfSHOd5vH36+6b/8J14RIgI8AL7tvPwd8GkApZVZKFcUqSCFCIasPka5y1LkbZf9Ra220ba5QSu3HtVq/w33f/wT+Syn1eeA08HH3/Z8D7ldK3Y1rRf9pXNMehUhIUtMXwoO7pr9Faz0c71iEiAYp7wghRBqRlb4QQqQRWekLIUQakaQvhBBpRJK+EEKkEUn6QgiRRiTpCyFEGvn/KZJyGosd/NoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log = pd.read_csv('x', header = None, names = ['Fold', 'Epoch', 'Re'], sep = ' ')\n",
    "log.groupby('Epoch').agg({'Re': ['mean', 'median']}).plot(grid = True, title = 'mean')\n",
    "log.groupby('Epoch').agg({'Re': 'std'}).plot(grid = True, title = 'std')\n",
    "# log.groupby('Epoch').agg({'Re': 'median'}).plot(grid = True, title = 'median')\n",
    "# log.groupby('Epoch').agg({'Re': 'count'}).plot(grid = True)\n",
    "log.groupby('Epoch').agg({'Re': 'mean'})\n",
    "# log[log.Fold == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cand shape:  16\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.377448\t1195\t3166\n",
      "\n",
      "\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.263108\t833\t3166\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unseen_class: \t0.385028\t1219\t3166\n",
      "\n",
      "\n",
      "cand shape:  16\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.612995\t1934\t3155\n",
      "\n",
      "\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.556894\t1757\t3155\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unseen_class: \t0.584152\t1843\t3155\n",
      "\n",
      "\n",
      "cand shape:  16\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.590740\t1901\t3218\n",
      "\n",
      "\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.631137\t2031\t3218\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unseen_class: \t0.628962\t2024\t3218\n",
      "\n",
      "\n",
      "cand shape:  16\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.572295\t1793\t3133\n",
      "\n",
      "\n",
      "16/16 [==============================] - 0s\n",
      "\n",
      "\n",
      "Unseen_class: \t0.575806\t1804\t3133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unseen_class: \t0.547399\t1715\t3133\n",
      "\n",
      "\n",
      "cand shape:  16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b714bdda1934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     multi_models_vote(models = zs_model_list, eval_df = validate_part_df,             cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr['class_id'].isin(unseen_class)],             img_feature_map = extract_array_from_series(validate_part_df['target']),\n\u001b[1;32m     20\u001b[0m             class_id_dict = {\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0;34m'Unseen_class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munseen_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             })\n",
      "\u001b[0;32m<ipython-input-26-6ca63de5e674>\u001b[0m in \u001b[0;36mmulti_models_vote\u001b[0;34m(models, eval_df, cand_class_id_emb_attr, img_feature_map, class_id_dict)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'cand shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcand_class_id_emb_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     preds = models_eval(models, eval_df, cand_class_id_emb_attr, img_feature_map, \n\u001b[0;32m---> 41\u001b[0;31m                 class_id_dict)\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# print (preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-6ca63de5e674>\u001b[0m in \u001b[0;36mmodels_eval\u001b[0;34m(models, eval_df, cand_class_id_emb_attr, img_feature_map, class_id_dict, class_to_id)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         pred = model_eval(model, model_type, eval_df = eval_df, cand_class_id_emb_attr = cand_class_id_emb_attr, \n\u001b[0;32m---> 81\u001b[0;31m             img_feature_map = img_feature_map, class_id_dict = class_id_dict, class_to_id = class_to_id)\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-6ca63de5e674>\u001b[0m in \u001b[0;36mmodel_eval\u001b[0;34m(model, model_type, eval_df, cand_class_id_emb_attr, img_feature_map, class_id_dict, class_to_id)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DEM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mzs_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mcand_feature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_dem_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand_class_id_emb_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_nearest_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand_class_id_emb_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcand_feature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_feature_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'class_id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     return self._predict_loop(\n\u001b[0;32m-> 1739\u001b[0;31m         f, ins, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m           \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m         **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 run_metadata):\n\u001b[1;32m   1292\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1354\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def lgbm_train(train_part, train_part_label, valide_part, valide_part_label, fold_seed,\n",
    "        fold = 5, train_weight = None, valide_weight = None, flags = None):\n",
    "    \"\"\"\n",
    "    LGBM Training\n",
    "    \"\"\"\n",
    "    if flags.stacking:\n",
    "        FEATURE_LIST += ['emb_' + str(i) for i in range(len(CATEGORY_FEATURES) * 5)] + ['k_pred']\n",
    "    print(\"-----LGBM training-----\")\n",
    "\n",
    "    d_train = lgb.Dataset(train_part[FEATURE_LIST].values, train_part_label, weight = train_weight, \n",
    "            feature_name = FEATURE_LIST, categorical_feature = CATEGORY_FEATURES,)#, init_score = train_part[:, -1])\n",
    "    d_valide = lgb.Dataset(valide_part[FEATURE_LIST].values, valide_part_label, weight = valide_weight,\n",
    "            feature_name = FEATURE_LIST, categorical_feature = CATEGORY_FEATURES,)#, init_score = valide_part[:, -1])\n",
    "    params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt', #'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'num_leaves': 240, #60, #40, # 60,\n",
    "            'min_sum_hessian_in_leaf': 10,\n",
    "            'max_depth': 50,#12, #6, # 10,\n",
    "            'learning_rate': 0.025, # 0.025,\n",
    "           # 'feature_fraction': 0.5,#0.35, # 0.6\n",
    "            'verbose': 0,\n",
    "            'num_boost_round': 500, #361,\n",
    "            'feature_fraction_seed': fold_seed,\n",
    "            #'drop_rate': 0.05,\n",
    "            # 'bagging_fraction': 0.8,\n",
    "            # 'bagging_freq': 20,\n",
    "            # 'bagging_seed': fold_seed,\n",
    "             'early_stopping_round': 1500,\n",
    "            # 'random_state': 10\n",
    "            # 'verbose_eval': 20\n",
    "            #'min_data_in_leaf': 665\n",
    "        }\n",
    "    params.update(config.all_params)\n",
    "    print (\"lightgbm params: {0}\\n\".format(params))\n",
    "\n",
    "    bst = lgb.train(\n",
    "                    params ,\n",
    "                    d_train,\n",
    "                    verbose_eval = 50,\n",
    "                    valid_sets = [d_train, d_valide],\n",
    "                    # feature_name= keras_train.DENSE_FEATURE_LIST,\n",
    "                    #feval = gini_lgbm\n",
    "                    #num_boost_round = 1\n",
    "                    )\n",
    "    #pred = model_eval(bst, 'l', valide_part)\n",
    "    #print(pred[:10])\n",
    "    #print(valide_part_label[:10])\n",
    "    #print(valide_part[:10, -1])\n",
    "    # exit(0)\n",
    "    feature_imp = bst.feature_importance(importance_type = 'gain')\n",
    "    sort_ind = np.argsort(feature_imp)[::-1]\n",
    "    print (np.c_[np.array(FEATURE_LIST)[sort_ind], feature_imp[sort_ind]])\n",
    "    # print (np.array(keras_train.FEATURE_LIST)[np.argsort(feature_imp)])\n",
    "    # exit(0)\n",
    "    # cv_result = lgb.cv(params, d_train, nfold=fold) #, feval = gini_lgbm)\n",
    "    # pd.DataFrame(cv_result).to_csv('cv_result', index = False)\n",
    "    # exit(0)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cand shape:  45\n",
      "32/45 [====================>.........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "def sub(models, train_data, test_data, class_id_emb_attr, img_model, output_model_path):\n",
    "    train_id = train_data['class_id'].unique()\n",
    "    test_img_feature_map = extract_array_from_series(test_data['target'])\n",
    "    preds = multi_models_vote(models = models, eval_df = test_data, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)], \\\n",
    "            img_feature_map = test_img_feature_map)\n",
    "    sub = pd.DataFrame(preds, index = test_data['img_id'])\n",
    "    time_label = time.strftime('%Y%m%d_%H%M%S')\n",
    "    tmp_model_dir = \"./model_sub/\"\n",
    "    if not os.path.isdir(tmp_model_dir):\n",
    "        os.makedirs(tmp_model_dir, exist_ok=True)\n",
    "    sub_name = tmp_model_dir + \"/submit_\"+ time_label + \".txt\"\n",
    "    sub.to_csv(sub_name, header = False, sep = '\\t')\n",
    "\n",
    "#     model_name = tmp_model_dir + \"imgmodel_\" + time_label + \".h5\"\n",
    "#     img_model[0].save(model_name)\n",
    "#     for i, model in enumerate(models):\n",
    "#         model_name = tmp_model_dir + \"zsmodel_\" + str(i) + time_label + \".h5\"\n",
    "#         model[0].save(model_name)\n",
    "\n",
    "    if not os.path.isdir(output_model_path):\n",
    "        os.makedirs(output_model_path, exist_ok=True)\n",
    "    for fileName in os.listdir(tmp_model_dir):\n",
    "        dst_file = os.path.join(output_model_path, fileName)\n",
    "        if os.path.exists(dst_file):\n",
    "            os.remove(dst_file)\n",
    "        shutil.move(os.path.join(tmp_model_dir, fileName), output_model_path)\n",
    "        \n",
    "cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(round2_class_id)]\n",
    "sub(models = zs_models, train_data = train_data, test_data = test_data, \n",
    "        class_id_emb_attr = cand_class_id_emb_attr, img_model = img_model, \n",
    "        output_model_path = '../submit/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model_dir = path + \"./model_dir/6_12_24_16_ini_64_grow_32_03535/\"\n",
    "# time_label = time.strftime('_%Y_%m_%d_%H_%M_%S', time.gmtime())\n",
    "# if not os.path.isdir(tmp_model_dir):\n",
    "#     os.makedirs(tmp_model_dir, exist_ok=True)\n",
    "# model_name = tmp_model_dir + \"model\" + time_label + \".h5\"\n",
    "# img_model.model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38221/38221 [==============================] - 2s 45us/step\n"
     ]
    }
   ],
   "source": [
    "pred_class_probas = img_classifi_model.predict(train_image_feature_map, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['preds'] = list(pred_class_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "891 * 80 / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n03598930', 'jigsaw_puzzle', 0.023861792), ('n02095314', 'wire-haired_fox_terrier', 0.022931756), ('n04589890', 'window_screen', 0.021361042)]\n"
     ]
    }
   ],
   "source": [
    "# np.asarray(list(train_data['img'])).shape\n",
    "# train_data[train_data['class_id'] == 'ZJL1']\n",
    "# train_data['class_id'].value_counts().hist()\n",
    "# train_data.head()\n",
    "# class_id_emb_attr.iloc[0].name\n",
    "# resnet50_model = ResNet50(weights='imagenet', input_shape=(224, 224, 3))\n",
    "img = image.load_img(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg', target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = vgg16.preprocess_input(img)\n",
    "preds = vgg_model.predict(np.expand_dims(img, axis=0))\n",
    "print('Predicted:', vgg16.decode_predictions(preds, top=3)[0])\n",
    "# imread(path + '/DatasetA_train_20180813/train/000c0d617f5b67d116dee15c40d1d47d.jpeg')\n",
    "# image.img_to_array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = setA_train_data\n",
    "\n",
    "img_model = DenseNet(blocks = [6, 12, 24, 16], \n",
    "                                cat_max = 205,\n",
    "                                weight_decay = 1e-4, \n",
    "                                kernel_initializer = 'glorot_normal',\n",
    "                                reduction = 0.5, \n",
    "                                init_filters = 128, \n",
    "                                growth_rate = 32).model\n",
    "img_model.load_weights(path + '/model_sub/6_12_24_16_ini64_growth32_inistride2_03621/model_0_2018_09_21_21_10_59.h5')\n",
    "img_model_flat = Model(input = img_model.input, output = img_model.get_layer(name = 'avg_pool').output)\n",
    "train_data['target'] = list(img_model_flat.predict(preprocess_img(train_data['img']), verbose = 1))\n",
    "# train_data['preds'] = list(img_model.predict(train_img, verbose = 1))\n",
    "# train_data['target'] = list(train_y) #\n",
    "# with open('../..//Data/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/model_0_2018_09_24_03_07_15.h5', 'rb') as handle:\n",
    "#     flat_train_re = pickle.load(handle)\n",
    "# train_data['target'] = list(flat_train_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0262023 , 1.0496653 , 0.42650044, ..., 0.09345146, 0.14242867,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_train_re[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2266190e+00, 1.6327184e-01, 2.8384233e-01, ..., 4.1941926e-04,\n",
       "       3.3683911e-02, 7.6473856e-01], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['target'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_part_img_id = pd.read_csv(path + '/model_sub/6_12_24_16_ini64_growth16_02962/train_part_img_id_0.csv', header = None)\n",
    "validate_part_img_id = pd.read_csv(path + '/model_sub/6_12_24_16_ini64_growth16_02962/validate_part_img_id_0.csv', header = None)\n",
    "train_part_img_id = train_part_img_id[0].values\n",
    "validate_part_img_id = validate_part_img_id[0].values\n",
    "\n",
    "train_part_df = train_data[train_data['img_id'].isin(train_part_img_id)]\n",
    "validate_part_df = train_data[train_data['img_id'].isin(validate_part_img_id)]\n",
    "\n",
    "seen_class = train_part_df.append(validate_part_df).class_id.unique()\n",
    "\n",
    "train_part_df = train_data[train_data['class_id'].isin(seen_class)]\n",
    "validate_part_df = train_data[~train_data['class_id'].isin(seen_class)]\n",
    "# unseen_class_df = train_data[~train_data['class_id'].isin(seen_class)]\n",
    "unseen_class = validate_part_df.class_id.unique()\n",
    "\n",
    "# validate_part_df = validate_part_df.append(unseen_class_df)\n",
    "# train_part_df = train_part_df.append(validate_part_df)\n",
    "# validate_part_df = unseen_class_df\n",
    "\n",
    "train_part_data = create_dnn_data(train_part_df)\n",
    "train_part_target = extract_array_from_series(train_part_df['target'])\n",
    "\n",
    "validate_part_data = create_dnn_data(validate_part_df)\n",
    "validate_part_target = extract_array_from_series(validate_part_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39184, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setB_train_data[setB_train_data.class_id.isin(seen_class)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3713906765013109"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 / 10.77032961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 6 4]\n",
      " [8 7 1]\n",
      " [2 2 5]\n",
      " [2 1 5]]\n",
      "[10.77032961 10.67707825  5.74456265  5.47722558]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.74278135, 0.55708601, 0.37139068],\n",
       "       [0.74926865, 0.65561007, 0.09365858],\n",
       "       [0.34815531, 0.34815531, 0.87038828],\n",
       "       [0.36514837, 0.18257419, 0.91287093]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(1, 10, (4,3))\n",
    "print (x)\n",
    "print (np.linalg.norm(x, axis = 1))\n",
    "sklearn.preprocessing.normalize(x, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "        \n",
    "def find_nearest_class(class_id_emb_attr, model, eval_df, cand_feature_map, img_feature_map, \n",
    "                       threshold = None, gamma = None, seen_class = None):\n",
    "#     cand_feature_map = model.predict(create_dnn_data(class_id_emb_attr))\n",
    "    # img_feature_map = np.repeat(img_feature_map, [cand_feature_map.shape[0]] * img_feature_map.shape[0], axis = 0)\n",
    "    nearest_class_id = ['ZJL'] * eval_df.shape[0]\n",
    "#     seen_class_bias = np.zeros(class_id_emb_attr.shape[0])\n",
    "#     seen_class_bias[class_id_emb_attr.class_id.isin(seen_class)] = gamma\n",
    "    \n",
    "#     seen_indice = [category_dict[c] for c in seen_class]\n",
    "#     preds = np.asarray(list(eval_df['preds']))[:, seen_indice]\n",
    "    for i in range(img_feature_map.shape[0]):\n",
    "        if False: #np.amax(preds[i]) > threshold:\n",
    "            nearest_class_id[i] = seen_class[np.argmax(preds[i])]\n",
    "        else:\n",
    "            img = img_feature_map[i]\n",
    "#             dis = 1 - sklearn.metrics.pairwise.cosine_similarity([img], \n",
    "#                                     cand_feature_map).reshape((cand_feature_map.shape[0]))\n",
    "            dis = np.linalg.norm(img - cand_feature_map, axis = 1)\n",
    "#             print (dis.shape)\n",
    "#             if np.amin(dis[class_id_emb_attr.class_id.isin(seen_class)]) > \\\n",
    "#                     gamma * np.amin(dis[~class_id_emb_attr.class_id.isin(seen_class)]):\n",
    "#                 dis[class_id_emb_attr.class_id.isin(seen_class)] = 200\n",
    "#             dis += seen_class_bias\n",
    "#             print(dis)\n",
    "#             plt.hist(dis)\n",
    "#             return\n",
    "            min_ind = np.where(dis == np.amin(dis))[0]\n",
    "            if len(min_ind) > 1:\n",
    "                print ('eval img id: ', eval_df.iloc[i]['class_id'], 'has multiple best candidates: ', len(min_ind), 'min val: ', np.amin(dis))\n",
    "    #         print (i, img, class_id_emb_attr.iloc[min_ind[0]].name)\n",
    "            nearest_class_id[i] = class_id_emb_attr.iloc[min_ind[0]]['class_id']\n",
    "#     print (nearest_class_id)\n",
    "    return np.asarray(nearest_class_id)\n",
    "        \n",
    "def calc_accuracy(eval_df, eval_class, preds):\n",
    "    eval_mask = eval_df.class_id.isin(eval_class)\n",
    "    eval_num = np.sum(eval_mask)\n",
    "    right_num = np.sum(preds[eval_mask] == eval_df.class_id[eval_mask])\n",
    "    return right_num / np.sum(eval_mask), right_num, eval_num\n",
    "    \n",
    "def calc_detailed_accuracy(eval_df, preds, seen_class, unseen_class):\n",
    "    all_re = calc_accuracy(eval_df, eval_df['class_id'].values, preds)\n",
    "    seen_re = calc_accuracy(eval_df, seen_class, preds)\n",
    "    unseen_re = calc_accuracy(eval_df, unseen_class, preds)\n",
    "    print(\"\\nAll_re: \\t%.6f\\t%.0f\\t%.0f\" % all_re)\n",
    "    print(\"Seen_re: \\t%.6f\\t%.0f\\t%.0f\" % seen_re)\n",
    "    print(\"Unseen_re: \\t%.6f\\t%.0f\\t%.0f\" % unseen_re)\n",
    "\n",
    "def model_eval(model, model_type, eval_df, cand_class_id_emb_attr, img_feature_map, seen_class = None, unseen_class = None):\n",
    "    if model_type == 'DEM':\n",
    "        zs_model = Model(inputs = model.inputs[:2], outputs = model.outputs[0])\n",
    "        cand_feature_map = zs_model.predict(create_dnn_data(cand_class_id_emb_attr))\n",
    "    elif model_type == 'GCN':\n",
    "        zs_model = Model(inputs = model.inputs[2:], outputs = model.outputs[0])\n",
    "        cand_class_to_id = [class_to_id[c] for c in cand_class_id_emb_attr.class_id.values]\n",
    "        cand_feature_map = zs_model.predict(None, steps = 1)[cand_class_to_id]\n",
    "    preds = find_nearest_class(cand_class_id_emb_attr, zs_model, eval_df, cand_feature_map, \n",
    "                               img_feature_map)\n",
    "    if 'class_id' in eval_df.columns:\n",
    "        calc_detailed_accuracy(eval_df, preds, seen_class, unseen_class)\n",
    "    return preds\n",
    "\n",
    "def models_eval(models, eval_df, cand_class_id_emb_attr, img_feature_map, \n",
    "                seen_class = None, unseen_class = None):\n",
    "    preds = []\n",
    "    for model, model_type in models:\n",
    "        pred = model_eval(model, model_type, eval_df, cand_class_id_emb_attr, img_feature_map, \n",
    "                          seen_class, unseen_class)\n",
    "        preds.append(pred)\n",
    "    return preds\n",
    "        \n",
    "def multi_models_vote(models, eval_df = None, cand_class_id_emb_attr = None, img_feature_map = None, \n",
    "                      seen_class = None, unseen_class = None):\n",
    "    preds = models_eval(models, eval_df, cand_class_id_emb_attr, img_feature_map, \n",
    "                seen_class, unseen_class)\n",
    "    preds = np.asarray(preds).T\n",
    "    print (preds)\n",
    "    vote_preds = []\n",
    "    for single_img_vote in preds:\n",
    "        uniq_val, counts = np.unique(single_img_vote, return_counts = True)\n",
    "        vote_preds.append(uniq_val[np.argmax(counts)])\n",
    "    vote_preds = np.asarray(vote_preds)\n",
    "    print (vote_preds)\n",
    "    if 'class_id' in eval_df.columns: \n",
    "        calc_detailed_accuracy(eval_df, vote_preds, seen_class, unseen_class)\n",
    "    return vote_preds\n",
    "    \n",
    "class AccuracyEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_interval = 1000000, verbose = 2, \\\n",
    "            scores = [], class_id_emb_attr = None, eval_df = None, threshold = None, \\\n",
    "                 seen_class = None, unseen_class = None, gamma = None, model_type = None):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        # print(\"y_val shape:{0}\".format(self.y_val.shape))\n",
    "        self.batch_interval = batch_interval\n",
    "        self.verbose = verbose\n",
    "        self.scores = scores\n",
    "        self.class_id_emb_attr = class_id_emb_attr\n",
    "        self.eval_df = eval_df\n",
    "        self.threshold = threshold\n",
    "        self.seen_class = seen_class\n",
    "        self.unseen_class = unseen_class\n",
    "        self.gamma = gamma\n",
    "        self.model_type = model_type\n",
    "#         seen_indice = [category_dict[c] for c in seen_class]\n",
    "#         self.preds = np.asarray(list(eval_df['preds']))[:, seen_indice]\n",
    "#         self.img_feature_map = self.y_val\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            model_eval(self.model, self.model_type, self.eval_df, self.class_id_emb_attr, \n",
    "                seen_class = self.seen_class, unseen_class = self.unseen_class, img_feature_map = self.y_val)\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "        if(self.verbose >= 2) and (batch % self.batch_interval == 0):\n",
    "            # y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            # loss = metrics.log_loss(self.y_val, y_pred)\n",
    "            print(\"Hi! on_batch_end() , batch=\",batch,\",logs:\",logs)\n",
    "            # print(\"Valide size=\",y_pred.shape[0], \"  Valide loss=\",loss)\n",
    "\n",
    "def full_connect_layer(input, hidden_dim, activation, resnet = False, adj_graphs = None, \n",
    "                       drop_out_ratio = None, kernel_initializer = 'he_normal'):\n",
    "    full_connect = input\n",
    "    for i, hn in enumerate(hidden_dim):\n",
    "        fc_in = full_connect\n",
    "        if drop_out_ratio is not None:\n",
    "            full_connect = Dropout(drop_out_ratio)(full_connect)\n",
    "        full_connect = BatchNormalization(epsilon=1.001e-5)(full_connect)\n",
    "        # full_connect = Dense(hn, kernel_regularizer = l2(0.001), activity_regularizer = l1(0.001))(full_connect)\n",
    "#         full_connect = Concatenate()([Dense(hn, kernel_initializer='lecun_uniform', activation = 'relu')(full_connect), \n",
    "#             Dense(hn, kernel_initializer='lecun_uniform', activation = 'sigmoid')(full_connect)])\n",
    "        full_connect = Dense(hn, kernel_initializer=kernel_initializer, kernel_regularizer = l2(1e-4), activation = activation)(full_connect)\n",
    "#         full_connect = LeakyReLU(alpha=0.02)(full_connect)\n",
    "        # full_connect = self.act_blend(full_connect)\n",
    "        # if self.full_connect_dropout > 0:\n",
    "#             full_connect = Dropout(self.full_connect_dropout)(full_connect) #Dropout(self.full_connect_dropout)(full_connect)\n",
    "        if adj_graphs is not None:\n",
    "            full_connect = Lambda(lambda x: K.dot(x[1], x[0]), \\\n",
    "                                  name = 'rela_' + str(i))([full_connect, adj_graphs])\n",
    "        if resnet:\n",
    "            full_connect = Concatenate()([fc_in, full_connect])\n",
    "    return full_connect\n",
    "\n",
    "def extract_array_from_series(s):\n",
    "    return np.asarray(list(s))\n",
    "\n",
    "def create_dnn_data(df):\n",
    "    # return [extract_array_from_series(df['attr']), extract_array_from_series(df['emb'])[:, :]]\n",
    "    return [extract_array_from_series(df['attr']), extract_array_from_series(df['emb'])[:, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD...\n"
     ]
    }
   ],
   "source": [
    "print ('SVD...')\n",
    "svd = decomposition.TruncatedSVD(n_components=10, n_iter=50, random_state=12)\n",
    "svd_features = svd.fit_transform(extract_array_from_series(class_id_emb_attr['attr']))\n",
    "class_id_emb_attr['svd_attr'] = list(svd_features)\n",
    "train_data = train_data.merge(class_id_emb_attr[['class_id', 'svd_attr']], how = 'left', on = 'class_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87249, 10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen unseen Classes:  164 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_140\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_140\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attr (InputLayer)               (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wv (InputLayer)                 (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 300)          9000        attr[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 900)          0           wv[0][0]                         \n",
      "                                                                 dense_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 900)          0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 900)          3600        dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_139 (Dense)               (None, 1536)         1383936     batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 1536)         6144        dense_139[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 1024)         1573888     batch_normalization_92[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 2,976,568\n",
      "Trainable params: 2,971,696\n",
      "Non-trainable params: 4,872\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 70408 samples, validate on 16841 samples\n",
      "Epoch 1/50\n",
      "70408/70408 [==============================] - 104s 1ms/step - loss: 0.5655 - val_loss: 0.4114\n",
      "\n",
      "All_re: \t0.199216\t3355\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.199216\t3355\t16841\n",
      "Epoch 2/50\n",
      "  128/70408 [..............................] - ETA: 1:08 - loss: 0.3791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70408/70408 [==============================] - 31s 436us/step - loss: 0.3235 - val_loss: 0.3294\n",
      "\n",
      "All_re: \t0.219999\t3705\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.219999\t3705\t16841\n",
      "Epoch 3/50\n",
      "70408/70408 [==============================] - 28s 394us/step - loss: 0.2883 - val_loss: 0.3257\n",
      "\n",
      "All_re: \t0.207945\t3502\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.207945\t3502\t16841\n",
      "Epoch 4/50\n",
      "70408/70408 [==============================] - 29s 418us/step - loss: 0.2808 - val_loss: 0.3216\n",
      "\n",
      "All_re: \t0.222315\t3744\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.222315\t3744\t16841\n",
      "Epoch 5/50\n",
      "70408/70408 [==============================] - 28s 402us/step - loss: 0.2787 - val_loss: 0.3213\n",
      "\n",
      "All_re: \t0.235972\t3974\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.235972\t3974\t16841\n",
      "Epoch 6/50\n",
      "70408/70408 [==============================] - 32s 449us/step - loss: 0.2776 - val_loss: 0.3168\n",
      "\n",
      "All_re: \t0.238525\t4017\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.238525\t4017\t16841\n",
      "Epoch 7/50\n",
      "70408/70408 [==============================] - 28s 399us/step - loss: 0.2766 - val_loss: 0.3047\n",
      "\n",
      "All_re: \t0.234547\t3950\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.234547\t3950\t16841\n",
      "Epoch 8/50\n",
      "70408/70408 [==============================] - 30s 432us/step - loss: 0.2744 - val_loss: 0.3047\n",
      "\n",
      "All_re: \t0.231993\t3907\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.231993\t3907\t16841\n",
      "Epoch 9/50\n",
      "70408/70408 [==============================] - 28s 396us/step - loss: 0.2723 - val_loss: 0.3039\n",
      "\n",
      "All_re: \t0.211626\t3564\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.211626\t3564\t16841\n",
      "Epoch 10/50\n",
      "70408/70408 [==============================] - 32s 451us/step - loss: 0.2705 - val_loss: 0.3030\n",
      "\n",
      "All_re: \t0.229321\t3862\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.229321\t3862\t16841\n",
      "Epoch 11/50\n",
      "70408/70408 [==============================] - 28s 402us/step - loss: 0.2700 - val_loss: 0.3027\n",
      "\n",
      "All_re: \t0.223621\t3766\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.223621\t3766\t16841\n",
      "Epoch 12/50\n",
      "70408/70408 [==============================] - 30s 420us/step - loss: 0.2694 - val_loss: 0.3019\n",
      "\n",
      "All_re: \t0.212695\t3582\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.212695\t3582\t16841\n",
      "Epoch 13/50\n",
      "70408/70408 [==============================] - 28s 394us/step - loss: 0.2692 - val_loss: 0.3031\n",
      "\n",
      "All_re: \t0.211033\t3554\t16841\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.211033\t3554\t16841\n",
      "Seen unseen Classes:  164 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_144\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_144\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 71411 samples, validate on 15838 samples\n",
      "Epoch 1/50\n",
      "71411/71411 [==============================] - 106s 1ms/step - loss: 0.5631 - val_loss: 0.4024\n",
      "\n",
      "All_re: \t0.194090\t3074\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.194090\t3074\t15838\n",
      "Epoch 2/50\n",
      "71411/71411 [==============================] - 28s 398us/step - loss: 0.3217 - val_loss: 0.3223\n",
      "\n",
      "All_re: \t0.224081\t3549\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.224081\t3549\t15838\n",
      "Epoch 3/50\n",
      "71411/71411 [==============================] - 29s 402us/step - loss: 0.2867 - val_loss: 0.3117\n",
      "\n",
      "All_re: \t0.208675\t3305\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.208675\t3305\t15838\n",
      "Epoch 4/50\n",
      "71411/71411 [==============================] - 29s 401us/step - loss: 0.2788 - val_loss: 0.3085\n",
      "\n",
      "All_re: \t0.203687\t3226\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.203687\t3226\t15838\n",
      "Epoch 5/50\n",
      "71411/71411 [==============================] - 28s 393us/step - loss: 0.2757 - val_loss: 0.3052\n",
      "\n",
      "All_re: \t0.207791\t3291\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.207791\t3291\t15838\n",
      "Epoch 6/50\n",
      "71411/71411 [==============================] - 28s 395us/step - loss: 0.2735 - val_loss: 0.3035\n",
      "\n",
      "All_re: \t0.218146\t3455\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.218146\t3455\t15838\n",
      "Epoch 7/50\n",
      "71411/71411 [==============================] - 28s 396us/step - loss: 0.2720 - val_loss: 0.3026\n",
      "\n",
      "All_re: \t0.229385\t3633\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.229385\t3633\t15838\n",
      "Epoch 8/50\n",
      "71411/71411 [==============================] - 29s 400us/step - loss: 0.2711 - val_loss: 0.3006\n",
      "\n",
      "All_re: \t0.231216\t3662\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.231216\t3662\t15838\n",
      "Epoch 9/50\n",
      "71411/71411 [==============================] - 28s 396us/step - loss: 0.2706 - val_loss: 0.3014\n",
      "\n",
      "All_re: \t0.245107\t3882\t15838\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.245107\t3882\t15838\n",
      "Seen unseen Classes:  164 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_148\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_148\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69141 samples, validate on 18108 samples\n",
      "Epoch 1/50\n",
      "69141/69141 [==============================] - 107s 2ms/step - loss: 0.5679 - val_loss: 0.4168\n",
      "\n",
      "All_re: \t0.197095\t3569\t18108\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.197095\t3569\t18108\n",
      "Epoch 2/50\n",
      "69141/69141 [==============================] - 30s 439us/step - loss: 0.3233 - val_loss: 0.3322\n",
      "\n",
      "All_re: \t0.204385\t3701\t18108\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.204385\t3701\t18108\n",
      "Epoch 3/50\n",
      "69141/69141 [==============================] - 30s 438us/step - loss: 0.2866 - val_loss: 0.3208\n",
      "\n",
      "All_re: \t0.193837\t3510\t18108\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.193837\t3510\t18108\n",
      "Epoch 4/50\n",
      "69141/69141 [==============================] - 30s 436us/step - loss: 0.2784 - val_loss: 0.3116\n",
      "\n",
      "All_re: \t0.206980\t3748\t18108\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.206980\t3748\t18108\n",
      "Epoch 5/50\n",
      "69141/69141 [==============================] - 30s 433us/step - loss: 0.2749 - val_loss: 0.3123\n",
      "\n",
      "All_re: \t0.200961\t3639\t18108\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.200961\t3639\t18108\n",
      "Seen unseen Classes:  164 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_152\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_152\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69739 samples, validate on 17510 samples\n",
      "Epoch 1/50\n",
      "69739/69739 [==============================] - 108s 2ms/step - loss: 0.5657 - val_loss: 0.4218\n",
      "\n",
      "All_re: \t0.141005\t2469\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.141005\t2469\t17510\n",
      "Epoch 2/50\n",
      "69739/69739 [==============================] - 30s 434us/step - loss: 0.3225 - val_loss: 0.3367\n",
      "\n",
      "All_re: \t0.165677\t2901\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.165677\t2901\t17510\n",
      "Epoch 3/50\n",
      "69739/69739 [==============================] - 30s 430us/step - loss: 0.2867 - val_loss: 0.3231\n",
      "\n",
      "All_re: \t0.139406\t2441\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.139406\t2441\t17510\n",
      "Epoch 4/50\n",
      "69739/69739 [==============================] - 30s 425us/step - loss: 0.2796 - val_loss: 0.3168\n",
      "\n",
      "All_re: \t0.153113\t2681\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.153113\t2681\t17510\n",
      "Epoch 5/50\n",
      "69739/69739 [==============================] - 29s 419us/step - loss: 0.2770 - val_loss: 0.3163\n",
      "\n",
      "All_re: \t0.141576\t2479\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.141576\t2479\t17510\n",
      "Epoch 6/50\n",
      "69739/69739 [==============================] - 30s 430us/step - loss: 0.2748 - val_loss: 0.3158\n",
      "\n",
      "All_re: \t0.171845\t3009\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.171845\t3009\t17510\n",
      "Epoch 7/50\n",
      "69739/69739 [==============================] - 30s 431us/step - loss: 0.2740 - val_loss: 0.3157\n",
      "\n",
      "All_re: \t0.150885\t2642\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.150885\t2642\t17510\n",
      "Epoch 8/50\n",
      "69739/69739 [==============================] - 30s 426us/step - loss: 0.2720 - val_loss: 0.3145\n",
      "\n",
      "All_re: \t0.170017\t2977\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.170017\t2977\t17510\n",
      "Epoch 9/50\n",
      "69739/69739 [==============================] - 30s 425us/step - loss: 0.2700 - val_loss: 0.3129\n",
      "\n",
      "All_re: \t0.168247\t2946\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.168247\t2946\t17510\n",
      "Epoch 10/50\n",
      "69739/69739 [==============================] - 30s 433us/step - loss: 0.2690 - val_loss: 0.3129\n",
      "\n",
      "All_re: \t0.159794\t2798\t17510\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.159794\t2798\t17510\n",
      "Seen unseen Classes:  164 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_156\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_156\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68297 samples, validate on 18952 samples\n",
      "Epoch 1/50\n",
      "68297/68297 [==============================] - 97s 1ms/step - loss: 0.5718 - val_loss: 0.4250\n",
      "\n",
      "All_re: \t0.190903\t3618\t18952\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.190903\t3618\t18952\n",
      "Epoch 2/50\n",
      "68297/68297 [==============================] - 30s 441us/step - loss: 0.3240 - val_loss: 0.3366\n",
      "\n",
      "All_re: \t0.209529\t3971\t18952\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.209529\t3971\t18952\n",
      "Epoch 3/50\n",
      "68297/68297 [==============================] - 30s 433us/step - loss: 0.2860 - val_loss: 0.3216\n",
      "\n",
      "All_re: \t0.201192\t3813\t18952\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.201192\t3813\t18952\n",
      "Epoch 4/50\n",
      "68297/68297 [==============================] - 29s 432us/step - loss: 0.2777 - val_loss: 0.3179\n",
      "\n",
      "All_re: \t0.212854\t4034\t18952\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.212854\t4034\t18952\n",
      "Epoch 5/50\n",
      "68297/68297 [==============================] - 29s 430us/step - loss: 0.2744 - val_loss: 0.3180\n",
      "\n",
      "All_re: \t0.206205\t3908\t18952\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.206205\t3908\t18952\n"
     ]
    }
   ],
   "source": [
    "def create_dnn(kernel_initializer = 'he_normal', img_flat_len = 1024):\n",
    "    alpha = 0.03\n",
    "    img_flat_len = img_flat_len\n",
    "    attr_input = Input(shape = (30,), name = 'attr')\n",
    "    word_emb = Input(shape = (600,), name = 'wv')\n",
    "    imag_classifier = Input(shape = (img_flat_len,), name = 'img')\n",
    "\n",
    "    attr_dense = Dense(300, use_bias = False, kernel_initializer=kernel_initializer, \n",
    "                       kernel_regularizer = l2(1e-4))(attr_input)\n",
    "#     attr_dense = Dense(512)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(256)(attr_dense)\n",
    "#     attr_dense = LeakyReLU(alpha=alpha)(attr_dense)\n",
    "#     attr_dense = Dense(300, activation=\"relu\")(attr_dense)\n",
    "    # attr_dense = Dense(512, activation=\"relu\")(attr_dense)\n",
    "    word_emb_dense = Dense(300, use_bias = False, kernel_initializer=kernel_initializer, \n",
    "                           kernel_regularizer = l2(1e-4))(word_emb)\n",
    "\n",
    "    attr_word_emb = Concatenate()([word_emb, attr_dense])\n",
    "#     attr_word_emb = word_emb #Add()([word_emb_dense, attr_dense])\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb, hidden_dim = [int(img_flat_len * 1.5), \n",
    "#                                                                           int(img_flat_len * 1.25), \n",
    "#                                                                           int(img_flat_len * 1.125),\n",
    "#                                                                           int(img_flat_len * 0.5)\n",
    "                                                                         ], \\\n",
    "                                             activation = 'relu', resnet = False, drop_out_ratio = 0.2)\n",
    "    attr_word_emb_dense = full_connect_layer(attr_word_emb_dense, hidden_dim = [img_flat_len], \n",
    "                                             activation = 'relu')\n",
    "\n",
    "    mse_loss = K.mean(keras.losses.mean_squared_error(imag_classifier, attr_word_emb_dense))\n",
    "    \n",
    "    model = Model([attr_input, word_emb, imag_classifier], outputs = attr_word_emb_dense) #, vgg_output])\n",
    "    model.add_loss(mse_loss)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=5e-4), loss=None)\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 100)\n",
    "num_fold = 0\n",
    "zs_model_list = []\n",
    "classes = train_data.class_id.unique()\n",
    "\n",
    "for train_index, test_index in kf.split(classes):\n",
    "    seen_class = classes[train_index]\n",
    "    unseen_class = classes[test_index]\n",
    "    \n",
    "    train_part_df = train_data[train_data.class_id.isin(seen_class)]\n",
    "    validate_part_df = train_data[train_data.class_id.isin(unseen_class)]\n",
    "    \n",
    "    train_part_data = create_dnn_data(train_part_df)\n",
    "    validate_part_data = create_dnn_data(validate_part_df)\n",
    "    \n",
    "    train_part_target = extract_array_from_series(train_part_df['target']) #sklearn.preprocessing.normalize(extract_array_from_series(train_part_df['target']), norm='l2')\n",
    "    validate_part_target = extract_array_from_series(validate_part_df['target']) #sklearn.preprocessing.normalize(extract_array_from_series(validate_part_df['target']), norm='l2')\n",
    "\n",
    "#     print ('Train Validation Classes: ', train_part_df.class_id.unique().shape[0], \n",
    "#            validate_part_df.class_id.unique().shape[0])\n",
    "    print ('Seen unseen Classes: ', seen_class.shape[0], unseen_class.shape[0])\n",
    "\n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=1, verbose=0),\n",
    "            AccuracyEvaluation(validation_data=(validate_part_data,  validate_part_target), interval=1, \\\n",
    "    #                         class_id_emb_attr = class_id_emb_attr, \\\n",
    "                               eval_df = validate_part_df, threshold= 0.3, \\\n",
    "                              seen_class = seen_class, unseen_class = unseen_class, \\\n",
    "                class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \\\n",
    "                              gamma = 0.8, model_type = 'DEM')\n",
    "            ]\n",
    "#     for i in range(5):\n",
    "    zs_model = create_dnn(kernel_initializer = 'he_normal', img_flat_len = 1024)\n",
    "    if num_fold == 0:\n",
    "        print (zs_model.summary())\n",
    "    zs_model.fit(train_part_data + [train_part_target],  validation_data = (validate_part_data + [validate_part_target], None),\n",
    "                  epochs=50, batch_size = 128, shuffle=True, verbose = 1, callbacks=callbacks)\n",
    "    zs_model_list.append((zs_model, 'DEM'))\n",
    "    num_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(zs_model_list):\n",
    "    model_name = path + '/model_sub/zs_model_' + str(i) + \"_05011.txt\"\n",
    "    zs_model_list[i][0].save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All_re: \t0.213811\t3570\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.213811\t3570\t16697\n",
      "\n",
      "All_re: \t0.227226\t3794\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.227226\t3794\t16697\n",
      "\n",
      "All_re: \t0.235911\t3939\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.235911\t3939\t16697\n",
      "\n",
      "All_re: \t0.216566\t3616\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.216566\t3616\t16697\n",
      "\n",
      "All_re: \t0.070492\t1177\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.070492\t1177\t16697\n",
      "[['ZJL200' 'ZJL200' 'ZJL200' 'ZJL19' 'ZJL101']\n",
      " ['ZJL4' 'ZJL100' 'ZJL41' 'ZJL4' 'ZJL101']\n",
      " ['ZJL192' 'ZJL192' 'ZJL192' 'ZJL192' 'ZJL101']\n",
      " ...\n",
      " ['ZJL261' 'ZJL102' 'ZJL254' 'ZJL254' 'ZJL261']\n",
      " ['ZJL254' 'ZJL254' 'ZJL261' 'ZJL254' 'ZJL137']\n",
      " ['ZJL261' 'ZJL261' 'ZJL261' 'ZJL254' 'ZJL261']]\n",
      "['ZJL200' 'ZJL4' 'ZJL192' ... 'ZJL254' 'ZJL254' 'ZJL261']\n",
      "\n",
      "All_re: \t0.234533\t3916\t16697\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.234533\t3916\t16697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ZJL200', 'ZJL4', 'ZJL192', ..., 'ZJL254', 'ZJL254', 'ZJL261'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_models_vote(models = zs_model_list, eval_df = validate_part_df, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \\\n",
    "            img_feature_map = validate_part_target, seen_class = seen_class, unseen_class = unseen_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 5, 9],\n",
       "       [8, 7, 7],\n",
       "       [1, 1, 7],\n",
       "       [7, 1, 9]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(1, 10, (4, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 7 8 9] [3 1 4 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_val, counts = np.unique(x, return_counts = True)\n",
    "print (uniq_val, counts)\n",
    "# uniq_val[np.argmax(counts)]\n",
    "np.argmin(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = np.array(list(class_id_emb_attr['attr']))\n",
    "# adj_graph = scipy.eye(attr.shape[0]) #1 - sklearn.metrics.pairwise.pairwise_distances(attr, metric = 'cosine')\n",
    "adj_graph = 1 - sklearn.metrics.pairwise.pairwise_distances(\n",
    "    np.array(list(class_id_emb_attr['emb'])), metric = 'cosine')\n",
    "# th = 0.99999\n",
    "# adj_graph[adj_graph > th] = 1\n",
    "# adj_graph[adj_graph <= th] = 0\n",
    "# adj_graph = adj_graph / np.linalg.norm(adj_graph)\n",
    "# adj_graph = adj_graph[:, np.argsort(adj_graph)[:]]\n",
    "# adj_graph[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = class_id_emb_attr.class_id.values\n",
    "class_to_id = dict([(c, i) for i, c in enumerate(class_ids)])\n",
    "# class_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen unseen Classes:  164 41\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_32 (InputLayer)            (285, 30)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_33 (InputLayer)            (285, 300)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_84 (Dense)                 (285, 300)            9000        input_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)     (285, 600)            0           input_33[0][0]                   \n",
      "                                                                   dense_84[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (285, 600)            2400        concatenate_15[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_85 (Dense)                 (285, 1548)           930348      batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "input_34 (InputLayer)            (285, 285)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "rela_0 (Lambda)                  (285, 1548)           0           dense_85[0][0]                   \n",
      "                                                                   input_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (285, 1548)           6192        rela_0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_86 (Dense)                 (285, 1290)           1998210     batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "rela_1 (Lambda)                  (285, 1290)           0           dense_86[0][0]                   \n",
      "                                                                   input_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (285, 1290)           5160        rela_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_87 (Dense)                 (285, 1032)           1332312     batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "rela_2 (Lambda)                  (285, 1032)           0           dense_87[0][0]                   \n",
      "                                                                   input_34[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 4,283,622\n",
      "Trainable params: 4,276,746\n",
      "Non-trainable params: 6,876\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:32: UserWarning: Output \"rela_2\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"rela_2\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69913 samples, validate on 17336 samples\n",
      "Epoch 1/25\n",
      "69792/69913 [============================>.] - ETA: 0s - loss: 1.7330eval img id:  ZJL263 has multiple best candidates:  2 min val:  18.49614\n",
      "\n",
      "All_re: \t0.038417\t666\t17336\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.038417\t666\t17336\n",
      "69913/69913 [==============================] - 33s - loss: 1.7317 - val_loss: 1.0597\n",
      "Epoch 2/25\n",
      "  416/69913 [..............................] - ETA: 29s - loss: 0.9983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69856/69913 [============================>.] - ETA: 0s - loss: 0.9736\n",
      "All_re: \t0.068066\t1180\t17336\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.068066\t1180\t17336\n",
      "69913/69913 [==============================] - 32s - loss: 0.9736 - val_loss: 1.0059\n",
      "Epoch 3/25\n",
      "69792/69913 [============================>.] - ETA: 0s - loss: 0.8904\n",
      "All_re: \t0.082603\t1432\t17336\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.082603\t1432\t17336\n",
      "69913/69913 [==============================] - 32s - loss: 0.8903 - val_loss: 0.9059\n",
      "Epoch 4/25\n",
      " 9536/69913 [===>..........................] - ETA: 24s - loss: 0.8300"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4eef8651ed11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     zs_model.fit([train_part_data, train_part_target],  \n\u001b[1;32m     74\u001b[0m                  \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidate_part_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_part_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                   epochs=25, batch_size = 32, shuffle=True, verbose = 1, callbacks=callbacks)\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mzs_model_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GCN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mnum_fold\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# adj_graph = 1 - sklearn.metrics.pairwise.pairwise_distances(\n",
    "#     np.array(list(class_id_emb_attr['emb']))[:, :300], metric = 'cosine')\n",
    "\n",
    "def create_gcn():\n",
    "    alpha = 0.03\n",
    "    img_flat_len = 1032\n",
    "    attr_input = Input(tensor=tf.constant(np.array(list(class_id_emb_attr['attr']), dtype = 'float32')))\n",
    "    all_word_emb = Input(tensor=tf.constant(np.array(list(class_id_emb_attr['emb']))[:, :300], dtype = 'float32')) #Input(shape = (230, 300,), name = 'wv')\n",
    "    class_index = Input(shape = (1, ), name = 'class_index', dtype = 'int32')\n",
    "    adj_graphs = Input(tensor=tf.constant(adj_graph, dtype = 'float32')) #Input(shape = (230, 230,), name = 'adj_graph')\n",
    "    imag_classifier = Input(shape = (img_flat_len,), name = 'img')\n",
    "    \n",
    "    attr_dense = Dense(300, use_bias = False, kernel_initializer='he_normal', \n",
    "                    kernel_regularizer = l2(1e-4))(attr_input)\n",
    "    attr_word_emb = Concatenate()([all_word_emb, attr_dense])\n",
    "#     x = Lambda(lambda xx: all_word_emb)(class_index)\n",
    "#     x = Dense(516, kernel_initializer='he_normal', kernel_regularizer = l2(1e-4), \n",
    "#               activation = 'relu', name = 'conv')(all_word_emb)\n",
    "#     all_classifier = Lambda(lambda x: K.dot(x[1], x[0]), name = 'rela')([x, adj_graphs])\n",
    "    all_classifier = full_connect_layer(attr_word_emb, hidden_dim = [int(img_flat_len * 1.5), \n",
    "                                                                    int(img_flat_len * 1.25 ),\n",
    "                                                                    img_flat_len], \n",
    "                                activation = 'relu', adj_graphs = adj_graphs)\n",
    "    x = tf.gather_nd(all_classifier, class_index)\n",
    "\n",
    "    mse_loss = K.mean(keras.losses.mean_squared_error(imag_classifier, x))\n",
    "    \n",
    "    model = Model([class_index, imag_classifier, attr_input, all_word_emb, adj_graphs], outputs = [all_classifier]) #, vgg_output])\n",
    "    model.add_loss(mse_loss)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-4), loss=None)\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 1)\n",
    "num_fold = 0\n",
    "zs_model_list = []\n",
    "classes = train_data.class_id.unique()\n",
    "class_ids = class_id_emb_attr.class_id.values\n",
    "class_to_id = dict([(c, i) for i, c in enumerate(class_ids)])\n",
    "\n",
    "for train_index, test_index in kf.split(classes):\n",
    "#     print (train_index)\n",
    "    seen_class = classes[train_index]\n",
    "    unseen_class = classes[test_index]\n",
    "    \n",
    "    train_part_df = train_data[train_data.class_id.isin(seen_class)]\n",
    "    validate_part_df = train_data[train_data.class_id.isin(unseen_class)]\n",
    "    \n",
    "    train_part_data = np.array([class_to_id[c] for c in train_part_df['class_id'].values]).astype('int32')\n",
    "    validate_part_data = np.array([class_to_id[c] for c in validate_part_df['class_id'].values]).astype('int32')\n",
    "\n",
    "    train_part_target = extract_array_from_series(train_part_df['target'])\n",
    "    validate_part_target = extract_array_from_series(validate_part_df['target'])\n",
    "\n",
    "#     print ('Train Validation Classes: ', train_part_df.class_id.unique().shape[0], \n",
    "#            validate_part_df.class_id.unique().shape[0])\n",
    "    print ('Seen unseen Classes: ', seen_class.shape[0], unseen_class.shape[0])\n",
    "\n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=50, verbose=0),\n",
    "            AccuracyEvaluation(validation_data=(validate_part_data,  validate_part_target), interval=1, \\\n",
    "    #                         class_id_emb_attr = class_id_emb_attr, \\\n",
    "                               eval_df = validate_part_df, threshold= 0.3, \\\n",
    "                              seen_class = seen_class, unseen_class = unseen_class, \\\n",
    "                class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \\\n",
    "                              gamma = 0.8, model_type = 'GCN')\n",
    "            ]\n",
    "    zs_model = create_gcn()\n",
    "    if num_fold == 0:\n",
    "        print (zs_model.summary())\n",
    "    zs_model.fit([train_part_data, train_part_target],  \n",
    "                 validation_data = ([validate_part_data, validate_part_target], None),\n",
    "                  epochs=25, batch_size = 32, shuffle=True, verbose = 1, callbacks=callbacks)\n",
    "    zs_model_list.append((zs_model, 'GCN'))\n",
    "    num_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All_re: \t0.156834\t2140\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.156834\t2140\t13645\n",
      "\n",
      "All_re: \t0.155148\t2117\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.155148\t2117\t13645\n",
      "\n",
      "All_re: \t0.151118\t2062\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.151118\t2062\t13645\n",
      "\n",
      "All_re: \t0.153316\t2092\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.153316\t2092\t13645\n",
      "\n",
      "All_re: \t0.157640\t2151\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.157640\t2151\t13645\n",
      "[['ZJL264' 'ZJL264' 'ZJL264' 'ZJL264' 'ZJL264']\n",
      " ['ZJL102' 'ZJL102' 'ZJL102' 'ZJL102' 'ZJL102']\n",
      " ['ZJL254' 'ZJL276' 'ZJL254' 'ZJL254' 'ZJL254']\n",
      " ...\n",
      " ['ZJL254' 'ZJL254' 'ZJL276' 'ZJL254' 'ZJL254']\n",
      " ['ZJL276' 'ZJL276' 'ZJL276' 'ZJL276' 'ZJL254']\n",
      " ['ZJL168' 'ZJL125' 'ZJL50' 'ZJL168' 'ZJL254']]\n",
      "['ZJL264' 'ZJL102' 'ZJL254' ... 'ZJL254' 'ZJL276' 'ZJL168']\n",
      "\n",
      "All_re: \t0.166215\t2268\t13645\n",
      "Seen_re: \tnan\t0\t0\n",
      "Unseen_re: \t0.166215\t2268\t13645\n"
     ]
    }
   ],
   "source": [
    "multi_models_vote(models = zs_model_list, eval_df = validate_part_df, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[class_id_emb_attr.class_id.isin(unseen_class)], \\\n",
    "            img_feature_map = validate_part_target, seen_class = seen_class, unseen_class = unseen_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'model_sub/train_data_2018_09_23_10_32_21.pickle', 'rb') as handle:\n",
    "    test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>img_id</th>\n",
       "      <th>img</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>[[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...</td>\n",
       "      <td>[2.2266192, 0.16327204, 0.2838421, 0.2219766, ...</td>\n",
       "      <td>[0.9520665, 4.647786e-09, 7.417136e-08, 3.9506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg</td>\n",
       "      <td>[[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...</td>\n",
       "      <td>[0.17702743, 0.55263615, 0.0, 0.030876435, 1.2...</td>\n",
       "      <td>[1.30949e-05, 5.735788e-10, 6.5571693e-12, 5.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>eda9f3bef2bd8da038f6acbc8355fc25.jpeg</td>\n",
       "      <td>[[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....</td>\n",
       "      <td>[0.0, 0.42584094, 0.0, 0.034428038, 0.527664, ...</td>\n",
       "      <td>[0.9993531, 4.2289447e-09, 1.2198088e-07, 3.68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>7d93ef45972154aae150b4f9980a79c0.jpeg</td>\n",
       "      <td>[[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....</td>\n",
       "      <td>[0.6332717, 0.23473893, 0.0, 0.779357, 1.38354...</td>\n",
       "      <td>[0.9999671, 4.578459e-10, 6.6002594e-12, 8.168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJL1</td>\n",
       "      <td>fb901b4f9a8e396c1d0155bccc5e5671.jpeg</td>\n",
       "      <td>[[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...</td>\n",
       "      <td>[0.37087774, 1.1033719, 0.0, 0.23497638, 3.003...</td>\n",
       "      <td>[0.86532485, 3.0740804e-08, 3.727919e-08, 1.21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_id                                 img_id  \\\n",
       "0     ZJL1  a6394b0f513290f4651cc46792e5ac86.jpeg   \n",
       "1     ZJL1  2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg   \n",
       "2     ZJL1  eda9f3bef2bd8da038f6acbc8355fc25.jpeg   \n",
       "3     ZJL1  7d93ef45972154aae150b4f9980a79c0.jpeg   \n",
       "4     ZJL1  fb901b4f9a8e396c1d0155bccc5e5671.jpeg   \n",
       "\n",
       "                                                 img  \\\n",
       "0  [[[20.0, 33.0, 7.0], [19.0, 32.0, 6.0], [22.0,...   \n",
       "1  [[[140.0, 45.0, 51.0], [144.0, 47.0, 54.0], [1...   \n",
       "2  [[[81.0, 69.0, 21.0], [86.0, 74.0, 26.0], [85....   \n",
       "3  [[[16.0, 14.0, 15.0], [18.0, 16.0, 17.0], [19....   \n",
       "4  [[[120.0, 124.0, 127.0], [89.0, 93.0, 96.0], [...   \n",
       "\n",
       "                                              target  \\\n",
       "0  [2.2266192, 0.16327204, 0.2838421, 0.2219766, ...   \n",
       "1  [0.17702743, 0.55263615, 0.0, 0.030876435, 1.2...   \n",
       "2  [0.0, 0.42584094, 0.0, 0.034428038, 0.527664, ...   \n",
       "3  [0.6332717, 0.23473893, 0.0, 0.779357, 1.38354...   \n",
       "4  [0.37087774, 1.1033719, 0.0, 0.23497638, 3.003...   \n",
       "\n",
       "                                               preds  \n",
       "0  [0.9520665, 4.647786e-09, 7.417136e-08, 3.9506...  \n",
       "1  [1.30949e-05, 5.735788e-10, 6.5571693e-12, 5.9...  \n",
       "2  [0.9993531, 4.2289447e-09, 1.2198088e-07, 3.68...  \n",
       "3  [0.9999671, 4.578459e-10, 6.6002594e-12, 8.168...  \n",
       "4  [0.86532485, 3.0740804e-08, 3.727919e-08, 1.21...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path + '/DatasetA_test_20180813/DatasetA_test/image.txt', header = None, names = ['img_id'])\n",
    "imag_path = path + '/DatasetA_test_20180813/DatasetA_test/test/'\n",
    "test_data['img'] = test_data['img_id'].apply(lambda id: read_image(imag_path, id))\n",
    "# with open(path + 'test_data.pickle', 'rb') as handle:\n",
    "#     test_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.12423625, 0.1190791, 0.7566846]\n",
       "1       [1.7260123e-13, 2.1865514e-08, 1.0]\n",
       "2       [0.2117803, 0.17989996, 0.60831976]\n",
       "3        [0.2420589, 0.17926142, 0.5786797]\n",
       "4    [0.041276723, 0.95284086, 0.005882429]\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(path + 'test_data.pickle', 'wb+') as handle:\n",
    "#     pickle.dump(test_data, handle)\n",
    "# test_data.head()\n",
    "with open(path + '/model_sub/stacking_train_label_2018_09_12_12_10_06.pickle', 'rb') as handle:\n",
    "    stacking_train_data = pickle.load(handle)\n",
    "stacking_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_17 (InputLayer)            (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D) (None, 70, 70, 3)     0           input_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)              (None, 68, 68, 64)    1728        zero_padding2d_3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)    (None, 68, 68, 64)    256         conv1/conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1/relu (Activation)          (None, 68, 68, 64)    0           conv1/bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D) (None, 70, 70, 64)    0           conv1/relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool1 (AveragePooling2D)         (None, 34, 34, 64)    0           zero_padding2d_4[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormaliz (None, 34, 34, 64)    256         pool1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation) (None, 34, 34, 64)    0           conv2_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)     (None, 34, 34, 64)    4096        conv2_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenate (None, 34, 34, 80)    0           pool1[0][0]                      \n",
      "                                                                   conv2_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormaliz (None, 34, 34, 80)    320         conv2_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation) (None, 34, 34, 80)    0           conv2_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)     (None, 34, 34, 64)    5120        conv2_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenate (None, 34, 34, 96)    0           conv2_block1_concat[0][0]        \n",
      "                                                                   conv2_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormaliz (None, 34, 34, 96)    384         conv2_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation) (None, 34, 34, 96)    0           conv2_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)     (None, 34, 34, 64)    6144        conv2_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenate (None, 34, 34, 112)   0           conv2_block2_concat[0][0]        \n",
      "                                                                   conv2_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormaliz (None, 34, 34, 112)   448         conv2_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation) (None, 34, 34, 112)   0           conv2_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)     (None, 34, 34, 64)    7168        conv2_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenate (None, 34, 34, 128)   0           conv2_block3_concat[0][0]        \n",
      "                                                                   conv2_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormaliz (None, 34, 34, 128)   512         conv2_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation) (None, 34, 34, 128)   0           conv2_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)     (None, 34, 34, 64)    8192        conv2_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenate (None, 34, 34, 144)   0           conv2_block4_concat[0][0]        \n",
      "                                                                   conv2_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormaliz (None, 34, 34, 144)   576         conv2_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation) (None, 34, 34, 144)   0           conv2_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)     (None, 34, 34, 64)    9216        conv2_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormaliz (None, 34, 34, 64)    256         conv2_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation) (None, 34, 34, 64)    0           conv2_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)     (None, 34, 34, 16)    9216        conv2_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenate (None, 34, 34, 160)   0           conv2_block5_concat[0][0]        \n",
      "                                                                   conv2_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)    (None, 34, 34, 160)   640         conv2_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "pool2_relu (Activation)          (None, 34, 34, 160)   0           pool2_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)              (None, 34, 34, 80)    12800       pool2_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)    (None, 17, 17, 80)    0           pool2_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormaliz (None, 17, 17, 80)    320         pool2_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation) (None, 17, 17, 80)    0           conv3_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)     (None, 17, 17, 64)    5120        conv3_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenate (None, 17, 17, 96)    0           pool2_pool[0][0]                 \n",
      "                                                                   conv3_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormaliz (None, 17, 17, 96)    384         conv3_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation) (None, 17, 17, 96)    0           conv3_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)     (None, 17, 17, 64)    6144        conv3_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenate (None, 17, 17, 112)   0           conv3_block1_concat[0][0]        \n",
      "                                                                   conv3_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormaliz (None, 17, 17, 112)   448         conv3_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation) (None, 17, 17, 112)   0           conv3_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)     (None, 17, 17, 64)    7168        conv3_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenate (None, 17, 17, 128)   0           conv3_block2_concat[0][0]        \n",
      "                                                                   conv3_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormaliz (None, 17, 17, 128)   512         conv3_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation) (None, 17, 17, 128)   0           conv3_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)     (None, 17, 17, 64)    8192        conv3_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenate (None, 17, 17, 144)   0           conv3_block3_concat[0][0]        \n",
      "                                                                   conv3_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormaliz (None, 17, 17, 144)   576         conv3_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation) (None, 17, 17, 144)   0           conv3_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)     (None, 17, 17, 64)    9216        conv3_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenate (None, 17, 17, 160)   0           conv3_block4_concat[0][0]        \n",
      "                                                                   conv3_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormaliz (None, 17, 17, 160)   640         conv3_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation) (None, 17, 17, 160)   0           conv3_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)     (None, 17, 17, 64)    10240       conv3_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenate (None, 17, 17, 176)   0           conv3_block5_concat[0][0]        \n",
      "                                                                   conv3_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormaliz (None, 17, 17, 176)   704         conv3_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation) (None, 17, 17, 176)   0           conv3_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)     (None, 17, 17, 64)    11264       conv3_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenate (None, 17, 17, 192)   0           conv3_block6_concat[0][0]        \n",
      "                                                                   conv3_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormaliz (None, 17, 17, 192)   768         conv3_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation) (None, 17, 17, 192)   0           conv3_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)     (None, 17, 17, 64)    12288       conv3_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenate (None, 17, 17, 208)   0           conv3_block7_concat[0][0]        \n",
      "                                                                   conv3_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormaliz (None, 17, 17, 208)   832         conv3_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation) (None, 17, 17, 208)   0           conv3_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)     (None, 17, 17, 64)    13312       conv3_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormaliz (None, 17, 17, 64)    256         conv3_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation) (None, 17, 17, 64)    0           conv3_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)     (None, 17, 17, 16)    9216        conv3_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenate (None, 17, 17, 224)   0           conv3_block8_concat[0][0]        \n",
      "                                                                   conv3_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormali (None, 17, 17, 224)   896         conv3_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activation (None, 17, 17, 224)   0           conv3_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)    (None, 17, 17, 64)    14336       conv3_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormali (None, 17, 17, 64)    256         conv3_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activation (None, 17, 17, 64)    0           conv3_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)    (None, 17, 17, 16)    9216        conv3_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatenat (None, 17, 17, 240)   0           conv3_block9_concat[0][0]        \n",
      "                                                                   conv3_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormali (None, 17, 17, 240)   960         conv3_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activation (None, 17, 17, 240)   0           conv3_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)    (None, 17, 17, 64)    15360       conv3_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormali (None, 17, 17, 64)    256         conv3_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activation (None, 17, 17, 64)    0           conv3_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)    (None, 17, 17, 16)    9216        conv3_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatenat (None, 17, 17, 256)   0           conv3_block10_concat[0][0]       \n",
      "                                                                   conv3_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormali (None, 17, 17, 256)   1024        conv3_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activation (None, 17, 17, 256)   0           conv3_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)    (None, 17, 17, 64)    16384       conv3_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormali (None, 17, 17, 64)    256         conv3_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activation (None, 17, 17, 64)    0           conv3_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)    (None, 17, 17, 16)    9216        conv3_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatenat (None, 17, 17, 272)   0           conv3_block11_concat[0][0]       \n",
      "                                                                   conv3_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)    (None, 17, 17, 272)   1088        conv3_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool3_relu (Activation)          (None, 17, 17, 272)   0           pool3_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)              (None, 17, 17, 136)   36992       pool3_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)    (None, 8, 8, 136)     0           pool3_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormaliz (None, 8, 8, 136)     544         pool3_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation) (None, 8, 8, 136)     0           conv4_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)     (None, 8, 8, 64)      8704        conv4_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenate (None, 8, 8, 152)     0           pool3_pool[0][0]                 \n",
      "                                                                   conv4_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormaliz (None, 8, 8, 152)     608         conv4_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation) (None, 8, 8, 152)     0           conv4_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)     (None, 8, 8, 64)      9728        conv4_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenate (None, 8, 8, 168)     0           conv4_block1_concat[0][0]        \n",
      "                                                                   conv4_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormaliz (None, 8, 8, 168)     672         conv4_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation) (None, 8, 8, 168)     0           conv4_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)     (None, 8, 8, 64)      10752       conv4_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenate (None, 8, 8, 184)     0           conv4_block2_concat[0][0]        \n",
      "                                                                   conv4_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormaliz (None, 8, 8, 184)     736         conv4_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation) (None, 8, 8, 184)     0           conv4_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)     (None, 8, 8, 64)      11776       conv4_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenate (None, 8, 8, 200)     0           conv4_block3_concat[0][0]        \n",
      "                                                                   conv4_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormaliz (None, 8, 8, 200)     800         conv4_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation) (None, 8, 8, 200)     0           conv4_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)     (None, 8, 8, 64)      12800       conv4_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenate (None, 8, 8, 216)     0           conv4_block4_concat[0][0]        \n",
      "                                                                   conv4_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormaliz (None, 8, 8, 216)     864         conv4_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation) (None, 8, 8, 216)     0           conv4_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)     (None, 8, 8, 64)      13824       conv4_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenate (None, 8, 8, 232)     0           conv4_block5_concat[0][0]        \n",
      "                                                                   conv4_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormaliz (None, 8, 8, 232)     928         conv4_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation) (None, 8, 8, 232)     0           conv4_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)     (None, 8, 8, 64)      14848       conv4_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenate (None, 8, 8, 248)     0           conv4_block6_concat[0][0]        \n",
      "                                                                   conv4_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormaliz (None, 8, 8, 248)     992         conv4_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation) (None, 8, 8, 248)     0           conv4_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)     (None, 8, 8, 64)      15872       conv4_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenate (None, 8, 8, 264)     0           conv4_block7_concat[0][0]        \n",
      "                                                                   conv4_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormaliz (None, 8, 8, 264)     1056        conv4_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation) (None, 8, 8, 264)     0           conv4_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)     (None, 8, 8, 64)      16896       conv4_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormaliz (None, 8, 8, 64)      256         conv4_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation) (None, 8, 8, 64)      0           conv4_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)     (None, 8, 8, 16)      9216        conv4_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenate (None, 8, 8, 280)     0           conv4_block8_concat[0][0]        \n",
      "                                                                   conv4_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormali (None, 8, 8, 280)     1120        conv4_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activation (None, 8, 8, 280)     0           conv4_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)    (None, 8, 8, 64)      17920       conv4_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activation (None, 8, 8, 64)      0           conv4_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatenat (None, 8, 8, 296)     0           conv4_block9_concat[0][0]        \n",
      "                                                                   conv4_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormali (None, 8, 8, 296)     1184        conv4_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activation (None, 8, 8, 296)     0           conv4_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)    (None, 8, 8, 64)      18944       conv4_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activation (None, 8, 8, 64)      0           conv4_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatenat (None, 8, 8, 312)     0           conv4_block10_concat[0][0]       \n",
      "                                                                   conv4_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormali (None, 8, 8, 312)     1248        conv4_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activation (None, 8, 8, 312)     0           conv4_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)    (None, 8, 8, 64)      19968       conv4_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activation (None, 8, 8, 64)      0           conv4_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatenat (None, 8, 8, 328)     0           conv4_block11_concat[0][0]       \n",
      "                                                                   conv4_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormali (None, 8, 8, 328)     1312        conv4_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activation (None, 8, 8, 328)     0           conv4_block13_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)    (None, 8, 8, 64)      20992       conv4_block13_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block13_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activation (None, 8, 8, 64)      0           conv4_block13_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block13_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatenat (None, 8, 8, 344)     0           conv4_block12_concat[0][0]       \n",
      "                                                                   conv4_block13_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormali (None, 8, 8, 344)     1376        conv4_block13_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activation (None, 8, 8, 344)     0           conv4_block14_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)    (None, 8, 8, 64)      22016       conv4_block14_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block14_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activation (None, 8, 8, 64)      0           conv4_block14_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block14_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatenat (None, 8, 8, 360)     0           conv4_block13_concat[0][0]       \n",
      "                                                                   conv4_block14_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormali (None, 8, 8, 360)     1440        conv4_block14_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activation (None, 8, 8, 360)     0           conv4_block15_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)    (None, 8, 8, 64)      23040       conv4_block15_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block15_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activation (None, 8, 8, 64)      0           conv4_block15_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block15_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatenat (None, 8, 8, 376)     0           conv4_block14_concat[0][0]       \n",
      "                                                                   conv4_block15_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormali (None, 8, 8, 376)     1504        conv4_block15_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activation (None, 8, 8, 376)     0           conv4_block16_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)    (None, 8, 8, 64)      24064       conv4_block16_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block16_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activation (None, 8, 8, 64)      0           conv4_block16_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block16_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatenat (None, 8, 8, 392)     0           conv4_block15_concat[0][0]       \n",
      "                                                                   conv4_block16_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormali (None, 8, 8, 392)     1568        conv4_block16_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activation (None, 8, 8, 392)     0           conv4_block17_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)    (None, 8, 8, 64)      25088       conv4_block17_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block17_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activation (None, 8, 8, 64)      0           conv4_block17_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block17_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatenat (None, 8, 8, 408)     0           conv4_block16_concat[0][0]       \n",
      "                                                                   conv4_block17_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormali (None, 8, 8, 408)     1632        conv4_block17_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activation (None, 8, 8, 408)     0           conv4_block18_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)    (None, 8, 8, 64)      26112       conv4_block18_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block18_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activation (None, 8, 8, 64)      0           conv4_block18_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block18_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatenat (None, 8, 8, 424)     0           conv4_block17_concat[0][0]       \n",
      "                                                                   conv4_block18_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormali (None, 8, 8, 424)     1696        conv4_block18_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activation (None, 8, 8, 424)     0           conv4_block19_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)    (None, 8, 8, 64)      27136       conv4_block19_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block19_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activation (None, 8, 8, 64)      0           conv4_block19_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block19_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatenat (None, 8, 8, 440)     0           conv4_block18_concat[0][0]       \n",
      "                                                                   conv4_block19_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormali (None, 8, 8, 440)     1760        conv4_block19_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activation (None, 8, 8, 440)     0           conv4_block20_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)    (None, 8, 8, 64)      28160       conv4_block20_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block20_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activation (None, 8, 8, 64)      0           conv4_block20_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block20_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatenat (None, 8, 8, 456)     0           conv4_block19_concat[0][0]       \n",
      "                                                                   conv4_block20_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormali (None, 8, 8, 456)     1824        conv4_block20_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activation (None, 8, 8, 456)     0           conv4_block21_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)    (None, 8, 8, 64)      29184       conv4_block21_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block21_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activation (None, 8, 8, 64)      0           conv4_block21_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block21_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatenat (None, 8, 8, 472)     0           conv4_block20_concat[0][0]       \n",
      "                                                                   conv4_block21_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormali (None, 8, 8, 472)     1888        conv4_block21_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activation (None, 8, 8, 472)     0           conv4_block22_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)    (None, 8, 8, 64)      30208       conv4_block22_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block22_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activation (None, 8, 8, 64)      0           conv4_block22_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block22_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatenat (None, 8, 8, 488)     0           conv4_block21_concat[0][0]       \n",
      "                                                                   conv4_block22_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormali (None, 8, 8, 488)     1952        conv4_block22_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activation (None, 8, 8, 488)     0           conv4_block23_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)    (None, 8, 8, 64)      31232       conv4_block23_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block23_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activation (None, 8, 8, 64)      0           conv4_block23_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block23_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatenat (None, 8, 8, 504)     0           conv4_block22_concat[0][0]       \n",
      "                                                                   conv4_block23_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormali (None, 8, 8, 504)     2016        conv4_block23_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activation (None, 8, 8, 504)     0           conv4_block24_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)    (None, 8, 8, 64)      32256       conv4_block24_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormali (None, 8, 8, 64)      256         conv4_block24_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activation (None, 8, 8, 64)      0           conv4_block24_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)    (None, 8, 8, 16)      9216        conv4_block24_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatenat (None, 8, 8, 520)     0           conv4_block23_concat[0][0]       \n",
      "                                                                   conv4_block24_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)    (None, 8, 8, 520)     2080        conv4_block24_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "pool4_relu (Activation)          (None, 8, 8, 520)     0           pool4_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)              (None, 8, 8, 260)     135200      pool4_relu[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)    (None, 4, 4, 260)     0           pool4_conv[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormaliz (None, 4, 4, 260)     1040        pool4_pool[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation) (None, 4, 4, 260)     0           conv5_block1_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)     (None, 4, 4, 64)      16640       conv5_block1_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block1_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block1_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block1_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenate (None, 4, 4, 276)     0           pool4_pool[0][0]                 \n",
      "                                                                   conv5_block1_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormaliz (None, 4, 4, 276)     1104        conv5_block1_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation) (None, 4, 4, 276)     0           conv5_block2_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)     (None, 4, 4, 64)      17664       conv5_block2_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block2_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block2_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block2_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenate (None, 4, 4, 292)     0           conv5_block1_concat[0][0]        \n",
      "                                                                   conv5_block2_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormaliz (None, 4, 4, 292)     1168        conv5_block2_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation) (None, 4, 4, 292)     0           conv5_block3_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)     (None, 4, 4, 64)      18688       conv5_block3_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block3_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block3_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block3_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenate (None, 4, 4, 308)     0           conv5_block2_concat[0][0]        \n",
      "                                                                   conv5_block3_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormaliz (None, 4, 4, 308)     1232        conv5_block3_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation) (None, 4, 4, 308)     0           conv5_block4_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)     (None, 4, 4, 64)      19712       conv5_block4_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block4_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block4_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block4_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenate (None, 4, 4, 324)     0           conv5_block3_concat[0][0]        \n",
      "                                                                   conv5_block4_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormaliz (None, 4, 4, 324)     1296        conv5_block4_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation) (None, 4, 4, 324)     0           conv5_block5_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)     (None, 4, 4, 64)      20736       conv5_block5_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block5_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block5_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block5_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenate (None, 4, 4, 340)     0           conv5_block4_concat[0][0]        \n",
      "                                                                   conv5_block5_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormaliz (None, 4, 4, 340)     1360        conv5_block5_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation) (None, 4, 4, 340)     0           conv5_block6_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)     (None, 4, 4, 64)      21760       conv5_block6_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block6_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block6_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block6_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenate (None, 4, 4, 356)     0           conv5_block5_concat[0][0]        \n",
      "                                                                   conv5_block6_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormaliz (None, 4, 4, 356)     1424        conv5_block6_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation) (None, 4, 4, 356)     0           conv5_block7_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)     (None, 4, 4, 64)      22784       conv5_block7_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block7_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block7_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block7_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenate (None, 4, 4, 372)     0           conv5_block6_concat[0][0]        \n",
      "                                                                   conv5_block7_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormaliz (None, 4, 4, 372)     1488        conv5_block7_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation) (None, 4, 4, 372)     0           conv5_block8_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)     (None, 4, 4, 64)      23808       conv5_block8_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block8_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block8_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block8_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenate (None, 4, 4, 388)     0           conv5_block7_concat[0][0]        \n",
      "                                                                   conv5_block8_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormaliz (None, 4, 4, 388)     1552        conv5_block8_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation) (None, 4, 4, 388)     0           conv5_block9_0_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)     (None, 4, 4, 64)      24832       conv5_block9_0_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormaliz (None, 4, 4, 64)      256         conv5_block9_1_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation) (None, 4, 4, 64)      0           conv5_block9_1_bn[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)     (None, 4, 4, 16)      9216        conv5_block9_1_relu[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenate (None, 4, 4, 404)     0           conv5_block8_concat[0][0]        \n",
      "                                                                   conv5_block9_2_conv[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormali (None, 4, 4, 404)     1616        conv5_block9_concat[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activation (None, 4, 4, 404)     0           conv5_block10_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)    (None, 4, 4, 64)      25856       conv5_block10_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block10_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activation (None, 4, 4, 64)      0           conv5_block10_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block10_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatenat (None, 4, 4, 420)     0           conv5_block9_concat[0][0]        \n",
      "                                                                   conv5_block10_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormali (None, 4, 4, 420)     1680        conv5_block10_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activation (None, 4, 4, 420)     0           conv5_block11_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)    (None, 4, 4, 64)      26880       conv5_block11_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block11_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activation (None, 4, 4, 64)      0           conv5_block11_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block11_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatenat (None, 4, 4, 436)     0           conv5_block10_concat[0][0]       \n",
      "                                                                   conv5_block11_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormali (None, 4, 4, 436)     1744        conv5_block11_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activation (None, 4, 4, 436)     0           conv5_block12_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)    (None, 4, 4, 64)      27904       conv5_block12_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block12_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activation (None, 4, 4, 64)      0           conv5_block12_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block12_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatenat (None, 4, 4, 452)     0           conv5_block11_concat[0][0]       \n",
      "                                                                   conv5_block12_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormali (None, 4, 4, 452)     1808        conv5_block12_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activation (None, 4, 4, 452)     0           conv5_block13_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)    (None, 4, 4, 64)      28928       conv5_block13_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block13_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activation (None, 4, 4, 64)      0           conv5_block13_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block13_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatenat (None, 4, 4, 468)     0           conv5_block12_concat[0][0]       \n",
      "                                                                   conv5_block13_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormali (None, 4, 4, 468)     1872        conv5_block13_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activation (None, 4, 4, 468)     0           conv5_block14_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)    (None, 4, 4, 64)      29952       conv5_block14_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block14_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activation (None, 4, 4, 64)      0           conv5_block14_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block14_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatenat (None, 4, 4, 484)     0           conv5_block13_concat[0][0]       \n",
      "                                                                   conv5_block14_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormali (None, 4, 4, 484)     1936        conv5_block14_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activation (None, 4, 4, 484)     0           conv5_block15_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)    (None, 4, 4, 64)      30976       conv5_block15_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block15_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activation (None, 4, 4, 64)      0           conv5_block15_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block15_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatenat (None, 4, 4, 500)     0           conv5_block14_concat[0][0]       \n",
      "                                                                   conv5_block15_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormali (None, 4, 4, 500)     2000        conv5_block15_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activation (None, 4, 4, 500)     0           conv5_block16_0_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)    (None, 4, 4, 64)      32000       conv5_block16_0_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormali (None, 4, 4, 64)      256         conv5_block16_1_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activation (None, 4, 4, 64)      0           conv5_block16_1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)    (None, 4, 4, 16)      9216        conv5_block16_1_relu[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatenat (None, 4, 4, 516)     0           conv5_block15_concat[0][0]       \n",
      "                                                                   conv5_block16_2_conv[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "bn (BatchNormalization)          (None, 4, 4, 516)     2064        conv5_block16_concat[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "relu (Activation)                (None, 4, 4, 516)     0           bn[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D (None, 516)           0           relu[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "fc (Dense)                       (None, 171)           88407       avg_pool[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1,945,831\n",
      "Trainable params: 1,902,543\n",
      "Non-trainable params: 43,288\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"av...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "img_model = DenseNet(blocks = [6, 12, 24, 16], \n",
    "                                cat_max = 171,\n",
    "                                weight_decay = 1e-4, \n",
    "                                kernel_initializer = 'glorot_normal',\n",
    "                                reduction = 0.5, \n",
    "                                init_filters = 64, \n",
    "                                growth_rate = 16).model\n",
    "img_model.load_weights(path + 'model_sub/6_12_24_16_ini64_growth16_02962/model_0_2018_09_13_08_23_48.h5')\n",
    "img_model_flat = Model(input = img_model.input, output = img_model.get_layer(name = 'avg_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = setB_test_data\n",
    "# # test_img = extract_array_from_series(test_data['img'])\n",
    "# # test_img = vgg16.preprocess_input(test_img)\n",
    "# # test_img_feature_map = img_model_flat.predict(test_img, verbose = 1)\n",
    "\n",
    "# with open(path + '/model_sub/6_12_24_16_ini64_growth32_inistride1_augdata_05010/flat_test_re_2018_09_22_19_24_38.pickle', 'rb') as handle:\n",
    "#     test_img_feature_map = pickle.load(handle)\n",
    "train_id = train_data['class_id'].unique()\n",
    "test_img_feature_map = extract_array_from_series(test_data['target'])\n",
    "# class_id_emb_attr.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_partial_model = Model(inputs = zs_model.inputs[2:], outputs = zs_model.outputs[0])\n",
    "test_class_id_emb_attr = class_id_emb_attr #[~class_id_emb_attr['class_id'].isin(train_id)]\n",
    "# pred_nearest_class_id = find_nearest_class(test_class_id_emb_attr, zs_partial_model, test_data, test_img_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_05011 = models_eval(models = zs_model_list, eval_df = test_data, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)], \\\n",
    "            img_feature_map = test_img_feature_map)\n",
    "preds_05011 = np.asarray(preds_05011).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ed5117811f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_05077\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "preds_05077.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_102\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_102\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_108\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_108\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_114\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_114\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_120\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_120\" during training.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Output \"dense_126\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_126\" during training.\n"
     ]
    }
   ],
   "source": [
    "with open(path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/flat_test_re_2018_09_24_03_07_15.pickle', 'rb') as handle:\n",
    "    flat_test_re = pickle.load(handle)\n",
    "zs_model_05077_list = []\n",
    "for i in range(5):\n",
    "    zs_model = create_dnn(kernel_initializer = 'he_normal', img_flat_len = 1032)\n",
    "    zs_model_name = path + '/model_sub/6_12_24_16_ini128_growth32_inistride1_augdata_05077/zs_model_' + str(i) +'_2018_09_25_01_01_31.txt'\n",
    "    zs_model.load_weights(zs_model_name)\n",
    "    zs_model_05077_list.append((zs_model, 'DEM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-086b73470e3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds_05077\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzs_model_05077_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mcand_class_id_emb_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_id_emb_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mclass_id_emb_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mimg_feature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_test_re\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds_05011\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_05077\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "preds_05077 = models_eval(models = zs_model_05077_list, eval_df = test_data, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)], \\\n",
    "            img_feature_map = flat_test_re)\n",
    "preds_05011 = np.asarray(preds_05011).T\n",
    "preds = np.c_[preds_05011, preds_05077]\n",
    "print (preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_preds = []\n",
    "for single_img_vote in preds:\n",
    "    uniq_val, counts = np.unique(single_img_vote, return_counts = True)\n",
    "    vote_preds.append(uniq_val[np.argmax(counts)])\n",
    "vote_preds = np.asarray(vote_preds)\n",
    "print (vote_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ZJL272' 'ZJL224' 'ZJL242' 'ZJL243' 'ZJL272']\n",
      " ['ZJL243' 'ZJL288' 'ZJL239' 'ZJL243' 'ZJL239']\n",
      " ['ZJL255' 'ZJL255' 'ZJL255' 'ZJL255' 'ZJL253']\n",
      " ...\n",
      " ['ZJL286' 'ZJL259' 'ZJL249' 'ZJL259' 'ZJL287']\n",
      " ['ZJL270' 'ZJL253' 'ZJL253' 'ZJL253' 'ZJL253']\n",
      " ['ZJL270' 'ZJL288' 'ZJL288' 'ZJL288' 'ZJL253']]\n",
      "['ZJL272' 'ZJL239' 'ZJL255' ... 'ZJL259' 'ZJL253' 'ZJL288']\n"
     ]
    }
   ],
   "source": [
    "pred_nearest_class_id = multi_models_vote(models = zs_model_list, eval_df = test_data, \\\n",
    "            cand_class_id_emb_attr = class_id_emb_attr[~class_id_emb_attr['class_id'].isin(train_id)], \\\n",
    "            img_feature_map = test_img_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_label = time.strftime('_%Y_%m_%d_%H_%M_%S', time.gmtime())\n",
    "sub_name = path + '/model_sub/sub' + time_label + '.txt'\n",
    "sub = pd.DataFrame(pred_nearest_class_id, index = test_data['img_id'])\n",
    "sub.to_csv(sub_name, header = False, sep = '\\t')\n",
    "# zs_model.save(path + 'zs_model' + time_label + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.444444444444445"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "152 * 200 / 3600"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
